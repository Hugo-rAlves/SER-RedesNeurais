{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>./AudioWAV/1004_IWL_DIS_XX.wav</td>\n",
       "      <td>disgust.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>./AudioWAV/1001_IOM_SAD_XX.wav</td>\n",
       "      <td>sad.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>./AudioWAV/1006_IEO_HAP_HI.wav</td>\n",
       "      <td>happy.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>./AudioWAV/1012_IWL_ANG_XX.wav</td>\n",
       "      <td>angry.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5354</th>\n",
       "      <td>./AudioWAV/1066_IWL_HAP_XX.wav</td>\n",
       "      <td>happy.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              speech        label\n",
       "286   ./AudioWAV/1004_IWL_DIS_XX.wav  disgust.wav\n",
       "27    ./AudioWAV/1001_IOM_SAD_XX.wav      sad.wav\n",
       "424   ./AudioWAV/1006_IEO_HAP_HI.wav    happy.wav\n",
       "929   ./AudioWAV/1012_IWL_ANG_XX.wav    angry.wav\n",
       "5354  ./AudioWAV/1066_IWL_HAP_XX.wav    happy.wav"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths=[]\n",
    "labels=[]\n",
    "for filename in os.listdir('./AudioWAV'):\n",
    "    \n",
    "    paths.append('./AudioWAV/' + filename)\n",
    "    file = filename.split('.')[0]\n",
    "   \n",
    "    label = file.split('_')[2]\n",
    "    if label == 'ANG':\n",
    "        labels.append('angry.wav')\n",
    "    elif label == 'DIS':\n",
    "        labels.append('disgust.wav')\n",
    "    elif label == 'FEA':\n",
    "        labels.append('fear.wav')\n",
    "    elif label == 'HAP':\n",
    "        labels.append('happy.wav')\n",
    "    elif label == 'NEU':\n",
    "        labels.append('neutral.wav')\n",
    "    elif label == 'SAD':\n",
    "        labels.append('sad.wav')\n",
    "        \n",
    "\n",
    "df_cremad = pd.DataFrame({'speech':paths,'label':labels})\n",
    "df_cremad.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFCC(filename):\n",
    "    y, sr = librosa.load(filename,duration=3,offset=0.5)\n",
    "    return np.mean(librosa.feature.mfcc(y=y,sr=sr,n_mfcc=40).T,axis=0)\n",
    "\n",
    "mfcc_cremad = df_cremad['speech'].apply(lambda x:MFCC(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7442, 40, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X =[x for x in mfcc_cremad]\n",
    "X =np.array(X)\n",
    "X.shape\n",
    "X =np.expand_dims(X,-1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe=OneHotEncoder()\n",
    "y = ohe.fit_transform(df_cremad[['label']] )\n",
    "y = y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7442, 40, 1), (7442, 6))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry.wav', 'disgust.wav', 'fear.wav', 'happy.wav', 'neutral.wav',\n",
       "       'sad.wav'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cremad['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Definindo os modelos\n",
    "\n",
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class LSTMAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
    "        out = torch.sum(attn_weights * out, dim=1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
    "        self.fc_input_size = 32 * 1 * 1\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, self.fc_input_size)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNNAttention(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNNAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
    "        self.attention = nn.Linear(32, 1)\n",
    "        self.fc = nn.Linear(32, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        attn_weights = self.softmax(self.attention(x.permute(0, 2, 1))).squeeze(-1)\n",
    "        attn_weights = attn_weights.unsqueeze(-1)\n",
    "        x = torch.sum(attn_weights * x, dim=2)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "# Construindo e treinando os modelos\n",
    "\n",
    "input_size = X.shape[1:]\n",
    "num_classes = y.shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Convertendo os dados para tensores PyTorch\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "# Definindo o tamanho do lote\n",
    "batch_size = 32\n",
    "\n",
    "# Criando conjuntos de dados PyTorch\n",
    "dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Definindo tensor para o LSTM\n",
    "X_tensorLSTM = X_tensor.permute(0, 2, 1)\n",
    "\n",
    "# Criando conjuntos de dados PyTorch para LSTM\n",
    "datasetLSTM = torch.utils.data.TensorDataset(X_tensorLSTM, y_tensor)\n",
    "train_sizeLSTM = int(0.8 * len(datasetLSTM))\n",
    "test_sizeLSTM = len(datasetLSTM) - train_sizeLSTM\n",
    "train_datasetLSTM, test_datasetLSTM = torch.utils.data.random_split(datasetLSTM, [train_sizeLSTM, test_sizeLSTM])\n",
    "\n",
    "# DataLoader para o LSTM\n",
    "train_loaderLSTM = DataLoader(train_datasetLSTM, batch_size=batch_size, shuffle=True)\n",
    "test_loaderLSTM = DataLoader(test_datasetLSTM, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Convertendo os dados para tensores PyTorch do CNN\n",
    "X_tensorCNN = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "\n",
    "# Criando conjuntos de dados PyTorch do CNN\n",
    "datasetCNN = torch.utils.data.TensorDataset(X_tensorCNN, y_tensor)\n",
    "train_sizeCNN = int(0.8 * len(datasetCNN))\n",
    "test_sizeCNN = len(datasetCNN) - train_sizeCNN\n",
    "train_datasetCNN, test_datasetCNN = torch.utils.data.random_split(datasetCNN, [train_sizeCNN, test_sizeCNN])\n",
    "\n",
    "# DataLoader para o CNN\n",
    "train_loaderCNN = DataLoader(train_datasetCNN, batch_size=batch_size, shuffle=True)\n",
    "test_loaderCNN = DataLoader(test_datasetCNN, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Função para treinamento\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs=500):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            #print(outputs.shape)\n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        accuracy = correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 11.7832, Accuracy: 0.1745\n",
      "Epoch [2/500], Loss: 10.1525, Accuracy: 0.1629\n",
      "Epoch [3/500], Loss: 8.9746, Accuracy: 0.1643\n",
      "Epoch [4/500], Loss: 8.0096, Accuracy: 0.1698\n",
      "Epoch [5/500], Loss: 7.3057, Accuracy: 0.1685\n",
      "Epoch [6/500], Loss: 6.9775, Accuracy: 0.1589\n",
      "Epoch [7/500], Loss: 6.3433, Accuracy: 0.1735\n",
      "Epoch [8/500], Loss: 5.8596, Accuracy: 0.1693\n",
      "Epoch [9/500], Loss: 5.4722, Accuracy: 0.1653\n",
      "Epoch [10/500], Loss: 5.1189, Accuracy: 0.1571\n",
      "Epoch [11/500], Loss: 4.7257, Accuracy: 0.1658\n",
      "Epoch [12/500], Loss: 4.4321, Accuracy: 0.1592\n",
      "Epoch [13/500], Loss: 3.9661, Accuracy: 0.1676\n",
      "Epoch [14/500], Loss: 3.7935, Accuracy: 0.1724\n",
      "Epoch [15/500], Loss: 3.5578, Accuracy: 0.1668\n",
      "Epoch [16/500], Loss: 3.3324, Accuracy: 0.1710\n",
      "Epoch [17/500], Loss: 3.1212, Accuracy: 0.1666\n",
      "Epoch [18/500], Loss: 2.9182, Accuracy: 0.1725\n",
      "Epoch [19/500], Loss: 2.8233, Accuracy: 0.1710\n",
      "Epoch [20/500], Loss: 2.7642, Accuracy: 0.1609\n",
      "Epoch [21/500], Loss: 2.5490, Accuracy: 0.1740\n",
      "Epoch [22/500], Loss: 2.4761, Accuracy: 0.1819\n",
      "Epoch [23/500], Loss: 2.4504, Accuracy: 0.1680\n",
      "Epoch [24/500], Loss: 2.3499, Accuracy: 0.1730\n",
      "Epoch [25/500], Loss: 2.2540, Accuracy: 0.1710\n",
      "Epoch [26/500], Loss: 2.2160, Accuracy: 0.1707\n",
      "Epoch [27/500], Loss: 2.1587, Accuracy: 0.1715\n",
      "Epoch [28/500], Loss: 2.1061, Accuracy: 0.1671\n",
      "Epoch [29/500], Loss: 2.0924, Accuracy: 0.1594\n",
      "Epoch [30/500], Loss: 2.0662, Accuracy: 0.1629\n",
      "Epoch [31/500], Loss: 2.0297, Accuracy: 0.1661\n",
      "Epoch [32/500], Loss: 2.0137, Accuracy: 0.1653\n",
      "Epoch [33/500], Loss: 1.9973, Accuracy: 0.1599\n",
      "Epoch [34/500], Loss: 1.9583, Accuracy: 0.1661\n",
      "Epoch [35/500], Loss: 1.9502, Accuracy: 0.1611\n",
      "Epoch [36/500], Loss: 1.9196, Accuracy: 0.1715\n",
      "Epoch [37/500], Loss: 1.9213, Accuracy: 0.1609\n",
      "Epoch [38/500], Loss: 1.9273, Accuracy: 0.1666\n",
      "Epoch [39/500], Loss: 1.8994, Accuracy: 0.1621\n",
      "Epoch [40/500], Loss: 1.8966, Accuracy: 0.1680\n",
      "Epoch [41/500], Loss: 1.9020, Accuracy: 0.1562\n",
      "Epoch [42/500], Loss: 1.8814, Accuracy: 0.1618\n",
      "Epoch [43/500], Loss: 1.8514, Accuracy: 0.1666\n",
      "Epoch [44/500], Loss: 1.8686, Accuracy: 0.1680\n",
      "Epoch [45/500], Loss: 1.8528, Accuracy: 0.1685\n",
      "Epoch [46/500], Loss: 1.8484, Accuracy: 0.1682\n",
      "Epoch [47/500], Loss: 1.8551, Accuracy: 0.1633\n",
      "Epoch [48/500], Loss: 1.8309, Accuracy: 0.1604\n",
      "Epoch [49/500], Loss: 1.8419, Accuracy: 0.1621\n",
      "Epoch [50/500], Loss: 1.8346, Accuracy: 0.1645\n",
      "Epoch [51/500], Loss: 1.8283, Accuracy: 0.1594\n",
      "Epoch [52/500], Loss: 1.8373, Accuracy: 0.1522\n",
      "Epoch [53/500], Loss: 1.8235, Accuracy: 0.1587\n",
      "Epoch [54/500], Loss: 1.8297, Accuracy: 0.1633\n",
      "Epoch [55/500], Loss: 1.8268, Accuracy: 0.1584\n",
      "Epoch [56/500], Loss: 1.8126, Accuracy: 0.1671\n",
      "Epoch [57/500], Loss: 1.8165, Accuracy: 0.1604\n",
      "Epoch [58/500], Loss: 1.8138, Accuracy: 0.1650\n",
      "Epoch [59/500], Loss: 1.8121, Accuracy: 0.1574\n",
      "Epoch [60/500], Loss: 1.8115, Accuracy: 0.1656\n",
      "Epoch [61/500], Loss: 1.8103, Accuracy: 0.1586\n",
      "Epoch [62/500], Loss: 1.8121, Accuracy: 0.1665\n",
      "Epoch [63/500], Loss: 1.8096, Accuracy: 0.1556\n",
      "Epoch [64/500], Loss: 1.8048, Accuracy: 0.1633\n",
      "Epoch [65/500], Loss: 1.8133, Accuracy: 0.1596\n",
      "Epoch [66/500], Loss: 1.8021, Accuracy: 0.1599\n",
      "Epoch [67/500], Loss: 1.8047, Accuracy: 0.1619\n",
      "Epoch [68/500], Loss: 1.8059, Accuracy: 0.1613\n",
      "Epoch [69/500], Loss: 1.7996, Accuracy: 0.1697\n",
      "Epoch [70/500], Loss: 1.8035, Accuracy: 0.1608\n",
      "Epoch [71/500], Loss: 1.8005, Accuracy: 0.1651\n",
      "Epoch [72/500], Loss: 1.8018, Accuracy: 0.1623\n",
      "Epoch [73/500], Loss: 1.8023, Accuracy: 0.1561\n",
      "Epoch [74/500], Loss: 1.8000, Accuracy: 0.1650\n",
      "Epoch [75/500], Loss: 1.7956, Accuracy: 0.1695\n",
      "Epoch [76/500], Loss: 1.7965, Accuracy: 0.1849\n",
      "Epoch [77/500], Loss: 1.7942, Accuracy: 0.1796\n",
      "Epoch [78/500], Loss: 1.7988, Accuracy: 0.1853\n",
      "Epoch [79/500], Loss: 1.7962, Accuracy: 0.1797\n",
      "Epoch [80/500], Loss: 1.7898, Accuracy: 0.1818\n",
      "Epoch [81/500], Loss: 1.7954, Accuracy: 0.1853\n",
      "Epoch [82/500], Loss: 1.7993, Accuracy: 0.1848\n",
      "Epoch [83/500], Loss: 1.7908, Accuracy: 0.1858\n",
      "Epoch [84/500], Loss: 1.7930, Accuracy: 0.1858\n",
      "Epoch [85/500], Loss: 1.7898, Accuracy: 0.1890\n",
      "Epoch [86/500], Loss: 1.7865, Accuracy: 0.1898\n",
      "Epoch [87/500], Loss: 1.7912, Accuracy: 0.1828\n",
      "Epoch [88/500], Loss: 1.7910, Accuracy: 0.1871\n",
      "Epoch [89/500], Loss: 1.7886, Accuracy: 0.1855\n",
      "Epoch [90/500], Loss: 1.7889, Accuracy: 0.1866\n",
      "Epoch [91/500], Loss: 1.7834, Accuracy: 0.1930\n",
      "Epoch [92/500], Loss: 1.7924, Accuracy: 0.1888\n",
      "Epoch [93/500], Loss: 1.7820, Accuracy: 0.1954\n",
      "Epoch [94/500], Loss: 1.7839, Accuracy: 0.1922\n",
      "Epoch [95/500], Loss: 1.7776, Accuracy: 0.1977\n",
      "Epoch [96/500], Loss: 1.7801, Accuracy: 0.2029\n",
      "Epoch [97/500], Loss: 1.7816, Accuracy: 0.1979\n",
      "Epoch [98/500], Loss: 1.7731, Accuracy: 0.2073\n",
      "Epoch [99/500], Loss: 1.7819, Accuracy: 0.2016\n",
      "Epoch [100/500], Loss: 1.7784, Accuracy: 0.2044\n",
      "Epoch [101/500], Loss: 1.7782, Accuracy: 0.2085\n",
      "Epoch [102/500], Loss: 1.7774, Accuracy: 0.2007\n",
      "Epoch [103/500], Loss: 1.7731, Accuracy: 0.2068\n",
      "Epoch [104/500], Loss: 1.7717, Accuracy: 0.2065\n",
      "Epoch [105/500], Loss: 1.7718, Accuracy: 0.2061\n",
      "Epoch [106/500], Loss: 1.7731, Accuracy: 0.2137\n",
      "Epoch [107/500], Loss: 1.7677, Accuracy: 0.2093\n",
      "Epoch [108/500], Loss: 1.7625, Accuracy: 0.2098\n",
      "Epoch [109/500], Loss: 1.7666, Accuracy: 0.2207\n",
      "Epoch [110/500], Loss: 1.7645, Accuracy: 0.2113\n",
      "Epoch [111/500], Loss: 1.7613, Accuracy: 0.2248\n",
      "Epoch [112/500], Loss: 1.7619, Accuracy: 0.2189\n",
      "Epoch [113/500], Loss: 1.7644, Accuracy: 0.2234\n",
      "Epoch [114/500], Loss: 1.7578, Accuracy: 0.2170\n",
      "Epoch [115/500], Loss: 1.7594, Accuracy: 0.2249\n",
      "Epoch [116/500], Loss: 1.7540, Accuracy: 0.2238\n",
      "Epoch [117/500], Loss: 1.7555, Accuracy: 0.2189\n",
      "Epoch [118/500], Loss: 1.7585, Accuracy: 0.2285\n",
      "Epoch [119/500], Loss: 1.7574, Accuracy: 0.2226\n",
      "Epoch [120/500], Loss: 1.7526, Accuracy: 0.2296\n",
      "Epoch [121/500], Loss: 1.7543, Accuracy: 0.2266\n",
      "Epoch [122/500], Loss: 1.7462, Accuracy: 0.2325\n",
      "Epoch [123/500], Loss: 1.7538, Accuracy: 0.2258\n",
      "Epoch [124/500], Loss: 1.7488, Accuracy: 0.2320\n",
      "Epoch [125/500], Loss: 1.7468, Accuracy: 0.2320\n",
      "Epoch [126/500], Loss: 1.7486, Accuracy: 0.2310\n",
      "Epoch [127/500], Loss: 1.7442, Accuracy: 0.2286\n",
      "Epoch [128/500], Loss: 1.7422, Accuracy: 0.2362\n",
      "Epoch [129/500], Loss: 1.7414, Accuracy: 0.2357\n",
      "Epoch [130/500], Loss: 1.7405, Accuracy: 0.2365\n",
      "Epoch [131/500], Loss: 1.7364, Accuracy: 0.2392\n",
      "Epoch [132/500], Loss: 1.7396, Accuracy: 0.2390\n",
      "Epoch [133/500], Loss: 1.7346, Accuracy: 0.2407\n",
      "Epoch [134/500], Loss: 1.7420, Accuracy: 0.2311\n",
      "Epoch [135/500], Loss: 1.7391, Accuracy: 0.2285\n",
      "Epoch [136/500], Loss: 1.7321, Accuracy: 0.2384\n",
      "Epoch [137/500], Loss: 1.7255, Accuracy: 0.2348\n",
      "Epoch [138/500], Loss: 1.7352, Accuracy: 0.2353\n",
      "Epoch [139/500], Loss: 1.7328, Accuracy: 0.2335\n",
      "Epoch [140/500], Loss: 1.7316, Accuracy: 0.2358\n",
      "Epoch [141/500], Loss: 1.7360, Accuracy: 0.2365\n",
      "Epoch [142/500], Loss: 1.7240, Accuracy: 0.2454\n",
      "Epoch [143/500], Loss: 1.7253, Accuracy: 0.2400\n",
      "Epoch [144/500], Loss: 1.7304, Accuracy: 0.2411\n",
      "Epoch [145/500], Loss: 1.7327, Accuracy: 0.2412\n",
      "Epoch [146/500], Loss: 1.7275, Accuracy: 0.2342\n",
      "Epoch [147/500], Loss: 1.7301, Accuracy: 0.2380\n",
      "Epoch [148/500], Loss: 1.7181, Accuracy: 0.2427\n",
      "Epoch [149/500], Loss: 1.7201, Accuracy: 0.2459\n",
      "Epoch [150/500], Loss: 1.7196, Accuracy: 0.2434\n",
      "Epoch [151/500], Loss: 1.7121, Accuracy: 0.2439\n",
      "Epoch [152/500], Loss: 1.7190, Accuracy: 0.2459\n",
      "Epoch [153/500], Loss: 1.7139, Accuracy: 0.2463\n",
      "Epoch [154/500], Loss: 1.7220, Accuracy: 0.2395\n",
      "Epoch [155/500], Loss: 1.7160, Accuracy: 0.2491\n",
      "Epoch [156/500], Loss: 1.7154, Accuracy: 0.2411\n",
      "Epoch [157/500], Loss: 1.7198, Accuracy: 0.2421\n",
      "Epoch [158/500], Loss: 1.7087, Accuracy: 0.2518\n",
      "Epoch [159/500], Loss: 1.7087, Accuracy: 0.2521\n",
      "Epoch [160/500], Loss: 1.7099, Accuracy: 0.2468\n",
      "Epoch [161/500], Loss: 1.7222, Accuracy: 0.2515\n",
      "Epoch [162/500], Loss: 1.7136, Accuracy: 0.2463\n",
      "Epoch [163/500], Loss: 1.7108, Accuracy: 0.2563\n",
      "Epoch [164/500], Loss: 1.7156, Accuracy: 0.2493\n",
      "Epoch [165/500], Loss: 1.7126, Accuracy: 0.2436\n",
      "Epoch [166/500], Loss: 1.7095, Accuracy: 0.2407\n",
      "Epoch [167/500], Loss: 1.7153, Accuracy: 0.2414\n",
      "Epoch [168/500], Loss: 1.7097, Accuracy: 0.2451\n",
      "Epoch [169/500], Loss: 1.7068, Accuracy: 0.2451\n",
      "Epoch [170/500], Loss: 1.6924, Accuracy: 0.2568\n",
      "Epoch [171/500], Loss: 1.7114, Accuracy: 0.2486\n",
      "Epoch [172/500], Loss: 1.7034, Accuracy: 0.2461\n",
      "Epoch [173/500], Loss: 1.6993, Accuracy: 0.2520\n",
      "Epoch [174/500], Loss: 1.7001, Accuracy: 0.2471\n",
      "Epoch [175/500], Loss: 1.7036, Accuracy: 0.2568\n",
      "Epoch [176/500], Loss: 1.7056, Accuracy: 0.2446\n",
      "Epoch [177/500], Loss: 1.6986, Accuracy: 0.2506\n",
      "Epoch [178/500], Loss: 1.6929, Accuracy: 0.2491\n",
      "Epoch [179/500], Loss: 1.6998, Accuracy: 0.2520\n",
      "Epoch [180/500], Loss: 1.6931, Accuracy: 0.2538\n",
      "Epoch [181/500], Loss: 1.6952, Accuracy: 0.2582\n",
      "Epoch [182/500], Loss: 1.6977, Accuracy: 0.2490\n",
      "Epoch [183/500], Loss: 1.7129, Accuracy: 0.2555\n",
      "Epoch [184/500], Loss: 1.6994, Accuracy: 0.2486\n",
      "Epoch [185/500], Loss: 1.7032, Accuracy: 0.2473\n",
      "Epoch [186/500], Loss: 1.6885, Accuracy: 0.2531\n",
      "Epoch [187/500], Loss: 1.6832, Accuracy: 0.2550\n",
      "Epoch [188/500], Loss: 1.6946, Accuracy: 0.2543\n",
      "Epoch [189/500], Loss: 1.6916, Accuracy: 0.2579\n",
      "Epoch [190/500], Loss: 1.6865, Accuracy: 0.2538\n",
      "Epoch [191/500], Loss: 1.6925, Accuracy: 0.2520\n",
      "Epoch [192/500], Loss: 1.6884, Accuracy: 0.2597\n",
      "Epoch [193/500], Loss: 1.6830, Accuracy: 0.2605\n",
      "Epoch [194/500], Loss: 1.6913, Accuracy: 0.2530\n",
      "Epoch [195/500], Loss: 1.6809, Accuracy: 0.2622\n",
      "Epoch [196/500], Loss: 1.6873, Accuracy: 0.2592\n",
      "Epoch [197/500], Loss: 1.6809, Accuracy: 0.2535\n",
      "Epoch [198/500], Loss: 1.6829, Accuracy: 0.2567\n",
      "Epoch [199/500], Loss: 1.6780, Accuracy: 0.2651\n",
      "Epoch [200/500], Loss: 1.6848, Accuracy: 0.2617\n",
      "Epoch [201/500], Loss: 1.6876, Accuracy: 0.2474\n",
      "Epoch [202/500], Loss: 1.6805, Accuracy: 0.2508\n",
      "Epoch [203/500], Loss: 1.6787, Accuracy: 0.2542\n",
      "Epoch [204/500], Loss: 1.6838, Accuracy: 0.2592\n",
      "Epoch [205/500], Loss: 1.6787, Accuracy: 0.2592\n",
      "Epoch [206/500], Loss: 1.6818, Accuracy: 0.2575\n",
      "Epoch [207/500], Loss: 1.6838, Accuracy: 0.2526\n",
      "Epoch [208/500], Loss: 1.6725, Accuracy: 0.2585\n",
      "Epoch [209/500], Loss: 1.6798, Accuracy: 0.2654\n",
      "Epoch [210/500], Loss: 1.6787, Accuracy: 0.2609\n",
      "Epoch [211/500], Loss: 1.6772, Accuracy: 0.2615\n",
      "Epoch [212/500], Loss: 1.6735, Accuracy: 0.2651\n",
      "Epoch [213/500], Loss: 1.6691, Accuracy: 0.2637\n",
      "Epoch [214/500], Loss: 1.6730, Accuracy: 0.2607\n",
      "Epoch [215/500], Loss: 1.6700, Accuracy: 0.2585\n",
      "Epoch [216/500], Loss: 1.6690, Accuracy: 0.2624\n",
      "Epoch [217/500], Loss: 1.6667, Accuracy: 0.2661\n",
      "Epoch [218/500], Loss: 1.6727, Accuracy: 0.2651\n",
      "Epoch [219/500], Loss: 1.6701, Accuracy: 0.2584\n",
      "Epoch [220/500], Loss: 1.6701, Accuracy: 0.2656\n",
      "Epoch [221/500], Loss: 1.6586, Accuracy: 0.2627\n",
      "Epoch [222/500], Loss: 1.6676, Accuracy: 0.2604\n",
      "Epoch [223/500], Loss: 1.6583, Accuracy: 0.2547\n",
      "Epoch [224/500], Loss: 1.6674, Accuracy: 0.2654\n",
      "Epoch [225/500], Loss: 1.6704, Accuracy: 0.2641\n",
      "Epoch [226/500], Loss: 1.6705, Accuracy: 0.2585\n",
      "Epoch [227/500], Loss: 1.6661, Accuracy: 0.2639\n",
      "Epoch [228/500], Loss: 1.6642, Accuracy: 0.2728\n",
      "Epoch [229/500], Loss: 1.6616, Accuracy: 0.2666\n",
      "Epoch [230/500], Loss: 1.6585, Accuracy: 0.2694\n",
      "Epoch [231/500], Loss: 1.6622, Accuracy: 0.2642\n",
      "Epoch [232/500], Loss: 1.6590, Accuracy: 0.2686\n",
      "Epoch [233/500], Loss: 1.6505, Accuracy: 0.2684\n",
      "Epoch [234/500], Loss: 1.6637, Accuracy: 0.2644\n",
      "Epoch [235/500], Loss: 1.6652, Accuracy: 0.2641\n",
      "Epoch [236/500], Loss: 1.6622, Accuracy: 0.2664\n",
      "Epoch [237/500], Loss: 1.6492, Accuracy: 0.2663\n",
      "Epoch [238/500], Loss: 1.6567, Accuracy: 0.2701\n",
      "Epoch [239/500], Loss: 1.6595, Accuracy: 0.2721\n",
      "Epoch [240/500], Loss: 1.6606, Accuracy: 0.2718\n",
      "Epoch [241/500], Loss: 1.6605, Accuracy: 0.2738\n",
      "Epoch [242/500], Loss: 1.6586, Accuracy: 0.2705\n",
      "Epoch [243/500], Loss: 1.6531, Accuracy: 0.2770\n",
      "Epoch [244/500], Loss: 1.6538, Accuracy: 0.2782\n",
      "Epoch [245/500], Loss: 1.6648, Accuracy: 0.2693\n",
      "Epoch [246/500], Loss: 1.6489, Accuracy: 0.2810\n",
      "Epoch [247/500], Loss: 1.6525, Accuracy: 0.2804\n",
      "Epoch [248/500], Loss: 1.6534, Accuracy: 0.2797\n",
      "Epoch [249/500], Loss: 1.6506, Accuracy: 0.2820\n",
      "Epoch [250/500], Loss: 1.6511, Accuracy: 0.2757\n",
      "Epoch [251/500], Loss: 1.6506, Accuracy: 0.2713\n",
      "Epoch [252/500], Loss: 1.6459, Accuracy: 0.2888\n",
      "Epoch [253/500], Loss: 1.6400, Accuracy: 0.2891\n",
      "Epoch [254/500], Loss: 1.6449, Accuracy: 0.2844\n",
      "Epoch [255/500], Loss: 1.6449, Accuracy: 0.2852\n",
      "Epoch [256/500], Loss: 1.6487, Accuracy: 0.2839\n",
      "Epoch [257/500], Loss: 1.6436, Accuracy: 0.2822\n",
      "Epoch [258/500], Loss: 1.6391, Accuracy: 0.2893\n",
      "Epoch [259/500], Loss: 1.6455, Accuracy: 0.2799\n",
      "Epoch [260/500], Loss: 1.6484, Accuracy: 0.2978\n",
      "Epoch [261/500], Loss: 1.6377, Accuracy: 0.2873\n",
      "Epoch [262/500], Loss: 1.6425, Accuracy: 0.2857\n",
      "Epoch [263/500], Loss: 1.6426, Accuracy: 0.2931\n",
      "Epoch [264/500], Loss: 1.6404, Accuracy: 0.2829\n",
      "Epoch [265/500], Loss: 1.6346, Accuracy: 0.2933\n",
      "Epoch [266/500], Loss: 1.6348, Accuracy: 0.2941\n",
      "Epoch [267/500], Loss: 1.6336, Accuracy: 0.2968\n",
      "Epoch [268/500], Loss: 1.6387, Accuracy: 0.2871\n",
      "Epoch [269/500], Loss: 1.6383, Accuracy: 0.2960\n",
      "Epoch [270/500], Loss: 1.6295, Accuracy: 0.2948\n",
      "Epoch [271/500], Loss: 1.6305, Accuracy: 0.2904\n",
      "Epoch [272/500], Loss: 1.6263, Accuracy: 0.2958\n",
      "Epoch [273/500], Loss: 1.6343, Accuracy: 0.2988\n",
      "Epoch [274/500], Loss: 1.6280, Accuracy: 0.2972\n",
      "Epoch [275/500], Loss: 1.6227, Accuracy: 0.2962\n",
      "Epoch [276/500], Loss: 1.6342, Accuracy: 0.2973\n",
      "Epoch [277/500], Loss: 1.6336, Accuracy: 0.2913\n",
      "Epoch [278/500], Loss: 1.6383, Accuracy: 0.2940\n",
      "Epoch [279/500], Loss: 1.6317, Accuracy: 0.3002\n",
      "Epoch [280/500], Loss: 1.6273, Accuracy: 0.3040\n",
      "Epoch [281/500], Loss: 1.6212, Accuracy: 0.2998\n",
      "Epoch [282/500], Loss: 1.6272, Accuracy: 0.2967\n",
      "Epoch [283/500], Loss: 1.6293, Accuracy: 0.3057\n",
      "Epoch [284/500], Loss: 1.6243, Accuracy: 0.2973\n",
      "Epoch [285/500], Loss: 1.6252, Accuracy: 0.3039\n",
      "Epoch [286/500], Loss: 1.6229, Accuracy: 0.2977\n",
      "Epoch [287/500], Loss: 1.6231, Accuracy: 0.3034\n",
      "Epoch [288/500], Loss: 1.6175, Accuracy: 0.2948\n",
      "Epoch [289/500], Loss: 1.6310, Accuracy: 0.2948\n",
      "Epoch [290/500], Loss: 1.6267, Accuracy: 0.2977\n",
      "Epoch [291/500], Loss: 1.6247, Accuracy: 0.2948\n",
      "Epoch [292/500], Loss: 1.6186, Accuracy: 0.3066\n",
      "Epoch [293/500], Loss: 1.6209, Accuracy: 0.3069\n",
      "Epoch [294/500], Loss: 1.6224, Accuracy: 0.3027\n",
      "Epoch [295/500], Loss: 1.6203, Accuracy: 0.3128\n",
      "Epoch [296/500], Loss: 1.6248, Accuracy: 0.3091\n",
      "Epoch [297/500], Loss: 1.6119, Accuracy: 0.3084\n",
      "Epoch [298/500], Loss: 1.6235, Accuracy: 0.3074\n",
      "Epoch [299/500], Loss: 1.6120, Accuracy: 0.2993\n",
      "Epoch [300/500], Loss: 1.6127, Accuracy: 0.3022\n",
      "Epoch [301/500], Loss: 1.6132, Accuracy: 0.3180\n",
      "Epoch [302/500], Loss: 1.6095, Accuracy: 0.3096\n",
      "Epoch [303/500], Loss: 1.6180, Accuracy: 0.3077\n",
      "Epoch [304/500], Loss: 1.6061, Accuracy: 0.3106\n",
      "Epoch [305/500], Loss: 1.6107, Accuracy: 0.3153\n",
      "Epoch [306/500], Loss: 1.6104, Accuracy: 0.3140\n",
      "Epoch [307/500], Loss: 1.6098, Accuracy: 0.3143\n",
      "Epoch [308/500], Loss: 1.6153, Accuracy: 0.3168\n",
      "Epoch [309/500], Loss: 1.6051, Accuracy: 0.3178\n",
      "Epoch [310/500], Loss: 1.6074, Accuracy: 0.3197\n",
      "Epoch [311/500], Loss: 1.6095, Accuracy: 0.3119\n",
      "Epoch [312/500], Loss: 1.6055, Accuracy: 0.3222\n",
      "Epoch [313/500], Loss: 1.6096, Accuracy: 0.3113\n",
      "Epoch [314/500], Loss: 1.6069, Accuracy: 0.3141\n",
      "Epoch [315/500], Loss: 1.6087, Accuracy: 0.3172\n",
      "Epoch [316/500], Loss: 1.6066, Accuracy: 0.3210\n",
      "Epoch [317/500], Loss: 1.5996, Accuracy: 0.3153\n",
      "Epoch [318/500], Loss: 1.6117, Accuracy: 0.3165\n",
      "Epoch [319/500], Loss: 1.6119, Accuracy: 0.3173\n",
      "Epoch [320/500], Loss: 1.6113, Accuracy: 0.3183\n",
      "Epoch [321/500], Loss: 1.6029, Accuracy: 0.3197\n",
      "Epoch [322/500], Loss: 1.6062, Accuracy: 0.3229\n",
      "Epoch [323/500], Loss: 1.5972, Accuracy: 0.3145\n",
      "Epoch [324/500], Loss: 1.6005, Accuracy: 0.3225\n",
      "Epoch [325/500], Loss: 1.6090, Accuracy: 0.3192\n",
      "Epoch [326/500], Loss: 1.6030, Accuracy: 0.3202\n",
      "Epoch [327/500], Loss: 1.6027, Accuracy: 0.3138\n",
      "Epoch [328/500], Loss: 1.6042, Accuracy: 0.3158\n",
      "Epoch [329/500], Loss: 1.6026, Accuracy: 0.3185\n",
      "Epoch [330/500], Loss: 1.6076, Accuracy: 0.3234\n",
      "Epoch [331/500], Loss: 1.5976, Accuracy: 0.3192\n",
      "Epoch [332/500], Loss: 1.6037, Accuracy: 0.3287\n",
      "Epoch [333/500], Loss: 1.6118, Accuracy: 0.3192\n",
      "Epoch [334/500], Loss: 1.5956, Accuracy: 0.3287\n",
      "Epoch [335/500], Loss: 1.6003, Accuracy: 0.3239\n",
      "Epoch [336/500], Loss: 1.5991, Accuracy: 0.3198\n",
      "Epoch [337/500], Loss: 1.5930, Accuracy: 0.3245\n",
      "Epoch [338/500], Loss: 1.5942, Accuracy: 0.3224\n",
      "Epoch [339/500], Loss: 1.5967, Accuracy: 0.3234\n",
      "Epoch [340/500], Loss: 1.5973, Accuracy: 0.3244\n",
      "Epoch [341/500], Loss: 1.5966, Accuracy: 0.3212\n",
      "Epoch [342/500], Loss: 1.5966, Accuracy: 0.3247\n",
      "Epoch [343/500], Loss: 1.5972, Accuracy: 0.3250\n",
      "Epoch [344/500], Loss: 1.5869, Accuracy: 0.3368\n",
      "Epoch [345/500], Loss: 1.5981, Accuracy: 0.3259\n",
      "Epoch [346/500], Loss: 1.5979, Accuracy: 0.3232\n",
      "Epoch [347/500], Loss: 1.6012, Accuracy: 0.3271\n",
      "Epoch [348/500], Loss: 1.5931, Accuracy: 0.3220\n",
      "Epoch [349/500], Loss: 1.5907, Accuracy: 0.3235\n",
      "Epoch [350/500], Loss: 1.5855, Accuracy: 0.3239\n",
      "Epoch [351/500], Loss: 1.5975, Accuracy: 0.3289\n",
      "Epoch [352/500], Loss: 1.5931, Accuracy: 0.3309\n",
      "Epoch [353/500], Loss: 1.5937, Accuracy: 0.3214\n",
      "Epoch [354/500], Loss: 1.5984, Accuracy: 0.3267\n",
      "Epoch [355/500], Loss: 1.5945, Accuracy: 0.3281\n",
      "Epoch [356/500], Loss: 1.5869, Accuracy: 0.3311\n",
      "Epoch [357/500], Loss: 1.5936, Accuracy: 0.3264\n",
      "Epoch [358/500], Loss: 1.5915, Accuracy: 0.3279\n",
      "Epoch [359/500], Loss: 1.5895, Accuracy: 0.3274\n",
      "Epoch [360/500], Loss: 1.5973, Accuracy: 0.3299\n",
      "Epoch [361/500], Loss: 1.5922, Accuracy: 0.3341\n",
      "Epoch [362/500], Loss: 1.5873, Accuracy: 0.3266\n",
      "Epoch [363/500], Loss: 1.5872, Accuracy: 0.3259\n",
      "Epoch [364/500], Loss: 1.5894, Accuracy: 0.3308\n",
      "Epoch [365/500], Loss: 1.5901, Accuracy: 0.3294\n",
      "Epoch [366/500], Loss: 1.5880, Accuracy: 0.3329\n",
      "Epoch [367/500], Loss: 1.5920, Accuracy: 0.3276\n",
      "Epoch [368/500], Loss: 1.5885, Accuracy: 0.3339\n",
      "Epoch [369/500], Loss: 1.5942, Accuracy: 0.3256\n",
      "Epoch [370/500], Loss: 1.5815, Accuracy: 0.3348\n",
      "Epoch [371/500], Loss: 1.5889, Accuracy: 0.3284\n",
      "Epoch [372/500], Loss: 1.5870, Accuracy: 0.3239\n",
      "Epoch [373/500], Loss: 1.5862, Accuracy: 0.3353\n",
      "Epoch [374/500], Loss: 1.5805, Accuracy: 0.3318\n",
      "Epoch [375/500], Loss: 1.5810, Accuracy: 0.3350\n",
      "Epoch [376/500], Loss: 1.5857, Accuracy: 0.3309\n",
      "Epoch [377/500], Loss: 1.5768, Accuracy: 0.3304\n",
      "Epoch [378/500], Loss: 1.5855, Accuracy: 0.3319\n",
      "Epoch [379/500], Loss: 1.5722, Accuracy: 0.3297\n",
      "Epoch [380/500], Loss: 1.5855, Accuracy: 0.3328\n",
      "Epoch [381/500], Loss: 1.5839, Accuracy: 0.3338\n",
      "Epoch [382/500], Loss: 1.5863, Accuracy: 0.3292\n",
      "Epoch [383/500], Loss: 1.5831, Accuracy: 0.3321\n",
      "Epoch [384/500], Loss: 1.5755, Accuracy: 0.3334\n",
      "Epoch [385/500], Loss: 1.5777, Accuracy: 0.3373\n",
      "Epoch [386/500], Loss: 1.5786, Accuracy: 0.3380\n",
      "Epoch [387/500], Loss: 1.5802, Accuracy: 0.3365\n",
      "Epoch [388/500], Loss: 1.5777, Accuracy: 0.3360\n",
      "Epoch [389/500], Loss: 1.5737, Accuracy: 0.3407\n",
      "Epoch [390/500], Loss: 1.5767, Accuracy: 0.3373\n",
      "Epoch [391/500], Loss: 1.5781, Accuracy: 0.3376\n",
      "Epoch [392/500], Loss: 1.5754, Accuracy: 0.3301\n",
      "Epoch [393/500], Loss: 1.5831, Accuracy: 0.3341\n",
      "Epoch [394/500], Loss: 1.5817, Accuracy: 0.3323\n",
      "Epoch [395/500], Loss: 1.5888, Accuracy: 0.3314\n",
      "Epoch [396/500], Loss: 1.5834, Accuracy: 0.3306\n",
      "Epoch [397/500], Loss: 1.5763, Accuracy: 0.3306\n",
      "Epoch [398/500], Loss: 1.5784, Accuracy: 0.3303\n",
      "Epoch [399/500], Loss: 1.5728, Accuracy: 0.3350\n",
      "Epoch [400/500], Loss: 1.5770, Accuracy: 0.3350\n",
      "Epoch [401/500], Loss: 1.5765, Accuracy: 0.3371\n",
      "Epoch [402/500], Loss: 1.5744, Accuracy: 0.3393\n",
      "Epoch [403/500], Loss: 1.5676, Accuracy: 0.3345\n",
      "Epoch [404/500], Loss: 1.5762, Accuracy: 0.3350\n",
      "Epoch [405/500], Loss: 1.5688, Accuracy: 0.3422\n",
      "Epoch [406/500], Loss: 1.5789, Accuracy: 0.3375\n",
      "Epoch [407/500], Loss: 1.5789, Accuracy: 0.3356\n",
      "Epoch [408/500], Loss: 1.5731, Accuracy: 0.3360\n",
      "Epoch [409/500], Loss: 1.5672, Accuracy: 0.3445\n",
      "Epoch [410/500], Loss: 1.5559, Accuracy: 0.3444\n",
      "Epoch [411/500], Loss: 1.5723, Accuracy: 0.3423\n",
      "Epoch [412/500], Loss: 1.5772, Accuracy: 0.3395\n",
      "Epoch [413/500], Loss: 1.5767, Accuracy: 0.3418\n",
      "Epoch [414/500], Loss: 1.5798, Accuracy: 0.3383\n",
      "Epoch [415/500], Loss: 1.5620, Accuracy: 0.3412\n",
      "Epoch [416/500], Loss: 1.5722, Accuracy: 0.3447\n",
      "Epoch [417/500], Loss: 1.5733, Accuracy: 0.3418\n",
      "Epoch [418/500], Loss: 1.5717, Accuracy: 0.3398\n",
      "Epoch [419/500], Loss: 1.5626, Accuracy: 0.3388\n",
      "Epoch [420/500], Loss: 1.5677, Accuracy: 0.3408\n",
      "Epoch [421/500], Loss: 1.5717, Accuracy: 0.3331\n",
      "Epoch [422/500], Loss: 1.5682, Accuracy: 0.3400\n",
      "Epoch [423/500], Loss: 1.5629, Accuracy: 0.3455\n",
      "Epoch [424/500], Loss: 1.5614, Accuracy: 0.3388\n",
      "Epoch [425/500], Loss: 1.5665, Accuracy: 0.3417\n",
      "Epoch [426/500], Loss: 1.5665, Accuracy: 0.3299\n",
      "Epoch [427/500], Loss: 1.5679, Accuracy: 0.3380\n",
      "Epoch [428/500], Loss: 1.5659, Accuracy: 0.3393\n",
      "Epoch [429/500], Loss: 1.5677, Accuracy: 0.3454\n",
      "Epoch [430/500], Loss: 1.5669, Accuracy: 0.3378\n",
      "Epoch [431/500], Loss: 1.5681, Accuracy: 0.3400\n",
      "Epoch [432/500], Loss: 1.5671, Accuracy: 0.3429\n",
      "Epoch [433/500], Loss: 1.5663, Accuracy: 0.3420\n",
      "Epoch [434/500], Loss: 1.5701, Accuracy: 0.3400\n",
      "Epoch [435/500], Loss: 1.5657, Accuracy: 0.3467\n",
      "Epoch [436/500], Loss: 1.5635, Accuracy: 0.3383\n",
      "Epoch [437/500], Loss: 1.5642, Accuracy: 0.3489\n",
      "Epoch [438/500], Loss: 1.5570, Accuracy: 0.3417\n",
      "Epoch [439/500], Loss: 1.5707, Accuracy: 0.3454\n",
      "Epoch [440/500], Loss: 1.5586, Accuracy: 0.3494\n",
      "Epoch [441/500], Loss: 1.5650, Accuracy: 0.3381\n",
      "Epoch [442/500], Loss: 1.5543, Accuracy: 0.3516\n",
      "Epoch [443/500], Loss: 1.5578, Accuracy: 0.3417\n",
      "Epoch [444/500], Loss: 1.5618, Accuracy: 0.3469\n",
      "Epoch [445/500], Loss: 1.5695, Accuracy: 0.3422\n",
      "Epoch [446/500], Loss: 1.5576, Accuracy: 0.3402\n",
      "Epoch [447/500], Loss: 1.5611, Accuracy: 0.3393\n",
      "Epoch [448/500], Loss: 1.5592, Accuracy: 0.3497\n",
      "Epoch [449/500], Loss: 1.5627, Accuracy: 0.3434\n",
      "Epoch [450/500], Loss: 1.5593, Accuracy: 0.3476\n",
      "Epoch [451/500], Loss: 1.5592, Accuracy: 0.3407\n",
      "Epoch [452/500], Loss: 1.5534, Accuracy: 0.3422\n",
      "Epoch [453/500], Loss: 1.5620, Accuracy: 0.3417\n",
      "Epoch [454/500], Loss: 1.5574, Accuracy: 0.3423\n",
      "Epoch [455/500], Loss: 1.5578, Accuracy: 0.3501\n",
      "Epoch [456/500], Loss: 1.5594, Accuracy: 0.3405\n",
      "Epoch [457/500], Loss: 1.5490, Accuracy: 0.3459\n",
      "Epoch [458/500], Loss: 1.5529, Accuracy: 0.3482\n",
      "Epoch [459/500], Loss: 1.5523, Accuracy: 0.3516\n",
      "Epoch [460/500], Loss: 1.5565, Accuracy: 0.3507\n",
      "Epoch [461/500], Loss: 1.5618, Accuracy: 0.3467\n",
      "Epoch [462/500], Loss: 1.5544, Accuracy: 0.3484\n",
      "Epoch [463/500], Loss: 1.5575, Accuracy: 0.3469\n",
      "Epoch [464/500], Loss: 1.5638, Accuracy: 0.3494\n",
      "Epoch [465/500], Loss: 1.5416, Accuracy: 0.3563\n",
      "Epoch [466/500], Loss: 1.5635, Accuracy: 0.3454\n",
      "Epoch [467/500], Loss: 1.5512, Accuracy: 0.3487\n",
      "Epoch [468/500], Loss: 1.5560, Accuracy: 0.3474\n",
      "Epoch [469/500], Loss: 1.5617, Accuracy: 0.3429\n",
      "Epoch [470/500], Loss: 1.5543, Accuracy: 0.3549\n",
      "Epoch [471/500], Loss: 1.5491, Accuracy: 0.3442\n",
      "Epoch [472/500], Loss: 1.5486, Accuracy: 0.3533\n",
      "Epoch [473/500], Loss: 1.5474, Accuracy: 0.3457\n",
      "Epoch [474/500], Loss: 1.5581, Accuracy: 0.3546\n",
      "Epoch [475/500], Loss: 1.5615, Accuracy: 0.3360\n",
      "Epoch [476/500], Loss: 1.5495, Accuracy: 0.3499\n",
      "Epoch [477/500], Loss: 1.5487, Accuracy: 0.3524\n",
      "Epoch [478/500], Loss: 1.5542, Accuracy: 0.3526\n",
      "Epoch [479/500], Loss: 1.5615, Accuracy: 0.3412\n",
      "Epoch [480/500], Loss: 1.5531, Accuracy: 0.3489\n",
      "Epoch [481/500], Loss: 1.5542, Accuracy: 0.3519\n",
      "Epoch [482/500], Loss: 1.5485, Accuracy: 0.3492\n",
      "Epoch [483/500], Loss: 1.5475, Accuracy: 0.3497\n",
      "Epoch [484/500], Loss: 1.5466, Accuracy: 0.3496\n",
      "Epoch [485/500], Loss: 1.5476, Accuracy: 0.3476\n",
      "Epoch [486/500], Loss: 1.5497, Accuracy: 0.3491\n",
      "Epoch [487/500], Loss: 1.5460, Accuracy: 0.3536\n",
      "Epoch [488/500], Loss: 1.5486, Accuracy: 0.3543\n",
      "Epoch [489/500], Loss: 1.5527, Accuracy: 0.3539\n",
      "Epoch [490/500], Loss: 1.5447, Accuracy: 0.3486\n",
      "Epoch [491/500], Loss: 1.5355, Accuracy: 0.3506\n",
      "Epoch [492/500], Loss: 1.5419, Accuracy: 0.3519\n",
      "Epoch [493/500], Loss: 1.5558, Accuracy: 0.3558\n",
      "Epoch [494/500], Loss: 1.5462, Accuracy: 0.3632\n",
      "Epoch [495/500], Loss: 1.5481, Accuracy: 0.3499\n",
      "Epoch [496/500], Loss: 1.5534, Accuracy: 0.3487\n",
      "Epoch [497/500], Loss: 1.5460, Accuracy: 0.3544\n",
      "Epoch [498/500], Loss: 1.5466, Accuracy: 0.3533\n",
      "Epoch [499/500], Loss: 1.5391, Accuracy: 0.3558\n",
      "Epoch [500/500], Loss: 1.5485, Accuracy: 0.3514\n"
     ]
    }
   ],
   "source": [
    "# Standard Deep Neural Network\n",
    "sdnn_model = SimpleDNN(input_size[0], num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(sdnn_model.parameters(), lr=0.00001)\n",
    "train(sdnn_model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.7929, Accuracy: 0.1628\n",
      "Epoch [2/500], Loss: 1.7925, Accuracy: 0.1655\n",
      "Epoch [3/500], Loss: 1.7916, Accuracy: 0.1645\n",
      "Epoch [4/500], Loss: 1.7914, Accuracy: 0.1671\n",
      "Epoch [5/500], Loss: 1.7908, Accuracy: 0.1698\n",
      "Epoch [6/500], Loss: 1.7899, Accuracy: 0.1771\n",
      "Epoch [7/500], Loss: 1.7893, Accuracy: 0.1831\n",
      "Epoch [8/500], Loss: 1.7879, Accuracy: 0.2034\n",
      "Epoch [9/500], Loss: 1.7865, Accuracy: 0.2374\n",
      "Epoch [10/500], Loss: 1.7844, Accuracy: 0.2705\n",
      "Epoch [11/500], Loss: 1.7831, Accuracy: 0.2817\n",
      "Epoch [12/500], Loss: 1.7807, Accuracy: 0.2854\n",
      "Epoch [13/500], Loss: 1.7785, Accuracy: 0.2909\n",
      "Epoch [14/500], Loss: 1.7761, Accuracy: 0.2935\n",
      "Epoch [15/500], Loss: 1.7738, Accuracy: 0.2956\n",
      "Epoch [16/500], Loss: 1.7715, Accuracy: 0.2946\n",
      "Epoch [17/500], Loss: 1.7682, Accuracy: 0.2973\n",
      "Epoch [18/500], Loss: 1.7646, Accuracy: 0.2980\n",
      "Epoch [19/500], Loss: 1.7617, Accuracy: 0.2977\n",
      "Epoch [20/500], Loss: 1.7586, Accuracy: 0.2985\n",
      "Epoch [21/500], Loss: 1.7539, Accuracy: 0.3034\n",
      "Epoch [22/500], Loss: 1.7482, Accuracy: 0.3064\n",
      "Epoch [23/500], Loss: 1.7437, Accuracy: 0.3084\n",
      "Epoch [24/500], Loss: 1.7392, Accuracy: 0.3104\n",
      "Epoch [25/500], Loss: 1.7337, Accuracy: 0.3082\n",
      "Epoch [26/500], Loss: 1.7281, Accuracy: 0.3099\n",
      "Epoch [27/500], Loss: 1.7228, Accuracy: 0.3113\n",
      "Epoch [28/500], Loss: 1.7166, Accuracy: 0.3116\n",
      "Epoch [29/500], Loss: 1.7078, Accuracy: 0.3130\n",
      "Epoch [30/500], Loss: 1.7039, Accuracy: 0.3109\n",
      "Epoch [31/500], Loss: 1.6985, Accuracy: 0.3108\n",
      "Epoch [32/500], Loss: 1.6913, Accuracy: 0.3109\n",
      "Epoch [33/500], Loss: 1.6862, Accuracy: 0.3093\n",
      "Epoch [34/500], Loss: 1.6788, Accuracy: 0.3103\n",
      "Epoch [35/500], Loss: 1.6746, Accuracy: 0.3101\n",
      "Epoch [36/500], Loss: 1.6686, Accuracy: 0.3119\n",
      "Epoch [37/500], Loss: 1.6633, Accuracy: 0.3118\n",
      "Epoch [38/500], Loss: 1.6600, Accuracy: 0.3140\n",
      "Epoch [39/500], Loss: 1.6548, Accuracy: 0.3126\n",
      "Epoch [40/500], Loss: 1.6497, Accuracy: 0.3124\n",
      "Epoch [41/500], Loss: 1.6469, Accuracy: 0.3131\n",
      "Epoch [42/500], Loss: 1.6401, Accuracy: 0.3145\n",
      "Epoch [43/500], Loss: 1.6369, Accuracy: 0.3156\n",
      "Epoch [44/500], Loss: 1.6318, Accuracy: 0.3158\n",
      "Epoch [45/500], Loss: 1.6282, Accuracy: 0.3178\n",
      "Epoch [46/500], Loss: 1.6255, Accuracy: 0.3173\n",
      "Epoch [47/500], Loss: 1.6233, Accuracy: 0.3173\n",
      "Epoch [48/500], Loss: 1.6191, Accuracy: 0.3190\n",
      "Epoch [49/500], Loss: 1.6155, Accuracy: 0.3200\n",
      "Epoch [50/500], Loss: 1.6121, Accuracy: 0.3205\n",
      "Epoch [51/500], Loss: 1.6093, Accuracy: 0.3208\n",
      "Epoch [52/500], Loss: 1.6060, Accuracy: 0.3212\n",
      "Epoch [53/500], Loss: 1.6035, Accuracy: 0.3252\n",
      "Epoch [54/500], Loss: 1.6012, Accuracy: 0.3262\n",
      "Epoch [55/500], Loss: 1.5971, Accuracy: 0.3266\n",
      "Epoch [56/500], Loss: 1.5960, Accuracy: 0.3276\n",
      "Epoch [57/500], Loss: 1.5983, Accuracy: 0.3281\n",
      "Epoch [58/500], Loss: 1.5920, Accuracy: 0.3294\n",
      "Epoch [59/500], Loss: 1.5903, Accuracy: 0.3313\n",
      "Epoch [60/500], Loss: 1.5861, Accuracy: 0.3304\n",
      "Epoch [61/500], Loss: 1.5861, Accuracy: 0.3324\n",
      "Epoch [62/500], Loss: 1.5842, Accuracy: 0.3323\n",
      "Epoch [63/500], Loss: 1.5827, Accuracy: 0.3323\n",
      "Epoch [64/500], Loss: 1.5790, Accuracy: 0.3329\n",
      "Epoch [65/500], Loss: 1.5771, Accuracy: 0.3338\n",
      "Epoch [66/500], Loss: 1.5792, Accuracy: 0.3334\n",
      "Epoch [67/500], Loss: 1.5762, Accuracy: 0.3345\n",
      "Epoch [68/500], Loss: 1.5697, Accuracy: 0.3336\n",
      "Epoch [69/500], Loss: 1.5718, Accuracy: 0.3350\n",
      "Epoch [70/500], Loss: 1.5721, Accuracy: 0.3351\n",
      "Epoch [71/500], Loss: 1.5679, Accuracy: 0.3356\n",
      "Epoch [72/500], Loss: 1.5694, Accuracy: 0.3371\n",
      "Epoch [73/500], Loss: 1.5623, Accuracy: 0.3366\n",
      "Epoch [74/500], Loss: 1.5663, Accuracy: 0.3365\n",
      "Epoch [75/500], Loss: 1.5644, Accuracy: 0.3375\n",
      "Epoch [76/500], Loss: 1.5647, Accuracy: 0.3390\n",
      "Epoch [77/500], Loss: 1.5640, Accuracy: 0.3393\n",
      "Epoch [78/500], Loss: 1.5608, Accuracy: 0.3392\n",
      "Epoch [79/500], Loss: 1.5616, Accuracy: 0.3397\n",
      "Epoch [80/500], Loss: 1.5610, Accuracy: 0.3410\n",
      "Epoch [81/500], Loss: 1.5610, Accuracy: 0.3412\n",
      "Epoch [82/500], Loss: 1.5613, Accuracy: 0.3415\n",
      "Epoch [83/500], Loss: 1.5565, Accuracy: 0.3439\n",
      "Epoch [84/500], Loss: 1.5552, Accuracy: 0.3422\n",
      "Epoch [85/500], Loss: 1.5570, Accuracy: 0.3412\n",
      "Epoch [86/500], Loss: 1.5569, Accuracy: 0.3437\n",
      "Epoch [87/500], Loss: 1.5554, Accuracy: 0.3440\n",
      "Epoch [88/500], Loss: 1.5531, Accuracy: 0.3427\n",
      "Epoch [89/500], Loss: 1.5558, Accuracy: 0.3454\n",
      "Epoch [90/500], Loss: 1.5542, Accuracy: 0.3429\n",
      "Epoch [91/500], Loss: 1.5521, Accuracy: 0.3452\n",
      "Epoch [92/500], Loss: 1.5501, Accuracy: 0.3460\n",
      "Epoch [93/500], Loss: 1.5488, Accuracy: 0.3457\n",
      "Epoch [94/500], Loss: 1.5425, Accuracy: 0.3445\n",
      "Epoch [95/500], Loss: 1.5457, Accuracy: 0.3464\n",
      "Epoch [96/500], Loss: 1.5468, Accuracy: 0.3477\n",
      "Epoch [97/500], Loss: 1.5466, Accuracy: 0.3474\n",
      "Epoch [98/500], Loss: 1.5393, Accuracy: 0.3472\n",
      "Epoch [99/500], Loss: 1.5476, Accuracy: 0.3471\n",
      "Epoch [100/500], Loss: 1.5419, Accuracy: 0.3479\n",
      "Epoch [101/500], Loss: 1.5431, Accuracy: 0.3487\n",
      "Epoch [102/500], Loss: 1.5402, Accuracy: 0.3482\n",
      "Epoch [103/500], Loss: 1.5422, Accuracy: 0.3482\n",
      "Epoch [104/500], Loss: 1.5412, Accuracy: 0.3472\n",
      "Epoch [105/500], Loss: 1.5407, Accuracy: 0.3502\n",
      "Epoch [106/500], Loss: 1.5430, Accuracy: 0.3474\n",
      "Epoch [107/500], Loss: 1.5409, Accuracy: 0.3523\n",
      "Epoch [108/500], Loss: 1.5376, Accuracy: 0.3501\n",
      "Epoch [109/500], Loss: 1.5382, Accuracy: 0.3502\n",
      "Epoch [110/500], Loss: 1.5335, Accuracy: 0.3513\n",
      "Epoch [111/500], Loss: 1.5391, Accuracy: 0.3507\n",
      "Epoch [112/500], Loss: 1.5338, Accuracy: 0.3516\n",
      "Epoch [113/500], Loss: 1.5336, Accuracy: 0.3526\n",
      "Epoch [114/500], Loss: 1.5327, Accuracy: 0.3543\n",
      "Epoch [115/500], Loss: 1.5335, Accuracy: 0.3533\n",
      "Epoch [116/500], Loss: 1.5325, Accuracy: 0.3526\n",
      "Epoch [117/500], Loss: 1.5330, Accuracy: 0.3539\n",
      "Epoch [118/500], Loss: 1.5258, Accuracy: 0.3560\n",
      "Epoch [119/500], Loss: 1.5313, Accuracy: 0.3536\n",
      "Epoch [120/500], Loss: 1.5307, Accuracy: 0.3548\n",
      "Epoch [121/500], Loss: 1.5279, Accuracy: 0.3553\n",
      "Epoch [122/500], Loss: 1.5222, Accuracy: 0.3551\n",
      "Epoch [123/500], Loss: 1.5296, Accuracy: 0.3549\n",
      "Epoch [124/500], Loss: 1.5276, Accuracy: 0.3553\n",
      "Epoch [125/500], Loss: 1.5304, Accuracy: 0.3566\n",
      "Epoch [126/500], Loss: 1.5231, Accuracy: 0.3578\n",
      "Epoch [127/500], Loss: 1.5284, Accuracy: 0.3583\n",
      "Epoch [128/500], Loss: 1.5249, Accuracy: 0.3581\n",
      "Epoch [129/500], Loss: 1.5265, Accuracy: 0.3581\n",
      "Epoch [130/500], Loss: 1.5230, Accuracy: 0.3585\n",
      "Epoch [131/500], Loss: 1.5244, Accuracy: 0.3598\n",
      "Epoch [132/500], Loss: 1.5236, Accuracy: 0.3588\n",
      "Epoch [133/500], Loss: 1.5203, Accuracy: 0.3603\n",
      "Epoch [134/500], Loss: 1.5174, Accuracy: 0.3627\n",
      "Epoch [135/500], Loss: 1.5214, Accuracy: 0.3612\n",
      "Epoch [136/500], Loss: 1.5206, Accuracy: 0.3617\n",
      "Epoch [137/500], Loss: 1.5201, Accuracy: 0.3632\n",
      "Epoch [138/500], Loss: 1.5169, Accuracy: 0.3620\n",
      "Epoch [139/500], Loss: 1.5193, Accuracy: 0.3640\n",
      "Epoch [140/500], Loss: 1.5166, Accuracy: 0.3644\n",
      "Epoch [141/500], Loss: 1.5135, Accuracy: 0.3635\n",
      "Epoch [142/500], Loss: 1.5100, Accuracy: 0.3622\n",
      "Epoch [143/500], Loss: 1.5171, Accuracy: 0.3672\n",
      "Epoch [144/500], Loss: 1.5153, Accuracy: 0.3637\n",
      "Epoch [145/500], Loss: 1.5140, Accuracy: 0.3644\n",
      "Epoch [146/500], Loss: 1.5124, Accuracy: 0.3657\n",
      "Epoch [147/500], Loss: 1.5114, Accuracy: 0.3657\n",
      "Epoch [148/500], Loss: 1.5087, Accuracy: 0.3655\n",
      "Epoch [149/500], Loss: 1.5128, Accuracy: 0.3659\n",
      "Epoch [150/500], Loss: 1.5109, Accuracy: 0.3669\n",
      "Epoch [151/500], Loss: 1.5294, Accuracy: 0.3675\n",
      "Epoch [152/500], Loss: 1.5081, Accuracy: 0.3679\n",
      "Epoch [153/500], Loss: 1.5101, Accuracy: 0.3696\n",
      "Epoch [154/500], Loss: 1.5173, Accuracy: 0.3696\n",
      "Epoch [155/500], Loss: 1.5077, Accuracy: 0.3701\n",
      "Epoch [156/500], Loss: 1.5088, Accuracy: 0.3697\n",
      "Epoch [157/500], Loss: 1.5021, Accuracy: 0.3707\n",
      "Epoch [158/500], Loss: 1.5118, Accuracy: 0.3704\n",
      "Epoch [159/500], Loss: 1.5101, Accuracy: 0.3724\n",
      "Epoch [160/500], Loss: 1.5060, Accuracy: 0.3734\n",
      "Epoch [161/500], Loss: 1.5075, Accuracy: 0.3729\n",
      "Epoch [162/500], Loss: 1.5110, Accuracy: 0.3724\n",
      "Epoch [163/500], Loss: 1.5076, Accuracy: 0.3739\n",
      "Epoch [164/500], Loss: 1.5062, Accuracy: 0.3717\n",
      "Epoch [165/500], Loss: 1.4971, Accuracy: 0.3749\n",
      "Epoch [166/500], Loss: 1.5034, Accuracy: 0.3746\n",
      "Epoch [167/500], Loss: 1.5051, Accuracy: 0.3743\n",
      "Epoch [168/500], Loss: 1.5017, Accuracy: 0.3759\n",
      "Epoch [169/500], Loss: 1.5014, Accuracy: 0.3754\n",
      "Epoch [170/500], Loss: 1.4985, Accuracy: 0.3753\n",
      "Epoch [171/500], Loss: 1.4978, Accuracy: 0.3754\n",
      "Epoch [172/500], Loss: 1.5001, Accuracy: 0.3780\n",
      "Epoch [173/500], Loss: 1.4927, Accuracy: 0.3776\n",
      "Epoch [174/500], Loss: 1.5001, Accuracy: 0.3756\n",
      "Epoch [175/500], Loss: 1.5019, Accuracy: 0.3766\n",
      "Epoch [176/500], Loss: 1.4945, Accuracy: 0.3781\n",
      "Epoch [177/500], Loss: 1.4954, Accuracy: 0.3761\n",
      "Epoch [178/500], Loss: 1.4915, Accuracy: 0.3770\n",
      "Epoch [179/500], Loss: 1.4922, Accuracy: 0.3773\n",
      "Epoch [180/500], Loss: 1.4968, Accuracy: 0.3761\n",
      "Epoch [181/500], Loss: 1.4915, Accuracy: 0.3781\n",
      "Epoch [182/500], Loss: 1.4929, Accuracy: 0.3810\n",
      "Epoch [183/500], Loss: 1.4959, Accuracy: 0.3793\n",
      "Epoch [184/500], Loss: 1.4913, Accuracy: 0.3813\n",
      "Epoch [185/500], Loss: 1.4900, Accuracy: 0.3815\n",
      "Epoch [186/500], Loss: 1.4913, Accuracy: 0.3828\n",
      "Epoch [187/500], Loss: 1.4910, Accuracy: 0.3805\n",
      "Epoch [188/500], Loss: 1.4921, Accuracy: 0.3801\n",
      "Epoch [189/500], Loss: 1.4905, Accuracy: 0.3842\n",
      "Epoch [190/500], Loss: 1.4836, Accuracy: 0.3842\n",
      "Epoch [191/500], Loss: 1.4887, Accuracy: 0.3833\n",
      "Epoch [192/500], Loss: 1.4893, Accuracy: 0.3835\n",
      "Epoch [193/500], Loss: 1.4805, Accuracy: 0.3852\n",
      "Epoch [194/500], Loss: 1.4864, Accuracy: 0.3838\n",
      "Epoch [195/500], Loss: 1.4796, Accuracy: 0.3850\n",
      "Epoch [196/500], Loss: 1.4842, Accuracy: 0.3823\n",
      "Epoch [197/500], Loss: 1.4839, Accuracy: 0.3850\n",
      "Epoch [198/500], Loss: 1.4785, Accuracy: 0.3847\n",
      "Epoch [199/500], Loss: 1.4860, Accuracy: 0.3869\n",
      "Epoch [200/500], Loss: 1.4815, Accuracy: 0.3864\n",
      "Epoch [201/500], Loss: 1.4785, Accuracy: 0.3872\n",
      "Epoch [202/500], Loss: 1.4801, Accuracy: 0.3850\n",
      "Epoch [203/500], Loss: 1.4769, Accuracy: 0.3875\n",
      "Epoch [204/500], Loss: 1.4827, Accuracy: 0.3867\n",
      "Epoch [205/500], Loss: 1.4789, Accuracy: 0.3872\n",
      "Epoch [206/500], Loss: 1.4777, Accuracy: 0.3869\n",
      "Epoch [207/500], Loss: 1.4750, Accuracy: 0.3874\n",
      "Epoch [208/500], Loss: 1.4791, Accuracy: 0.3872\n",
      "Epoch [209/500], Loss: 1.4771, Accuracy: 0.3887\n",
      "Epoch [210/500], Loss: 1.4778, Accuracy: 0.3877\n",
      "Epoch [211/500], Loss: 1.4801, Accuracy: 0.3912\n",
      "Epoch [212/500], Loss: 1.4732, Accuracy: 0.3874\n",
      "Epoch [213/500], Loss: 1.4789, Accuracy: 0.3885\n",
      "Epoch [214/500], Loss: 1.4726, Accuracy: 0.3892\n",
      "Epoch [215/500], Loss: 1.4755, Accuracy: 0.3875\n",
      "Epoch [216/500], Loss: 1.4714, Accuracy: 0.3887\n",
      "Epoch [217/500], Loss: 1.4739, Accuracy: 0.3882\n",
      "Epoch [218/500], Loss: 1.4720, Accuracy: 0.3907\n",
      "Epoch [219/500], Loss: 1.4774, Accuracy: 0.3904\n",
      "Epoch [220/500], Loss: 1.4725, Accuracy: 0.3917\n",
      "Epoch [221/500], Loss: 1.4713, Accuracy: 0.3906\n",
      "Epoch [222/500], Loss: 1.4734, Accuracy: 0.3927\n",
      "Epoch [223/500], Loss: 1.4691, Accuracy: 0.3896\n",
      "Epoch [224/500], Loss: 1.4655, Accuracy: 0.3926\n",
      "Epoch [225/500], Loss: 1.4671, Accuracy: 0.3921\n",
      "Epoch [226/500], Loss: 1.4662, Accuracy: 0.3938\n",
      "Epoch [227/500], Loss: 1.4677, Accuracy: 0.3924\n",
      "Epoch [228/500], Loss: 1.4723, Accuracy: 0.3927\n",
      "Epoch [229/500], Loss: 1.4596, Accuracy: 0.3938\n",
      "Epoch [230/500], Loss: 1.4647, Accuracy: 0.3927\n",
      "Epoch [231/500], Loss: 1.4669, Accuracy: 0.3948\n",
      "Epoch [232/500], Loss: 1.4605, Accuracy: 0.3969\n",
      "Epoch [233/500], Loss: 1.4686, Accuracy: 0.3943\n",
      "Epoch [234/500], Loss: 1.4599, Accuracy: 0.3963\n",
      "Epoch [235/500], Loss: 1.4624, Accuracy: 0.3969\n",
      "Epoch [236/500], Loss: 1.4634, Accuracy: 0.3985\n",
      "Epoch [237/500], Loss: 1.4585, Accuracy: 0.3961\n",
      "Epoch [238/500], Loss: 1.4610, Accuracy: 0.3973\n",
      "Epoch [239/500], Loss: 1.4610, Accuracy: 0.3983\n",
      "Epoch [240/500], Loss: 1.4594, Accuracy: 0.3988\n",
      "Epoch [241/500], Loss: 1.4547, Accuracy: 0.3973\n",
      "Epoch [242/500], Loss: 1.4595, Accuracy: 0.3974\n",
      "Epoch [243/500], Loss: 1.4577, Accuracy: 0.3983\n",
      "Epoch [244/500], Loss: 1.4533, Accuracy: 0.3996\n",
      "Epoch [245/500], Loss: 1.4602, Accuracy: 0.3993\n",
      "Epoch [246/500], Loss: 1.4629, Accuracy: 0.3993\n",
      "Epoch [247/500], Loss: 1.4583, Accuracy: 0.3983\n",
      "Epoch [248/500], Loss: 1.4568, Accuracy: 0.3996\n",
      "Epoch [249/500], Loss: 1.4517, Accuracy: 0.4000\n",
      "Epoch [250/500], Loss: 1.4534, Accuracy: 0.3993\n",
      "Epoch [251/500], Loss: 1.4522, Accuracy: 0.4015\n",
      "Epoch [252/500], Loss: 1.4591, Accuracy: 0.4006\n",
      "Epoch [253/500], Loss: 1.4499, Accuracy: 0.3998\n",
      "Epoch [254/500], Loss: 1.4487, Accuracy: 0.4011\n",
      "Epoch [255/500], Loss: 1.4606, Accuracy: 0.4035\n",
      "Epoch [256/500], Loss: 1.4464, Accuracy: 0.4030\n",
      "Epoch [257/500], Loss: 1.4552, Accuracy: 0.4015\n",
      "Epoch [258/500], Loss: 1.4551, Accuracy: 0.4032\n",
      "Epoch [259/500], Loss: 1.4503, Accuracy: 0.4016\n",
      "Epoch [260/500], Loss: 1.4548, Accuracy: 0.4030\n",
      "Epoch [261/500], Loss: 1.4510, Accuracy: 0.4062\n",
      "Epoch [262/500], Loss: 1.4511, Accuracy: 0.4022\n",
      "Epoch [263/500], Loss: 1.4476, Accuracy: 0.4043\n",
      "Epoch [264/500], Loss: 1.4484, Accuracy: 0.4033\n",
      "Epoch [265/500], Loss: 1.4507, Accuracy: 0.4060\n",
      "Epoch [266/500], Loss: 1.4540, Accuracy: 0.4062\n",
      "Epoch [267/500], Loss: 1.4493, Accuracy: 0.4055\n",
      "Epoch [268/500], Loss: 1.4498, Accuracy: 0.4050\n",
      "Epoch [269/500], Loss: 1.4492, Accuracy: 0.4048\n",
      "Epoch [270/500], Loss: 1.4463, Accuracy: 0.4048\n",
      "Epoch [271/500], Loss: 1.4478, Accuracy: 0.4063\n",
      "Epoch [272/500], Loss: 1.4398, Accuracy: 0.4063\n",
      "Epoch [273/500], Loss: 1.4414, Accuracy: 0.4058\n",
      "Epoch [274/500], Loss: 1.4379, Accuracy: 0.4058\n",
      "Epoch [275/500], Loss: 1.4520, Accuracy: 0.4040\n",
      "Epoch [276/500], Loss: 1.4426, Accuracy: 0.4072\n",
      "Epoch [277/500], Loss: 1.4501, Accuracy: 0.4077\n",
      "Epoch [278/500], Loss: 1.4407, Accuracy: 0.4065\n",
      "Epoch [279/500], Loss: 1.4399, Accuracy: 0.4065\n",
      "Epoch [280/500], Loss: 1.4460, Accuracy: 0.4065\n",
      "Epoch [281/500], Loss: 1.4454, Accuracy: 0.4070\n",
      "Epoch [282/500], Loss: 1.4387, Accuracy: 0.4087\n",
      "Epoch [283/500], Loss: 1.4425, Accuracy: 0.4084\n",
      "Epoch [284/500], Loss: 1.4394, Accuracy: 0.4092\n",
      "Epoch [285/500], Loss: 1.4410, Accuracy: 0.4100\n",
      "Epoch [286/500], Loss: 1.4406, Accuracy: 0.4114\n",
      "Epoch [287/500], Loss: 1.4405, Accuracy: 0.4094\n",
      "Epoch [288/500], Loss: 1.4412, Accuracy: 0.4105\n",
      "Epoch [289/500], Loss: 1.4393, Accuracy: 0.4087\n",
      "Epoch [290/500], Loss: 1.4390, Accuracy: 0.4097\n",
      "Epoch [291/500], Loss: 1.4492, Accuracy: 0.4085\n",
      "Epoch [292/500], Loss: 1.4384, Accuracy: 0.4119\n",
      "Epoch [293/500], Loss: 1.4395, Accuracy: 0.4090\n",
      "Epoch [294/500], Loss: 1.4460, Accuracy: 0.4117\n",
      "Epoch [295/500], Loss: 1.4329, Accuracy: 0.4116\n",
      "Epoch [296/500], Loss: 1.4324, Accuracy: 0.4132\n",
      "Epoch [297/500], Loss: 1.4379, Accuracy: 0.4112\n",
      "Epoch [298/500], Loss: 1.4378, Accuracy: 0.4116\n",
      "Epoch [299/500], Loss: 1.4327, Accuracy: 0.4129\n",
      "Epoch [300/500], Loss: 1.4311, Accuracy: 0.4124\n",
      "Epoch [301/500], Loss: 1.4333, Accuracy: 0.4127\n",
      "Epoch [302/500], Loss: 1.4310, Accuracy: 0.4132\n",
      "Epoch [303/500], Loss: 1.4276, Accuracy: 0.4124\n",
      "Epoch [304/500], Loss: 1.4306, Accuracy: 0.4151\n",
      "Epoch [305/500], Loss: 1.4300, Accuracy: 0.4149\n",
      "Epoch [306/500], Loss: 1.4334, Accuracy: 0.4136\n",
      "Epoch [307/500], Loss: 1.4310, Accuracy: 0.4139\n",
      "Epoch [308/500], Loss: 1.4289, Accuracy: 0.4141\n",
      "Epoch [309/500], Loss: 1.4293, Accuracy: 0.4154\n",
      "Epoch [310/500], Loss: 1.4227, Accuracy: 0.4131\n",
      "Epoch [311/500], Loss: 1.4241, Accuracy: 0.4161\n",
      "Epoch [312/500], Loss: 1.4281, Accuracy: 0.4159\n",
      "Epoch [313/500], Loss: 1.4269, Accuracy: 0.4171\n",
      "Epoch [314/500], Loss: 1.4266, Accuracy: 0.4142\n",
      "Epoch [315/500], Loss: 1.4341, Accuracy: 0.4147\n",
      "Epoch [316/500], Loss: 1.4278, Accuracy: 0.4158\n",
      "Epoch [317/500], Loss: 1.4282, Accuracy: 0.4144\n",
      "Epoch [318/500], Loss: 1.4242, Accuracy: 0.4154\n",
      "Epoch [319/500], Loss: 1.4257, Accuracy: 0.4186\n",
      "Epoch [320/500], Loss: 1.4226, Accuracy: 0.4158\n",
      "Epoch [321/500], Loss: 1.4278, Accuracy: 0.4149\n",
      "Epoch [322/500], Loss: 1.4195, Accuracy: 0.4161\n",
      "Epoch [323/500], Loss: 1.4197, Accuracy: 0.4166\n",
      "Epoch [324/500], Loss: 1.4214, Accuracy: 0.4179\n",
      "Epoch [325/500], Loss: 1.4220, Accuracy: 0.4168\n",
      "Epoch [326/500], Loss: 1.4201, Accuracy: 0.4166\n",
      "Epoch [327/500], Loss: 1.4228, Accuracy: 0.4184\n",
      "Epoch [328/500], Loss: 1.4235, Accuracy: 0.4173\n",
      "Epoch [329/500], Loss: 1.4264, Accuracy: 0.4164\n",
      "Epoch [330/500], Loss: 1.4261, Accuracy: 0.4163\n",
      "Epoch [331/500], Loss: 1.4137, Accuracy: 0.4163\n",
      "Epoch [332/500], Loss: 1.4351, Accuracy: 0.4206\n",
      "Epoch [333/500], Loss: 1.4227, Accuracy: 0.4164\n",
      "Epoch [334/500], Loss: 1.4180, Accuracy: 0.4173\n",
      "Epoch [335/500], Loss: 1.4134, Accuracy: 0.4196\n",
      "Epoch [336/500], Loss: 1.4211, Accuracy: 0.4189\n",
      "Epoch [337/500], Loss: 1.4161, Accuracy: 0.4198\n",
      "Epoch [338/500], Loss: 1.4202, Accuracy: 0.4189\n",
      "Epoch [339/500], Loss: 1.4159, Accuracy: 0.4186\n",
      "Epoch [340/500], Loss: 1.4135, Accuracy: 0.4178\n",
      "Epoch [341/500], Loss: 1.4112, Accuracy: 0.4201\n",
      "Epoch [342/500], Loss: 1.4186, Accuracy: 0.4203\n",
      "Epoch [343/500], Loss: 1.4154, Accuracy: 0.4200\n",
      "Epoch [344/500], Loss: 1.4168, Accuracy: 0.4208\n",
      "Epoch [345/500], Loss: 1.4187, Accuracy: 0.4188\n",
      "Epoch [346/500], Loss: 1.4165, Accuracy: 0.4184\n",
      "Epoch [347/500], Loss: 1.4123, Accuracy: 0.4226\n",
      "Epoch [348/500], Loss: 1.4129, Accuracy: 0.4208\n",
      "Epoch [349/500], Loss: 1.4160, Accuracy: 0.4210\n",
      "Epoch [350/500], Loss: 1.4110, Accuracy: 0.4215\n",
      "Epoch [351/500], Loss: 1.4156, Accuracy: 0.4208\n",
      "Epoch [352/500], Loss: 1.4115, Accuracy: 0.4225\n",
      "Epoch [353/500], Loss: 1.4135, Accuracy: 0.4243\n",
      "Epoch [354/500], Loss: 1.4116, Accuracy: 0.4218\n",
      "Epoch [355/500], Loss: 1.4089, Accuracy: 0.4205\n",
      "Epoch [356/500], Loss: 1.4088, Accuracy: 0.4230\n",
      "Epoch [357/500], Loss: 1.4084, Accuracy: 0.4206\n",
      "Epoch [358/500], Loss: 1.4201, Accuracy: 0.4255\n",
      "Epoch [359/500], Loss: 1.4127, Accuracy: 0.4233\n",
      "Epoch [360/500], Loss: 1.4104, Accuracy: 0.4265\n",
      "Epoch [361/500], Loss: 1.4088, Accuracy: 0.4250\n",
      "Epoch [362/500], Loss: 1.4030, Accuracy: 0.4243\n",
      "Epoch [363/500], Loss: 1.4161, Accuracy: 0.4257\n",
      "Epoch [364/500], Loss: 1.4080, Accuracy: 0.4252\n",
      "Epoch [365/500], Loss: 1.4067, Accuracy: 0.4258\n",
      "Epoch [366/500], Loss: 1.4105, Accuracy: 0.4252\n",
      "Epoch [367/500], Loss: 1.4046, Accuracy: 0.4247\n",
      "Epoch [368/500], Loss: 1.4050, Accuracy: 0.4247\n",
      "Epoch [369/500], Loss: 1.4038, Accuracy: 0.4275\n",
      "Epoch [370/500], Loss: 1.4027, Accuracy: 0.4279\n",
      "Epoch [371/500], Loss: 1.4070, Accuracy: 0.4263\n",
      "Epoch [372/500], Loss: 1.4031, Accuracy: 0.4262\n",
      "Epoch [373/500], Loss: 1.4122, Accuracy: 0.4252\n",
      "Epoch [374/500], Loss: 1.4074, Accuracy: 0.4260\n",
      "Epoch [375/500], Loss: 1.4008, Accuracy: 0.4272\n",
      "Epoch [376/500], Loss: 1.4013, Accuracy: 0.4273\n",
      "Epoch [377/500], Loss: 1.4013, Accuracy: 0.4243\n",
      "Epoch [378/500], Loss: 1.4045, Accuracy: 0.4258\n",
      "Epoch [379/500], Loss: 1.4014, Accuracy: 0.4294\n",
      "Epoch [380/500], Loss: 1.4024, Accuracy: 0.4289\n",
      "Epoch [381/500], Loss: 1.3997, Accuracy: 0.4284\n",
      "Epoch [382/500], Loss: 1.3990, Accuracy: 0.4287\n",
      "Epoch [383/500], Loss: 1.4008, Accuracy: 0.4279\n",
      "Epoch [384/500], Loss: 1.3938, Accuracy: 0.4272\n",
      "Epoch [385/500], Loss: 1.4042, Accuracy: 0.4289\n",
      "Epoch [386/500], Loss: 1.3996, Accuracy: 0.4290\n",
      "Epoch [387/500], Loss: 1.3940, Accuracy: 0.4287\n",
      "Epoch [388/500], Loss: 1.3977, Accuracy: 0.4302\n",
      "Epoch [389/500], Loss: 1.3983, Accuracy: 0.4307\n",
      "Epoch [390/500], Loss: 1.4032, Accuracy: 0.4309\n",
      "Epoch [391/500], Loss: 1.3976, Accuracy: 0.4273\n",
      "Epoch [392/500], Loss: 1.3956, Accuracy: 0.4294\n",
      "Epoch [393/500], Loss: 1.3964, Accuracy: 0.4341\n",
      "Epoch [394/500], Loss: 1.3949, Accuracy: 0.4290\n",
      "Epoch [395/500], Loss: 1.3907, Accuracy: 0.4302\n",
      "Epoch [396/500], Loss: 1.3944, Accuracy: 0.4331\n",
      "Epoch [397/500], Loss: 1.4007, Accuracy: 0.4317\n",
      "Epoch [398/500], Loss: 1.3890, Accuracy: 0.4310\n",
      "Epoch [399/500], Loss: 1.3977, Accuracy: 0.4322\n",
      "Epoch [400/500], Loss: 1.3941, Accuracy: 0.4310\n",
      "Epoch [401/500], Loss: 1.3938, Accuracy: 0.4324\n",
      "Epoch [402/500], Loss: 1.3972, Accuracy: 0.4331\n",
      "Epoch [403/500], Loss: 1.3912, Accuracy: 0.4297\n",
      "Epoch [404/500], Loss: 1.3905, Accuracy: 0.4322\n",
      "Epoch [405/500], Loss: 1.3874, Accuracy: 0.4299\n",
      "Epoch [406/500], Loss: 1.4054, Accuracy: 0.4344\n",
      "Epoch [407/500], Loss: 1.3921, Accuracy: 0.4327\n",
      "Epoch [408/500], Loss: 1.3932, Accuracy: 0.4312\n",
      "Epoch [409/500], Loss: 1.3901, Accuracy: 0.4336\n",
      "Epoch [410/500], Loss: 1.3925, Accuracy: 0.4337\n",
      "Epoch [411/500], Loss: 1.3906, Accuracy: 0.4336\n",
      "Epoch [412/500], Loss: 1.3939, Accuracy: 0.4346\n",
      "Epoch [413/500], Loss: 1.3882, Accuracy: 0.4351\n",
      "Epoch [414/500], Loss: 1.3890, Accuracy: 0.4349\n",
      "Epoch [415/500], Loss: 1.3826, Accuracy: 0.4334\n",
      "Epoch [416/500], Loss: 1.3916, Accuracy: 0.4354\n",
      "Epoch [417/500], Loss: 1.4015, Accuracy: 0.4354\n",
      "Epoch [418/500], Loss: 1.3860, Accuracy: 0.4354\n",
      "Epoch [419/500], Loss: 1.3871, Accuracy: 0.4357\n",
      "Epoch [420/500], Loss: 1.3904, Accuracy: 0.4347\n",
      "Epoch [421/500], Loss: 1.3897, Accuracy: 0.4346\n",
      "Epoch [422/500], Loss: 1.3928, Accuracy: 0.4374\n",
      "Epoch [423/500], Loss: 1.3868, Accuracy: 0.4363\n",
      "Epoch [424/500], Loss: 1.3876, Accuracy: 0.4363\n",
      "Epoch [425/500], Loss: 1.3838, Accuracy: 0.4366\n",
      "Epoch [426/500], Loss: 1.3856, Accuracy: 0.4366\n",
      "Epoch [427/500], Loss: 1.3787, Accuracy: 0.4378\n",
      "Epoch [428/500], Loss: 1.3837, Accuracy: 0.4398\n",
      "Epoch [429/500], Loss: 1.3795, Accuracy: 0.4368\n",
      "Epoch [430/500], Loss: 1.3822, Accuracy: 0.4394\n",
      "Epoch [431/500], Loss: 1.3842, Accuracy: 0.4374\n",
      "Epoch [432/500], Loss: 1.3870, Accuracy: 0.4388\n",
      "Epoch [433/500], Loss: 1.3860, Accuracy: 0.4399\n",
      "Epoch [434/500], Loss: 1.3834, Accuracy: 0.4384\n",
      "Epoch [435/500], Loss: 1.3801, Accuracy: 0.4399\n",
      "Epoch [436/500], Loss: 1.3790, Accuracy: 0.4396\n",
      "Epoch [437/500], Loss: 1.3784, Accuracy: 0.4406\n",
      "Epoch [438/500], Loss: 1.3814, Accuracy: 0.4405\n",
      "Epoch [439/500], Loss: 1.3825, Accuracy: 0.4399\n",
      "Epoch [440/500], Loss: 1.3773, Accuracy: 0.4399\n",
      "Epoch [441/500], Loss: 1.3768, Accuracy: 0.4416\n",
      "Epoch [442/500], Loss: 1.3857, Accuracy: 0.4411\n",
      "Epoch [443/500], Loss: 1.3765, Accuracy: 0.4408\n",
      "Epoch [444/500], Loss: 1.3818, Accuracy: 0.4408\n",
      "Epoch [445/500], Loss: 1.3787, Accuracy: 0.4408\n",
      "Epoch [446/500], Loss: 1.3816, Accuracy: 0.4415\n",
      "Epoch [447/500], Loss: 1.3817, Accuracy: 0.4413\n",
      "Epoch [448/500], Loss: 1.3758, Accuracy: 0.4423\n",
      "Epoch [449/500], Loss: 1.3756, Accuracy: 0.4418\n",
      "Epoch [450/500], Loss: 1.3754, Accuracy: 0.4430\n",
      "Epoch [451/500], Loss: 1.3804, Accuracy: 0.4425\n",
      "Epoch [452/500], Loss: 1.3748, Accuracy: 0.4425\n",
      "Epoch [453/500], Loss: 1.3770, Accuracy: 0.4441\n",
      "Epoch [454/500], Loss: 1.3807, Accuracy: 0.4428\n",
      "Epoch [455/500], Loss: 1.3741, Accuracy: 0.4428\n",
      "Epoch [456/500], Loss: 1.3692, Accuracy: 0.4416\n",
      "Epoch [457/500], Loss: 1.3720, Accuracy: 0.4446\n",
      "Epoch [458/500], Loss: 1.3801, Accuracy: 0.4428\n",
      "Epoch [459/500], Loss: 1.3779, Accuracy: 0.4452\n",
      "Epoch [460/500], Loss: 1.3739, Accuracy: 0.4446\n",
      "Epoch [461/500], Loss: 1.3734, Accuracy: 0.4421\n",
      "Epoch [462/500], Loss: 1.3706, Accuracy: 0.4428\n",
      "Epoch [463/500], Loss: 1.3674, Accuracy: 0.4455\n",
      "Epoch [464/500], Loss: 1.3721, Accuracy: 0.4445\n",
      "Epoch [465/500], Loss: 1.3690, Accuracy: 0.4462\n",
      "Epoch [466/500], Loss: 1.3716, Accuracy: 0.4446\n",
      "Epoch [467/500], Loss: 1.3785, Accuracy: 0.4450\n",
      "Epoch [468/500], Loss: 1.3715, Accuracy: 0.4450\n",
      "Epoch [469/500], Loss: 1.3716, Accuracy: 0.4453\n",
      "Epoch [470/500], Loss: 1.3709, Accuracy: 0.4460\n",
      "Epoch [471/500], Loss: 1.3701, Accuracy: 0.4452\n",
      "Epoch [472/500], Loss: 1.3693, Accuracy: 0.4445\n",
      "Epoch [473/500], Loss: 1.3654, Accuracy: 0.4470\n",
      "Epoch [474/500], Loss: 1.3697, Accuracy: 0.4441\n",
      "Epoch [475/500], Loss: 1.3752, Accuracy: 0.4450\n",
      "Epoch [476/500], Loss: 1.3667, Accuracy: 0.4455\n",
      "Epoch [477/500], Loss: 1.3648, Accuracy: 0.4470\n",
      "Epoch [478/500], Loss: 1.3723, Accuracy: 0.4478\n",
      "Epoch [479/500], Loss: 1.3689, Accuracy: 0.4467\n",
      "Epoch [480/500], Loss: 1.3664, Accuracy: 0.4460\n",
      "Epoch [481/500], Loss: 1.3613, Accuracy: 0.4488\n",
      "Epoch [482/500], Loss: 1.3660, Accuracy: 0.4467\n",
      "Epoch [483/500], Loss: 1.3661, Accuracy: 0.4463\n",
      "Epoch [484/500], Loss: 1.3677, Accuracy: 0.4441\n",
      "Epoch [485/500], Loss: 1.3693, Accuracy: 0.4448\n",
      "Epoch [486/500], Loss: 1.3635, Accuracy: 0.4487\n",
      "Epoch [487/500], Loss: 1.3644, Accuracy: 0.4468\n",
      "Epoch [488/500], Loss: 1.3652, Accuracy: 0.4483\n",
      "Epoch [489/500], Loss: 1.3629, Accuracy: 0.4460\n",
      "Epoch [490/500], Loss: 1.3643, Accuracy: 0.4470\n",
      "Epoch [491/500], Loss: 1.3621, Accuracy: 0.4490\n",
      "Epoch [492/500], Loss: 1.3626, Accuracy: 0.4502\n",
      "Epoch [493/500], Loss: 1.3573, Accuracy: 0.4494\n",
      "Epoch [494/500], Loss: 1.3660, Accuracy: 0.4502\n",
      "Epoch [495/500], Loss: 1.3625, Accuracy: 0.4487\n",
      "Epoch [496/500], Loss: 1.3611, Accuracy: 0.4494\n",
      "Epoch [497/500], Loss: 1.3574, Accuracy: 0.4495\n",
      "Epoch [498/500], Loss: 1.3605, Accuracy: 0.4499\n",
      "Epoch [499/500], Loss: 1.3587, Accuracy: 0.4507\n",
      "Epoch [500/500], Loss: 1.3601, Accuracy: 0.4509\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "lstm_model = LSTMModel(input_size[0], hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.00001)\n",
    "train(lstm_model, train_loaderLSTM, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.7957, Accuracy: 0.1487\n",
      "Epoch [2/500], Loss: 1.7953, Accuracy: 0.1475\n",
      "Epoch [3/500], Loss: 1.7941, Accuracy: 0.1505\n",
      "Epoch [4/500], Loss: 1.7938, Accuracy: 0.1676\n",
      "Epoch [5/500], Loss: 1.7925, Accuracy: 0.1687\n",
      "Epoch [6/500], Loss: 1.7916, Accuracy: 0.1690\n",
      "Epoch [7/500], Loss: 1.7909, Accuracy: 0.1692\n",
      "Epoch [8/500], Loss: 1.7894, Accuracy: 0.1692\n",
      "Epoch [9/500], Loss: 1.7886, Accuracy: 0.1692\n",
      "Epoch [10/500], Loss: 1.7874, Accuracy: 0.1692\n",
      "Epoch [11/500], Loss: 1.7862, Accuracy: 0.1692\n",
      "Epoch [12/500], Loss: 1.7853, Accuracy: 0.1697\n",
      "Epoch [13/500], Loss: 1.7839, Accuracy: 0.1784\n",
      "Epoch [14/500], Loss: 1.7823, Accuracy: 0.2039\n",
      "Epoch [15/500], Loss: 1.7811, Accuracy: 0.2303\n",
      "Epoch [16/500], Loss: 1.7791, Accuracy: 0.2508\n",
      "Epoch [17/500], Loss: 1.7771, Accuracy: 0.2698\n",
      "Epoch [18/500], Loss: 1.7745, Accuracy: 0.2837\n",
      "Epoch [19/500], Loss: 1.7715, Accuracy: 0.2960\n",
      "Epoch [20/500], Loss: 1.7690, Accuracy: 0.3015\n",
      "Epoch [21/500], Loss: 1.7654, Accuracy: 0.3074\n",
      "Epoch [22/500], Loss: 1.7620, Accuracy: 0.3096\n",
      "Epoch [23/500], Loss: 1.7589, Accuracy: 0.3109\n",
      "Epoch [24/500], Loss: 1.7546, Accuracy: 0.3131\n",
      "Epoch [25/500], Loss: 1.7512, Accuracy: 0.3153\n",
      "Epoch [26/500], Loss: 1.7468, Accuracy: 0.3172\n",
      "Epoch [27/500], Loss: 1.7416, Accuracy: 0.3172\n",
      "Epoch [28/500], Loss: 1.7373, Accuracy: 0.3175\n",
      "Epoch [29/500], Loss: 1.7324, Accuracy: 0.3166\n",
      "Epoch [30/500], Loss: 1.7266, Accuracy: 0.3158\n",
      "Epoch [31/500], Loss: 1.7224, Accuracy: 0.3160\n",
      "Epoch [32/500], Loss: 1.7172, Accuracy: 0.3143\n",
      "Epoch [33/500], Loss: 1.7124, Accuracy: 0.3148\n",
      "Epoch [34/500], Loss: 1.7070, Accuracy: 0.3153\n",
      "Epoch [35/500], Loss: 1.7010, Accuracy: 0.3150\n",
      "Epoch [36/500], Loss: 1.6956, Accuracy: 0.3158\n",
      "Epoch [37/500], Loss: 1.6888, Accuracy: 0.3150\n",
      "Epoch [38/500], Loss: 1.6857, Accuracy: 0.3156\n",
      "Epoch [39/500], Loss: 1.6803, Accuracy: 0.3165\n",
      "Epoch [40/500], Loss: 1.6755, Accuracy: 0.3155\n",
      "Epoch [41/500], Loss: 1.6695, Accuracy: 0.3172\n",
      "Epoch [42/500], Loss: 1.6602, Accuracy: 0.3192\n",
      "Epoch [43/500], Loss: 1.6548, Accuracy: 0.3151\n",
      "Epoch [44/500], Loss: 1.6513, Accuracy: 0.3166\n",
      "Epoch [45/500], Loss: 1.6459, Accuracy: 0.3175\n",
      "Epoch [46/500], Loss: 1.6416, Accuracy: 0.3173\n",
      "Epoch [47/500], Loss: 1.6370, Accuracy: 0.3180\n",
      "Epoch [48/500], Loss: 1.6327, Accuracy: 0.3168\n",
      "Epoch [49/500], Loss: 1.6289, Accuracy: 0.3208\n",
      "Epoch [50/500], Loss: 1.6275, Accuracy: 0.3197\n",
      "Epoch [51/500], Loss: 1.6208, Accuracy: 0.3182\n",
      "Epoch [52/500], Loss: 1.6200, Accuracy: 0.3210\n",
      "Epoch [53/500], Loss: 1.6152, Accuracy: 0.3229\n",
      "Epoch [54/500], Loss: 1.6113, Accuracy: 0.3237\n",
      "Epoch [55/500], Loss: 1.6076, Accuracy: 0.3252\n",
      "Epoch [56/500], Loss: 1.6016, Accuracy: 0.3257\n",
      "Epoch [57/500], Loss: 1.6054, Accuracy: 0.3261\n",
      "Epoch [58/500], Loss: 1.6017, Accuracy: 0.3271\n",
      "Epoch [59/500], Loss: 1.5988, Accuracy: 0.3287\n",
      "Epoch [60/500], Loss: 1.5926, Accuracy: 0.3291\n",
      "Epoch [61/500], Loss: 1.5931, Accuracy: 0.3299\n",
      "Epoch [62/500], Loss: 1.5924, Accuracy: 0.3314\n",
      "Epoch [63/500], Loss: 1.5876, Accuracy: 0.3324\n",
      "Epoch [64/500], Loss: 1.5880, Accuracy: 0.3329\n",
      "Epoch [65/500], Loss: 1.5886, Accuracy: 0.3366\n",
      "Epoch [66/500], Loss: 1.5850, Accuracy: 0.3353\n",
      "Epoch [67/500], Loss: 1.5825, Accuracy: 0.3361\n",
      "Epoch [68/500], Loss: 1.5805, Accuracy: 0.3381\n",
      "Epoch [69/500], Loss: 1.5779, Accuracy: 0.3413\n",
      "Epoch [70/500], Loss: 1.5781, Accuracy: 0.3403\n",
      "Epoch [71/500], Loss: 1.5762, Accuracy: 0.3410\n",
      "Epoch [72/500], Loss: 1.5731, Accuracy: 0.3410\n",
      "Epoch [73/500], Loss: 1.5759, Accuracy: 0.3422\n",
      "Epoch [74/500], Loss: 1.5722, Accuracy: 0.3430\n",
      "Epoch [75/500], Loss: 1.5724, Accuracy: 0.3418\n",
      "Epoch [76/500], Loss: 1.5725, Accuracy: 0.3434\n",
      "Epoch [77/500], Loss: 1.5687, Accuracy: 0.3437\n",
      "Epoch [78/500], Loss: 1.5674, Accuracy: 0.3444\n",
      "Epoch [79/500], Loss: 1.5664, Accuracy: 0.3452\n",
      "Epoch [80/500], Loss: 1.5675, Accuracy: 0.3449\n",
      "Epoch [81/500], Loss: 1.5640, Accuracy: 0.3450\n",
      "Epoch [82/500], Loss: 1.5662, Accuracy: 0.3471\n",
      "Epoch [83/500], Loss: 1.5616, Accuracy: 0.3496\n",
      "Epoch [84/500], Loss: 1.5610, Accuracy: 0.3491\n",
      "Epoch [85/500], Loss: 1.5576, Accuracy: 0.3506\n",
      "Epoch [86/500], Loss: 1.5599, Accuracy: 0.3499\n",
      "Epoch [87/500], Loss: 1.5621, Accuracy: 0.3506\n",
      "Epoch [88/500], Loss: 1.5569, Accuracy: 0.3504\n",
      "Epoch [89/500], Loss: 1.5647, Accuracy: 0.3516\n",
      "Epoch [90/500], Loss: 1.5581, Accuracy: 0.3519\n",
      "Epoch [91/500], Loss: 1.5489, Accuracy: 0.3524\n",
      "Epoch [92/500], Loss: 1.5512, Accuracy: 0.3519\n",
      "Epoch [93/500], Loss: 1.5537, Accuracy: 0.3521\n",
      "Epoch [94/500], Loss: 1.5540, Accuracy: 0.3516\n",
      "Epoch [95/500], Loss: 1.5510, Accuracy: 0.3519\n",
      "Epoch [96/500], Loss: 1.5499, Accuracy: 0.3518\n",
      "Epoch [97/500], Loss: 1.5513, Accuracy: 0.3511\n",
      "Epoch [98/500], Loss: 1.5462, Accuracy: 0.3533\n",
      "Epoch [99/500], Loss: 1.5442, Accuracy: 0.3528\n",
      "Epoch [100/500], Loss: 1.5475, Accuracy: 0.3531\n",
      "Epoch [101/500], Loss: 1.5457, Accuracy: 0.3523\n",
      "Epoch [102/500], Loss: 1.5480, Accuracy: 0.3546\n",
      "Epoch [103/500], Loss: 1.5478, Accuracy: 0.3553\n",
      "Epoch [104/500], Loss: 1.5440, Accuracy: 0.3553\n",
      "Epoch [105/500], Loss: 1.5413, Accuracy: 0.3560\n",
      "Epoch [106/500], Loss: 1.5417, Accuracy: 0.3560\n",
      "Epoch [107/500], Loss: 1.5449, Accuracy: 0.3546\n",
      "Epoch [108/500], Loss: 1.5404, Accuracy: 0.3558\n",
      "Epoch [109/500], Loss: 1.5338, Accuracy: 0.3568\n",
      "Epoch [110/500], Loss: 1.5410, Accuracy: 0.3563\n",
      "Epoch [111/500], Loss: 1.5393, Accuracy: 0.3565\n",
      "Epoch [112/500], Loss: 1.5346, Accuracy: 0.3556\n",
      "Epoch [113/500], Loss: 1.5332, Accuracy: 0.3561\n",
      "Epoch [114/500], Loss: 1.5377, Accuracy: 0.3563\n",
      "Epoch [115/500], Loss: 1.5408, Accuracy: 0.3563\n",
      "Epoch [116/500], Loss: 1.5295, Accuracy: 0.3575\n",
      "Epoch [117/500], Loss: 1.5349, Accuracy: 0.3573\n",
      "Epoch [118/500], Loss: 1.5347, Accuracy: 0.3566\n",
      "Epoch [119/500], Loss: 1.5338, Accuracy: 0.3570\n",
      "Epoch [120/500], Loss: 1.5314, Accuracy: 0.3570\n",
      "Epoch [121/500], Loss: 1.5321, Accuracy: 0.3575\n",
      "Epoch [122/500], Loss: 1.5335, Accuracy: 0.3560\n",
      "Epoch [123/500], Loss: 1.5306, Accuracy: 0.3575\n",
      "Epoch [124/500], Loss: 1.5287, Accuracy: 0.3563\n",
      "Epoch [125/500], Loss: 1.5298, Accuracy: 0.3570\n",
      "Epoch [126/500], Loss: 1.5275, Accuracy: 0.3568\n",
      "Epoch [127/500], Loss: 1.5297, Accuracy: 0.3583\n",
      "Epoch [128/500], Loss: 1.5257, Accuracy: 0.3573\n",
      "Epoch [129/500], Loss: 1.5263, Accuracy: 0.3588\n",
      "Epoch [130/500], Loss: 1.5235, Accuracy: 0.3578\n",
      "Epoch [131/500], Loss: 1.5194, Accuracy: 0.3600\n",
      "Epoch [132/500], Loss: 1.5185, Accuracy: 0.3580\n",
      "Epoch [133/500], Loss: 1.5204, Accuracy: 0.3590\n",
      "Epoch [134/500], Loss: 1.5279, Accuracy: 0.3595\n",
      "Epoch [135/500], Loss: 1.5273, Accuracy: 0.3597\n",
      "Epoch [136/500], Loss: 1.5231, Accuracy: 0.3605\n",
      "Epoch [137/500], Loss: 1.5262, Accuracy: 0.3598\n",
      "Epoch [138/500], Loss: 1.5240, Accuracy: 0.3608\n",
      "Epoch [139/500], Loss: 1.5274, Accuracy: 0.3608\n",
      "Epoch [140/500], Loss: 1.5213, Accuracy: 0.3597\n",
      "Epoch [141/500], Loss: 1.5197, Accuracy: 0.3608\n",
      "Epoch [142/500], Loss: 1.5217, Accuracy: 0.3613\n",
      "Epoch [143/500], Loss: 1.5204, Accuracy: 0.3613\n",
      "Epoch [144/500], Loss: 1.5198, Accuracy: 0.3615\n",
      "Epoch [145/500], Loss: 1.5169, Accuracy: 0.3605\n",
      "Epoch [146/500], Loss: 1.5186, Accuracy: 0.3602\n",
      "Epoch [147/500], Loss: 1.5190, Accuracy: 0.3622\n",
      "Epoch [148/500], Loss: 1.5194, Accuracy: 0.3622\n",
      "Epoch [149/500], Loss: 1.5102, Accuracy: 0.3627\n",
      "Epoch [150/500], Loss: 1.5140, Accuracy: 0.3630\n",
      "Epoch [151/500], Loss: 1.5193, Accuracy: 0.3627\n",
      "Epoch [152/500], Loss: 1.5133, Accuracy: 0.3632\n",
      "Epoch [153/500], Loss: 1.5151, Accuracy: 0.3628\n",
      "Epoch [154/500], Loss: 1.5126, Accuracy: 0.3650\n",
      "Epoch [155/500], Loss: 1.5078, Accuracy: 0.3637\n",
      "Epoch [156/500], Loss: 1.5131, Accuracy: 0.3647\n",
      "Epoch [157/500], Loss: 1.5137, Accuracy: 0.3642\n",
      "Epoch [158/500], Loss: 1.5105, Accuracy: 0.3649\n",
      "Epoch [159/500], Loss: 1.5138, Accuracy: 0.3637\n",
      "Epoch [160/500], Loss: 1.5132, Accuracy: 0.3655\n",
      "Epoch [161/500], Loss: 1.5051, Accuracy: 0.3654\n",
      "Epoch [162/500], Loss: 1.5030, Accuracy: 0.3675\n",
      "Epoch [163/500], Loss: 1.5146, Accuracy: 0.3664\n",
      "Epoch [164/500], Loss: 1.5113, Accuracy: 0.3674\n",
      "Epoch [165/500], Loss: 1.5071, Accuracy: 0.3674\n",
      "Epoch [166/500], Loss: 1.5061, Accuracy: 0.3654\n",
      "Epoch [167/500], Loss: 1.5072, Accuracy: 0.3657\n",
      "Epoch [168/500], Loss: 1.5076, Accuracy: 0.3674\n",
      "Epoch [169/500], Loss: 1.5078, Accuracy: 0.3669\n",
      "Epoch [170/500], Loss: 1.5066, Accuracy: 0.3684\n",
      "Epoch [171/500], Loss: 1.5034, Accuracy: 0.3677\n",
      "Epoch [172/500], Loss: 1.5043, Accuracy: 0.3689\n",
      "Epoch [173/500], Loss: 1.5108, Accuracy: 0.3674\n",
      "Epoch [174/500], Loss: 1.5000, Accuracy: 0.3691\n",
      "Epoch [175/500], Loss: 1.5036, Accuracy: 0.3697\n",
      "Epoch [176/500], Loss: 1.5030, Accuracy: 0.3689\n",
      "Epoch [177/500], Loss: 1.5018, Accuracy: 0.3692\n",
      "Epoch [178/500], Loss: 1.5089, Accuracy: 0.3694\n",
      "Epoch [179/500], Loss: 1.5046, Accuracy: 0.3704\n",
      "Epoch [180/500], Loss: 1.5022, Accuracy: 0.3699\n",
      "Epoch [181/500], Loss: 1.5093, Accuracy: 0.3706\n",
      "Epoch [182/500], Loss: 1.4973, Accuracy: 0.3702\n",
      "Epoch [183/500], Loss: 1.5021, Accuracy: 0.3696\n",
      "Epoch [184/500], Loss: 1.4960, Accuracy: 0.3706\n",
      "Epoch [185/500], Loss: 1.4966, Accuracy: 0.3721\n",
      "Epoch [186/500], Loss: 1.5012, Accuracy: 0.3709\n",
      "Epoch [187/500], Loss: 1.4975, Accuracy: 0.3704\n",
      "Epoch [188/500], Loss: 1.5009, Accuracy: 0.3717\n",
      "Epoch [189/500], Loss: 1.4932, Accuracy: 0.3712\n",
      "Epoch [190/500], Loss: 1.5031, Accuracy: 0.3711\n",
      "Epoch [191/500], Loss: 1.4976, Accuracy: 0.3694\n",
      "Epoch [192/500], Loss: 1.4925, Accuracy: 0.3736\n",
      "Epoch [193/500], Loss: 1.4929, Accuracy: 0.3746\n",
      "Epoch [194/500], Loss: 1.4965, Accuracy: 0.3741\n",
      "Epoch [195/500], Loss: 1.4956, Accuracy: 0.3731\n",
      "Epoch [196/500], Loss: 1.4899, Accuracy: 0.3738\n",
      "Epoch [197/500], Loss: 1.4950, Accuracy: 0.3748\n",
      "Epoch [198/500], Loss: 1.4919, Accuracy: 0.3744\n",
      "Epoch [199/500], Loss: 1.4935, Accuracy: 0.3739\n",
      "Epoch [200/500], Loss: 1.4885, Accuracy: 0.3736\n",
      "Epoch [201/500], Loss: 1.4886, Accuracy: 0.3753\n",
      "Epoch [202/500], Loss: 1.4939, Accuracy: 0.3743\n",
      "Epoch [203/500], Loss: 1.4978, Accuracy: 0.3748\n",
      "Epoch [204/500], Loss: 1.4922, Accuracy: 0.3758\n",
      "Epoch [205/500], Loss: 1.4922, Accuracy: 0.3754\n",
      "Epoch [206/500], Loss: 1.4864, Accuracy: 0.3768\n",
      "Epoch [207/500], Loss: 1.4913, Accuracy: 0.3761\n",
      "Epoch [208/500], Loss: 1.4923, Accuracy: 0.3758\n",
      "Epoch [209/500], Loss: 1.4895, Accuracy: 0.3759\n",
      "Epoch [210/500], Loss: 1.4917, Accuracy: 0.3790\n",
      "Epoch [211/500], Loss: 1.4887, Accuracy: 0.3753\n",
      "Epoch [212/500], Loss: 1.4907, Accuracy: 0.3764\n",
      "Epoch [213/500], Loss: 1.4952, Accuracy: 0.3780\n",
      "Epoch [214/500], Loss: 1.4865, Accuracy: 0.3780\n",
      "Epoch [215/500], Loss: 1.4861, Accuracy: 0.3771\n",
      "Epoch [216/500], Loss: 1.4814, Accuracy: 0.3780\n",
      "Epoch [217/500], Loss: 1.4790, Accuracy: 0.3771\n",
      "Epoch [218/500], Loss: 1.4857, Accuracy: 0.3786\n",
      "Epoch [219/500], Loss: 1.4896, Accuracy: 0.3798\n",
      "Epoch [220/500], Loss: 1.4888, Accuracy: 0.3800\n",
      "Epoch [221/500], Loss: 1.4856, Accuracy: 0.3793\n",
      "Epoch [222/500], Loss: 1.4792, Accuracy: 0.3815\n",
      "Epoch [223/500], Loss: 1.4836, Accuracy: 0.3806\n",
      "Epoch [224/500], Loss: 1.4846, Accuracy: 0.3817\n",
      "Epoch [225/500], Loss: 1.4773, Accuracy: 0.3810\n",
      "Epoch [226/500], Loss: 1.4832, Accuracy: 0.3837\n",
      "Epoch [227/500], Loss: 1.4833, Accuracy: 0.3838\n",
      "Epoch [228/500], Loss: 1.4811, Accuracy: 0.3837\n",
      "Epoch [229/500], Loss: 1.4819, Accuracy: 0.3818\n",
      "Epoch [230/500], Loss: 1.4826, Accuracy: 0.3842\n",
      "Epoch [231/500], Loss: 1.4783, Accuracy: 0.3848\n",
      "Epoch [232/500], Loss: 1.4797, Accuracy: 0.3832\n",
      "Epoch [233/500], Loss: 1.4812, Accuracy: 0.3835\n",
      "Epoch [234/500], Loss: 1.4774, Accuracy: 0.3833\n",
      "Epoch [235/500], Loss: 1.4775, Accuracy: 0.3850\n",
      "Epoch [236/500], Loss: 1.4811, Accuracy: 0.3852\n",
      "Epoch [237/500], Loss: 1.4774, Accuracy: 0.3867\n",
      "Epoch [238/500], Loss: 1.4780, Accuracy: 0.3862\n",
      "Epoch [239/500], Loss: 1.4721, Accuracy: 0.3870\n",
      "Epoch [240/500], Loss: 1.4708, Accuracy: 0.3872\n",
      "Epoch [241/500], Loss: 1.4779, Accuracy: 0.3872\n",
      "Epoch [242/500], Loss: 1.4705, Accuracy: 0.3872\n",
      "Epoch [243/500], Loss: 1.4715, Accuracy: 0.3864\n",
      "Epoch [244/500], Loss: 1.4753, Accuracy: 0.3865\n",
      "Epoch [245/500], Loss: 1.4736, Accuracy: 0.3877\n",
      "Epoch [246/500], Loss: 1.4800, Accuracy: 0.3872\n",
      "Epoch [247/500], Loss: 1.4704, Accuracy: 0.3882\n",
      "Epoch [248/500], Loss: 1.4702, Accuracy: 0.3887\n",
      "Epoch [249/500], Loss: 1.4725, Accuracy: 0.3877\n",
      "Epoch [250/500], Loss: 1.4683, Accuracy: 0.3897\n",
      "Epoch [251/500], Loss: 1.4644, Accuracy: 0.3899\n",
      "Epoch [252/500], Loss: 1.4721, Accuracy: 0.3894\n",
      "Epoch [253/500], Loss: 1.4772, Accuracy: 0.3894\n",
      "Epoch [254/500], Loss: 1.4679, Accuracy: 0.3909\n",
      "Epoch [255/500], Loss: 1.4665, Accuracy: 0.3885\n",
      "Epoch [256/500], Loss: 1.4673, Accuracy: 0.3909\n",
      "Epoch [257/500], Loss: 1.4685, Accuracy: 0.3907\n",
      "Epoch [258/500], Loss: 1.4644, Accuracy: 0.3906\n",
      "Epoch [259/500], Loss: 1.4747, Accuracy: 0.3912\n",
      "Epoch [260/500], Loss: 1.4709, Accuracy: 0.3901\n",
      "Epoch [261/500], Loss: 1.4644, Accuracy: 0.3894\n",
      "Epoch [262/500], Loss: 1.4660, Accuracy: 0.3926\n",
      "Epoch [263/500], Loss: 1.4673, Accuracy: 0.3916\n",
      "Epoch [264/500], Loss: 1.4653, Accuracy: 0.3927\n",
      "Epoch [265/500], Loss: 1.4681, Accuracy: 0.3932\n",
      "Epoch [266/500], Loss: 1.4600, Accuracy: 0.3926\n",
      "Epoch [267/500], Loss: 1.4612, Accuracy: 0.3927\n",
      "Epoch [268/500], Loss: 1.4640, Accuracy: 0.3934\n",
      "Epoch [269/500], Loss: 1.4630, Accuracy: 0.3944\n",
      "Epoch [270/500], Loss: 1.4630, Accuracy: 0.3934\n",
      "Epoch [271/500], Loss: 1.4603, Accuracy: 0.3948\n",
      "Epoch [272/500], Loss: 1.4619, Accuracy: 0.3953\n",
      "Epoch [273/500], Loss: 1.4633, Accuracy: 0.3932\n",
      "Epoch [274/500], Loss: 1.4619, Accuracy: 0.3938\n",
      "Epoch [275/500], Loss: 1.4615, Accuracy: 0.3963\n",
      "Epoch [276/500], Loss: 1.4609, Accuracy: 0.3944\n",
      "Epoch [277/500], Loss: 1.4618, Accuracy: 0.3936\n",
      "Epoch [278/500], Loss: 1.4585, Accuracy: 0.3948\n",
      "Epoch [279/500], Loss: 1.4600, Accuracy: 0.3949\n",
      "Epoch [280/500], Loss: 1.4609, Accuracy: 0.3939\n",
      "Epoch [281/500], Loss: 1.4595, Accuracy: 0.3946\n",
      "Epoch [282/500], Loss: 1.4536, Accuracy: 0.3966\n",
      "Epoch [283/500], Loss: 1.4617, Accuracy: 0.3959\n",
      "Epoch [284/500], Loss: 1.4557, Accuracy: 0.3963\n",
      "Epoch [285/500], Loss: 1.4562, Accuracy: 0.3943\n",
      "Epoch [286/500], Loss: 1.4577, Accuracy: 0.3961\n",
      "Epoch [287/500], Loss: 1.4585, Accuracy: 0.3963\n",
      "Epoch [288/500], Loss: 1.4570, Accuracy: 0.3953\n",
      "Epoch [289/500], Loss: 1.4509, Accuracy: 0.3958\n",
      "Epoch [290/500], Loss: 1.4538, Accuracy: 0.3956\n",
      "Epoch [291/500], Loss: 1.4525, Accuracy: 0.3968\n",
      "Epoch [292/500], Loss: 1.4542, Accuracy: 0.3966\n",
      "Epoch [293/500], Loss: 1.4531, Accuracy: 0.3978\n",
      "Epoch [294/500], Loss: 1.4549, Accuracy: 0.3961\n",
      "Epoch [295/500], Loss: 1.4514, Accuracy: 0.3991\n",
      "Epoch [296/500], Loss: 1.4520, Accuracy: 0.3995\n",
      "Epoch [297/500], Loss: 1.4526, Accuracy: 0.3968\n",
      "Epoch [298/500], Loss: 1.4501, Accuracy: 0.3991\n",
      "Epoch [299/500], Loss: 1.4532, Accuracy: 0.3986\n",
      "Epoch [300/500], Loss: 1.4477, Accuracy: 0.3968\n",
      "Epoch [301/500], Loss: 1.4510, Accuracy: 0.3988\n",
      "Epoch [302/500], Loss: 1.4514, Accuracy: 0.4000\n",
      "Epoch [303/500], Loss: 1.4485, Accuracy: 0.3993\n",
      "Epoch [304/500], Loss: 1.4526, Accuracy: 0.4001\n",
      "Epoch [305/500], Loss: 1.4488, Accuracy: 0.4015\n",
      "Epoch [306/500], Loss: 1.4501, Accuracy: 0.4008\n",
      "Epoch [307/500], Loss: 1.4500, Accuracy: 0.4015\n",
      "Epoch [308/500], Loss: 1.4426, Accuracy: 0.4013\n",
      "Epoch [309/500], Loss: 1.4464, Accuracy: 0.4028\n",
      "Epoch [310/500], Loss: 1.4554, Accuracy: 0.4025\n",
      "Epoch [311/500], Loss: 1.4476, Accuracy: 0.4043\n",
      "Epoch [312/500], Loss: 1.4444, Accuracy: 0.4038\n",
      "Epoch [313/500], Loss: 1.4459, Accuracy: 0.4010\n",
      "Epoch [314/500], Loss: 1.4432, Accuracy: 0.4055\n",
      "Epoch [315/500], Loss: 1.4486, Accuracy: 0.4020\n",
      "Epoch [316/500], Loss: 1.4441, Accuracy: 0.4023\n",
      "Epoch [317/500], Loss: 1.4379, Accuracy: 0.4042\n",
      "Epoch [318/500], Loss: 1.4448, Accuracy: 0.4050\n",
      "Epoch [319/500], Loss: 1.4440, Accuracy: 0.4040\n",
      "Epoch [320/500], Loss: 1.4462, Accuracy: 0.4045\n",
      "Epoch [321/500], Loss: 1.4408, Accuracy: 0.4040\n",
      "Epoch [322/500], Loss: 1.4408, Accuracy: 0.4047\n",
      "Epoch [323/500], Loss: 1.4433, Accuracy: 0.4045\n",
      "Epoch [324/500], Loss: 1.4453, Accuracy: 0.4043\n",
      "Epoch [325/500], Loss: 1.4367, Accuracy: 0.4052\n",
      "Epoch [326/500], Loss: 1.4434, Accuracy: 0.4057\n",
      "Epoch [327/500], Loss: 1.4341, Accuracy: 0.4067\n",
      "Epoch [328/500], Loss: 1.4392, Accuracy: 0.4063\n",
      "Epoch [329/500], Loss: 1.4391, Accuracy: 0.4070\n",
      "Epoch [330/500], Loss: 1.4395, Accuracy: 0.4070\n",
      "Epoch [331/500], Loss: 1.4374, Accuracy: 0.4075\n",
      "Epoch [332/500], Loss: 1.4358, Accuracy: 0.4069\n",
      "Epoch [333/500], Loss: 1.4416, Accuracy: 0.4075\n",
      "Epoch [334/500], Loss: 1.4368, Accuracy: 0.4104\n",
      "Epoch [335/500], Loss: 1.4373, Accuracy: 0.4063\n",
      "Epoch [336/500], Loss: 1.4393, Accuracy: 0.4082\n",
      "Epoch [337/500], Loss: 1.4305, Accuracy: 0.4092\n",
      "Epoch [338/500], Loss: 1.4349, Accuracy: 0.4095\n",
      "Epoch [339/500], Loss: 1.4333, Accuracy: 0.4105\n",
      "Epoch [340/500], Loss: 1.4337, Accuracy: 0.4085\n",
      "Epoch [341/500], Loss: 1.4332, Accuracy: 0.4092\n",
      "Epoch [342/500], Loss: 1.4445, Accuracy: 0.4085\n",
      "Epoch [343/500], Loss: 1.4348, Accuracy: 0.4107\n",
      "Epoch [344/500], Loss: 1.4362, Accuracy: 0.4105\n",
      "Epoch [345/500], Loss: 1.4400, Accuracy: 0.4116\n",
      "Epoch [346/500], Loss: 1.4311, Accuracy: 0.4111\n",
      "Epoch [347/500], Loss: 1.4326, Accuracy: 0.4100\n",
      "Epoch [348/500], Loss: 1.4343, Accuracy: 0.4107\n",
      "Epoch [349/500], Loss: 1.4339, Accuracy: 0.4116\n",
      "Epoch [350/500], Loss: 1.4315, Accuracy: 0.4129\n",
      "Epoch [351/500], Loss: 1.4286, Accuracy: 0.4116\n",
      "Epoch [352/500], Loss: 1.4247, Accuracy: 0.4117\n",
      "Epoch [353/500], Loss: 1.4359, Accuracy: 0.4119\n",
      "Epoch [354/500], Loss: 1.4308, Accuracy: 0.4137\n",
      "Epoch [355/500], Loss: 1.4254, Accuracy: 0.4117\n",
      "Epoch [356/500], Loss: 1.4275, Accuracy: 0.4129\n",
      "Epoch [357/500], Loss: 1.4296, Accuracy: 0.4122\n",
      "Epoch [358/500], Loss: 1.4384, Accuracy: 0.4112\n",
      "Epoch [359/500], Loss: 1.4269, Accuracy: 0.4126\n",
      "Epoch [360/500], Loss: 1.4286, Accuracy: 0.4141\n",
      "Epoch [361/500], Loss: 1.4300, Accuracy: 0.4156\n",
      "Epoch [362/500], Loss: 1.4272, Accuracy: 0.4139\n",
      "Epoch [363/500], Loss: 1.4250, Accuracy: 0.4137\n",
      "Epoch [364/500], Loss: 1.4287, Accuracy: 0.4156\n",
      "Epoch [365/500], Loss: 1.4245, Accuracy: 0.4144\n",
      "Epoch [366/500], Loss: 1.4262, Accuracy: 0.4131\n",
      "Epoch [367/500], Loss: 1.4248, Accuracy: 0.4129\n",
      "Epoch [368/500], Loss: 1.4212, Accuracy: 0.4149\n",
      "Epoch [369/500], Loss: 1.4211, Accuracy: 0.4169\n",
      "Epoch [370/500], Loss: 1.4231, Accuracy: 0.4139\n",
      "Epoch [371/500], Loss: 1.4258, Accuracy: 0.4131\n",
      "Epoch [372/500], Loss: 1.4234, Accuracy: 0.4164\n",
      "Epoch [373/500], Loss: 1.4260, Accuracy: 0.4136\n",
      "Epoch [374/500], Loss: 1.4219, Accuracy: 0.4166\n",
      "Epoch [375/500], Loss: 1.4209, Accuracy: 0.4168\n",
      "Epoch [376/500], Loss: 1.4239, Accuracy: 0.4158\n",
      "Epoch [377/500], Loss: 1.4265, Accuracy: 0.4151\n",
      "Epoch [378/500], Loss: 1.4233, Accuracy: 0.4191\n",
      "Epoch [379/500], Loss: 1.4230, Accuracy: 0.4164\n",
      "Epoch [380/500], Loss: 1.4170, Accuracy: 0.4163\n",
      "Epoch [381/500], Loss: 1.4193, Accuracy: 0.4176\n",
      "Epoch [382/500], Loss: 1.4217, Accuracy: 0.4179\n",
      "Epoch [383/500], Loss: 1.4196, Accuracy: 0.4181\n",
      "Epoch [384/500], Loss: 1.4185, Accuracy: 0.4183\n",
      "Epoch [385/500], Loss: 1.4207, Accuracy: 0.4174\n",
      "Epoch [386/500], Loss: 1.4223, Accuracy: 0.4174\n",
      "Epoch [387/500], Loss: 1.4187, Accuracy: 0.4184\n",
      "Epoch [388/500], Loss: 1.4191, Accuracy: 0.4181\n",
      "Epoch [389/500], Loss: 1.4135, Accuracy: 0.4179\n",
      "Epoch [390/500], Loss: 1.4168, Accuracy: 0.4189\n",
      "Epoch [391/500], Loss: 1.4183, Accuracy: 0.4184\n",
      "Epoch [392/500], Loss: 1.4169, Accuracy: 0.4191\n",
      "Epoch [393/500], Loss: 1.4149, Accuracy: 0.4188\n",
      "Epoch [394/500], Loss: 1.4120, Accuracy: 0.4179\n",
      "Epoch [395/500], Loss: 1.4191, Accuracy: 0.4179\n",
      "Epoch [396/500], Loss: 1.4142, Accuracy: 0.4186\n",
      "Epoch [397/500], Loss: 1.4115, Accuracy: 0.4196\n",
      "Epoch [398/500], Loss: 1.4145, Accuracy: 0.4206\n",
      "Epoch [399/500], Loss: 1.4140, Accuracy: 0.4210\n",
      "Epoch [400/500], Loss: 1.4158, Accuracy: 0.4193\n",
      "Epoch [401/500], Loss: 1.4119, Accuracy: 0.4193\n",
      "Epoch [402/500], Loss: 1.4175, Accuracy: 0.4221\n",
      "Epoch [403/500], Loss: 1.4149, Accuracy: 0.4228\n",
      "Epoch [404/500], Loss: 1.4140, Accuracy: 0.4218\n",
      "Epoch [405/500], Loss: 1.4252, Accuracy: 0.4206\n",
      "Epoch [406/500], Loss: 1.4112, Accuracy: 0.4206\n",
      "Epoch [407/500], Loss: 1.4098, Accuracy: 0.4220\n",
      "Epoch [408/500], Loss: 1.4128, Accuracy: 0.4226\n",
      "Epoch [409/500], Loss: 1.4165, Accuracy: 0.4216\n",
      "Epoch [410/500], Loss: 1.4104, Accuracy: 0.4215\n",
      "Epoch [411/500], Loss: 1.4057, Accuracy: 0.4213\n",
      "Epoch [412/500], Loss: 1.4069, Accuracy: 0.4221\n",
      "Epoch [413/500], Loss: 1.4037, Accuracy: 0.4237\n",
      "Epoch [414/500], Loss: 1.4067, Accuracy: 0.4238\n",
      "Epoch [415/500], Loss: 1.4044, Accuracy: 0.4243\n",
      "Epoch [416/500], Loss: 1.4080, Accuracy: 0.4215\n",
      "Epoch [417/500], Loss: 1.4096, Accuracy: 0.4225\n",
      "Epoch [418/500], Loss: 1.4076, Accuracy: 0.4245\n",
      "Epoch [419/500], Loss: 1.4070, Accuracy: 0.4215\n",
      "Epoch [420/500], Loss: 1.4170, Accuracy: 0.4238\n",
      "Epoch [421/500], Loss: 1.4055, Accuracy: 0.4243\n",
      "Epoch [422/500], Loss: 1.4041, Accuracy: 0.4248\n",
      "Epoch [423/500], Loss: 1.4056, Accuracy: 0.4247\n",
      "Epoch [424/500], Loss: 1.3994, Accuracy: 0.4243\n",
      "Epoch [425/500], Loss: 1.4038, Accuracy: 0.4247\n",
      "Epoch [426/500], Loss: 1.4051, Accuracy: 0.4257\n",
      "Epoch [427/500], Loss: 1.4091, Accuracy: 0.4258\n",
      "Epoch [428/500], Loss: 1.3998, Accuracy: 0.4265\n",
      "Epoch [429/500], Loss: 1.4096, Accuracy: 0.4253\n",
      "Epoch [430/500], Loss: 1.4088, Accuracy: 0.4262\n",
      "Epoch [431/500], Loss: 1.4055, Accuracy: 0.4267\n",
      "Epoch [432/500], Loss: 1.4038, Accuracy: 0.4267\n",
      "Epoch [433/500], Loss: 1.4004, Accuracy: 0.4277\n",
      "Epoch [434/500], Loss: 1.3977, Accuracy: 0.4258\n",
      "Epoch [435/500], Loss: 1.4018, Accuracy: 0.4265\n",
      "Epoch [436/500], Loss: 1.3994, Accuracy: 0.4265\n",
      "Epoch [437/500], Loss: 1.3989, Accuracy: 0.4270\n",
      "Epoch [438/500], Loss: 1.4033, Accuracy: 0.4277\n",
      "Epoch [439/500], Loss: 1.3965, Accuracy: 0.4262\n",
      "Epoch [440/500], Loss: 1.4003, Accuracy: 0.4280\n",
      "Epoch [441/500], Loss: 1.4024, Accuracy: 0.4273\n",
      "Epoch [442/500], Loss: 1.3994, Accuracy: 0.4280\n",
      "Epoch [443/500], Loss: 1.3931, Accuracy: 0.4285\n",
      "Epoch [444/500], Loss: 1.3982, Accuracy: 0.4280\n",
      "Epoch [445/500], Loss: 1.4014, Accuracy: 0.4272\n",
      "Epoch [446/500], Loss: 1.4024, Accuracy: 0.4265\n",
      "Epoch [447/500], Loss: 1.4010, Accuracy: 0.4268\n",
      "Epoch [448/500], Loss: 1.3964, Accuracy: 0.4270\n",
      "Epoch [449/500], Loss: 1.3947, Accuracy: 0.4292\n",
      "Epoch [450/500], Loss: 1.4004, Accuracy: 0.4279\n",
      "Epoch [451/500], Loss: 1.3953, Accuracy: 0.4258\n",
      "Epoch [452/500], Loss: 1.3927, Accuracy: 0.4287\n",
      "Epoch [453/500], Loss: 1.3939, Accuracy: 0.4297\n",
      "Epoch [454/500], Loss: 1.3940, Accuracy: 0.4294\n",
      "Epoch [455/500], Loss: 1.3914, Accuracy: 0.4299\n",
      "Epoch [456/500], Loss: 1.3970, Accuracy: 0.4290\n",
      "Epoch [457/500], Loss: 1.3953, Accuracy: 0.4305\n",
      "Epoch [458/500], Loss: 1.3972, Accuracy: 0.4297\n",
      "Epoch [459/500], Loss: 1.3972, Accuracy: 0.4282\n",
      "Epoch [460/500], Loss: 1.3929, Accuracy: 0.4290\n",
      "Epoch [461/500], Loss: 1.3940, Accuracy: 0.4297\n",
      "Epoch [462/500], Loss: 1.3900, Accuracy: 0.4300\n",
      "Epoch [463/500], Loss: 1.3967, Accuracy: 0.4304\n",
      "Epoch [464/500], Loss: 1.3931, Accuracy: 0.4314\n",
      "Epoch [465/500], Loss: 1.3898, Accuracy: 0.4309\n",
      "Epoch [466/500], Loss: 1.3896, Accuracy: 0.4327\n",
      "Epoch [467/500], Loss: 1.3944, Accuracy: 0.4302\n",
      "Epoch [468/500], Loss: 1.3859, Accuracy: 0.4310\n",
      "Epoch [469/500], Loss: 1.4009, Accuracy: 0.4292\n",
      "Epoch [470/500], Loss: 1.3876, Accuracy: 0.4327\n",
      "Epoch [471/500], Loss: 1.3946, Accuracy: 0.4315\n",
      "Epoch [472/500], Loss: 1.3882, Accuracy: 0.4332\n",
      "Epoch [473/500], Loss: 1.3918, Accuracy: 0.4322\n",
      "Epoch [474/500], Loss: 1.3916, Accuracy: 0.4332\n",
      "Epoch [475/500], Loss: 1.3889, Accuracy: 0.4331\n",
      "Epoch [476/500], Loss: 1.3900, Accuracy: 0.4324\n",
      "Epoch [477/500], Loss: 1.3873, Accuracy: 0.4322\n",
      "Epoch [478/500], Loss: 1.3870, Accuracy: 0.4341\n",
      "Epoch [479/500], Loss: 1.3903, Accuracy: 0.4344\n",
      "Epoch [480/500], Loss: 1.3889, Accuracy: 0.4329\n",
      "Epoch [481/500], Loss: 1.3848, Accuracy: 0.4332\n",
      "Epoch [482/500], Loss: 1.3972, Accuracy: 0.4342\n",
      "Epoch [483/500], Loss: 1.3850, Accuracy: 0.4342\n",
      "Epoch [484/500], Loss: 1.3915, Accuracy: 0.4332\n",
      "Epoch [485/500], Loss: 1.3897, Accuracy: 0.4326\n",
      "Epoch [486/500], Loss: 1.3845, Accuracy: 0.4347\n",
      "Epoch [487/500], Loss: 1.3923, Accuracy: 0.4356\n",
      "Epoch [488/500], Loss: 1.3850, Accuracy: 0.4337\n",
      "Epoch [489/500], Loss: 1.3822, Accuracy: 0.4344\n",
      "Epoch [490/500], Loss: 1.3841, Accuracy: 0.4356\n",
      "Epoch [491/500], Loss: 1.3815, Accuracy: 0.4354\n",
      "Epoch [492/500], Loss: 1.3815, Accuracy: 0.4347\n",
      "Epoch [493/500], Loss: 1.3814, Accuracy: 0.4342\n",
      "Epoch [494/500], Loss: 1.3871, Accuracy: 0.4339\n",
      "Epoch [495/500], Loss: 1.3885, Accuracy: 0.4336\n",
      "Epoch [496/500], Loss: 1.3892, Accuracy: 0.4339\n",
      "Epoch [497/500], Loss: 1.3872, Accuracy: 0.4357\n",
      "Epoch [498/500], Loss: 1.3810, Accuracy: 0.4351\n",
      "Epoch [499/500], Loss: 1.3867, Accuracy: 0.4366\n",
      "Epoch [500/500], Loss: 1.3855, Accuracy: 0.4364\n"
     ]
    }
   ],
   "source": [
    "# LSTM with Attention\n",
    "lstm_atn_model = LSTMAttention(input_size[0], hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_atn_model.parameters(), lr=0.00001)\n",
    "train(lstm_atn_model, train_loaderLSTM, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 2.1224, Accuracy: 0.1608\n",
      "Epoch [2/500], Loss: 1.9625, Accuracy: 0.1727\n",
      "Epoch [3/500], Loss: 1.9240, Accuracy: 0.1658\n",
      "Epoch [4/500], Loss: 1.8756, Accuracy: 0.1668\n",
      "Epoch [5/500], Loss: 1.8542, Accuracy: 0.1666\n",
      "Epoch [6/500], Loss: 1.8194, Accuracy: 0.1824\n",
      "Epoch [7/500], Loss: 1.8137, Accuracy: 0.1828\n",
      "Epoch [8/500], Loss: 1.8091, Accuracy: 0.1777\n",
      "Epoch [9/500], Loss: 1.8013, Accuracy: 0.1816\n",
      "Epoch [10/500], Loss: 1.7891, Accuracy: 0.1923\n",
      "Epoch [11/500], Loss: 1.7803, Accuracy: 0.1964\n",
      "Epoch [12/500], Loss: 1.7760, Accuracy: 0.2002\n",
      "Epoch [13/500], Loss: 1.7729, Accuracy: 0.2065\n",
      "Epoch [14/500], Loss: 1.7656, Accuracy: 0.2222\n",
      "Epoch [15/500], Loss: 1.7613, Accuracy: 0.2148\n",
      "Epoch [16/500], Loss: 1.7595, Accuracy: 0.2147\n",
      "Epoch [17/500], Loss: 1.7570, Accuracy: 0.2343\n",
      "Epoch [18/500], Loss: 1.7503, Accuracy: 0.2419\n",
      "Epoch [19/500], Loss: 1.7456, Accuracy: 0.2441\n",
      "Epoch [20/500], Loss: 1.7459, Accuracy: 0.2466\n",
      "Epoch [21/500], Loss: 1.7418, Accuracy: 0.2478\n",
      "Epoch [22/500], Loss: 1.7335, Accuracy: 0.2656\n",
      "Epoch [23/500], Loss: 1.7295, Accuracy: 0.2525\n",
      "Epoch [24/500], Loss: 1.7253, Accuracy: 0.2767\n",
      "Epoch [25/500], Loss: 1.7195, Accuracy: 0.2671\n",
      "Epoch [26/500], Loss: 1.7074, Accuracy: 0.2820\n",
      "Epoch [27/500], Loss: 1.7103, Accuracy: 0.2701\n",
      "Epoch [28/500], Loss: 1.7043, Accuracy: 0.2721\n",
      "Epoch [29/500], Loss: 1.7042, Accuracy: 0.2723\n",
      "Epoch [30/500], Loss: 1.6933, Accuracy: 0.2825\n",
      "Epoch [31/500], Loss: 1.6900, Accuracy: 0.2852\n",
      "Epoch [32/500], Loss: 1.6835, Accuracy: 0.2898\n",
      "Epoch [33/500], Loss: 1.6847, Accuracy: 0.2874\n",
      "Epoch [34/500], Loss: 1.6789, Accuracy: 0.2844\n",
      "Epoch [35/500], Loss: 1.6664, Accuracy: 0.2881\n",
      "Epoch [36/500], Loss: 1.6764, Accuracy: 0.2874\n",
      "Epoch [37/500], Loss: 1.6674, Accuracy: 0.2889\n",
      "Epoch [38/500], Loss: 1.6742, Accuracy: 0.2985\n",
      "Epoch [39/500], Loss: 1.6643, Accuracy: 0.2968\n",
      "Epoch [40/500], Loss: 1.6598, Accuracy: 0.3004\n",
      "Epoch [41/500], Loss: 1.6602, Accuracy: 0.2951\n",
      "Epoch [42/500], Loss: 1.6571, Accuracy: 0.2987\n",
      "Epoch [43/500], Loss: 1.6552, Accuracy: 0.2967\n",
      "Epoch [44/500], Loss: 1.6421, Accuracy: 0.3039\n",
      "Epoch [45/500], Loss: 1.6583, Accuracy: 0.2977\n",
      "Epoch [46/500], Loss: 1.6448, Accuracy: 0.3062\n",
      "Epoch [47/500], Loss: 1.6477, Accuracy: 0.3072\n",
      "Epoch [48/500], Loss: 1.6443, Accuracy: 0.3150\n",
      "Epoch [49/500], Loss: 1.6386, Accuracy: 0.3040\n",
      "Epoch [50/500], Loss: 1.6467, Accuracy: 0.3064\n",
      "Epoch [51/500], Loss: 1.6382, Accuracy: 0.3099\n",
      "Epoch [52/500], Loss: 1.6356, Accuracy: 0.3054\n",
      "Epoch [53/500], Loss: 1.6292, Accuracy: 0.3175\n",
      "Epoch [54/500], Loss: 1.6174, Accuracy: 0.3140\n",
      "Epoch [55/500], Loss: 1.6305, Accuracy: 0.3163\n",
      "Epoch [56/500], Loss: 1.6303, Accuracy: 0.3067\n",
      "Epoch [57/500], Loss: 1.6245, Accuracy: 0.3111\n",
      "Epoch [58/500], Loss: 1.6245, Accuracy: 0.3197\n",
      "Epoch [59/500], Loss: 1.6235, Accuracy: 0.3096\n",
      "Epoch [60/500], Loss: 1.6217, Accuracy: 0.3074\n",
      "Epoch [61/500], Loss: 1.6216, Accuracy: 0.3182\n",
      "Epoch [62/500], Loss: 1.6210, Accuracy: 0.3148\n",
      "Epoch [63/500], Loss: 1.6200, Accuracy: 0.3198\n",
      "Epoch [64/500], Loss: 1.6161, Accuracy: 0.3163\n",
      "Epoch [65/500], Loss: 1.6135, Accuracy: 0.3156\n",
      "Epoch [66/500], Loss: 1.6168, Accuracy: 0.3123\n",
      "Epoch [67/500], Loss: 1.6147, Accuracy: 0.3188\n",
      "Epoch [68/500], Loss: 1.6131, Accuracy: 0.3108\n",
      "Epoch [69/500], Loss: 1.6130, Accuracy: 0.3202\n",
      "Epoch [70/500], Loss: 1.6137, Accuracy: 0.3205\n",
      "Epoch [71/500], Loss: 1.6129, Accuracy: 0.3141\n",
      "Epoch [72/500], Loss: 1.6104, Accuracy: 0.3215\n",
      "Epoch [73/500], Loss: 1.6120, Accuracy: 0.3086\n",
      "Epoch [74/500], Loss: 1.6122, Accuracy: 0.3214\n",
      "Epoch [75/500], Loss: 1.6129, Accuracy: 0.3247\n",
      "Epoch [76/500], Loss: 1.6037, Accuracy: 0.3200\n",
      "Epoch [77/500], Loss: 1.6112, Accuracy: 0.3180\n",
      "Epoch [78/500], Loss: 1.6071, Accuracy: 0.3232\n",
      "Epoch [79/500], Loss: 1.6078, Accuracy: 0.3210\n",
      "Epoch [80/500], Loss: 1.6021, Accuracy: 0.3222\n",
      "Epoch [81/500], Loss: 1.6016, Accuracy: 0.3192\n",
      "Epoch [82/500], Loss: 1.6021, Accuracy: 0.3301\n",
      "Epoch [83/500], Loss: 1.6035, Accuracy: 0.3217\n",
      "Epoch [84/500], Loss: 1.5915, Accuracy: 0.3292\n",
      "Epoch [85/500], Loss: 1.5989, Accuracy: 0.3271\n",
      "Epoch [86/500], Loss: 1.6012, Accuracy: 0.3205\n",
      "Epoch [87/500], Loss: 1.5953, Accuracy: 0.3294\n",
      "Epoch [88/500], Loss: 1.5978, Accuracy: 0.3247\n",
      "Epoch [89/500], Loss: 1.5984, Accuracy: 0.3230\n",
      "Epoch [90/500], Loss: 1.5917, Accuracy: 0.3247\n",
      "Epoch [91/500], Loss: 1.5924, Accuracy: 0.3309\n",
      "Epoch [92/500], Loss: 1.5985, Accuracy: 0.3245\n",
      "Epoch [93/500], Loss: 1.5940, Accuracy: 0.3289\n",
      "Epoch [94/500], Loss: 1.5923, Accuracy: 0.3303\n",
      "Epoch [95/500], Loss: 1.5956, Accuracy: 0.3252\n",
      "Epoch [96/500], Loss: 1.5949, Accuracy: 0.3281\n",
      "Epoch [97/500], Loss: 1.5889, Accuracy: 0.3279\n",
      "Epoch [98/500], Loss: 1.5843, Accuracy: 0.3306\n",
      "Epoch [99/500], Loss: 1.5860, Accuracy: 0.3284\n",
      "Epoch [100/500], Loss: 1.5920, Accuracy: 0.3284\n",
      "Epoch [101/500], Loss: 1.5920, Accuracy: 0.3250\n",
      "Epoch [102/500], Loss: 1.5888, Accuracy: 0.3259\n",
      "Epoch [103/500], Loss: 1.5871, Accuracy: 0.3348\n",
      "Epoch [104/500], Loss: 1.5812, Accuracy: 0.3346\n",
      "Epoch [105/500], Loss: 1.5853, Accuracy: 0.3329\n",
      "Epoch [106/500], Loss: 1.5839, Accuracy: 0.3266\n",
      "Epoch [107/500], Loss: 1.5863, Accuracy: 0.3269\n",
      "Epoch [108/500], Loss: 1.5830, Accuracy: 0.3329\n",
      "Epoch [109/500], Loss: 1.5761, Accuracy: 0.3299\n",
      "Epoch [110/500], Loss: 1.5807, Accuracy: 0.3316\n",
      "Epoch [111/500], Loss: 1.5784, Accuracy: 0.3353\n",
      "Epoch [112/500], Loss: 1.5807, Accuracy: 0.3323\n",
      "Epoch [113/500], Loss: 1.5812, Accuracy: 0.3328\n",
      "Epoch [114/500], Loss: 1.5741, Accuracy: 0.3346\n",
      "Epoch [115/500], Loss: 1.5798, Accuracy: 0.3397\n",
      "Epoch [116/500], Loss: 1.5730, Accuracy: 0.3326\n",
      "Epoch [117/500], Loss: 1.5779, Accuracy: 0.3333\n",
      "Epoch [118/500], Loss: 1.5753, Accuracy: 0.3363\n",
      "Epoch [119/500], Loss: 1.5760, Accuracy: 0.3366\n",
      "Epoch [120/500], Loss: 1.5782, Accuracy: 0.3397\n",
      "Epoch [121/500], Loss: 1.5722, Accuracy: 0.3289\n",
      "Epoch [122/500], Loss: 1.5831, Accuracy: 0.3353\n",
      "Epoch [123/500], Loss: 1.5767, Accuracy: 0.3329\n",
      "Epoch [124/500], Loss: 1.5705, Accuracy: 0.3408\n",
      "Epoch [125/500], Loss: 1.5659, Accuracy: 0.3397\n",
      "Epoch [126/500], Loss: 1.5713, Accuracy: 0.3371\n",
      "Epoch [127/500], Loss: 1.5636, Accuracy: 0.3407\n",
      "Epoch [128/500], Loss: 1.5694, Accuracy: 0.3375\n",
      "Epoch [129/500], Loss: 1.5705, Accuracy: 0.3360\n",
      "Epoch [130/500], Loss: 1.5733, Accuracy: 0.3368\n",
      "Epoch [131/500], Loss: 1.5642, Accuracy: 0.3403\n",
      "Epoch [132/500], Loss: 1.5683, Accuracy: 0.3427\n",
      "Epoch [133/500], Loss: 1.5730, Accuracy: 0.3371\n",
      "Epoch [134/500], Loss: 1.5595, Accuracy: 0.3387\n",
      "Epoch [135/500], Loss: 1.5703, Accuracy: 0.3378\n",
      "Epoch [136/500], Loss: 1.5704, Accuracy: 0.3353\n",
      "Epoch [137/500], Loss: 1.5679, Accuracy: 0.3491\n",
      "Epoch [138/500], Loss: 1.5663, Accuracy: 0.3373\n",
      "Epoch [139/500], Loss: 1.5660, Accuracy: 0.3397\n",
      "Epoch [140/500], Loss: 1.5636, Accuracy: 0.3430\n",
      "Epoch [141/500], Loss: 1.5717, Accuracy: 0.3370\n",
      "Epoch [142/500], Loss: 1.5640, Accuracy: 0.3437\n",
      "Epoch [143/500], Loss: 1.5616, Accuracy: 0.3449\n",
      "Epoch [144/500], Loss: 1.5642, Accuracy: 0.3393\n",
      "Epoch [145/500], Loss: 1.5609, Accuracy: 0.3502\n",
      "Epoch [146/500], Loss: 1.5619, Accuracy: 0.3387\n",
      "Epoch [147/500], Loss: 1.5594, Accuracy: 0.3434\n",
      "Epoch [148/500], Loss: 1.5561, Accuracy: 0.3422\n",
      "Epoch [149/500], Loss: 1.5560, Accuracy: 0.3457\n",
      "Epoch [150/500], Loss: 1.5557, Accuracy: 0.3519\n",
      "Epoch [151/500], Loss: 1.5587, Accuracy: 0.3501\n",
      "Epoch [152/500], Loss: 1.5606, Accuracy: 0.3393\n",
      "Epoch [153/500], Loss: 1.5610, Accuracy: 0.3390\n",
      "Epoch [154/500], Loss: 1.5587, Accuracy: 0.3484\n",
      "Epoch [155/500], Loss: 1.5612, Accuracy: 0.3437\n",
      "Epoch [156/500], Loss: 1.5613, Accuracy: 0.3440\n",
      "Epoch [157/500], Loss: 1.5616, Accuracy: 0.3514\n",
      "Epoch [158/500], Loss: 1.5559, Accuracy: 0.3501\n",
      "Epoch [159/500], Loss: 1.5567, Accuracy: 0.3427\n",
      "Epoch [160/500], Loss: 1.5558, Accuracy: 0.3445\n",
      "Epoch [161/500], Loss: 1.5507, Accuracy: 0.3454\n",
      "Epoch [162/500], Loss: 1.5550, Accuracy: 0.3494\n",
      "Epoch [163/500], Loss: 1.5566, Accuracy: 0.3455\n",
      "Epoch [164/500], Loss: 1.5584, Accuracy: 0.3487\n",
      "Epoch [165/500], Loss: 1.5532, Accuracy: 0.3415\n",
      "Epoch [166/500], Loss: 1.5554, Accuracy: 0.3482\n",
      "Epoch [167/500], Loss: 1.5488, Accuracy: 0.3492\n",
      "Epoch [168/500], Loss: 1.5559, Accuracy: 0.3434\n",
      "Epoch [169/500], Loss: 1.5520, Accuracy: 0.3417\n",
      "Epoch [170/500], Loss: 1.5535, Accuracy: 0.3506\n",
      "Epoch [171/500], Loss: 1.5457, Accuracy: 0.3511\n",
      "Epoch [172/500], Loss: 1.5445, Accuracy: 0.3474\n",
      "Epoch [173/500], Loss: 1.5557, Accuracy: 0.3484\n",
      "Epoch [174/500], Loss: 1.5517, Accuracy: 0.3460\n",
      "Epoch [175/500], Loss: 1.5519, Accuracy: 0.3514\n",
      "Epoch [176/500], Loss: 1.5527, Accuracy: 0.3487\n",
      "Epoch [177/500], Loss: 1.5567, Accuracy: 0.3502\n",
      "Epoch [178/500], Loss: 1.5475, Accuracy: 0.3556\n",
      "Epoch [179/500], Loss: 1.5469, Accuracy: 0.3526\n",
      "Epoch [180/500], Loss: 1.5451, Accuracy: 0.3544\n",
      "Epoch [181/500], Loss: 1.5493, Accuracy: 0.3570\n",
      "Epoch [182/500], Loss: 1.5443, Accuracy: 0.3445\n",
      "Epoch [183/500], Loss: 1.5455, Accuracy: 0.3454\n",
      "Epoch [184/500], Loss: 1.5430, Accuracy: 0.3571\n",
      "Epoch [185/500], Loss: 1.5480, Accuracy: 0.3511\n",
      "Epoch [186/500], Loss: 1.5469, Accuracy: 0.3472\n",
      "Epoch [187/500], Loss: 1.5418, Accuracy: 0.3607\n",
      "Epoch [188/500], Loss: 1.5373, Accuracy: 0.3531\n",
      "Epoch [189/500], Loss: 1.5401, Accuracy: 0.3597\n",
      "Epoch [190/500], Loss: 1.5481, Accuracy: 0.3528\n",
      "Epoch [191/500], Loss: 1.5428, Accuracy: 0.3524\n",
      "Epoch [192/500], Loss: 1.5461, Accuracy: 0.3578\n",
      "Epoch [193/500], Loss: 1.5363, Accuracy: 0.3605\n",
      "Epoch [194/500], Loss: 1.5480, Accuracy: 0.3536\n",
      "Epoch [195/500], Loss: 1.5426, Accuracy: 0.3553\n",
      "Epoch [196/500], Loss: 1.5393, Accuracy: 0.3534\n",
      "Epoch [197/500], Loss: 1.5433, Accuracy: 0.3518\n",
      "Epoch [198/500], Loss: 1.5355, Accuracy: 0.3570\n",
      "Epoch [199/500], Loss: 1.5411, Accuracy: 0.3502\n",
      "Epoch [200/500], Loss: 1.5358, Accuracy: 0.3531\n",
      "Epoch [201/500], Loss: 1.5306, Accuracy: 0.3576\n",
      "Epoch [202/500], Loss: 1.5369, Accuracy: 0.3578\n",
      "Epoch [203/500], Loss: 1.5395, Accuracy: 0.3523\n",
      "Epoch [204/500], Loss: 1.5446, Accuracy: 0.3524\n",
      "Epoch [205/500], Loss: 1.5337, Accuracy: 0.3607\n",
      "Epoch [206/500], Loss: 1.5370, Accuracy: 0.3578\n",
      "Epoch [207/500], Loss: 1.5376, Accuracy: 0.3536\n",
      "Epoch [208/500], Loss: 1.5426, Accuracy: 0.3501\n",
      "Epoch [209/500], Loss: 1.5362, Accuracy: 0.3590\n",
      "Epoch [210/500], Loss: 1.5402, Accuracy: 0.3610\n",
      "Epoch [211/500], Loss: 1.5406, Accuracy: 0.3571\n",
      "Epoch [212/500], Loss: 1.5368, Accuracy: 0.3534\n",
      "Epoch [213/500], Loss: 1.5331, Accuracy: 0.3607\n",
      "Epoch [214/500], Loss: 1.5349, Accuracy: 0.3603\n",
      "Epoch [215/500], Loss: 1.5248, Accuracy: 0.3519\n",
      "Epoch [216/500], Loss: 1.5294, Accuracy: 0.3602\n",
      "Epoch [217/500], Loss: 1.5295, Accuracy: 0.3578\n",
      "Epoch [218/500], Loss: 1.5301, Accuracy: 0.3548\n",
      "Epoch [219/500], Loss: 1.5400, Accuracy: 0.3556\n",
      "Epoch [220/500], Loss: 1.5322, Accuracy: 0.3553\n",
      "Epoch [221/500], Loss: 1.5407, Accuracy: 0.3561\n",
      "Epoch [222/500], Loss: 1.5235, Accuracy: 0.3649\n",
      "Epoch [223/500], Loss: 1.5334, Accuracy: 0.3549\n",
      "Epoch [224/500], Loss: 1.5359, Accuracy: 0.3657\n",
      "Epoch [225/500], Loss: 1.5448, Accuracy: 0.3536\n",
      "Epoch [226/500], Loss: 1.5431, Accuracy: 0.3561\n",
      "Epoch [227/500], Loss: 1.5355, Accuracy: 0.3585\n",
      "Epoch [228/500], Loss: 1.5266, Accuracy: 0.3640\n",
      "Epoch [229/500], Loss: 1.5312, Accuracy: 0.3586\n",
      "Epoch [230/500], Loss: 1.5341, Accuracy: 0.3560\n",
      "Epoch [231/500], Loss: 1.5333, Accuracy: 0.3551\n",
      "Epoch [232/500], Loss: 1.5253, Accuracy: 0.3684\n",
      "Epoch [233/500], Loss: 1.5320, Accuracy: 0.3558\n",
      "Epoch [234/500], Loss: 1.5262, Accuracy: 0.3707\n",
      "Epoch [235/500], Loss: 1.5286, Accuracy: 0.3691\n",
      "Epoch [236/500], Loss: 1.5230, Accuracy: 0.3605\n",
      "Epoch [237/500], Loss: 1.5248, Accuracy: 0.3647\n",
      "Epoch [238/500], Loss: 1.5190, Accuracy: 0.3617\n",
      "Epoch [239/500], Loss: 1.5286, Accuracy: 0.3630\n",
      "Epoch [240/500], Loss: 1.5240, Accuracy: 0.3639\n",
      "Epoch [241/500], Loss: 1.5223, Accuracy: 0.3672\n",
      "Epoch [242/500], Loss: 1.5266, Accuracy: 0.3682\n",
      "Epoch [243/500], Loss: 1.5200, Accuracy: 0.3657\n",
      "Epoch [244/500], Loss: 1.5227, Accuracy: 0.3669\n",
      "Epoch [245/500], Loss: 1.5242, Accuracy: 0.3586\n",
      "Epoch [246/500], Loss: 1.5257, Accuracy: 0.3701\n",
      "Epoch [247/500], Loss: 1.5291, Accuracy: 0.3657\n",
      "Epoch [248/500], Loss: 1.5242, Accuracy: 0.3623\n",
      "Epoch [249/500], Loss: 1.5195, Accuracy: 0.3654\n",
      "Epoch [250/500], Loss: 1.5280, Accuracy: 0.3686\n",
      "Epoch [251/500], Loss: 1.5302, Accuracy: 0.3644\n",
      "Epoch [252/500], Loss: 1.5251, Accuracy: 0.3647\n",
      "Epoch [253/500], Loss: 1.5244, Accuracy: 0.3613\n",
      "Epoch [254/500], Loss: 1.5290, Accuracy: 0.3630\n",
      "Epoch [255/500], Loss: 1.5169, Accuracy: 0.3719\n",
      "Epoch [256/500], Loss: 1.5324, Accuracy: 0.3591\n",
      "Epoch [257/500], Loss: 1.5262, Accuracy: 0.3711\n",
      "Epoch [258/500], Loss: 1.5248, Accuracy: 0.3588\n",
      "Epoch [259/500], Loss: 1.5246, Accuracy: 0.3633\n",
      "Epoch [260/500], Loss: 1.5195, Accuracy: 0.3612\n",
      "Epoch [261/500], Loss: 1.5246, Accuracy: 0.3706\n",
      "Epoch [262/500], Loss: 1.5165, Accuracy: 0.3639\n",
      "Epoch [263/500], Loss: 1.5236, Accuracy: 0.3602\n",
      "Epoch [264/500], Loss: 1.5263, Accuracy: 0.3635\n",
      "Epoch [265/500], Loss: 1.5226, Accuracy: 0.3644\n",
      "Epoch [266/500], Loss: 1.5248, Accuracy: 0.3680\n",
      "Epoch [267/500], Loss: 1.5118, Accuracy: 0.3706\n",
      "Epoch [268/500], Loss: 1.5163, Accuracy: 0.3689\n",
      "Epoch [269/500], Loss: 1.5169, Accuracy: 0.3753\n",
      "Epoch [270/500], Loss: 1.5126, Accuracy: 0.3605\n",
      "Epoch [271/500], Loss: 1.5192, Accuracy: 0.3644\n",
      "Epoch [272/500], Loss: 1.5170, Accuracy: 0.3667\n",
      "Epoch [273/500], Loss: 1.5253, Accuracy: 0.3672\n",
      "Epoch [274/500], Loss: 1.5119, Accuracy: 0.3640\n",
      "Epoch [275/500], Loss: 1.5180, Accuracy: 0.3672\n",
      "Epoch [276/500], Loss: 1.5184, Accuracy: 0.3647\n",
      "Epoch [277/500], Loss: 1.5121, Accuracy: 0.3711\n",
      "Epoch [278/500], Loss: 1.5202, Accuracy: 0.3597\n",
      "Epoch [279/500], Loss: 1.5141, Accuracy: 0.3739\n",
      "Epoch [280/500], Loss: 1.5144, Accuracy: 0.3644\n",
      "Epoch [281/500], Loss: 1.5229, Accuracy: 0.3669\n",
      "Epoch [282/500], Loss: 1.5198, Accuracy: 0.3622\n",
      "Epoch [283/500], Loss: 1.5247, Accuracy: 0.3721\n",
      "Epoch [284/500], Loss: 1.5130, Accuracy: 0.3721\n",
      "Epoch [285/500], Loss: 1.5155, Accuracy: 0.3630\n",
      "Epoch [286/500], Loss: 1.5146, Accuracy: 0.3686\n",
      "Epoch [287/500], Loss: 1.5206, Accuracy: 0.3689\n",
      "Epoch [288/500], Loss: 1.5082, Accuracy: 0.3717\n",
      "Epoch [289/500], Loss: 1.5169, Accuracy: 0.3644\n",
      "Epoch [290/500], Loss: 1.5106, Accuracy: 0.3716\n",
      "Epoch [291/500], Loss: 1.5128, Accuracy: 0.3699\n",
      "Epoch [292/500], Loss: 1.5110, Accuracy: 0.3748\n",
      "Epoch [293/500], Loss: 1.5137, Accuracy: 0.3664\n",
      "Epoch [294/500], Loss: 1.5041, Accuracy: 0.3679\n",
      "Epoch [295/500], Loss: 1.5098, Accuracy: 0.3704\n",
      "Epoch [296/500], Loss: 1.5145, Accuracy: 0.3632\n",
      "Epoch [297/500], Loss: 1.5124, Accuracy: 0.3654\n",
      "Epoch [298/500], Loss: 1.5153, Accuracy: 0.3650\n",
      "Epoch [299/500], Loss: 1.5114, Accuracy: 0.3667\n",
      "Epoch [300/500], Loss: 1.5059, Accuracy: 0.3669\n",
      "Epoch [301/500], Loss: 1.5149, Accuracy: 0.3699\n",
      "Epoch [302/500], Loss: 1.5120, Accuracy: 0.3759\n",
      "Epoch [303/500], Loss: 1.5098, Accuracy: 0.3707\n",
      "Epoch [304/500], Loss: 1.5055, Accuracy: 0.3820\n",
      "Epoch [305/500], Loss: 1.5089, Accuracy: 0.3749\n",
      "Epoch [306/500], Loss: 1.5104, Accuracy: 0.3756\n",
      "Epoch [307/500], Loss: 1.5132, Accuracy: 0.3684\n",
      "Epoch [308/500], Loss: 1.5096, Accuracy: 0.3714\n",
      "Epoch [309/500], Loss: 1.5143, Accuracy: 0.3625\n",
      "Epoch [310/500], Loss: 1.5092, Accuracy: 0.3743\n",
      "Epoch [311/500], Loss: 1.5055, Accuracy: 0.3776\n",
      "Epoch [312/500], Loss: 1.5049, Accuracy: 0.3714\n",
      "Epoch [313/500], Loss: 1.5126, Accuracy: 0.3644\n",
      "Epoch [314/500], Loss: 1.5122, Accuracy: 0.3647\n",
      "Epoch [315/500], Loss: 1.5082, Accuracy: 0.3744\n",
      "Epoch [316/500], Loss: 1.5094, Accuracy: 0.3717\n",
      "Epoch [317/500], Loss: 1.5094, Accuracy: 0.3781\n",
      "Epoch [318/500], Loss: 1.5112, Accuracy: 0.3699\n",
      "Epoch [319/500], Loss: 1.5014, Accuracy: 0.3758\n",
      "Epoch [320/500], Loss: 1.4972, Accuracy: 0.3763\n",
      "Epoch [321/500], Loss: 1.5080, Accuracy: 0.3759\n",
      "Epoch [322/500], Loss: 1.5117, Accuracy: 0.3696\n",
      "Epoch [323/500], Loss: 1.5090, Accuracy: 0.3696\n",
      "Epoch [324/500], Loss: 1.5124, Accuracy: 0.3627\n",
      "Epoch [325/500], Loss: 1.5060, Accuracy: 0.3738\n",
      "Epoch [326/500], Loss: 1.5113, Accuracy: 0.3689\n",
      "Epoch [327/500], Loss: 1.5051, Accuracy: 0.3743\n",
      "Epoch [328/500], Loss: 1.5115, Accuracy: 0.3728\n",
      "Epoch [329/500], Loss: 1.5040, Accuracy: 0.3775\n",
      "Epoch [330/500], Loss: 1.5101, Accuracy: 0.3711\n",
      "Epoch [331/500], Loss: 1.5054, Accuracy: 0.3756\n",
      "Epoch [332/500], Loss: 1.5009, Accuracy: 0.3766\n",
      "Epoch [333/500], Loss: 1.5033, Accuracy: 0.3786\n",
      "Epoch [334/500], Loss: 1.4972, Accuracy: 0.3729\n",
      "Epoch [335/500], Loss: 1.4973, Accuracy: 0.3724\n",
      "Epoch [336/500], Loss: 1.5026, Accuracy: 0.3729\n",
      "Epoch [337/500], Loss: 1.5077, Accuracy: 0.3680\n",
      "Epoch [338/500], Loss: 1.5040, Accuracy: 0.3753\n",
      "Epoch [339/500], Loss: 1.4954, Accuracy: 0.3780\n",
      "Epoch [340/500], Loss: 1.5066, Accuracy: 0.3702\n",
      "Epoch [341/500], Loss: 1.4983, Accuracy: 0.3763\n",
      "Epoch [342/500], Loss: 1.4898, Accuracy: 0.3817\n",
      "Epoch [343/500], Loss: 1.4957, Accuracy: 0.3709\n",
      "Epoch [344/500], Loss: 1.4977, Accuracy: 0.3775\n",
      "Epoch [345/500], Loss: 1.5021, Accuracy: 0.3754\n",
      "Epoch [346/500], Loss: 1.4997, Accuracy: 0.3825\n",
      "Epoch [347/500], Loss: 1.4988, Accuracy: 0.3748\n",
      "Epoch [348/500], Loss: 1.4970, Accuracy: 0.3773\n",
      "Epoch [349/500], Loss: 1.4908, Accuracy: 0.3785\n",
      "Epoch [350/500], Loss: 1.5017, Accuracy: 0.3691\n",
      "Epoch [351/500], Loss: 1.5075, Accuracy: 0.3726\n",
      "Epoch [352/500], Loss: 1.4946, Accuracy: 0.3795\n",
      "Epoch [353/500], Loss: 1.4963, Accuracy: 0.3781\n",
      "Epoch [354/500], Loss: 1.5012, Accuracy: 0.3719\n",
      "Epoch [355/500], Loss: 1.5053, Accuracy: 0.3773\n",
      "Epoch [356/500], Loss: 1.4964, Accuracy: 0.3798\n",
      "Epoch [357/500], Loss: 1.5021, Accuracy: 0.3761\n",
      "Epoch [358/500], Loss: 1.4969, Accuracy: 0.3728\n",
      "Epoch [359/500], Loss: 1.5040, Accuracy: 0.3741\n",
      "Epoch [360/500], Loss: 1.5007, Accuracy: 0.3806\n",
      "Epoch [361/500], Loss: 1.4977, Accuracy: 0.3795\n",
      "Epoch [362/500], Loss: 1.4931, Accuracy: 0.3857\n",
      "Epoch [363/500], Loss: 1.5017, Accuracy: 0.3785\n",
      "Epoch [364/500], Loss: 1.4983, Accuracy: 0.3758\n",
      "Epoch [365/500], Loss: 1.4957, Accuracy: 0.3788\n",
      "Epoch [366/500], Loss: 1.4862, Accuracy: 0.3790\n",
      "Epoch [367/500], Loss: 1.4857, Accuracy: 0.3827\n",
      "Epoch [368/500], Loss: 1.5013, Accuracy: 0.3689\n",
      "Epoch [369/500], Loss: 1.4925, Accuracy: 0.3813\n",
      "Epoch [370/500], Loss: 1.5042, Accuracy: 0.3771\n",
      "Epoch [371/500], Loss: 1.4990, Accuracy: 0.3795\n",
      "Epoch [372/500], Loss: 1.4920, Accuracy: 0.3823\n",
      "Epoch [373/500], Loss: 1.4856, Accuracy: 0.3808\n",
      "Epoch [374/500], Loss: 1.4949, Accuracy: 0.3828\n",
      "Epoch [375/500], Loss: 1.4988, Accuracy: 0.3768\n",
      "Epoch [376/500], Loss: 1.4914, Accuracy: 0.3771\n",
      "Epoch [377/500], Loss: 1.4899, Accuracy: 0.3798\n",
      "Epoch [378/500], Loss: 1.4986, Accuracy: 0.3828\n",
      "Epoch [379/500], Loss: 1.4919, Accuracy: 0.3806\n",
      "Epoch [380/500], Loss: 1.4901, Accuracy: 0.3795\n",
      "Epoch [381/500], Loss: 1.4982, Accuracy: 0.3850\n",
      "Epoch [382/500], Loss: 1.4938, Accuracy: 0.3785\n",
      "Epoch [383/500], Loss: 1.4857, Accuracy: 0.3808\n",
      "Epoch [384/500], Loss: 1.4908, Accuracy: 0.3822\n",
      "Epoch [385/500], Loss: 1.5038, Accuracy: 0.3776\n",
      "Epoch [386/500], Loss: 1.4859, Accuracy: 0.3803\n",
      "Epoch [387/500], Loss: 1.4989, Accuracy: 0.3766\n",
      "Epoch [388/500], Loss: 1.4932, Accuracy: 0.3806\n",
      "Epoch [389/500], Loss: 1.4929, Accuracy: 0.3788\n",
      "Epoch [390/500], Loss: 1.4870, Accuracy: 0.3775\n",
      "Epoch [391/500], Loss: 1.4937, Accuracy: 0.3766\n",
      "Epoch [392/500], Loss: 1.4907, Accuracy: 0.3805\n",
      "Epoch [393/500], Loss: 1.4866, Accuracy: 0.3825\n",
      "Epoch [394/500], Loss: 1.4971, Accuracy: 0.3790\n",
      "Epoch [395/500], Loss: 1.4938, Accuracy: 0.3766\n",
      "Epoch [396/500], Loss: 1.4950, Accuracy: 0.3827\n",
      "Epoch [397/500], Loss: 1.4901, Accuracy: 0.3796\n",
      "Epoch [398/500], Loss: 1.4883, Accuracy: 0.3820\n",
      "Epoch [399/500], Loss: 1.4938, Accuracy: 0.3859\n",
      "Epoch [400/500], Loss: 1.4925, Accuracy: 0.3870\n",
      "Epoch [401/500], Loss: 1.4887, Accuracy: 0.3837\n",
      "Epoch [402/500], Loss: 1.4987, Accuracy: 0.3731\n",
      "Epoch [403/500], Loss: 1.4841, Accuracy: 0.3835\n",
      "Epoch [404/500], Loss: 1.4828, Accuracy: 0.3842\n",
      "Epoch [405/500], Loss: 1.4865, Accuracy: 0.3842\n",
      "Epoch [406/500], Loss: 1.4840, Accuracy: 0.3798\n",
      "Epoch [407/500], Loss: 1.4869, Accuracy: 0.3790\n",
      "Epoch [408/500], Loss: 1.4896, Accuracy: 0.3749\n",
      "Epoch [409/500], Loss: 1.4869, Accuracy: 0.3879\n",
      "Epoch [410/500], Loss: 1.4844, Accuracy: 0.3892\n",
      "Epoch [411/500], Loss: 1.4865, Accuracy: 0.3852\n",
      "Epoch [412/500], Loss: 1.4875, Accuracy: 0.3780\n",
      "Epoch [413/500], Loss: 1.4932, Accuracy: 0.3726\n",
      "Epoch [414/500], Loss: 1.4918, Accuracy: 0.3749\n",
      "Epoch [415/500], Loss: 1.4765, Accuracy: 0.3786\n",
      "Epoch [416/500], Loss: 1.4833, Accuracy: 0.3843\n",
      "Epoch [417/500], Loss: 1.4836, Accuracy: 0.3833\n",
      "Epoch [418/500], Loss: 1.4841, Accuracy: 0.3775\n",
      "Epoch [419/500], Loss: 1.4888, Accuracy: 0.3778\n",
      "Epoch [420/500], Loss: 1.4898, Accuracy: 0.3837\n",
      "Epoch [421/500], Loss: 1.4835, Accuracy: 0.3837\n",
      "Epoch [422/500], Loss: 1.4897, Accuracy: 0.3808\n",
      "Epoch [423/500], Loss: 1.4870, Accuracy: 0.3904\n",
      "Epoch [424/500], Loss: 1.4839, Accuracy: 0.3817\n",
      "Epoch [425/500], Loss: 1.4862, Accuracy: 0.3874\n",
      "Epoch [426/500], Loss: 1.4811, Accuracy: 0.3770\n",
      "Epoch [427/500], Loss: 1.4821, Accuracy: 0.3879\n",
      "Epoch [428/500], Loss: 1.4844, Accuracy: 0.3842\n",
      "Epoch [429/500], Loss: 1.4884, Accuracy: 0.3882\n",
      "Epoch [430/500], Loss: 1.4886, Accuracy: 0.3843\n",
      "Epoch [431/500], Loss: 1.4931, Accuracy: 0.3808\n",
      "Epoch [432/500], Loss: 1.4865, Accuracy: 0.3817\n",
      "Epoch [433/500], Loss: 1.4889, Accuracy: 0.3875\n",
      "Epoch [434/500], Loss: 1.4892, Accuracy: 0.3780\n",
      "Epoch [435/500], Loss: 1.4789, Accuracy: 0.3904\n",
      "Epoch [436/500], Loss: 1.4863, Accuracy: 0.3835\n",
      "Epoch [437/500], Loss: 1.4828, Accuracy: 0.3850\n",
      "Epoch [438/500], Loss: 1.4767, Accuracy: 0.3860\n",
      "Epoch [439/500], Loss: 1.4830, Accuracy: 0.3790\n",
      "Epoch [440/500], Loss: 1.4813, Accuracy: 0.3795\n",
      "Epoch [441/500], Loss: 1.4892, Accuracy: 0.3852\n",
      "Epoch [442/500], Loss: 1.4797, Accuracy: 0.3901\n",
      "Epoch [443/500], Loss: 1.4784, Accuracy: 0.3874\n",
      "Epoch [444/500], Loss: 1.4782, Accuracy: 0.3902\n",
      "Epoch [445/500], Loss: 1.4791, Accuracy: 0.3874\n",
      "Epoch [446/500], Loss: 1.4845, Accuracy: 0.3815\n",
      "Epoch [447/500], Loss: 1.4833, Accuracy: 0.3798\n",
      "Epoch [448/500], Loss: 1.4781, Accuracy: 0.3865\n",
      "Epoch [449/500], Loss: 1.4829, Accuracy: 0.3870\n",
      "Epoch [450/500], Loss: 1.4860, Accuracy: 0.3781\n",
      "Epoch [451/500], Loss: 1.4791, Accuracy: 0.3875\n",
      "Epoch [452/500], Loss: 1.4792, Accuracy: 0.3838\n",
      "Epoch [453/500], Loss: 1.4772, Accuracy: 0.3845\n",
      "Epoch [454/500], Loss: 1.4758, Accuracy: 0.3850\n",
      "Epoch [455/500], Loss: 1.4814, Accuracy: 0.3859\n",
      "Epoch [456/500], Loss: 1.4751, Accuracy: 0.3921\n",
      "Epoch [457/500], Loss: 1.4802, Accuracy: 0.3820\n",
      "Epoch [458/500], Loss: 1.4781, Accuracy: 0.3808\n",
      "Epoch [459/500], Loss: 1.4788, Accuracy: 0.3837\n",
      "Epoch [460/500], Loss: 1.4752, Accuracy: 0.3869\n",
      "Epoch [461/500], Loss: 1.4824, Accuracy: 0.3842\n",
      "Epoch [462/500], Loss: 1.4772, Accuracy: 0.3830\n",
      "Epoch [463/500], Loss: 1.4810, Accuracy: 0.3788\n",
      "Epoch [464/500], Loss: 1.4832, Accuracy: 0.3862\n",
      "Epoch [465/500], Loss: 1.4840, Accuracy: 0.3823\n",
      "Epoch [466/500], Loss: 1.4717, Accuracy: 0.3892\n",
      "Epoch [467/500], Loss: 1.4708, Accuracy: 0.3901\n",
      "Epoch [468/500], Loss: 1.4747, Accuracy: 0.3911\n",
      "Epoch [469/500], Loss: 1.4770, Accuracy: 0.3867\n",
      "Epoch [470/500], Loss: 1.4766, Accuracy: 0.3927\n",
      "Epoch [471/500], Loss: 1.4751, Accuracy: 0.3922\n",
      "Epoch [472/500], Loss: 1.4782, Accuracy: 0.3877\n",
      "Epoch [473/500], Loss: 1.4700, Accuracy: 0.3904\n",
      "Epoch [474/500], Loss: 1.4717, Accuracy: 0.3877\n",
      "Epoch [475/500], Loss: 1.4709, Accuracy: 0.3877\n",
      "Epoch [476/500], Loss: 1.4763, Accuracy: 0.3917\n",
      "Epoch [477/500], Loss: 1.4810, Accuracy: 0.3931\n",
      "Epoch [478/500], Loss: 1.4757, Accuracy: 0.3902\n",
      "Epoch [479/500], Loss: 1.4925, Accuracy: 0.3796\n",
      "Epoch [480/500], Loss: 1.4759, Accuracy: 0.3835\n",
      "Epoch [481/500], Loss: 1.4756, Accuracy: 0.3932\n",
      "Epoch [482/500], Loss: 1.4814, Accuracy: 0.3862\n",
      "Epoch [483/500], Loss: 1.4793, Accuracy: 0.3825\n",
      "Epoch [484/500], Loss: 1.4720, Accuracy: 0.4000\n",
      "Epoch [485/500], Loss: 1.4766, Accuracy: 0.3857\n",
      "Epoch [486/500], Loss: 1.4745, Accuracy: 0.3904\n",
      "Epoch [487/500], Loss: 1.4743, Accuracy: 0.3887\n",
      "Epoch [488/500], Loss: 1.4719, Accuracy: 0.3828\n",
      "Epoch [489/500], Loss: 1.4752, Accuracy: 0.3916\n",
      "Epoch [490/500], Loss: 1.4745, Accuracy: 0.3902\n",
      "Epoch [491/500], Loss: 1.4791, Accuracy: 0.3909\n",
      "Epoch [492/500], Loss: 1.4733, Accuracy: 0.3894\n",
      "Epoch [493/500], Loss: 1.4662, Accuracy: 0.3912\n",
      "Epoch [494/500], Loss: 1.4783, Accuracy: 0.3892\n",
      "Epoch [495/500], Loss: 1.4782, Accuracy: 0.3887\n",
      "Epoch [496/500], Loss: 1.4760, Accuracy: 0.3837\n",
      "Epoch [497/500], Loss: 1.4692, Accuracy: 0.3884\n",
      "Epoch [498/500], Loss: 1.4660, Accuracy: 0.3951\n",
      "Epoch [499/500], Loss: 1.4722, Accuracy: 0.3980\n",
      "Epoch [500/500], Loss: 1.4734, Accuracy: 0.3880\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network\n",
    "cnn_model = CNNModel(input_size[0],num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.00001)\n",
    "train(cnn_model, train_loaderCNN, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 3.8311, Accuracy: 0.1698\n",
      "Epoch [2/500], Loss: 2.5819, Accuracy: 0.1698\n",
      "Epoch [3/500], Loss: 2.0658, Accuracy: 0.1698\n",
      "Epoch [4/500], Loss: 1.8669, Accuracy: 0.1720\n",
      "Epoch [5/500], Loss: 1.8025, Accuracy: 0.2053\n",
      "Epoch [6/500], Loss: 1.7774, Accuracy: 0.2699\n",
      "Epoch [7/500], Loss: 1.7615, Accuracy: 0.2735\n",
      "Epoch [8/500], Loss: 1.7472, Accuracy: 0.2745\n",
      "Epoch [9/500], Loss: 1.7268, Accuracy: 0.2834\n",
      "Epoch [10/500], Loss: 1.7102, Accuracy: 0.2926\n",
      "Epoch [11/500], Loss: 1.6971, Accuracy: 0.2978\n",
      "Epoch [12/500], Loss: 1.6880, Accuracy: 0.3007\n",
      "Epoch [13/500], Loss: 1.6794, Accuracy: 0.3059\n",
      "Epoch [14/500], Loss: 1.6700, Accuracy: 0.3099\n",
      "Epoch [15/500], Loss: 1.6621, Accuracy: 0.3066\n",
      "Epoch [16/500], Loss: 1.6550, Accuracy: 0.3094\n",
      "Epoch [17/500], Loss: 1.6469, Accuracy: 0.3151\n",
      "Epoch [18/500], Loss: 1.6397, Accuracy: 0.3131\n",
      "Epoch [19/500], Loss: 1.6362, Accuracy: 0.3160\n",
      "Epoch [20/500], Loss: 1.6326, Accuracy: 0.3150\n",
      "Epoch [21/500], Loss: 1.6298, Accuracy: 0.3200\n",
      "Epoch [22/500], Loss: 1.6229, Accuracy: 0.3232\n",
      "Epoch [23/500], Loss: 1.6196, Accuracy: 0.3242\n",
      "Epoch [24/500], Loss: 1.6101, Accuracy: 0.3242\n",
      "Epoch [25/500], Loss: 1.6073, Accuracy: 0.3279\n",
      "Epoch [26/500], Loss: 1.6063, Accuracy: 0.3239\n",
      "Epoch [27/500], Loss: 1.5978, Accuracy: 0.3308\n",
      "Epoch [28/500], Loss: 1.5991, Accuracy: 0.3313\n",
      "Epoch [29/500], Loss: 1.5993, Accuracy: 0.3303\n",
      "Epoch [30/500], Loss: 1.5951, Accuracy: 0.3328\n",
      "Epoch [31/500], Loss: 1.5921, Accuracy: 0.3353\n",
      "Epoch [32/500], Loss: 1.5910, Accuracy: 0.3346\n",
      "Epoch [33/500], Loss: 1.5858, Accuracy: 0.3348\n",
      "Epoch [34/500], Loss: 1.5849, Accuracy: 0.3361\n",
      "Epoch [35/500], Loss: 1.5912, Accuracy: 0.3381\n",
      "Epoch [36/500], Loss: 1.5812, Accuracy: 0.3370\n",
      "Epoch [37/500], Loss: 1.5785, Accuracy: 0.3368\n",
      "Epoch [38/500], Loss: 1.5797, Accuracy: 0.3383\n",
      "Epoch [39/500], Loss: 1.5749, Accuracy: 0.3398\n",
      "Epoch [40/500], Loss: 1.5717, Accuracy: 0.3410\n",
      "Epoch [41/500], Loss: 1.5655, Accuracy: 0.3420\n",
      "Epoch [42/500], Loss: 1.5699, Accuracy: 0.3450\n",
      "Epoch [43/500], Loss: 1.5666, Accuracy: 0.3403\n",
      "Epoch [44/500], Loss: 1.5675, Accuracy: 0.3429\n",
      "Epoch [45/500], Loss: 1.5674, Accuracy: 0.3423\n",
      "Epoch [46/500], Loss: 1.5572, Accuracy: 0.3460\n",
      "Epoch [47/500], Loss: 1.5628, Accuracy: 0.3462\n",
      "Epoch [48/500], Loss: 1.5647, Accuracy: 0.3454\n",
      "Epoch [49/500], Loss: 1.5613, Accuracy: 0.3482\n",
      "Epoch [50/500], Loss: 1.5577, Accuracy: 0.3524\n",
      "Epoch [51/500], Loss: 1.5649, Accuracy: 0.3486\n",
      "Epoch [52/500], Loss: 1.5584, Accuracy: 0.3492\n",
      "Epoch [53/500], Loss: 1.5554, Accuracy: 0.3489\n",
      "Epoch [54/500], Loss: 1.5520, Accuracy: 0.3511\n",
      "Epoch [55/500], Loss: 1.5590, Accuracy: 0.3492\n",
      "Epoch [56/500], Loss: 1.5579, Accuracy: 0.3519\n",
      "Epoch [57/500], Loss: 1.5511, Accuracy: 0.3523\n",
      "Epoch [58/500], Loss: 1.5490, Accuracy: 0.3551\n",
      "Epoch [59/500], Loss: 1.5473, Accuracy: 0.3526\n",
      "Epoch [60/500], Loss: 1.5492, Accuracy: 0.3561\n",
      "Epoch [61/500], Loss: 1.5487, Accuracy: 0.3560\n",
      "Epoch [62/500], Loss: 1.5485, Accuracy: 0.3583\n",
      "Epoch [63/500], Loss: 1.5456, Accuracy: 0.3556\n",
      "Epoch [64/500], Loss: 1.5460, Accuracy: 0.3565\n",
      "Epoch [65/500], Loss: 1.5442, Accuracy: 0.3561\n",
      "Epoch [66/500], Loss: 1.5420, Accuracy: 0.3598\n",
      "Epoch [67/500], Loss: 1.5457, Accuracy: 0.3588\n",
      "Epoch [68/500], Loss: 1.5410, Accuracy: 0.3598\n",
      "Epoch [69/500], Loss: 1.5378, Accuracy: 0.3622\n",
      "Epoch [70/500], Loss: 1.5384, Accuracy: 0.3608\n",
      "Epoch [71/500], Loss: 1.5333, Accuracy: 0.3590\n",
      "Epoch [72/500], Loss: 1.5315, Accuracy: 0.3602\n",
      "Epoch [73/500], Loss: 1.5317, Accuracy: 0.3602\n",
      "Epoch [74/500], Loss: 1.5377, Accuracy: 0.3605\n",
      "Epoch [75/500], Loss: 1.5290, Accuracy: 0.3622\n",
      "Epoch [76/500], Loss: 1.5357, Accuracy: 0.3612\n",
      "Epoch [77/500], Loss: 1.5370, Accuracy: 0.3608\n",
      "Epoch [78/500], Loss: 1.5354, Accuracy: 0.3660\n",
      "Epoch [79/500], Loss: 1.5349, Accuracy: 0.3637\n",
      "Epoch [80/500], Loss: 1.5317, Accuracy: 0.3608\n",
      "Epoch [81/500], Loss: 1.5314, Accuracy: 0.3617\n",
      "Epoch [82/500], Loss: 1.5284, Accuracy: 0.3664\n",
      "Epoch [83/500], Loss: 1.5296, Accuracy: 0.3639\n",
      "Epoch [84/500], Loss: 1.5289, Accuracy: 0.3645\n",
      "Epoch [85/500], Loss: 1.5327, Accuracy: 0.3605\n",
      "Epoch [86/500], Loss: 1.5281, Accuracy: 0.3625\n",
      "Epoch [87/500], Loss: 1.5264, Accuracy: 0.3660\n",
      "Epoch [88/500], Loss: 1.5251, Accuracy: 0.3647\n",
      "Epoch [89/500], Loss: 1.5254, Accuracy: 0.3657\n",
      "Epoch [90/500], Loss: 1.5267, Accuracy: 0.3652\n",
      "Epoch [91/500], Loss: 1.5292, Accuracy: 0.3642\n",
      "Epoch [92/500], Loss: 1.5236, Accuracy: 0.3615\n",
      "Epoch [93/500], Loss: 1.5216, Accuracy: 0.3612\n",
      "Epoch [94/500], Loss: 1.5240, Accuracy: 0.3647\n",
      "Epoch [95/500], Loss: 1.5222, Accuracy: 0.3684\n",
      "Epoch [96/500], Loss: 1.5221, Accuracy: 0.3655\n",
      "Epoch [97/500], Loss: 1.5218, Accuracy: 0.3670\n",
      "Epoch [98/500], Loss: 1.5311, Accuracy: 0.3660\n",
      "Epoch [99/500], Loss: 1.5203, Accuracy: 0.3659\n",
      "Epoch [100/500], Loss: 1.5206, Accuracy: 0.3699\n",
      "Epoch [101/500], Loss: 1.5183, Accuracy: 0.3682\n",
      "Epoch [102/500], Loss: 1.5191, Accuracy: 0.3677\n",
      "Epoch [103/500], Loss: 1.5172, Accuracy: 0.3660\n",
      "Epoch [104/500], Loss: 1.5160, Accuracy: 0.3680\n",
      "Epoch [105/500], Loss: 1.5156, Accuracy: 0.3660\n",
      "Epoch [106/500], Loss: 1.5141, Accuracy: 0.3682\n",
      "Epoch [107/500], Loss: 1.5147, Accuracy: 0.3714\n",
      "Epoch [108/500], Loss: 1.5091, Accuracy: 0.3702\n",
      "Epoch [109/500], Loss: 1.5164, Accuracy: 0.3684\n",
      "Epoch [110/500], Loss: 1.5114, Accuracy: 0.3696\n",
      "Epoch [111/500], Loss: 1.5147, Accuracy: 0.3714\n",
      "Epoch [112/500], Loss: 1.5163, Accuracy: 0.3699\n",
      "Epoch [113/500], Loss: 1.5076, Accuracy: 0.3687\n",
      "Epoch [114/500], Loss: 1.5088, Accuracy: 0.3717\n",
      "Epoch [115/500], Loss: 1.5082, Accuracy: 0.3739\n",
      "Epoch [116/500], Loss: 1.5082, Accuracy: 0.3721\n",
      "Epoch [117/500], Loss: 1.5180, Accuracy: 0.3749\n",
      "Epoch [118/500], Loss: 1.5062, Accuracy: 0.3731\n",
      "Epoch [119/500], Loss: 1.5047, Accuracy: 0.3734\n",
      "Epoch [120/500], Loss: 1.5064, Accuracy: 0.3726\n",
      "Epoch [121/500], Loss: 1.5081, Accuracy: 0.3707\n",
      "Epoch [122/500], Loss: 1.5063, Accuracy: 0.3766\n",
      "Epoch [123/500], Loss: 1.5036, Accuracy: 0.3734\n",
      "Epoch [124/500], Loss: 1.5037, Accuracy: 0.3736\n",
      "Epoch [125/500], Loss: 1.5033, Accuracy: 0.3748\n",
      "Epoch [126/500], Loss: 1.5027, Accuracy: 0.3753\n",
      "Epoch [127/500], Loss: 1.5019, Accuracy: 0.3744\n",
      "Epoch [128/500], Loss: 1.4990, Accuracy: 0.3763\n",
      "Epoch [129/500], Loss: 1.5012, Accuracy: 0.3726\n",
      "Epoch [130/500], Loss: 1.4945, Accuracy: 0.3768\n",
      "Epoch [131/500], Loss: 1.5013, Accuracy: 0.3768\n",
      "Epoch [132/500], Loss: 1.5011, Accuracy: 0.3778\n",
      "Epoch [133/500], Loss: 1.4956, Accuracy: 0.3776\n",
      "Epoch [134/500], Loss: 1.4990, Accuracy: 0.3733\n",
      "Epoch [135/500], Loss: 1.4940, Accuracy: 0.3770\n",
      "Epoch [136/500], Loss: 1.4992, Accuracy: 0.3773\n",
      "Epoch [137/500], Loss: 1.4980, Accuracy: 0.3798\n",
      "Epoch [138/500], Loss: 1.4955, Accuracy: 0.3766\n",
      "Epoch [139/500], Loss: 1.4984, Accuracy: 0.3818\n",
      "Epoch [140/500], Loss: 1.4947, Accuracy: 0.3815\n",
      "Epoch [141/500], Loss: 1.4900, Accuracy: 0.3783\n",
      "Epoch [142/500], Loss: 1.4973, Accuracy: 0.3793\n",
      "Epoch [143/500], Loss: 1.4970, Accuracy: 0.3832\n",
      "Epoch [144/500], Loss: 1.4935, Accuracy: 0.3768\n",
      "Epoch [145/500], Loss: 1.4948, Accuracy: 0.3823\n",
      "Epoch [146/500], Loss: 1.5030, Accuracy: 0.3808\n",
      "Epoch [147/500], Loss: 1.4941, Accuracy: 0.3812\n",
      "Epoch [148/500], Loss: 1.4919, Accuracy: 0.3827\n",
      "Epoch [149/500], Loss: 1.4921, Accuracy: 0.3828\n",
      "Epoch [150/500], Loss: 1.4923, Accuracy: 0.3832\n",
      "Epoch [151/500], Loss: 1.4867, Accuracy: 0.3812\n",
      "Epoch [152/500], Loss: 1.4901, Accuracy: 0.3815\n",
      "Epoch [153/500], Loss: 1.4912, Accuracy: 0.3838\n",
      "Epoch [154/500], Loss: 1.4892, Accuracy: 0.3823\n",
      "Epoch [155/500], Loss: 1.4937, Accuracy: 0.3848\n",
      "Epoch [156/500], Loss: 1.4882, Accuracy: 0.3825\n",
      "Epoch [157/500], Loss: 1.4857, Accuracy: 0.3847\n",
      "Epoch [158/500], Loss: 1.4876, Accuracy: 0.3855\n",
      "Epoch [159/500], Loss: 1.4891, Accuracy: 0.3838\n",
      "Epoch [160/500], Loss: 1.4856, Accuracy: 0.3837\n",
      "Epoch [161/500], Loss: 1.4901, Accuracy: 0.3870\n",
      "Epoch [162/500], Loss: 1.4815, Accuracy: 0.3843\n",
      "Epoch [163/500], Loss: 1.4794, Accuracy: 0.3840\n",
      "Epoch [164/500], Loss: 1.4849, Accuracy: 0.3862\n",
      "Epoch [165/500], Loss: 1.4826, Accuracy: 0.3855\n",
      "Epoch [166/500], Loss: 1.4808, Accuracy: 0.3867\n",
      "Epoch [167/500], Loss: 1.4831, Accuracy: 0.3862\n",
      "Epoch [168/500], Loss: 1.4786, Accuracy: 0.3850\n",
      "Epoch [169/500], Loss: 1.4765, Accuracy: 0.3887\n",
      "Epoch [170/500], Loss: 1.4766, Accuracy: 0.3864\n",
      "Epoch [171/500], Loss: 1.4758, Accuracy: 0.3845\n",
      "Epoch [172/500], Loss: 1.4819, Accuracy: 0.3869\n",
      "Epoch [173/500], Loss: 1.4804, Accuracy: 0.3885\n",
      "Epoch [174/500], Loss: 1.4722, Accuracy: 0.3825\n",
      "Epoch [175/500], Loss: 1.4717, Accuracy: 0.3854\n",
      "Epoch [176/500], Loss: 1.4770, Accuracy: 0.3909\n",
      "Epoch [177/500], Loss: 1.4748, Accuracy: 0.3890\n",
      "Epoch [178/500], Loss: 1.4753, Accuracy: 0.3899\n",
      "Epoch [179/500], Loss: 1.4791, Accuracy: 0.3892\n",
      "Epoch [180/500], Loss: 1.4767, Accuracy: 0.3892\n",
      "Epoch [181/500], Loss: 1.4748, Accuracy: 0.3880\n",
      "Epoch [182/500], Loss: 1.4725, Accuracy: 0.3877\n",
      "Epoch [183/500], Loss: 1.4746, Accuracy: 0.3912\n",
      "Epoch [184/500], Loss: 1.4732, Accuracy: 0.3926\n",
      "Epoch [185/500], Loss: 1.4730, Accuracy: 0.3911\n",
      "Epoch [186/500], Loss: 1.4733, Accuracy: 0.3902\n",
      "Epoch [187/500], Loss: 1.4664, Accuracy: 0.3931\n",
      "Epoch [188/500], Loss: 1.4694, Accuracy: 0.3914\n",
      "Epoch [189/500], Loss: 1.4811, Accuracy: 0.3926\n",
      "Epoch [190/500], Loss: 1.4687, Accuracy: 0.3902\n",
      "Epoch [191/500], Loss: 1.4752, Accuracy: 0.3936\n",
      "Epoch [192/500], Loss: 1.4689, Accuracy: 0.3924\n",
      "Epoch [193/500], Loss: 1.4706, Accuracy: 0.3936\n",
      "Epoch [194/500], Loss: 1.4732, Accuracy: 0.3906\n",
      "Epoch [195/500], Loss: 1.4685, Accuracy: 0.3932\n",
      "Epoch [196/500], Loss: 1.4671, Accuracy: 0.3926\n",
      "Epoch [197/500], Loss: 1.4698, Accuracy: 0.3954\n",
      "Epoch [198/500], Loss: 1.4683, Accuracy: 0.3926\n",
      "Epoch [199/500], Loss: 1.4695, Accuracy: 0.3926\n",
      "Epoch [200/500], Loss: 1.4643, Accuracy: 0.3932\n",
      "Epoch [201/500], Loss: 1.4653, Accuracy: 0.3941\n",
      "Epoch [202/500], Loss: 1.4659, Accuracy: 0.3932\n",
      "Epoch [203/500], Loss: 1.4670, Accuracy: 0.3934\n",
      "Epoch [204/500], Loss: 1.4636, Accuracy: 0.3943\n",
      "Epoch [205/500], Loss: 1.4618, Accuracy: 0.3949\n",
      "Epoch [206/500], Loss: 1.4653, Accuracy: 0.3936\n",
      "Epoch [207/500], Loss: 1.4665, Accuracy: 0.3971\n",
      "Epoch [208/500], Loss: 1.4648, Accuracy: 0.3929\n",
      "Epoch [209/500], Loss: 1.4628, Accuracy: 0.3944\n",
      "Epoch [210/500], Loss: 1.4623, Accuracy: 0.3958\n",
      "Epoch [211/500], Loss: 1.4642, Accuracy: 0.3954\n",
      "Epoch [212/500], Loss: 1.4634, Accuracy: 0.3991\n",
      "Epoch [213/500], Loss: 1.4620, Accuracy: 0.3973\n",
      "Epoch [214/500], Loss: 1.4609, Accuracy: 0.3983\n",
      "Epoch [215/500], Loss: 1.4611, Accuracy: 0.3958\n",
      "Epoch [216/500], Loss: 1.4674, Accuracy: 0.3983\n",
      "Epoch [217/500], Loss: 1.4555, Accuracy: 0.3991\n",
      "Epoch [218/500], Loss: 1.4587, Accuracy: 0.3971\n",
      "Epoch [219/500], Loss: 1.4613, Accuracy: 0.4000\n",
      "Epoch [220/500], Loss: 1.4639, Accuracy: 0.3995\n",
      "Epoch [221/500], Loss: 1.4592, Accuracy: 0.4011\n",
      "Epoch [222/500], Loss: 1.4605, Accuracy: 0.3993\n",
      "Epoch [223/500], Loss: 1.4564, Accuracy: 0.3983\n",
      "Epoch [224/500], Loss: 1.4569, Accuracy: 0.4020\n",
      "Epoch [225/500], Loss: 1.4551, Accuracy: 0.3974\n",
      "Epoch [226/500], Loss: 1.4571, Accuracy: 0.3996\n",
      "Epoch [227/500], Loss: 1.4499, Accuracy: 0.3986\n",
      "Epoch [228/500], Loss: 1.4589, Accuracy: 0.4016\n",
      "Epoch [229/500], Loss: 1.4565, Accuracy: 0.3990\n",
      "Epoch [230/500], Loss: 1.4557, Accuracy: 0.4023\n",
      "Epoch [231/500], Loss: 1.4512, Accuracy: 0.4008\n",
      "Epoch [232/500], Loss: 1.4512, Accuracy: 0.4020\n",
      "Epoch [233/500], Loss: 1.4558, Accuracy: 0.4022\n",
      "Epoch [234/500], Loss: 1.4533, Accuracy: 0.4008\n",
      "Epoch [235/500], Loss: 1.4490, Accuracy: 0.4023\n",
      "Epoch [236/500], Loss: 1.4544, Accuracy: 0.4016\n",
      "Epoch [237/500], Loss: 1.4533, Accuracy: 0.4045\n",
      "Epoch [238/500], Loss: 1.4530, Accuracy: 0.4006\n",
      "Epoch [239/500], Loss: 1.4514, Accuracy: 0.4010\n",
      "Epoch [240/500], Loss: 1.4554, Accuracy: 0.4047\n",
      "Epoch [241/500], Loss: 1.4501, Accuracy: 0.4000\n",
      "Epoch [242/500], Loss: 1.4547, Accuracy: 0.4038\n",
      "Epoch [243/500], Loss: 1.4470, Accuracy: 0.4023\n",
      "Epoch [244/500], Loss: 1.4513, Accuracy: 0.4035\n",
      "Epoch [245/500], Loss: 1.4496, Accuracy: 0.4072\n",
      "Epoch [246/500], Loss: 1.4450, Accuracy: 0.4045\n",
      "Epoch [247/500], Loss: 1.4504, Accuracy: 0.4020\n",
      "Epoch [248/500], Loss: 1.4459, Accuracy: 0.4047\n",
      "Epoch [249/500], Loss: 1.4436, Accuracy: 0.4052\n",
      "Epoch [250/500], Loss: 1.4494, Accuracy: 0.4055\n",
      "Epoch [251/500], Loss: 1.4483, Accuracy: 0.4050\n",
      "Epoch [252/500], Loss: 1.4487, Accuracy: 0.4053\n",
      "Epoch [253/500], Loss: 1.4465, Accuracy: 0.4027\n",
      "Epoch [254/500], Loss: 1.4444, Accuracy: 0.4008\n",
      "Epoch [255/500], Loss: 1.4404, Accuracy: 0.4043\n",
      "Epoch [256/500], Loss: 1.4436, Accuracy: 0.4085\n",
      "Epoch [257/500], Loss: 1.4455, Accuracy: 0.4058\n",
      "Epoch [258/500], Loss: 1.4437, Accuracy: 0.4069\n",
      "Epoch [259/500], Loss: 1.4387, Accuracy: 0.4072\n",
      "Epoch [260/500], Loss: 1.4430, Accuracy: 0.4082\n",
      "Epoch [261/500], Loss: 1.4531, Accuracy: 0.4060\n",
      "Epoch [262/500], Loss: 1.4442, Accuracy: 0.4027\n",
      "Epoch [263/500], Loss: 1.4423, Accuracy: 0.4065\n",
      "Epoch [264/500], Loss: 1.4452, Accuracy: 0.4074\n",
      "Epoch [265/500], Loss: 1.4462, Accuracy: 0.4030\n",
      "Epoch [266/500], Loss: 1.4426, Accuracy: 0.4040\n",
      "Epoch [267/500], Loss: 1.4439, Accuracy: 0.4053\n",
      "Epoch [268/500], Loss: 1.4451, Accuracy: 0.4057\n",
      "Epoch [269/500], Loss: 1.4438, Accuracy: 0.4084\n",
      "Epoch [270/500], Loss: 1.4398, Accuracy: 0.4092\n",
      "Epoch [271/500], Loss: 1.4449, Accuracy: 0.4085\n",
      "Epoch [272/500], Loss: 1.4372, Accuracy: 0.4082\n",
      "Epoch [273/500], Loss: 1.4420, Accuracy: 0.4105\n",
      "Epoch [274/500], Loss: 1.4404, Accuracy: 0.4090\n",
      "Epoch [275/500], Loss: 1.4429, Accuracy: 0.4089\n",
      "Epoch [276/500], Loss: 1.4408, Accuracy: 0.4072\n",
      "Epoch [277/500], Loss: 1.4372, Accuracy: 0.4090\n",
      "Epoch [278/500], Loss: 1.4386, Accuracy: 0.4072\n",
      "Epoch [279/500], Loss: 1.4429, Accuracy: 0.4100\n",
      "Epoch [280/500], Loss: 1.4406, Accuracy: 0.4097\n",
      "Epoch [281/500], Loss: 1.4358, Accuracy: 0.4095\n",
      "Epoch [282/500], Loss: 1.4391, Accuracy: 0.4112\n",
      "Epoch [283/500], Loss: 1.4380, Accuracy: 0.4097\n",
      "Epoch [284/500], Loss: 1.4408, Accuracy: 0.4104\n",
      "Epoch [285/500], Loss: 1.4426, Accuracy: 0.4100\n",
      "Epoch [286/500], Loss: 1.4369, Accuracy: 0.4094\n",
      "Epoch [287/500], Loss: 1.4326, Accuracy: 0.4107\n",
      "Epoch [288/500], Loss: 1.4374, Accuracy: 0.4104\n",
      "Epoch [289/500], Loss: 1.4387, Accuracy: 0.4102\n",
      "Epoch [290/500], Loss: 1.4345, Accuracy: 0.4100\n",
      "Epoch [291/500], Loss: 1.4364, Accuracy: 0.4109\n",
      "Epoch [292/500], Loss: 1.4297, Accuracy: 0.4087\n",
      "Epoch [293/500], Loss: 1.4362, Accuracy: 0.4104\n",
      "Epoch [294/500], Loss: 1.4334, Accuracy: 0.4117\n",
      "Epoch [295/500], Loss: 1.4362, Accuracy: 0.4129\n",
      "Epoch [296/500], Loss: 1.4336, Accuracy: 0.4114\n",
      "Epoch [297/500], Loss: 1.4376, Accuracy: 0.4112\n",
      "Epoch [298/500], Loss: 1.4323, Accuracy: 0.4116\n",
      "Epoch [299/500], Loss: 1.4310, Accuracy: 0.4134\n",
      "Epoch [300/500], Loss: 1.4358, Accuracy: 0.4154\n",
      "Epoch [301/500], Loss: 1.4328, Accuracy: 0.4127\n",
      "Epoch [302/500], Loss: 1.4378, Accuracy: 0.4104\n",
      "Epoch [303/500], Loss: 1.4343, Accuracy: 0.4144\n",
      "Epoch [304/500], Loss: 1.4371, Accuracy: 0.4142\n",
      "Epoch [305/500], Loss: 1.4325, Accuracy: 0.4151\n",
      "Epoch [306/500], Loss: 1.4337, Accuracy: 0.4127\n",
      "Epoch [307/500], Loss: 1.4311, Accuracy: 0.4156\n",
      "Epoch [308/500], Loss: 1.4336, Accuracy: 0.4142\n",
      "Epoch [309/500], Loss: 1.4329, Accuracy: 0.4102\n",
      "Epoch [310/500], Loss: 1.4294, Accuracy: 0.4129\n",
      "Epoch [311/500], Loss: 1.4322, Accuracy: 0.4136\n",
      "Epoch [312/500], Loss: 1.4287, Accuracy: 0.4141\n",
      "Epoch [313/500], Loss: 1.4326, Accuracy: 0.4147\n",
      "Epoch [314/500], Loss: 1.4282, Accuracy: 0.4131\n",
      "Epoch [315/500], Loss: 1.4294, Accuracy: 0.4149\n",
      "Epoch [316/500], Loss: 1.4321, Accuracy: 0.4131\n",
      "Epoch [317/500], Loss: 1.4274, Accuracy: 0.4136\n",
      "Epoch [318/500], Loss: 1.4307, Accuracy: 0.4169\n",
      "Epoch [319/500], Loss: 1.4249, Accuracy: 0.4144\n",
      "Epoch [320/500], Loss: 1.4310, Accuracy: 0.4164\n",
      "Epoch [321/500], Loss: 1.4233, Accuracy: 0.4149\n",
      "Epoch [322/500], Loss: 1.4290, Accuracy: 0.4171\n",
      "Epoch [323/500], Loss: 1.4282, Accuracy: 0.4153\n",
      "Epoch [324/500], Loss: 1.4209, Accuracy: 0.4169\n",
      "Epoch [325/500], Loss: 1.4301, Accuracy: 0.4142\n",
      "Epoch [326/500], Loss: 1.4270, Accuracy: 0.4178\n",
      "Epoch [327/500], Loss: 1.4311, Accuracy: 0.4161\n",
      "Epoch [328/500], Loss: 1.4263, Accuracy: 0.4139\n",
      "Epoch [329/500], Loss: 1.4307, Accuracy: 0.4161\n",
      "Epoch [330/500], Loss: 1.4286, Accuracy: 0.4171\n",
      "Epoch [331/500], Loss: 1.4294, Accuracy: 0.4151\n",
      "Epoch [332/500], Loss: 1.4289, Accuracy: 0.4173\n",
      "Epoch [333/500], Loss: 1.4272, Accuracy: 0.4161\n",
      "Epoch [334/500], Loss: 1.4188, Accuracy: 0.4184\n",
      "Epoch [335/500], Loss: 1.4241, Accuracy: 0.4179\n",
      "Epoch [336/500], Loss: 1.4305, Accuracy: 0.4210\n",
      "Epoch [337/500], Loss: 1.4214, Accuracy: 0.4174\n",
      "Epoch [338/500], Loss: 1.4315, Accuracy: 0.4164\n",
      "Epoch [339/500], Loss: 1.4179, Accuracy: 0.4161\n",
      "Epoch [340/500], Loss: 1.4228, Accuracy: 0.4147\n",
      "Epoch [341/500], Loss: 1.4211, Accuracy: 0.4189\n",
      "Epoch [342/500], Loss: 1.4308, Accuracy: 0.4186\n",
      "Epoch [343/500], Loss: 1.4273, Accuracy: 0.4168\n",
      "Epoch [344/500], Loss: 1.4267, Accuracy: 0.4153\n",
      "Epoch [345/500], Loss: 1.4222, Accuracy: 0.4151\n",
      "Epoch [346/500], Loss: 1.4226, Accuracy: 0.4163\n",
      "Epoch [347/500], Loss: 1.4266, Accuracy: 0.4161\n",
      "Epoch [348/500], Loss: 1.4191, Accuracy: 0.4146\n",
      "Epoch [349/500], Loss: 1.4256, Accuracy: 0.4159\n",
      "Epoch [350/500], Loss: 1.4277, Accuracy: 0.4179\n",
      "Epoch [351/500], Loss: 1.4251, Accuracy: 0.4186\n",
      "Epoch [352/500], Loss: 1.4249, Accuracy: 0.4176\n",
      "Epoch [353/500], Loss: 1.4193, Accuracy: 0.4183\n",
      "Epoch [354/500], Loss: 1.4243, Accuracy: 0.4195\n",
      "Epoch [355/500], Loss: 1.4231, Accuracy: 0.4169\n",
      "Epoch [356/500], Loss: 1.4208, Accuracy: 0.4198\n",
      "Epoch [357/500], Loss: 1.4232, Accuracy: 0.4216\n",
      "Epoch [358/500], Loss: 1.4148, Accuracy: 0.4176\n",
      "Epoch [359/500], Loss: 1.4179, Accuracy: 0.4200\n",
      "Epoch [360/500], Loss: 1.4170, Accuracy: 0.4211\n",
      "Epoch [361/500], Loss: 1.4204, Accuracy: 0.4216\n",
      "Epoch [362/500], Loss: 1.4202, Accuracy: 0.4183\n",
      "Epoch [363/500], Loss: 1.4209, Accuracy: 0.4166\n",
      "Epoch [364/500], Loss: 1.4179, Accuracy: 0.4171\n",
      "Epoch [365/500], Loss: 1.4194, Accuracy: 0.4203\n",
      "Epoch [366/500], Loss: 1.4207, Accuracy: 0.4178\n",
      "Epoch [367/500], Loss: 1.4192, Accuracy: 0.4216\n",
      "Epoch [368/500], Loss: 1.4183, Accuracy: 0.4198\n",
      "Epoch [369/500], Loss: 1.4175, Accuracy: 0.4196\n",
      "Epoch [370/500], Loss: 1.4196, Accuracy: 0.4198\n",
      "Epoch [371/500], Loss: 1.4171, Accuracy: 0.4184\n",
      "Epoch [372/500], Loss: 1.4189, Accuracy: 0.4208\n",
      "Epoch [373/500], Loss: 1.4152, Accuracy: 0.4201\n",
      "Epoch [374/500], Loss: 1.4193, Accuracy: 0.4193\n",
      "Epoch [375/500], Loss: 1.4163, Accuracy: 0.4195\n",
      "Epoch [376/500], Loss: 1.4174, Accuracy: 0.4210\n",
      "Epoch [377/500], Loss: 1.4144, Accuracy: 0.4168\n",
      "Epoch [378/500], Loss: 1.4175, Accuracy: 0.4203\n",
      "Epoch [379/500], Loss: 1.4182, Accuracy: 0.4196\n",
      "Epoch [380/500], Loss: 1.4187, Accuracy: 0.4215\n",
      "Epoch [381/500], Loss: 1.4141, Accuracy: 0.4196\n",
      "Epoch [382/500], Loss: 1.4247, Accuracy: 0.4200\n",
      "Epoch [383/500], Loss: 1.4130, Accuracy: 0.4200\n",
      "Epoch [384/500], Loss: 1.4121, Accuracy: 0.4195\n",
      "Epoch [385/500], Loss: 1.4148, Accuracy: 0.4205\n",
      "Epoch [386/500], Loss: 1.4125, Accuracy: 0.4215\n",
      "Epoch [387/500], Loss: 1.4175, Accuracy: 0.4201\n",
      "Epoch [388/500], Loss: 1.4162, Accuracy: 0.4173\n",
      "Epoch [389/500], Loss: 1.4145, Accuracy: 0.4216\n",
      "Epoch [390/500], Loss: 1.4112, Accuracy: 0.4183\n",
      "Epoch [391/500], Loss: 1.4121, Accuracy: 0.4205\n",
      "Epoch [392/500], Loss: 1.4171, Accuracy: 0.4198\n",
      "Epoch [393/500], Loss: 1.4083, Accuracy: 0.4226\n",
      "Epoch [394/500], Loss: 1.4140, Accuracy: 0.4184\n",
      "Epoch [395/500], Loss: 1.4152, Accuracy: 0.4210\n",
      "Epoch [396/500], Loss: 1.4212, Accuracy: 0.4215\n",
      "Epoch [397/500], Loss: 1.4171, Accuracy: 0.4220\n",
      "Epoch [398/500], Loss: 1.4195, Accuracy: 0.4221\n",
      "Epoch [399/500], Loss: 1.4135, Accuracy: 0.4230\n",
      "Epoch [400/500], Loss: 1.4135, Accuracy: 0.4221\n",
      "Epoch [401/500], Loss: 1.4116, Accuracy: 0.4211\n",
      "Epoch [402/500], Loss: 1.4105, Accuracy: 0.4226\n",
      "Epoch [403/500], Loss: 1.4147, Accuracy: 0.4216\n",
      "Epoch [404/500], Loss: 1.4141, Accuracy: 0.4205\n",
      "Epoch [405/500], Loss: 1.4174, Accuracy: 0.4220\n",
      "Epoch [406/500], Loss: 1.4059, Accuracy: 0.4228\n",
      "Epoch [407/500], Loss: 1.4076, Accuracy: 0.4216\n",
      "Epoch [408/500], Loss: 1.4087, Accuracy: 0.4208\n",
      "Epoch [409/500], Loss: 1.4118, Accuracy: 0.4230\n",
      "Epoch [410/500], Loss: 1.4108, Accuracy: 0.4188\n",
      "Epoch [411/500], Loss: 1.4154, Accuracy: 0.4210\n",
      "Epoch [412/500], Loss: 1.4058, Accuracy: 0.4221\n",
      "Epoch [413/500], Loss: 1.4270, Accuracy: 0.4247\n",
      "Epoch [414/500], Loss: 1.4222, Accuracy: 0.4220\n",
      "Epoch [415/500], Loss: 1.4164, Accuracy: 0.4243\n",
      "Epoch [416/500], Loss: 1.4144, Accuracy: 0.4211\n",
      "Epoch [417/500], Loss: 1.4134, Accuracy: 0.4225\n",
      "Epoch [418/500], Loss: 1.4111, Accuracy: 0.4231\n",
      "Epoch [419/500], Loss: 1.4087, Accuracy: 0.4220\n",
      "Epoch [420/500], Loss: 1.4082, Accuracy: 0.4233\n",
      "Epoch [421/500], Loss: 1.4212, Accuracy: 0.4247\n",
      "Epoch [422/500], Loss: 1.4073, Accuracy: 0.4225\n",
      "Epoch [423/500], Loss: 1.4091, Accuracy: 0.4230\n",
      "Epoch [424/500], Loss: 1.4075, Accuracy: 0.4205\n",
      "Epoch [425/500], Loss: 1.4133, Accuracy: 0.4231\n",
      "Epoch [426/500], Loss: 1.4103, Accuracy: 0.4226\n",
      "Epoch [427/500], Loss: 1.4055, Accuracy: 0.4243\n",
      "Epoch [428/500], Loss: 1.4134, Accuracy: 0.4220\n",
      "Epoch [429/500], Loss: 1.4062, Accuracy: 0.4230\n",
      "Epoch [430/500], Loss: 1.4181, Accuracy: 0.4248\n",
      "Epoch [431/500], Loss: 1.4037, Accuracy: 0.4215\n",
      "Epoch [432/500], Loss: 1.4075, Accuracy: 0.4252\n",
      "Epoch [433/500], Loss: 1.4091, Accuracy: 0.4233\n",
      "Epoch [434/500], Loss: 1.4084, Accuracy: 0.4250\n",
      "Epoch [435/500], Loss: 1.4022, Accuracy: 0.4237\n",
      "Epoch [436/500], Loss: 1.4111, Accuracy: 0.4238\n",
      "Epoch [437/500], Loss: 1.4065, Accuracy: 0.4233\n",
      "Epoch [438/500], Loss: 1.4087, Accuracy: 0.4252\n",
      "Epoch [439/500], Loss: 1.4067, Accuracy: 0.4263\n",
      "Epoch [440/500], Loss: 1.4052, Accuracy: 0.4223\n",
      "Epoch [441/500], Loss: 1.4094, Accuracy: 0.4242\n",
      "Epoch [442/500], Loss: 1.4074, Accuracy: 0.4206\n",
      "Epoch [443/500], Loss: 1.4056, Accuracy: 0.4235\n",
      "Epoch [444/500], Loss: 1.4030, Accuracy: 0.4237\n",
      "Epoch [445/500], Loss: 1.3987, Accuracy: 0.4260\n",
      "Epoch [446/500], Loss: 1.4091, Accuracy: 0.4257\n",
      "Epoch [447/500], Loss: 1.4062, Accuracy: 0.4260\n",
      "Epoch [448/500], Loss: 1.4011, Accuracy: 0.4250\n",
      "Epoch [449/500], Loss: 1.4088, Accuracy: 0.4243\n",
      "Epoch [450/500], Loss: 1.4053, Accuracy: 0.4243\n",
      "Epoch [451/500], Loss: 1.4086, Accuracy: 0.4270\n",
      "Epoch [452/500], Loss: 1.4004, Accuracy: 0.4267\n",
      "Epoch [453/500], Loss: 1.4076, Accuracy: 0.4258\n",
      "Epoch [454/500], Loss: 1.4039, Accuracy: 0.4255\n",
      "Epoch [455/500], Loss: 1.4055, Accuracy: 0.4253\n",
      "Epoch [456/500], Loss: 1.3986, Accuracy: 0.4253\n",
      "Epoch [457/500], Loss: 1.4070, Accuracy: 0.4231\n",
      "Epoch [458/500], Loss: 1.4012, Accuracy: 0.4252\n",
      "Epoch [459/500], Loss: 1.4115, Accuracy: 0.4237\n",
      "Epoch [460/500], Loss: 1.4006, Accuracy: 0.4231\n",
      "Epoch [461/500], Loss: 1.4002, Accuracy: 0.4267\n",
      "Epoch [462/500], Loss: 1.4070, Accuracy: 0.4263\n",
      "Epoch [463/500], Loss: 1.3960, Accuracy: 0.4268\n",
      "Epoch [464/500], Loss: 1.3979, Accuracy: 0.4263\n",
      "Epoch [465/500], Loss: 1.4031, Accuracy: 0.4262\n",
      "Epoch [466/500], Loss: 1.3969, Accuracy: 0.4260\n",
      "Epoch [467/500], Loss: 1.4032, Accuracy: 0.4260\n",
      "Epoch [468/500], Loss: 1.4007, Accuracy: 0.4282\n",
      "Epoch [469/500], Loss: 1.4003, Accuracy: 0.4252\n",
      "Epoch [470/500], Loss: 1.4028, Accuracy: 0.4268\n",
      "Epoch [471/500], Loss: 1.4111, Accuracy: 0.4295\n",
      "Epoch [472/500], Loss: 1.4125, Accuracy: 0.4282\n",
      "Epoch [473/500], Loss: 1.3974, Accuracy: 0.4285\n",
      "Epoch [474/500], Loss: 1.3987, Accuracy: 0.4277\n",
      "Epoch [475/500], Loss: 1.4040, Accuracy: 0.4282\n",
      "Epoch [476/500], Loss: 1.4045, Accuracy: 0.4285\n",
      "Epoch [477/500], Loss: 1.4006, Accuracy: 0.4279\n",
      "Epoch [478/500], Loss: 1.3975, Accuracy: 0.4262\n",
      "Epoch [479/500], Loss: 1.3965, Accuracy: 0.4290\n",
      "Epoch [480/500], Loss: 1.4059, Accuracy: 0.4287\n",
      "Epoch [481/500], Loss: 1.3983, Accuracy: 0.4258\n",
      "Epoch [482/500], Loss: 1.3999, Accuracy: 0.4287\n",
      "Epoch [483/500], Loss: 1.3977, Accuracy: 0.4273\n",
      "Epoch [484/500], Loss: 1.3981, Accuracy: 0.4277\n",
      "Epoch [485/500], Loss: 1.4043, Accuracy: 0.4297\n",
      "Epoch [486/500], Loss: 1.4008, Accuracy: 0.4290\n",
      "Epoch [487/500], Loss: 1.3929, Accuracy: 0.4287\n",
      "Epoch [488/500], Loss: 1.3979, Accuracy: 0.4290\n",
      "Epoch [489/500], Loss: 1.4001, Accuracy: 0.4292\n",
      "Epoch [490/500], Loss: 1.3958, Accuracy: 0.4292\n",
      "Epoch [491/500], Loss: 1.3979, Accuracy: 0.4255\n",
      "Epoch [492/500], Loss: 1.3984, Accuracy: 0.4297\n",
      "Epoch [493/500], Loss: 1.3932, Accuracy: 0.4302\n",
      "Epoch [494/500], Loss: 1.3990, Accuracy: 0.4312\n",
      "Epoch [495/500], Loss: 1.3980, Accuracy: 0.4295\n",
      "Epoch [496/500], Loss: 1.3973, Accuracy: 0.4270\n",
      "Epoch [497/500], Loss: 1.3992, Accuracy: 0.4284\n",
      "Epoch [498/500], Loss: 1.3960, Accuracy: 0.4279\n",
      "Epoch [499/500], Loss: 1.3962, Accuracy: 0.4292\n",
      "Epoch [500/500], Loss: 1.3988, Accuracy: 0.4295\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network with Attention\n",
    "cnn_atn_model = CNNAttention(input_size[0],num_classes).to(device)\n",
    "optimizer = optim.Adam(cnn_atn_model.parameters(), lr=0.00001)\n",
    "train(cnn_atn_model, train_loaderCNN, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para teste\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n",
    "\n",
    "    test_loss = running_loss / len(test_loader)\n",
    "    test_accuracy = correct / total\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SimpleDNN:\n",
      "Test Loss: 1.5304, Test Accuracy: 0.3526\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing SimpleDNN:\")\n",
    "test(sdnn_model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing LSTMModel:\n",
      "Test Loss: 1.4163, Test Accuracy: 0.4184\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting LSTMModel:\")\n",
    "test(lstm_model, test_loaderLSTM, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing LSTMAttention:\n",
      "Test Loss: 1.4278, Test Accuracy: 0.4150\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting LSTMAttention:\")\n",
    "test(lstm_atn_model, test_loaderLSTM, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing CNNModel:\n",
      "Test Loss: 1.4725, Test Accuracy: 0.4150\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting CNNModel:\")\n",
    "test(cnn_model, test_loaderCNN, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing CNNAttention:\n",
      "Test Loss: 1.4288, Test Accuracy: 0.4150\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting CNNAttention:\")\n",
    "test(cnn_atn_model, test_loaderCNN, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
