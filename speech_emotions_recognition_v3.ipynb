{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6422</th>\n",
       "      <td>./AudioWAV/1079_IWW_ANG_XX.wav</td>\n",
       "      <td>angry.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>./AudioWAV/1007_IWW_FEA_XX.wav</td>\n",
       "      <td>fear.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5635</th>\n",
       "      <td>./AudioWAV/1069_WSI_FEA_XX.wav</td>\n",
       "      <td>fear.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>./AudioWAV/1010_DFA_HAP_XX.wav</td>\n",
       "      <td>happy.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>./AudioWAV/1025_ITH_FEA_XX.wav</td>\n",
       "      <td>fear.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              speech      label\n",
       "6422  ./AudioWAV/1079_IWW_ANG_XX.wav  angry.wav\n",
       "539   ./AudioWAV/1007_IWW_FEA_XX.wav   fear.wav\n",
       "5635  ./AudioWAV/1069_WSI_FEA_XX.wav   fear.wav\n",
       "728   ./AudioWAV/1010_DFA_HAP_XX.wav  happy.wav\n",
       "1979  ./AudioWAV/1025_ITH_FEA_XX.wav   fear.wav"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths=[]\n",
    "labels=[]\n",
    "for filename in os.listdir('./AudioWAV'):\n",
    "    \n",
    "    paths.append('./AudioWAV/' + filename)\n",
    "    file = filename.split('.')[0]\n",
    "   \n",
    "    label = file.split('_')[2]\n",
    "    if label == 'ANG':\n",
    "        labels.append('angry.wav')\n",
    "    elif label == 'DIS':\n",
    "        labels.append('disgust.wav')\n",
    "    elif label == 'FEA':\n",
    "        labels.append('fear.wav')\n",
    "    elif label == 'HAP':\n",
    "        labels.append('happy.wav')\n",
    "    elif label == 'NEU':\n",
    "        labels.append('neutral.wav')\n",
    "    elif label == 'SAD':\n",
    "        labels.append('sad.wav')\n",
    "        \n",
    "\n",
    "df_cremad = pd.DataFrame({'speech':paths,'label':labels})\n",
    "df_cremad.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFCC(filename):\n",
    "    y, sr = librosa.load(filename,duration=3,offset=0.5)\n",
    "    return np.mean(librosa.feature.mfcc(y=y,sr=sr,n_mfcc=40).T,axis=0)\n",
    "\n",
    "mfcc_cremad = df_cremad['speech'].apply(lambda x:MFCC(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7442, 40, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X =[x for x in mfcc_cremad]\n",
    "X =np.array(X)\n",
    "X.shape\n",
    "X =np.expand_dims(X,-1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe=OneHotEncoder()\n",
    "y = ohe.fit_transform(df_cremad[['label']] )\n",
    "y = y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7442, 40, 1), (7442, 6))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry.wav', 'disgust.wav', 'fear.wav', 'happy.wav', 'neutral.wav',\n",
       "       'sad.wav'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cremad['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Definindo os modelos\n",
    "\n",
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class LSTMAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
    "        out = torch.sum(attn_weights * out, dim=1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
    "        self.fc_input_size = 32 * 1 * 1\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, self.fc_input_size)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNNAttention(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNNAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
    "        self.attention = nn.Linear(32, 1)\n",
    "        self.fc = nn.Linear(32, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        attn_weights = self.softmax(self.attention(x.permute(0, 2, 1))).squeeze(-1)\n",
    "        attn_weights = attn_weights.unsqueeze(-1)\n",
    "        x = torch.sum(attn_weights * x, dim=2)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "# Construindo e treinando os modelos\n",
    "\n",
    "input_size = X.shape[1:]\n",
    "num_classes = y.shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Convertendo os dados para tensores PyTorch\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "# Definindo o tamanho do lote\n",
    "batch_size = 32\n",
    "\n",
    "# Criando conjuntos de dados PyTorch\n",
    "dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Definindo tensor para o LSTM\n",
    "X_tensorLSTM = X_tensor.permute(0, 2, 1)\n",
    "\n",
    "# Criando conjuntos de dados PyTorch para LSTM\n",
    "datasetLSTM = torch.utils.data.TensorDataset(X_tensorLSTM, y_tensor)\n",
    "train_sizeLSTM = int(0.8 * len(datasetLSTM))\n",
    "test_sizeLSTM = len(datasetLSTM) - train_sizeLSTM\n",
    "train_datasetLSTM, test_datasetLSTM = torch.utils.data.random_split(datasetLSTM, [train_sizeLSTM, test_sizeLSTM])\n",
    "\n",
    "# DataLoader para o LSTM\n",
    "train_loaderLSTM = DataLoader(train_datasetLSTM, batch_size=batch_size, shuffle=True)\n",
    "test_loaderLSTM = DataLoader(test_datasetLSTM, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Convertendo os dados para tensores PyTorch do CNN\n",
    "X_tensorCNN = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "\n",
    "# Criando conjuntos de dados PyTorch do CNN\n",
    "datasetCNN = torch.utils.data.TensorDataset(X_tensorCNN, y_tensor)\n",
    "train_sizeCNN = int(0.8 * len(datasetCNN))\n",
    "test_sizeCNN = len(datasetCNN) - train_sizeCNN\n",
    "train_datasetCNN, test_datasetCNN = torch.utils.data.random_split(datasetCNN, [train_sizeCNN, test_sizeCNN])\n",
    "\n",
    "# DataLoader para o CNN\n",
    "train_loaderCNN = DataLoader(train_datasetCNN, batch_size=batch_size, shuffle=True)\n",
    "test_loaderCNN = DataLoader(test_datasetCNN, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Função para treinamento\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs=500):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            #print(outputs.shape)\n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        accuracy = correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 2.9579, Accuracy: 0.1626\n",
      "Epoch [2/500], Loss: 1.8077, Accuracy: 0.1596\n",
      "Epoch [3/500], Loss: 1.7907, Accuracy: 0.1957\n",
      "Epoch [4/500], Loss: 1.7651, Accuracy: 0.2243\n",
      "Epoch [5/500], Loss: 1.7385, Accuracy: 0.2427\n",
      "Epoch [6/500], Loss: 1.7248, Accuracy: 0.2573\n",
      "Epoch [7/500], Loss: 1.6949, Accuracy: 0.2644\n",
      "Epoch [8/500], Loss: 1.6773, Accuracy: 0.2699\n",
      "Epoch [9/500], Loss: 1.6504, Accuracy: 0.2792\n",
      "Epoch [10/500], Loss: 1.6467, Accuracy: 0.2925\n",
      "Epoch [11/500], Loss: 1.6263, Accuracy: 0.3042\n",
      "Epoch [12/500], Loss: 1.6099, Accuracy: 0.3111\n",
      "Epoch [13/500], Loss: 1.6085, Accuracy: 0.3035\n",
      "Epoch [14/500], Loss: 1.6018, Accuracy: 0.3057\n",
      "Epoch [15/500], Loss: 1.5889, Accuracy: 0.3130\n",
      "Epoch [16/500], Loss: 1.5841, Accuracy: 0.3296\n",
      "Epoch [17/500], Loss: 1.5752, Accuracy: 0.3242\n",
      "Epoch [18/500], Loss: 1.5699, Accuracy: 0.3329\n",
      "Epoch [19/500], Loss: 1.5751, Accuracy: 0.3363\n",
      "Epoch [20/500], Loss: 1.5581, Accuracy: 0.3316\n",
      "Epoch [21/500], Loss: 1.5562, Accuracy: 0.3465\n",
      "Epoch [22/500], Loss: 1.5456, Accuracy: 0.3506\n",
      "Epoch [23/500], Loss: 1.5479, Accuracy: 0.3449\n",
      "Epoch [24/500], Loss: 1.5481, Accuracy: 0.3467\n",
      "Epoch [25/500], Loss: 1.5463, Accuracy: 0.3491\n",
      "Epoch [26/500], Loss: 1.5443, Accuracy: 0.3481\n",
      "Epoch [27/500], Loss: 1.5345, Accuracy: 0.3528\n",
      "Epoch [28/500], Loss: 1.5357, Accuracy: 0.3539\n",
      "Epoch [29/500], Loss: 1.5383, Accuracy: 0.3556\n",
      "Epoch [30/500], Loss: 1.5268, Accuracy: 0.3590\n",
      "Epoch [31/500], Loss: 1.5324, Accuracy: 0.3558\n",
      "Epoch [32/500], Loss: 1.5261, Accuracy: 0.3548\n",
      "Epoch [33/500], Loss: 1.5208, Accuracy: 0.3528\n",
      "Epoch [34/500], Loss: 1.5246, Accuracy: 0.3597\n",
      "Epoch [35/500], Loss: 1.5220, Accuracy: 0.3650\n",
      "Epoch [36/500], Loss: 1.5209, Accuracy: 0.3623\n",
      "Epoch [37/500], Loss: 1.5157, Accuracy: 0.3625\n",
      "Epoch [38/500], Loss: 1.5166, Accuracy: 0.3665\n",
      "Epoch [39/500], Loss: 1.5168, Accuracy: 0.3662\n",
      "Epoch [40/500], Loss: 1.5178, Accuracy: 0.3612\n",
      "Epoch [41/500], Loss: 1.5104, Accuracy: 0.3632\n",
      "Epoch [42/500], Loss: 1.4987, Accuracy: 0.3699\n",
      "Epoch [43/500], Loss: 1.4984, Accuracy: 0.3675\n",
      "Epoch [44/500], Loss: 1.5098, Accuracy: 0.3660\n",
      "Epoch [45/500], Loss: 1.4926, Accuracy: 0.3731\n",
      "Epoch [46/500], Loss: 1.5141, Accuracy: 0.3623\n",
      "Epoch [47/500], Loss: 1.4933, Accuracy: 0.3728\n",
      "Epoch [48/500], Loss: 1.5016, Accuracy: 0.3753\n",
      "Epoch [49/500], Loss: 1.4997, Accuracy: 0.3714\n",
      "Epoch [50/500], Loss: 1.5045, Accuracy: 0.3754\n",
      "Epoch [51/500], Loss: 1.4993, Accuracy: 0.3734\n",
      "Epoch [52/500], Loss: 1.4884, Accuracy: 0.3768\n",
      "Epoch [53/500], Loss: 1.4834, Accuracy: 0.3833\n",
      "Epoch [54/500], Loss: 1.4849, Accuracy: 0.3684\n",
      "Epoch [55/500], Loss: 1.4994, Accuracy: 0.3761\n",
      "Epoch [56/500], Loss: 1.4897, Accuracy: 0.3733\n",
      "Epoch [57/500], Loss: 1.4934, Accuracy: 0.3773\n",
      "Epoch [58/500], Loss: 1.4959, Accuracy: 0.3761\n",
      "Epoch [59/500], Loss: 1.4795, Accuracy: 0.3909\n",
      "Epoch [60/500], Loss: 1.4813, Accuracy: 0.3827\n",
      "Epoch [61/500], Loss: 1.4854, Accuracy: 0.3733\n",
      "Epoch [62/500], Loss: 1.4687, Accuracy: 0.3926\n",
      "Epoch [63/500], Loss: 1.4781, Accuracy: 0.3833\n",
      "Epoch [64/500], Loss: 1.4839, Accuracy: 0.3817\n",
      "Epoch [65/500], Loss: 1.4778, Accuracy: 0.3801\n",
      "Epoch [66/500], Loss: 1.4744, Accuracy: 0.3899\n",
      "Epoch [67/500], Loss: 1.4734, Accuracy: 0.3882\n",
      "Epoch [68/500], Loss: 1.4659, Accuracy: 0.3906\n",
      "Epoch [69/500], Loss: 1.4735, Accuracy: 0.3827\n",
      "Epoch [70/500], Loss: 1.4713, Accuracy: 0.3798\n",
      "Epoch [71/500], Loss: 1.4842, Accuracy: 0.3854\n",
      "Epoch [72/500], Loss: 1.4712, Accuracy: 0.3872\n",
      "Epoch [73/500], Loss: 1.4665, Accuracy: 0.3867\n",
      "Epoch [74/500], Loss: 1.4746, Accuracy: 0.3869\n",
      "Epoch [75/500], Loss: 1.4680, Accuracy: 0.3894\n",
      "Epoch [76/500], Loss: 1.4554, Accuracy: 0.3958\n",
      "Epoch [77/500], Loss: 1.4622, Accuracy: 0.3921\n",
      "Epoch [78/500], Loss: 1.4756, Accuracy: 0.3806\n",
      "Epoch [79/500], Loss: 1.4648, Accuracy: 0.3916\n",
      "Epoch [80/500], Loss: 1.4785, Accuracy: 0.3859\n",
      "Epoch [81/500], Loss: 1.4628, Accuracy: 0.3926\n",
      "Epoch [82/500], Loss: 1.4595, Accuracy: 0.4040\n",
      "Epoch [83/500], Loss: 1.4641, Accuracy: 0.3867\n",
      "Epoch [84/500], Loss: 1.4668, Accuracy: 0.3874\n",
      "Epoch [85/500], Loss: 1.4576, Accuracy: 0.4000\n",
      "Epoch [86/500], Loss: 1.4661, Accuracy: 0.3899\n",
      "Epoch [87/500], Loss: 1.4564, Accuracy: 0.3938\n",
      "Epoch [88/500], Loss: 1.4711, Accuracy: 0.4000\n",
      "Epoch [89/500], Loss: 1.4529, Accuracy: 0.3948\n",
      "Epoch [90/500], Loss: 1.4600, Accuracy: 0.3865\n",
      "Epoch [91/500], Loss: 1.4666, Accuracy: 0.3892\n",
      "Epoch [92/500], Loss: 1.4597, Accuracy: 0.3922\n",
      "Epoch [93/500], Loss: 1.4590, Accuracy: 0.3968\n",
      "Epoch [94/500], Loss: 1.4628, Accuracy: 0.3964\n",
      "Epoch [95/500], Loss: 1.4655, Accuracy: 0.3956\n",
      "Epoch [96/500], Loss: 1.4685, Accuracy: 0.3869\n",
      "Epoch [97/500], Loss: 1.4635, Accuracy: 0.3907\n",
      "Epoch [98/500], Loss: 1.4601, Accuracy: 0.3941\n",
      "Epoch [99/500], Loss: 1.4707, Accuracy: 0.3857\n",
      "Epoch [100/500], Loss: 1.4628, Accuracy: 0.3978\n",
      "Epoch [101/500], Loss: 1.4512, Accuracy: 0.3901\n",
      "Epoch [102/500], Loss: 1.4656, Accuracy: 0.3911\n",
      "Epoch [103/500], Loss: 1.4554, Accuracy: 0.3949\n",
      "Epoch [104/500], Loss: 1.4466, Accuracy: 0.4052\n",
      "Epoch [105/500], Loss: 1.4656, Accuracy: 0.3917\n",
      "Epoch [106/500], Loss: 1.4560, Accuracy: 0.3949\n",
      "Epoch [107/500], Loss: 1.4617, Accuracy: 0.4001\n",
      "Epoch [108/500], Loss: 1.4767, Accuracy: 0.3887\n",
      "Epoch [109/500], Loss: 1.4605, Accuracy: 0.4124\n",
      "Epoch [110/500], Loss: 1.4461, Accuracy: 0.4077\n",
      "Epoch [111/500], Loss: 1.4498, Accuracy: 0.4052\n",
      "Epoch [112/500], Loss: 1.4517, Accuracy: 0.4003\n",
      "Epoch [113/500], Loss: 1.4701, Accuracy: 0.3812\n",
      "Epoch [114/500], Loss: 1.4673, Accuracy: 0.3931\n",
      "Epoch [115/500], Loss: 1.4702, Accuracy: 0.3939\n",
      "Epoch [116/500], Loss: 1.4680, Accuracy: 0.3921\n",
      "Epoch [117/500], Loss: 1.4594, Accuracy: 0.3938\n",
      "Epoch [118/500], Loss: 1.4624, Accuracy: 0.3944\n",
      "Epoch [119/500], Loss: 1.4543, Accuracy: 0.3944\n",
      "Epoch [120/500], Loss: 1.4534, Accuracy: 0.4043\n",
      "Epoch [121/500], Loss: 1.4569, Accuracy: 0.3964\n",
      "Epoch [122/500], Loss: 1.4601, Accuracy: 0.4010\n",
      "Epoch [123/500], Loss: 1.4495, Accuracy: 0.4121\n",
      "Epoch [124/500], Loss: 1.4418, Accuracy: 0.4069\n",
      "Epoch [125/500], Loss: 1.4598, Accuracy: 0.3971\n",
      "Epoch [126/500], Loss: 1.4641, Accuracy: 0.3938\n",
      "Epoch [127/500], Loss: 1.4540, Accuracy: 0.4055\n",
      "Epoch [128/500], Loss: 1.4559, Accuracy: 0.4020\n",
      "Epoch [129/500], Loss: 1.4466, Accuracy: 0.3968\n",
      "Epoch [130/500], Loss: 1.4484, Accuracy: 0.4055\n",
      "Epoch [131/500], Loss: 1.4443, Accuracy: 0.4127\n",
      "Epoch [132/500], Loss: 1.4323, Accuracy: 0.4072\n",
      "Epoch [133/500], Loss: 1.4592, Accuracy: 0.4042\n",
      "Epoch [134/500], Loss: 1.4559, Accuracy: 0.3958\n",
      "Epoch [135/500], Loss: 1.4411, Accuracy: 0.4062\n",
      "Epoch [136/500], Loss: 1.4507, Accuracy: 0.4065\n",
      "Epoch [137/500], Loss: 1.4418, Accuracy: 0.4085\n",
      "Epoch [138/500], Loss: 1.4394, Accuracy: 0.4178\n",
      "Epoch [139/500], Loss: 1.4524, Accuracy: 0.4063\n",
      "Epoch [140/500], Loss: 1.4659, Accuracy: 0.3959\n",
      "Epoch [141/500], Loss: 1.4336, Accuracy: 0.4139\n",
      "Epoch [142/500], Loss: 1.4365, Accuracy: 0.4147\n",
      "Epoch [143/500], Loss: 1.4359, Accuracy: 0.4141\n",
      "Epoch [144/500], Loss: 1.4350, Accuracy: 0.4063\n",
      "Epoch [145/500], Loss: 1.4220, Accuracy: 0.4131\n",
      "Epoch [146/500], Loss: 1.4351, Accuracy: 0.4107\n",
      "Epoch [147/500], Loss: 1.4419, Accuracy: 0.4105\n",
      "Epoch [148/500], Loss: 1.4337, Accuracy: 0.4137\n",
      "Epoch [149/500], Loss: 1.4302, Accuracy: 0.4141\n",
      "Epoch [150/500], Loss: 1.4268, Accuracy: 0.4144\n",
      "Epoch [151/500], Loss: 1.4367, Accuracy: 0.4084\n",
      "Epoch [152/500], Loss: 1.4363, Accuracy: 0.4092\n",
      "Epoch [153/500], Loss: 1.4445, Accuracy: 0.4047\n",
      "Epoch [154/500], Loss: 1.4259, Accuracy: 0.4183\n",
      "Epoch [155/500], Loss: 1.4414, Accuracy: 0.4092\n",
      "Epoch [156/500], Loss: 1.4393, Accuracy: 0.3980\n",
      "Epoch [157/500], Loss: 1.4537, Accuracy: 0.3988\n",
      "Epoch [158/500], Loss: 1.4409, Accuracy: 0.4043\n",
      "Epoch [159/500], Loss: 1.4492, Accuracy: 0.4102\n",
      "Epoch [160/500], Loss: 1.4335, Accuracy: 0.4089\n",
      "Epoch [161/500], Loss: 1.4382, Accuracy: 0.4048\n",
      "Epoch [162/500], Loss: 1.4342, Accuracy: 0.4060\n",
      "Epoch [163/500], Loss: 1.4296, Accuracy: 0.4105\n",
      "Epoch [164/500], Loss: 1.4419, Accuracy: 0.4062\n",
      "Epoch [165/500], Loss: 1.4258, Accuracy: 0.4144\n",
      "Epoch [166/500], Loss: 1.4399, Accuracy: 0.4099\n",
      "Epoch [167/500], Loss: 1.4396, Accuracy: 0.3978\n",
      "Epoch [168/500], Loss: 1.4336, Accuracy: 0.4060\n",
      "Epoch [169/500], Loss: 1.4321, Accuracy: 0.4097\n",
      "Epoch [170/500], Loss: 1.4387, Accuracy: 0.4131\n",
      "Epoch [171/500], Loss: 1.4205, Accuracy: 0.4228\n",
      "Epoch [172/500], Loss: 1.4284, Accuracy: 0.4105\n",
      "Epoch [173/500], Loss: 1.4184, Accuracy: 0.4164\n",
      "Epoch [174/500], Loss: 1.4308, Accuracy: 0.4121\n",
      "Epoch [175/500], Loss: 1.4374, Accuracy: 0.4040\n",
      "Epoch [176/500], Loss: 1.4463, Accuracy: 0.4047\n",
      "Epoch [177/500], Loss: 1.4318, Accuracy: 0.4124\n",
      "Epoch [178/500], Loss: 1.4320, Accuracy: 0.4022\n",
      "Epoch [179/500], Loss: 1.4422, Accuracy: 0.4095\n",
      "Epoch [180/500], Loss: 1.4317, Accuracy: 0.4149\n",
      "Epoch [181/500], Loss: 1.4348, Accuracy: 0.4154\n",
      "Epoch [182/500], Loss: 1.4260, Accuracy: 0.4104\n",
      "Epoch [183/500], Loss: 1.4214, Accuracy: 0.4126\n",
      "Epoch [184/500], Loss: 1.4195, Accuracy: 0.4126\n",
      "Epoch [185/500], Loss: 1.4277, Accuracy: 0.4189\n",
      "Epoch [186/500], Loss: 1.4356, Accuracy: 0.4025\n",
      "Epoch [187/500], Loss: 1.4403, Accuracy: 0.4072\n",
      "Epoch [188/500], Loss: 1.4443, Accuracy: 0.4030\n",
      "Epoch [189/500], Loss: 1.4510, Accuracy: 0.4080\n",
      "Epoch [190/500], Loss: 1.4437, Accuracy: 0.4062\n",
      "Epoch [191/500], Loss: 1.4286, Accuracy: 0.4102\n",
      "Epoch [192/500], Loss: 1.4337, Accuracy: 0.4153\n",
      "Epoch [193/500], Loss: 1.4337, Accuracy: 0.4105\n",
      "Epoch [194/500], Loss: 1.4268, Accuracy: 0.4117\n",
      "Epoch [195/500], Loss: 1.4229, Accuracy: 0.4074\n",
      "Epoch [196/500], Loss: 1.4325, Accuracy: 0.4037\n",
      "Epoch [197/500], Loss: 1.4309, Accuracy: 0.4099\n",
      "Epoch [198/500], Loss: 1.4297, Accuracy: 0.4074\n",
      "Epoch [199/500], Loss: 1.4260, Accuracy: 0.4149\n",
      "Epoch [200/500], Loss: 1.4251, Accuracy: 0.4141\n",
      "Epoch [201/500], Loss: 1.4191, Accuracy: 0.4181\n",
      "Epoch [202/500], Loss: 1.4315, Accuracy: 0.4072\n",
      "Epoch [203/500], Loss: 1.4167, Accuracy: 0.4195\n",
      "Epoch [204/500], Loss: 1.4216, Accuracy: 0.4215\n",
      "Epoch [205/500], Loss: 1.4351, Accuracy: 0.4166\n",
      "Epoch [206/500], Loss: 1.4285, Accuracy: 0.4159\n",
      "Epoch [207/500], Loss: 1.4229, Accuracy: 0.4176\n",
      "Epoch [208/500], Loss: 1.4396, Accuracy: 0.4126\n",
      "Epoch [209/500], Loss: 1.4258, Accuracy: 0.4052\n",
      "Epoch [210/500], Loss: 1.4241, Accuracy: 0.4156\n",
      "Epoch [211/500], Loss: 1.4183, Accuracy: 0.4126\n",
      "Epoch [212/500], Loss: 1.4273, Accuracy: 0.4119\n",
      "Epoch [213/500], Loss: 1.4292, Accuracy: 0.4173\n",
      "Epoch [214/500], Loss: 1.4263, Accuracy: 0.4164\n",
      "Epoch [215/500], Loss: 1.4088, Accuracy: 0.4255\n",
      "Epoch [216/500], Loss: 1.4143, Accuracy: 0.4183\n",
      "Epoch [217/500], Loss: 1.4210, Accuracy: 0.4230\n",
      "Epoch [218/500], Loss: 1.4211, Accuracy: 0.4200\n",
      "Epoch [219/500], Loss: 1.4113, Accuracy: 0.4141\n",
      "Epoch [220/500], Loss: 1.4221, Accuracy: 0.4297\n",
      "Epoch [221/500], Loss: 1.4189, Accuracy: 0.4079\n",
      "Epoch [222/500], Loss: 1.4181, Accuracy: 0.4114\n",
      "Epoch [223/500], Loss: 1.4279, Accuracy: 0.4154\n",
      "Epoch [224/500], Loss: 1.4216, Accuracy: 0.4206\n",
      "Epoch [225/500], Loss: 1.4355, Accuracy: 0.4171\n",
      "Epoch [226/500], Loss: 1.4262, Accuracy: 0.4168\n",
      "Epoch [227/500], Loss: 1.4264, Accuracy: 0.4154\n",
      "Epoch [228/500], Loss: 1.4171, Accuracy: 0.4221\n",
      "Epoch [229/500], Loss: 1.4298, Accuracy: 0.4220\n",
      "Epoch [230/500], Loss: 1.4084, Accuracy: 0.4161\n",
      "Epoch [231/500], Loss: 1.4209, Accuracy: 0.4149\n",
      "Epoch [232/500], Loss: 1.4199, Accuracy: 0.4201\n",
      "Epoch [233/500], Loss: 1.4199, Accuracy: 0.4245\n",
      "Epoch [234/500], Loss: 1.4084, Accuracy: 0.4237\n",
      "Epoch [235/500], Loss: 1.4129, Accuracy: 0.4168\n",
      "Epoch [236/500], Loss: 1.4105, Accuracy: 0.4168\n",
      "Epoch [237/500], Loss: 1.4189, Accuracy: 0.4220\n",
      "Epoch [238/500], Loss: 1.4165, Accuracy: 0.4159\n",
      "Epoch [239/500], Loss: 1.4139, Accuracy: 0.4114\n",
      "Epoch [240/500], Loss: 1.4154, Accuracy: 0.4137\n",
      "Epoch [241/500], Loss: 1.4064, Accuracy: 0.4208\n",
      "Epoch [242/500], Loss: 1.4121, Accuracy: 0.4131\n",
      "Epoch [243/500], Loss: 1.4108, Accuracy: 0.4154\n",
      "Epoch [244/500], Loss: 1.4333, Accuracy: 0.4158\n",
      "Epoch [245/500], Loss: 1.4250, Accuracy: 0.4094\n",
      "Epoch [246/500], Loss: 1.4154, Accuracy: 0.4183\n",
      "Epoch [247/500], Loss: 1.4114, Accuracy: 0.4189\n",
      "Epoch [248/500], Loss: 1.4150, Accuracy: 0.4211\n",
      "Epoch [249/500], Loss: 1.4077, Accuracy: 0.4153\n",
      "Epoch [250/500], Loss: 1.4125, Accuracy: 0.4201\n",
      "Epoch [251/500], Loss: 1.4182, Accuracy: 0.4163\n",
      "Epoch [252/500], Loss: 1.4060, Accuracy: 0.4188\n",
      "Epoch [253/500], Loss: 1.4123, Accuracy: 0.4189\n",
      "Epoch [254/500], Loss: 1.4149, Accuracy: 0.4223\n",
      "Epoch [255/500], Loss: 1.4314, Accuracy: 0.4181\n",
      "Epoch [256/500], Loss: 1.4172, Accuracy: 0.4151\n",
      "Epoch [257/500], Loss: 1.3975, Accuracy: 0.4277\n",
      "Epoch [258/500], Loss: 1.4221, Accuracy: 0.4228\n",
      "Epoch [259/500], Loss: 1.4125, Accuracy: 0.4210\n",
      "Epoch [260/500], Loss: 1.4137, Accuracy: 0.4193\n",
      "Epoch [261/500], Loss: 1.4097, Accuracy: 0.4193\n",
      "Epoch [262/500], Loss: 1.4134, Accuracy: 0.4231\n",
      "Epoch [263/500], Loss: 1.4095, Accuracy: 0.4211\n",
      "Epoch [264/500], Loss: 1.4037, Accuracy: 0.4237\n",
      "Epoch [265/500], Loss: 1.4114, Accuracy: 0.4253\n",
      "Epoch [266/500], Loss: 1.4209, Accuracy: 0.4237\n",
      "Epoch [267/500], Loss: 1.4401, Accuracy: 0.4107\n",
      "Epoch [268/500], Loss: 1.4033, Accuracy: 0.4294\n",
      "Epoch [269/500], Loss: 1.4240, Accuracy: 0.4126\n",
      "Epoch [270/500], Loss: 1.4112, Accuracy: 0.4220\n",
      "Epoch [271/500], Loss: 1.4092, Accuracy: 0.4268\n",
      "Epoch [272/500], Loss: 1.4078, Accuracy: 0.4243\n",
      "Epoch [273/500], Loss: 1.4252, Accuracy: 0.4154\n",
      "Epoch [274/500], Loss: 1.4115, Accuracy: 0.4231\n",
      "Epoch [275/500], Loss: 1.4095, Accuracy: 0.4191\n",
      "Epoch [276/500], Loss: 1.4275, Accuracy: 0.4173\n",
      "Epoch [277/500], Loss: 1.4215, Accuracy: 0.4144\n",
      "Epoch [278/500], Loss: 1.4245, Accuracy: 0.4164\n",
      "Epoch [279/500], Loss: 1.4241, Accuracy: 0.4121\n",
      "Epoch [280/500], Loss: 1.4264, Accuracy: 0.4090\n",
      "Epoch [281/500], Loss: 1.4127, Accuracy: 0.4100\n",
      "Epoch [282/500], Loss: 1.4059, Accuracy: 0.4183\n",
      "Epoch [283/500], Loss: 1.4160, Accuracy: 0.4201\n",
      "Epoch [284/500], Loss: 1.4038, Accuracy: 0.4221\n",
      "Epoch [285/500], Loss: 1.3992, Accuracy: 0.4247\n",
      "Epoch [286/500], Loss: 1.4127, Accuracy: 0.4181\n",
      "Epoch [287/500], Loss: 1.3948, Accuracy: 0.4282\n",
      "Epoch [288/500], Loss: 1.4132, Accuracy: 0.4203\n",
      "Epoch [289/500], Loss: 1.4121, Accuracy: 0.4107\n",
      "Epoch [290/500], Loss: 1.4106, Accuracy: 0.4250\n",
      "Epoch [291/500], Loss: 1.3915, Accuracy: 0.4258\n",
      "Epoch [292/500], Loss: 1.4051, Accuracy: 0.4195\n",
      "Epoch [293/500], Loss: 1.4175, Accuracy: 0.4174\n",
      "Epoch [294/500], Loss: 1.4058, Accuracy: 0.4153\n",
      "Epoch [295/500], Loss: 1.4187, Accuracy: 0.4228\n",
      "Epoch [296/500], Loss: 1.4109, Accuracy: 0.4151\n",
      "Epoch [297/500], Loss: 1.4165, Accuracy: 0.4168\n",
      "Epoch [298/500], Loss: 1.4178, Accuracy: 0.4226\n",
      "Epoch [299/500], Loss: 1.4085, Accuracy: 0.4240\n",
      "Epoch [300/500], Loss: 1.4028, Accuracy: 0.4352\n",
      "Epoch [301/500], Loss: 1.4242, Accuracy: 0.4121\n",
      "Epoch [302/500], Loss: 1.4168, Accuracy: 0.4275\n",
      "Epoch [303/500], Loss: 1.4193, Accuracy: 0.4198\n",
      "Epoch [304/500], Loss: 1.4140, Accuracy: 0.4237\n",
      "Epoch [305/500], Loss: 1.4296, Accuracy: 0.4077\n",
      "Epoch [306/500], Loss: 1.4148, Accuracy: 0.4159\n",
      "Epoch [307/500], Loss: 1.4171, Accuracy: 0.4195\n",
      "Epoch [308/500], Loss: 1.4045, Accuracy: 0.4273\n",
      "Epoch [309/500], Loss: 1.4146, Accuracy: 0.4221\n",
      "Epoch [310/500], Loss: 1.4007, Accuracy: 0.4213\n",
      "Epoch [311/500], Loss: 1.4064, Accuracy: 0.4226\n",
      "Epoch [312/500], Loss: 1.4092, Accuracy: 0.4231\n",
      "Epoch [313/500], Loss: 1.4105, Accuracy: 0.4235\n",
      "Epoch [314/500], Loss: 1.3989, Accuracy: 0.4255\n",
      "Epoch [315/500], Loss: 1.3975, Accuracy: 0.4215\n",
      "Epoch [316/500], Loss: 1.3985, Accuracy: 0.4304\n",
      "Epoch [317/500], Loss: 1.4048, Accuracy: 0.4233\n",
      "Epoch [318/500], Loss: 1.3920, Accuracy: 0.4208\n",
      "Epoch [319/500], Loss: 1.4042, Accuracy: 0.4300\n",
      "Epoch [320/500], Loss: 1.3984, Accuracy: 0.4297\n",
      "Epoch [321/500], Loss: 1.4016, Accuracy: 0.4310\n",
      "Epoch [322/500], Loss: 1.3953, Accuracy: 0.4275\n",
      "Epoch [323/500], Loss: 1.3958, Accuracy: 0.4324\n",
      "Epoch [324/500], Loss: 1.4041, Accuracy: 0.4168\n",
      "Epoch [325/500], Loss: 1.4035, Accuracy: 0.4169\n",
      "Epoch [326/500], Loss: 1.4117, Accuracy: 0.4169\n",
      "Epoch [327/500], Loss: 1.3945, Accuracy: 0.4154\n",
      "Epoch [328/500], Loss: 1.4203, Accuracy: 0.4107\n",
      "Epoch [329/500], Loss: 1.4117, Accuracy: 0.4164\n",
      "Epoch [330/500], Loss: 1.3992, Accuracy: 0.4332\n",
      "Epoch [331/500], Loss: 1.4046, Accuracy: 0.4146\n",
      "Epoch [332/500], Loss: 1.3970, Accuracy: 0.4257\n",
      "Epoch [333/500], Loss: 1.3944, Accuracy: 0.4206\n",
      "Epoch [334/500], Loss: 1.4042, Accuracy: 0.4205\n",
      "Epoch [335/500], Loss: 1.4035, Accuracy: 0.4176\n",
      "Epoch [336/500], Loss: 1.4153, Accuracy: 0.4213\n",
      "Epoch [337/500], Loss: 1.4335, Accuracy: 0.4112\n",
      "Epoch [338/500], Loss: 1.4193, Accuracy: 0.4099\n",
      "Epoch [339/500], Loss: 1.4086, Accuracy: 0.4231\n",
      "Epoch [340/500], Loss: 1.4027, Accuracy: 0.4218\n",
      "Epoch [341/500], Loss: 1.3999, Accuracy: 0.4304\n",
      "Epoch [342/500], Loss: 1.3988, Accuracy: 0.4277\n",
      "Epoch [343/500], Loss: 1.4067, Accuracy: 0.4277\n",
      "Epoch [344/500], Loss: 1.3927, Accuracy: 0.4297\n",
      "Epoch [345/500], Loss: 1.3976, Accuracy: 0.4302\n",
      "Epoch [346/500], Loss: 1.4044, Accuracy: 0.4243\n",
      "Epoch [347/500], Loss: 1.3984, Accuracy: 0.4208\n",
      "Epoch [348/500], Loss: 1.3945, Accuracy: 0.4297\n",
      "Epoch [349/500], Loss: 1.3964, Accuracy: 0.4279\n",
      "Epoch [350/500], Loss: 1.3996, Accuracy: 0.4237\n",
      "Epoch [351/500], Loss: 1.4093, Accuracy: 0.4255\n",
      "Epoch [352/500], Loss: 1.3884, Accuracy: 0.4361\n",
      "Epoch [353/500], Loss: 1.4091, Accuracy: 0.4166\n",
      "Epoch [354/500], Loss: 1.4071, Accuracy: 0.4168\n",
      "Epoch [355/500], Loss: 1.4112, Accuracy: 0.4195\n",
      "Epoch [356/500], Loss: 1.3958, Accuracy: 0.4220\n",
      "Epoch [357/500], Loss: 1.3957, Accuracy: 0.4260\n",
      "Epoch [358/500], Loss: 1.3958, Accuracy: 0.4297\n",
      "Epoch [359/500], Loss: 1.3986, Accuracy: 0.4270\n",
      "Epoch [360/500], Loss: 1.4049, Accuracy: 0.4247\n",
      "Epoch [361/500], Loss: 1.4170, Accuracy: 0.4153\n",
      "Epoch [362/500], Loss: 1.4126, Accuracy: 0.4280\n",
      "Epoch [363/500], Loss: 1.3803, Accuracy: 0.4357\n",
      "Epoch [364/500], Loss: 1.4064, Accuracy: 0.4317\n",
      "Epoch [365/500], Loss: 1.3954, Accuracy: 0.4277\n",
      "Epoch [366/500], Loss: 1.4034, Accuracy: 0.4213\n",
      "Epoch [367/500], Loss: 1.4122, Accuracy: 0.4203\n",
      "Epoch [368/500], Loss: 1.4113, Accuracy: 0.4273\n",
      "Epoch [369/500], Loss: 1.4111, Accuracy: 0.4174\n",
      "Epoch [370/500], Loss: 1.3991, Accuracy: 0.4257\n",
      "Epoch [371/500], Loss: 1.3984, Accuracy: 0.4243\n",
      "Epoch [372/500], Loss: 1.4007, Accuracy: 0.4262\n",
      "Epoch [373/500], Loss: 1.4040, Accuracy: 0.4208\n",
      "Epoch [374/500], Loss: 1.4118, Accuracy: 0.4181\n",
      "Epoch [375/500], Loss: 1.4170, Accuracy: 0.4292\n",
      "Epoch [376/500], Loss: 1.4042, Accuracy: 0.4248\n",
      "Epoch [377/500], Loss: 1.4064, Accuracy: 0.4181\n",
      "Epoch [378/500], Loss: 1.4121, Accuracy: 0.4146\n",
      "Epoch [379/500], Loss: 1.4144, Accuracy: 0.4210\n",
      "Epoch [380/500], Loss: 1.3941, Accuracy: 0.4290\n",
      "Epoch [381/500], Loss: 1.4024, Accuracy: 0.4280\n",
      "Epoch [382/500], Loss: 1.4131, Accuracy: 0.4146\n",
      "Epoch [383/500], Loss: 1.4003, Accuracy: 0.4242\n",
      "Epoch [384/500], Loss: 1.3886, Accuracy: 0.4268\n",
      "Epoch [385/500], Loss: 1.3923, Accuracy: 0.4322\n",
      "Epoch [386/500], Loss: 1.4151, Accuracy: 0.4193\n",
      "Epoch [387/500], Loss: 1.4116, Accuracy: 0.4184\n",
      "Epoch [388/500], Loss: 1.3933, Accuracy: 0.4231\n",
      "Epoch [389/500], Loss: 1.4111, Accuracy: 0.4247\n",
      "Epoch [390/500], Loss: 1.3894, Accuracy: 0.4193\n",
      "Epoch [391/500], Loss: 1.3976, Accuracy: 0.4312\n",
      "Epoch [392/500], Loss: 1.4039, Accuracy: 0.4221\n",
      "Epoch [393/500], Loss: 1.3956, Accuracy: 0.4317\n",
      "Epoch [394/500], Loss: 1.3887, Accuracy: 0.4285\n",
      "Epoch [395/500], Loss: 1.3904, Accuracy: 0.4341\n",
      "Epoch [396/500], Loss: 1.3967, Accuracy: 0.4188\n",
      "Epoch [397/500], Loss: 1.4134, Accuracy: 0.4228\n",
      "Epoch [398/500], Loss: 1.4011, Accuracy: 0.4263\n",
      "Epoch [399/500], Loss: 1.4056, Accuracy: 0.4262\n",
      "Epoch [400/500], Loss: 1.3968, Accuracy: 0.4233\n",
      "Epoch [401/500], Loss: 1.4084, Accuracy: 0.4263\n",
      "Epoch [402/500], Loss: 1.3872, Accuracy: 0.4233\n",
      "Epoch [403/500], Loss: 1.3960, Accuracy: 0.4235\n",
      "Epoch [404/500], Loss: 1.3874, Accuracy: 0.4275\n",
      "Epoch [405/500], Loss: 1.4004, Accuracy: 0.4273\n",
      "Epoch [406/500], Loss: 1.4000, Accuracy: 0.4279\n",
      "Epoch [407/500], Loss: 1.4018, Accuracy: 0.4243\n",
      "Epoch [408/500], Loss: 1.3911, Accuracy: 0.4386\n",
      "Epoch [409/500], Loss: 1.4210, Accuracy: 0.4238\n",
      "Epoch [410/500], Loss: 1.4153, Accuracy: 0.4258\n",
      "Epoch [411/500], Loss: 1.4029, Accuracy: 0.4299\n",
      "Epoch [412/500], Loss: 1.4034, Accuracy: 0.4225\n",
      "Epoch [413/500], Loss: 1.3918, Accuracy: 0.4317\n",
      "Epoch [414/500], Loss: 1.3922, Accuracy: 0.4263\n",
      "Epoch [415/500], Loss: 1.3986, Accuracy: 0.4253\n",
      "Epoch [416/500], Loss: 1.3803, Accuracy: 0.4294\n",
      "Epoch [417/500], Loss: 1.3818, Accuracy: 0.4302\n",
      "Epoch [418/500], Loss: 1.3947, Accuracy: 0.4186\n",
      "Epoch [419/500], Loss: 1.3863, Accuracy: 0.4344\n",
      "Epoch [420/500], Loss: 1.4053, Accuracy: 0.4215\n",
      "Epoch [421/500], Loss: 1.3834, Accuracy: 0.4337\n",
      "Epoch [422/500], Loss: 1.3885, Accuracy: 0.4341\n",
      "Epoch [423/500], Loss: 1.3955, Accuracy: 0.4265\n",
      "Epoch [424/500], Loss: 1.3778, Accuracy: 0.4304\n",
      "Epoch [425/500], Loss: 1.3934, Accuracy: 0.4287\n",
      "Epoch [426/500], Loss: 1.3894, Accuracy: 0.4279\n",
      "Epoch [427/500], Loss: 1.3971, Accuracy: 0.4245\n",
      "Epoch [428/500], Loss: 1.3847, Accuracy: 0.4250\n",
      "Epoch [429/500], Loss: 1.3877, Accuracy: 0.4294\n",
      "Epoch [430/500], Loss: 1.3915, Accuracy: 0.4275\n",
      "Epoch [431/500], Loss: 1.3920, Accuracy: 0.4280\n",
      "Epoch [432/500], Loss: 1.3871, Accuracy: 0.4305\n",
      "Epoch [433/500], Loss: 1.3923, Accuracy: 0.4252\n",
      "Epoch [434/500], Loss: 1.4020, Accuracy: 0.4260\n",
      "Epoch [435/500], Loss: 1.4070, Accuracy: 0.4208\n",
      "Epoch [436/500], Loss: 1.4190, Accuracy: 0.4243\n",
      "Epoch [437/500], Loss: 1.3912, Accuracy: 0.4324\n",
      "Epoch [438/500], Loss: 1.4012, Accuracy: 0.4237\n",
      "Epoch [439/500], Loss: 1.3921, Accuracy: 0.4299\n",
      "Epoch [440/500], Loss: 1.3946, Accuracy: 0.4287\n",
      "Epoch [441/500], Loss: 1.3883, Accuracy: 0.4342\n",
      "Epoch [442/500], Loss: 1.3908, Accuracy: 0.4253\n",
      "Epoch [443/500], Loss: 1.4103, Accuracy: 0.4300\n",
      "Epoch [444/500], Loss: 1.3875, Accuracy: 0.4200\n",
      "Epoch [445/500], Loss: 1.3984, Accuracy: 0.4215\n",
      "Epoch [446/500], Loss: 1.4030, Accuracy: 0.4250\n",
      "Epoch [447/500], Loss: 1.3951, Accuracy: 0.4326\n",
      "Epoch [448/500], Loss: 1.4117, Accuracy: 0.4136\n",
      "Epoch [449/500], Loss: 1.3970, Accuracy: 0.4226\n",
      "Epoch [450/500], Loss: 1.3978, Accuracy: 0.4240\n",
      "Epoch [451/500], Loss: 1.4027, Accuracy: 0.4200\n",
      "Epoch [452/500], Loss: 1.4063, Accuracy: 0.4228\n",
      "Epoch [453/500], Loss: 1.4016, Accuracy: 0.4225\n",
      "Epoch [454/500], Loss: 1.3919, Accuracy: 0.4307\n",
      "Epoch [455/500], Loss: 1.3888, Accuracy: 0.4304\n",
      "Epoch [456/500], Loss: 1.3976, Accuracy: 0.4228\n",
      "Epoch [457/500], Loss: 1.4036, Accuracy: 0.4273\n",
      "Epoch [458/500], Loss: 1.3846, Accuracy: 0.4384\n",
      "Epoch [459/500], Loss: 1.3984, Accuracy: 0.4315\n",
      "Epoch [460/500], Loss: 1.3996, Accuracy: 0.4205\n",
      "Epoch [461/500], Loss: 1.4025, Accuracy: 0.4164\n",
      "Epoch [462/500], Loss: 1.4095, Accuracy: 0.4174\n",
      "Epoch [463/500], Loss: 1.4018, Accuracy: 0.4159\n",
      "Epoch [464/500], Loss: 1.3966, Accuracy: 0.4223\n",
      "Epoch [465/500], Loss: 1.3959, Accuracy: 0.4337\n",
      "Epoch [466/500], Loss: 1.3983, Accuracy: 0.4208\n",
      "Epoch [467/500], Loss: 1.3916, Accuracy: 0.4300\n",
      "Epoch [468/500], Loss: 1.3970, Accuracy: 0.4238\n",
      "Epoch [469/500], Loss: 1.3868, Accuracy: 0.4363\n",
      "Epoch [470/500], Loss: 1.3997, Accuracy: 0.4273\n",
      "Epoch [471/500], Loss: 1.3849, Accuracy: 0.4347\n",
      "Epoch [472/500], Loss: 1.3781, Accuracy: 0.4381\n",
      "Epoch [473/500], Loss: 1.3826, Accuracy: 0.4337\n",
      "Epoch [474/500], Loss: 1.3948, Accuracy: 0.4250\n",
      "Epoch [475/500], Loss: 1.3638, Accuracy: 0.4304\n",
      "Epoch [476/500], Loss: 1.4019, Accuracy: 0.4263\n",
      "Epoch [477/500], Loss: 1.3877, Accuracy: 0.4295\n",
      "Epoch [478/500], Loss: 1.3835, Accuracy: 0.4272\n",
      "Epoch [479/500], Loss: 1.3879, Accuracy: 0.4336\n",
      "Epoch [480/500], Loss: 1.3900, Accuracy: 0.4410\n",
      "Epoch [481/500], Loss: 1.3947, Accuracy: 0.4324\n",
      "Epoch [482/500], Loss: 1.3986, Accuracy: 0.4208\n",
      "Epoch [483/500], Loss: 1.3826, Accuracy: 0.4287\n",
      "Epoch [484/500], Loss: 1.3982, Accuracy: 0.4312\n",
      "Epoch [485/500], Loss: 1.3992, Accuracy: 0.4265\n",
      "Epoch [486/500], Loss: 1.3955, Accuracy: 0.4263\n",
      "Epoch [487/500], Loss: 1.3965, Accuracy: 0.4247\n",
      "Epoch [488/500], Loss: 1.4042, Accuracy: 0.4263\n",
      "Epoch [489/500], Loss: 1.3890, Accuracy: 0.4279\n",
      "Epoch [490/500], Loss: 1.3877, Accuracy: 0.4255\n",
      "Epoch [491/500], Loss: 1.3865, Accuracy: 0.4307\n",
      "Epoch [492/500], Loss: 1.3955, Accuracy: 0.4225\n",
      "Epoch [493/500], Loss: 1.3777, Accuracy: 0.4366\n",
      "Epoch [494/500], Loss: 1.3864, Accuracy: 0.4248\n",
      "Epoch [495/500], Loss: 1.3859, Accuracy: 0.4312\n",
      "Epoch [496/500], Loss: 1.3897, Accuracy: 0.4242\n",
      "Epoch [497/500], Loss: 1.3752, Accuracy: 0.4324\n",
      "Epoch [498/500], Loss: 1.3795, Accuracy: 0.4307\n",
      "Epoch [499/500], Loss: 1.3863, Accuracy: 0.4321\n",
      "Epoch [500/500], Loss: 1.4000, Accuracy: 0.4366\n"
     ]
    }
   ],
   "source": [
    "# Standard Deep Neural Network\n",
    "sdnn_model = SimpleDNN(input_size[0], num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(sdnn_model.parameters(), lr=0.001)\n",
    "train(sdnn_model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.6525, Accuracy: 0.2956\n",
      "Epoch [2/500], Loss: 1.5594, Accuracy: 0.3355\n",
      "Epoch [3/500], Loss: 1.5317, Accuracy: 0.3536\n",
      "Epoch [4/500], Loss: 1.5332, Accuracy: 0.3660\n",
      "Epoch [5/500], Loss: 1.4989, Accuracy: 0.3687\n",
      "Epoch [6/500], Loss: 1.4805, Accuracy: 0.3872\n",
      "Epoch [7/500], Loss: 1.4692, Accuracy: 0.3971\n",
      "Epoch [8/500], Loss: 1.4510, Accuracy: 0.4047\n",
      "Epoch [9/500], Loss: 1.4465, Accuracy: 0.4112\n",
      "Epoch [10/500], Loss: 1.4298, Accuracy: 0.4136\n",
      "Epoch [11/500], Loss: 1.4275, Accuracy: 0.4216\n",
      "Epoch [12/500], Loss: 1.4108, Accuracy: 0.4237\n",
      "Epoch [13/500], Loss: 1.4091, Accuracy: 0.4243\n",
      "Epoch [14/500], Loss: 1.4115, Accuracy: 0.4321\n",
      "Epoch [15/500], Loss: 1.3988, Accuracy: 0.4435\n",
      "Epoch [16/500], Loss: 1.4013, Accuracy: 0.4208\n",
      "Epoch [17/500], Loss: 1.3930, Accuracy: 0.4352\n",
      "Epoch [18/500], Loss: 1.3837, Accuracy: 0.4460\n",
      "Epoch [19/500], Loss: 1.3848, Accuracy: 0.4381\n",
      "Epoch [20/500], Loss: 1.3746, Accuracy: 0.4420\n",
      "Epoch [21/500], Loss: 1.3585, Accuracy: 0.4507\n",
      "Epoch [22/500], Loss: 1.3667, Accuracy: 0.4470\n",
      "Epoch [23/500], Loss: 1.3686, Accuracy: 0.4525\n",
      "Epoch [24/500], Loss: 1.3865, Accuracy: 0.4394\n",
      "Epoch [25/500], Loss: 1.3654, Accuracy: 0.4509\n",
      "Epoch [26/500], Loss: 1.3713, Accuracy: 0.4445\n",
      "Epoch [27/500], Loss: 1.3528, Accuracy: 0.4552\n",
      "Epoch [28/500], Loss: 1.3429, Accuracy: 0.4594\n",
      "Epoch [29/500], Loss: 1.3470, Accuracy: 0.4547\n",
      "Epoch [30/500], Loss: 1.3469, Accuracy: 0.4645\n",
      "Epoch [31/500], Loss: 1.3379, Accuracy: 0.4626\n",
      "Epoch [32/500], Loss: 1.3696, Accuracy: 0.4559\n",
      "Epoch [33/500], Loss: 1.3412, Accuracy: 0.4630\n",
      "Epoch [34/500], Loss: 1.3432, Accuracy: 0.4579\n",
      "Epoch [35/500], Loss: 1.3294, Accuracy: 0.4672\n",
      "Epoch [36/500], Loss: 1.3325, Accuracy: 0.4672\n",
      "Epoch [37/500], Loss: 1.3233, Accuracy: 0.4675\n",
      "Epoch [38/500], Loss: 1.3166, Accuracy: 0.4729\n",
      "Epoch [39/500], Loss: 1.3318, Accuracy: 0.4722\n",
      "Epoch [40/500], Loss: 1.3328, Accuracy: 0.4633\n",
      "Epoch [41/500], Loss: 1.3269, Accuracy: 0.4677\n",
      "Epoch [42/500], Loss: 1.3210, Accuracy: 0.4677\n",
      "Epoch [43/500], Loss: 1.3216, Accuracy: 0.4660\n",
      "Epoch [44/500], Loss: 1.2986, Accuracy: 0.4762\n",
      "Epoch [45/500], Loss: 1.3008, Accuracy: 0.4680\n",
      "Epoch [46/500], Loss: 1.3100, Accuracy: 0.4722\n",
      "Epoch [47/500], Loss: 1.3206, Accuracy: 0.4683\n",
      "Epoch [48/500], Loss: 1.3140, Accuracy: 0.4871\n",
      "Epoch [49/500], Loss: 1.3200, Accuracy: 0.4730\n",
      "Epoch [50/500], Loss: 1.2987, Accuracy: 0.4752\n",
      "Epoch [51/500], Loss: 1.3134, Accuracy: 0.4732\n",
      "Epoch [52/500], Loss: 1.2914, Accuracy: 0.4882\n",
      "Epoch [53/500], Loss: 1.2838, Accuracy: 0.4898\n",
      "Epoch [54/500], Loss: 1.3107, Accuracy: 0.4756\n",
      "Epoch [55/500], Loss: 1.2993, Accuracy: 0.4860\n",
      "Epoch [56/500], Loss: 1.2856, Accuracy: 0.4828\n",
      "Epoch [57/500], Loss: 1.3035, Accuracy: 0.4808\n",
      "Epoch [58/500], Loss: 1.3136, Accuracy: 0.4796\n",
      "Epoch [59/500], Loss: 1.2820, Accuracy: 0.4875\n",
      "Epoch [60/500], Loss: 1.2923, Accuracy: 0.4861\n",
      "Epoch [61/500], Loss: 1.2930, Accuracy: 0.4848\n",
      "Epoch [62/500], Loss: 1.2846, Accuracy: 0.4829\n",
      "Epoch [63/500], Loss: 1.2745, Accuracy: 0.4809\n",
      "Epoch [64/500], Loss: 1.2807, Accuracy: 0.4861\n",
      "Epoch [65/500], Loss: 1.2670, Accuracy: 0.4937\n",
      "Epoch [66/500], Loss: 1.2676, Accuracy: 0.4977\n",
      "Epoch [67/500], Loss: 1.2702, Accuracy: 0.4962\n",
      "Epoch [68/500], Loss: 1.2728, Accuracy: 0.4971\n",
      "Epoch [69/500], Loss: 1.2841, Accuracy: 0.4823\n",
      "Epoch [70/500], Loss: 1.2720, Accuracy: 0.4940\n",
      "Epoch [71/500], Loss: 1.2674, Accuracy: 0.4915\n",
      "Epoch [72/500], Loss: 1.2636, Accuracy: 0.4915\n",
      "Epoch [73/500], Loss: 1.2546, Accuracy: 0.4954\n",
      "Epoch [74/500], Loss: 1.2545, Accuracy: 0.5009\n",
      "Epoch [75/500], Loss: 1.2543, Accuracy: 0.4944\n",
      "Epoch [76/500], Loss: 1.2558, Accuracy: 0.4972\n",
      "Epoch [77/500], Loss: 1.2515, Accuracy: 0.5061\n",
      "Epoch [78/500], Loss: 1.2585, Accuracy: 0.4961\n",
      "Epoch [79/500], Loss: 1.2565, Accuracy: 0.5081\n",
      "Epoch [80/500], Loss: 1.2767, Accuracy: 0.4892\n",
      "Epoch [81/500], Loss: 1.2422, Accuracy: 0.4969\n",
      "Epoch [82/500], Loss: 1.2425, Accuracy: 0.5048\n",
      "Epoch [83/500], Loss: 1.2451, Accuracy: 0.5071\n",
      "Epoch [84/500], Loss: 1.2424, Accuracy: 0.5039\n",
      "Epoch [85/500], Loss: 1.2433, Accuracy: 0.5058\n",
      "Epoch [86/500], Loss: 1.2346, Accuracy: 0.5058\n",
      "Epoch [87/500], Loss: 1.2358, Accuracy: 0.5023\n",
      "Epoch [88/500], Loss: 1.2413, Accuracy: 0.5087\n",
      "Epoch [89/500], Loss: 1.2722, Accuracy: 0.4922\n",
      "Epoch [90/500], Loss: 1.2299, Accuracy: 0.5108\n",
      "Epoch [91/500], Loss: 1.2248, Accuracy: 0.5105\n",
      "Epoch [92/500], Loss: 1.2354, Accuracy: 0.5039\n",
      "Epoch [93/500], Loss: 1.2276, Accuracy: 0.5100\n",
      "Epoch [94/500], Loss: 1.2229, Accuracy: 0.5144\n",
      "Epoch [95/500], Loss: 1.2203, Accuracy: 0.5246\n",
      "Epoch [96/500], Loss: 1.2306, Accuracy: 0.5060\n",
      "Epoch [97/500], Loss: 1.2233, Accuracy: 0.5160\n",
      "Epoch [98/500], Loss: 1.2212, Accuracy: 0.5172\n",
      "Epoch [99/500], Loss: 1.2249, Accuracy: 0.5254\n",
      "Epoch [100/500], Loss: 1.2213, Accuracy: 0.5162\n",
      "Epoch [101/500], Loss: 1.2386, Accuracy: 0.5108\n",
      "Epoch [102/500], Loss: 1.2276, Accuracy: 0.5197\n",
      "Epoch [103/500], Loss: 1.2245, Accuracy: 0.5123\n",
      "Epoch [104/500], Loss: 1.2162, Accuracy: 0.5181\n",
      "Epoch [105/500], Loss: 1.2113, Accuracy: 0.5194\n",
      "Epoch [106/500], Loss: 1.2029, Accuracy: 0.5231\n",
      "Epoch [107/500], Loss: 1.2175, Accuracy: 0.5192\n",
      "Epoch [108/500], Loss: 1.2021, Accuracy: 0.5246\n",
      "Epoch [109/500], Loss: 1.2038, Accuracy: 0.5228\n",
      "Epoch [110/500], Loss: 1.1981, Accuracy: 0.5249\n",
      "Epoch [111/500], Loss: 1.2076, Accuracy: 0.5181\n",
      "Epoch [112/500], Loss: 1.2042, Accuracy: 0.5318\n",
      "Epoch [113/500], Loss: 1.2003, Accuracy: 0.5268\n",
      "Epoch [114/500], Loss: 1.1941, Accuracy: 0.5337\n",
      "Epoch [115/500], Loss: 1.1860, Accuracy: 0.5313\n",
      "Epoch [116/500], Loss: 1.1843, Accuracy: 0.5256\n",
      "Epoch [117/500], Loss: 1.1722, Accuracy: 0.5382\n",
      "Epoch [118/500], Loss: 1.1753, Accuracy: 0.5327\n",
      "Epoch [119/500], Loss: 1.1884, Accuracy: 0.5295\n",
      "Epoch [120/500], Loss: 1.2002, Accuracy: 0.5211\n",
      "Epoch [121/500], Loss: 1.2027, Accuracy: 0.5201\n",
      "Epoch [122/500], Loss: 1.1915, Accuracy: 0.5318\n",
      "Epoch [123/500], Loss: 1.2122, Accuracy: 0.5144\n",
      "Epoch [124/500], Loss: 1.1768, Accuracy: 0.5344\n",
      "Epoch [125/500], Loss: 1.1756, Accuracy: 0.5344\n",
      "Epoch [126/500], Loss: 1.1769, Accuracy: 0.5322\n",
      "Epoch [127/500], Loss: 1.1704, Accuracy: 0.5349\n",
      "Epoch [128/500], Loss: 1.1919, Accuracy: 0.5328\n",
      "Epoch [129/500], Loss: 1.1842, Accuracy: 0.5285\n",
      "Epoch [130/500], Loss: 1.1670, Accuracy: 0.5426\n",
      "Epoch [131/500], Loss: 1.1915, Accuracy: 0.5275\n",
      "Epoch [132/500], Loss: 1.1737, Accuracy: 0.5379\n",
      "Epoch [133/500], Loss: 1.1630, Accuracy: 0.5454\n",
      "Epoch [134/500], Loss: 1.1688, Accuracy: 0.5322\n",
      "Epoch [135/500], Loss: 1.1639, Accuracy: 0.5488\n",
      "Epoch [136/500], Loss: 1.1768, Accuracy: 0.5283\n",
      "Epoch [137/500], Loss: 1.1738, Accuracy: 0.5342\n",
      "Epoch [138/500], Loss: 1.1793, Accuracy: 0.5364\n",
      "Epoch [139/500], Loss: 1.1564, Accuracy: 0.5392\n",
      "Epoch [140/500], Loss: 1.1545, Accuracy: 0.5426\n",
      "Epoch [141/500], Loss: 1.1659, Accuracy: 0.5464\n",
      "Epoch [142/500], Loss: 1.1634, Accuracy: 0.5419\n",
      "Epoch [143/500], Loss: 1.1582, Accuracy: 0.5416\n",
      "Epoch [144/500], Loss: 1.1490, Accuracy: 0.5485\n",
      "Epoch [145/500], Loss: 1.1523, Accuracy: 0.5428\n",
      "Epoch [146/500], Loss: 1.1677, Accuracy: 0.5409\n",
      "Epoch [147/500], Loss: 1.1674, Accuracy: 0.5380\n",
      "Epoch [148/500], Loss: 1.1467, Accuracy: 0.5496\n",
      "Epoch [149/500], Loss: 1.1467, Accuracy: 0.5548\n",
      "Epoch [150/500], Loss: 1.1684, Accuracy: 0.5379\n",
      "Epoch [151/500], Loss: 1.1823, Accuracy: 0.5281\n",
      "Epoch [152/500], Loss: 1.1617, Accuracy: 0.5438\n",
      "Epoch [153/500], Loss: 1.1556, Accuracy: 0.5406\n",
      "Epoch [154/500], Loss: 1.1389, Accuracy: 0.5483\n",
      "Epoch [155/500], Loss: 1.1459, Accuracy: 0.5517\n",
      "Epoch [156/500], Loss: 1.1515, Accuracy: 0.5458\n",
      "Epoch [157/500], Loss: 1.1399, Accuracy: 0.5513\n",
      "Epoch [158/500], Loss: 1.1433, Accuracy: 0.5500\n",
      "Epoch [159/500], Loss: 1.1281, Accuracy: 0.5559\n",
      "Epoch [160/500], Loss: 1.1348, Accuracy: 0.5547\n",
      "Epoch [161/500], Loss: 1.1423, Accuracy: 0.5508\n",
      "Epoch [162/500], Loss: 1.1248, Accuracy: 0.5540\n",
      "Epoch [163/500], Loss: 1.1268, Accuracy: 0.5567\n",
      "Epoch [164/500], Loss: 1.1428, Accuracy: 0.5545\n",
      "Epoch [165/500], Loss: 1.1293, Accuracy: 0.5543\n",
      "Epoch [166/500], Loss: 1.1350, Accuracy: 0.5523\n",
      "Epoch [167/500], Loss: 1.1257, Accuracy: 0.5564\n",
      "Epoch [168/500], Loss: 1.1316, Accuracy: 0.5547\n",
      "Epoch [169/500], Loss: 1.1252, Accuracy: 0.5547\n",
      "Epoch [170/500], Loss: 1.1294, Accuracy: 0.5584\n",
      "Epoch [171/500], Loss: 1.1092, Accuracy: 0.5602\n",
      "Epoch [172/500], Loss: 1.1097, Accuracy: 0.5607\n",
      "Epoch [173/500], Loss: 1.1172, Accuracy: 0.5590\n",
      "Epoch [174/500], Loss: 1.1178, Accuracy: 0.5599\n",
      "Epoch [175/500], Loss: 1.1249, Accuracy: 0.5557\n",
      "Epoch [176/500], Loss: 1.1099, Accuracy: 0.5602\n",
      "Epoch [177/500], Loss: 1.1122, Accuracy: 0.5611\n",
      "Epoch [178/500], Loss: 1.1156, Accuracy: 0.5592\n",
      "Epoch [179/500], Loss: 1.1012, Accuracy: 0.5676\n",
      "Epoch [180/500], Loss: 1.1170, Accuracy: 0.5584\n",
      "Epoch [181/500], Loss: 1.1048, Accuracy: 0.5570\n",
      "Epoch [182/500], Loss: 1.0991, Accuracy: 0.5705\n",
      "Epoch [183/500], Loss: 1.0978, Accuracy: 0.5752\n",
      "Epoch [184/500], Loss: 1.0963, Accuracy: 0.5686\n",
      "Epoch [185/500], Loss: 1.0936, Accuracy: 0.5695\n",
      "Epoch [186/500], Loss: 1.0921, Accuracy: 0.5674\n",
      "Epoch [187/500], Loss: 1.1108, Accuracy: 0.5641\n",
      "Epoch [188/500], Loss: 1.1130, Accuracy: 0.5616\n",
      "Epoch [189/500], Loss: 1.0987, Accuracy: 0.5634\n",
      "Epoch [190/500], Loss: 1.0824, Accuracy: 0.5760\n",
      "Epoch [191/500], Loss: 1.0934, Accuracy: 0.5622\n",
      "Epoch [192/500], Loss: 1.0937, Accuracy: 0.5658\n",
      "Epoch [193/500], Loss: 1.0923, Accuracy: 0.5631\n",
      "Epoch [194/500], Loss: 1.0886, Accuracy: 0.5696\n",
      "Epoch [195/500], Loss: 1.0934, Accuracy: 0.5710\n",
      "Epoch [196/500], Loss: 1.1317, Accuracy: 0.5478\n",
      "Epoch [197/500], Loss: 1.0874, Accuracy: 0.5718\n",
      "Epoch [198/500], Loss: 1.0826, Accuracy: 0.5715\n",
      "Epoch [199/500], Loss: 1.0819, Accuracy: 0.5777\n",
      "Epoch [200/500], Loss: 1.0914, Accuracy: 0.5695\n",
      "Epoch [201/500], Loss: 1.0765, Accuracy: 0.5742\n",
      "Epoch [202/500], Loss: 1.0757, Accuracy: 0.5740\n",
      "Epoch [203/500], Loss: 1.0765, Accuracy: 0.5807\n",
      "Epoch [204/500], Loss: 1.0675, Accuracy: 0.5758\n",
      "Epoch [205/500], Loss: 1.0719, Accuracy: 0.5763\n",
      "Epoch [206/500], Loss: 1.0740, Accuracy: 0.5809\n",
      "Epoch [207/500], Loss: 1.0803, Accuracy: 0.5817\n",
      "Epoch [208/500], Loss: 1.0885, Accuracy: 0.5643\n",
      "Epoch [209/500], Loss: 1.0594, Accuracy: 0.5775\n",
      "Epoch [210/500], Loss: 1.0686, Accuracy: 0.5780\n",
      "Epoch [211/500], Loss: 1.0640, Accuracy: 0.5844\n",
      "Epoch [212/500], Loss: 1.0711, Accuracy: 0.5762\n",
      "Epoch [213/500], Loss: 1.0700, Accuracy: 0.5785\n",
      "Epoch [214/500], Loss: 1.0642, Accuracy: 0.5831\n",
      "Epoch [215/500], Loss: 1.0667, Accuracy: 0.5819\n",
      "Epoch [216/500], Loss: 1.0655, Accuracy: 0.5811\n",
      "Epoch [217/500], Loss: 1.0767, Accuracy: 0.5740\n",
      "Epoch [218/500], Loss: 1.0613, Accuracy: 0.5822\n",
      "Epoch [219/500], Loss: 1.0673, Accuracy: 0.5775\n",
      "Epoch [220/500], Loss: 1.0608, Accuracy: 0.5874\n",
      "Epoch [221/500], Loss: 1.0712, Accuracy: 0.5747\n",
      "Epoch [222/500], Loss: 1.0423, Accuracy: 0.5901\n",
      "Epoch [223/500], Loss: 1.0618, Accuracy: 0.5770\n",
      "Epoch [224/500], Loss: 1.0480, Accuracy: 0.5841\n",
      "Epoch [225/500], Loss: 1.0507, Accuracy: 0.5889\n",
      "Epoch [226/500], Loss: 1.0678, Accuracy: 0.5784\n",
      "Epoch [227/500], Loss: 1.1601, Accuracy: 0.5365\n",
      "Epoch [228/500], Loss: 1.1046, Accuracy: 0.5649\n",
      "Epoch [229/500], Loss: 1.0868, Accuracy: 0.5743\n",
      "Epoch [230/500], Loss: 1.0794, Accuracy: 0.5676\n",
      "Epoch [231/500], Loss: 1.0636, Accuracy: 0.5799\n",
      "Epoch [232/500], Loss: 1.0567, Accuracy: 0.5819\n",
      "Epoch [233/500], Loss: 1.0485, Accuracy: 0.5844\n",
      "Epoch [234/500], Loss: 1.0392, Accuracy: 0.5973\n",
      "Epoch [235/500], Loss: 1.0497, Accuracy: 0.5879\n",
      "Epoch [236/500], Loss: 1.0387, Accuracy: 0.5901\n",
      "Epoch [237/500], Loss: 1.0346, Accuracy: 0.5933\n",
      "Epoch [238/500], Loss: 1.0471, Accuracy: 0.5938\n",
      "Epoch [239/500], Loss: 1.0354, Accuracy: 0.5945\n",
      "Epoch [240/500], Loss: 1.0390, Accuracy: 0.5950\n",
      "Epoch [241/500], Loss: 1.0288, Accuracy: 0.5952\n",
      "Epoch [242/500], Loss: 1.0333, Accuracy: 0.5958\n",
      "Epoch [243/500], Loss: 1.0727, Accuracy: 0.5769\n",
      "Epoch [244/500], Loss: 1.0617, Accuracy: 0.5819\n",
      "Epoch [245/500], Loss: 1.0622, Accuracy: 0.5822\n",
      "Epoch [246/500], Loss: 1.0578, Accuracy: 0.5900\n",
      "Epoch [247/500], Loss: 1.0401, Accuracy: 0.5945\n",
      "Epoch [248/500], Loss: 1.0473, Accuracy: 0.5921\n",
      "Epoch [249/500], Loss: 1.0399, Accuracy: 0.5854\n",
      "Epoch [250/500], Loss: 1.0418, Accuracy: 0.5928\n",
      "Epoch [251/500], Loss: 1.0433, Accuracy: 0.5947\n",
      "Epoch [252/500], Loss: 1.0749, Accuracy: 0.5705\n",
      "Epoch [253/500], Loss: 1.0402, Accuracy: 0.5905\n",
      "Epoch [254/500], Loss: 1.0291, Accuracy: 0.5965\n",
      "Epoch [255/500], Loss: 1.0320, Accuracy: 0.5980\n",
      "Epoch [256/500], Loss: 1.0236, Accuracy: 0.5968\n",
      "Epoch [257/500], Loss: 1.0336, Accuracy: 0.5958\n",
      "Epoch [258/500], Loss: 1.0294, Accuracy: 0.5940\n",
      "Epoch [259/500], Loss: 1.0238, Accuracy: 0.5920\n",
      "Epoch [260/500], Loss: 1.0262, Accuracy: 0.6002\n",
      "Epoch [261/500], Loss: 1.0337, Accuracy: 0.5928\n",
      "Epoch [262/500], Loss: 1.0299, Accuracy: 0.5987\n",
      "Epoch [263/500], Loss: 1.0029, Accuracy: 0.6024\n",
      "Epoch [264/500], Loss: 1.0205, Accuracy: 0.6044\n",
      "Epoch [265/500], Loss: 1.0202, Accuracy: 0.6042\n",
      "Epoch [266/500], Loss: 1.0226, Accuracy: 0.6020\n",
      "Epoch [267/500], Loss: 0.9944, Accuracy: 0.6133\n",
      "Epoch [268/500], Loss: 1.0164, Accuracy: 0.6037\n",
      "Epoch [269/500], Loss: 1.0385, Accuracy: 0.5967\n",
      "Epoch [270/500], Loss: 1.0721, Accuracy: 0.5777\n",
      "Epoch [271/500], Loss: 1.0275, Accuracy: 0.6044\n",
      "Epoch [272/500], Loss: 1.0556, Accuracy: 0.5913\n",
      "Epoch [273/500], Loss: 1.0540, Accuracy: 0.5876\n",
      "Epoch [274/500], Loss: 1.0116, Accuracy: 0.6020\n",
      "Epoch [275/500], Loss: 1.0090, Accuracy: 0.5995\n",
      "Epoch [276/500], Loss: 0.9889, Accuracy: 0.6152\n",
      "Epoch [277/500], Loss: 1.0141, Accuracy: 0.6032\n",
      "Epoch [278/500], Loss: 1.0055, Accuracy: 0.6039\n",
      "Epoch [279/500], Loss: 1.0143, Accuracy: 0.6061\n",
      "Epoch [280/500], Loss: 0.9848, Accuracy: 0.6121\n",
      "Epoch [281/500], Loss: 0.9942, Accuracy: 0.6126\n",
      "Epoch [282/500], Loss: 0.9925, Accuracy: 0.6110\n",
      "Epoch [283/500], Loss: 0.9923, Accuracy: 0.6103\n",
      "Epoch [284/500], Loss: 1.0402, Accuracy: 0.5938\n",
      "Epoch [285/500], Loss: 0.9915, Accuracy: 0.6138\n",
      "Epoch [286/500], Loss: 0.9891, Accuracy: 0.6180\n",
      "Epoch [287/500], Loss: 0.9868, Accuracy: 0.6089\n",
      "Epoch [288/500], Loss: 1.0016, Accuracy: 0.6135\n",
      "Epoch [289/500], Loss: 1.0474, Accuracy: 0.5911\n",
      "Epoch [290/500], Loss: 1.0096, Accuracy: 0.6046\n",
      "Epoch [291/500], Loss: 1.0311, Accuracy: 0.6009\n",
      "Epoch [292/500], Loss: 1.0089, Accuracy: 0.6071\n",
      "Epoch [293/500], Loss: 1.0063, Accuracy: 0.6120\n",
      "Epoch [294/500], Loss: 1.0025, Accuracy: 0.6047\n",
      "Epoch [295/500], Loss: 1.0184, Accuracy: 0.6096\n",
      "Epoch [296/500], Loss: 1.0617, Accuracy: 0.5883\n",
      "Epoch [297/500], Loss: 1.0033, Accuracy: 0.6026\n",
      "Epoch [298/500], Loss: 0.9841, Accuracy: 0.6163\n",
      "Epoch [299/500], Loss: 0.9936, Accuracy: 0.6103\n",
      "Epoch [300/500], Loss: 0.9879, Accuracy: 0.6177\n",
      "Epoch [301/500], Loss: 0.9693, Accuracy: 0.6241\n",
      "Epoch [302/500], Loss: 0.9763, Accuracy: 0.6227\n",
      "Epoch [303/500], Loss: 1.0472, Accuracy: 0.5999\n",
      "Epoch [304/500], Loss: 0.9618, Accuracy: 0.6251\n",
      "Epoch [305/500], Loss: 0.9706, Accuracy: 0.6190\n",
      "Epoch [306/500], Loss: 0.9573, Accuracy: 0.6313\n",
      "Epoch [307/500], Loss: 0.9652, Accuracy: 0.6278\n",
      "Epoch [308/500], Loss: 0.9880, Accuracy: 0.6141\n",
      "Epoch [309/500], Loss: 0.9961, Accuracy: 0.6116\n",
      "Epoch [310/500], Loss: 1.0014, Accuracy: 0.6140\n",
      "Epoch [311/500], Loss: 0.9976, Accuracy: 0.6126\n",
      "Epoch [312/500], Loss: 0.9980, Accuracy: 0.6116\n",
      "Epoch [313/500], Loss: 0.9794, Accuracy: 0.6202\n",
      "Epoch [314/500], Loss: 0.9630, Accuracy: 0.6278\n",
      "Epoch [315/500], Loss: 0.9931, Accuracy: 0.6106\n",
      "Epoch [316/500], Loss: 0.9679, Accuracy: 0.6299\n",
      "Epoch [317/500], Loss: 1.0079, Accuracy: 0.6104\n",
      "Epoch [318/500], Loss: 0.9595, Accuracy: 0.6283\n",
      "Epoch [319/500], Loss: 0.9884, Accuracy: 0.6130\n",
      "Epoch [320/500], Loss: 0.9657, Accuracy: 0.6239\n",
      "Epoch [321/500], Loss: 0.9518, Accuracy: 0.6308\n",
      "Epoch [322/500], Loss: 0.9585, Accuracy: 0.6318\n",
      "Epoch [323/500], Loss: 0.9423, Accuracy: 0.6398\n",
      "Epoch [324/500], Loss: 0.9382, Accuracy: 0.6328\n",
      "Epoch [325/500], Loss: 0.9492, Accuracy: 0.6278\n",
      "Epoch [326/500], Loss: 0.9450, Accuracy: 0.6338\n",
      "Epoch [327/500], Loss: 0.9628, Accuracy: 0.6262\n",
      "Epoch [328/500], Loss: 0.9688, Accuracy: 0.6236\n",
      "Epoch [329/500], Loss: 0.9533, Accuracy: 0.6271\n",
      "Epoch [330/500], Loss: 0.9444, Accuracy: 0.6330\n",
      "Epoch [331/500], Loss: 0.9502, Accuracy: 0.6303\n",
      "Epoch [332/500], Loss: 0.9572, Accuracy: 0.6284\n",
      "Epoch [333/500], Loss: 0.9478, Accuracy: 0.6298\n",
      "Epoch [334/500], Loss: 0.9441, Accuracy: 0.6355\n",
      "Epoch [335/500], Loss: 0.9490, Accuracy: 0.6293\n",
      "Epoch [336/500], Loss: 0.9438, Accuracy: 0.6355\n",
      "Epoch [337/500], Loss: 0.9447, Accuracy: 0.6304\n",
      "Epoch [338/500], Loss: 0.9509, Accuracy: 0.6372\n",
      "Epoch [339/500], Loss: 0.9617, Accuracy: 0.6256\n",
      "Epoch [340/500], Loss: 0.9560, Accuracy: 0.6271\n",
      "Epoch [341/500], Loss: 0.9437, Accuracy: 0.6350\n",
      "Epoch [342/500], Loss: 0.9460, Accuracy: 0.6313\n",
      "Epoch [343/500], Loss: 0.9434, Accuracy: 0.6370\n",
      "Epoch [344/500], Loss: 0.9476, Accuracy: 0.6336\n",
      "Epoch [345/500], Loss: 0.9407, Accuracy: 0.6377\n",
      "Epoch [346/500], Loss: 0.9292, Accuracy: 0.6360\n",
      "Epoch [347/500], Loss: 0.9406, Accuracy: 0.6358\n",
      "Epoch [348/500], Loss: 0.9376, Accuracy: 0.6355\n",
      "Epoch [349/500], Loss: 0.9281, Accuracy: 0.6380\n",
      "Epoch [350/500], Loss: 0.9358, Accuracy: 0.6370\n",
      "Epoch [351/500], Loss: 0.9300, Accuracy: 0.6385\n",
      "Epoch [352/500], Loss: 0.9529, Accuracy: 0.6308\n",
      "Epoch [353/500], Loss: 0.9266, Accuracy: 0.6390\n",
      "Epoch [354/500], Loss: 0.9351, Accuracy: 0.6387\n",
      "Epoch [355/500], Loss: 0.9286, Accuracy: 0.6414\n",
      "Epoch [356/500], Loss: 0.9203, Accuracy: 0.6434\n",
      "Epoch [357/500], Loss: 0.9226, Accuracy: 0.6459\n",
      "Epoch [358/500], Loss: 0.9339, Accuracy: 0.6388\n",
      "Epoch [359/500], Loss: 0.9404, Accuracy: 0.6361\n",
      "Epoch [360/500], Loss: 0.9255, Accuracy: 0.6437\n",
      "Epoch [361/500], Loss: 0.9278, Accuracy: 0.6388\n",
      "Epoch [362/500], Loss: 0.9342, Accuracy: 0.6361\n",
      "Epoch [363/500], Loss: 0.9184, Accuracy: 0.6464\n",
      "Epoch [364/500], Loss: 0.9083, Accuracy: 0.6451\n",
      "Epoch [365/500], Loss: 0.9251, Accuracy: 0.6452\n",
      "Epoch [366/500], Loss: 0.9348, Accuracy: 0.6375\n",
      "Epoch [367/500], Loss: 0.9070, Accuracy: 0.6516\n",
      "Epoch [368/500], Loss: 0.9238, Accuracy: 0.6419\n",
      "Epoch [369/500], Loss: 0.9004, Accuracy: 0.6583\n",
      "Epoch [370/500], Loss: 0.9009, Accuracy: 0.6540\n",
      "Epoch [371/500], Loss: 0.9160, Accuracy: 0.6498\n",
      "Epoch [372/500], Loss: 0.9262, Accuracy: 0.6403\n",
      "Epoch [373/500], Loss: 0.9117, Accuracy: 0.6454\n",
      "Epoch [374/500], Loss: 0.9215, Accuracy: 0.6493\n",
      "Epoch [375/500], Loss: 0.9360, Accuracy: 0.6387\n",
      "Epoch [376/500], Loss: 0.9198, Accuracy: 0.6402\n",
      "Epoch [377/500], Loss: 0.9066, Accuracy: 0.6439\n",
      "Epoch [378/500], Loss: 0.9111, Accuracy: 0.6467\n",
      "Epoch [379/500], Loss: 0.9160, Accuracy: 0.6435\n",
      "Epoch [380/500], Loss: 0.9162, Accuracy: 0.6412\n",
      "Epoch [381/500], Loss: 0.9111, Accuracy: 0.6504\n",
      "Epoch [382/500], Loss: 0.8994, Accuracy: 0.6524\n",
      "Epoch [383/500], Loss: 0.9567, Accuracy: 0.6266\n",
      "Epoch [384/500], Loss: 0.9246, Accuracy: 0.6407\n",
      "Epoch [385/500], Loss: 0.9049, Accuracy: 0.6467\n",
      "Epoch [386/500], Loss: 0.9072, Accuracy: 0.6486\n",
      "Epoch [387/500], Loss: 0.9127, Accuracy: 0.6518\n",
      "Epoch [388/500], Loss: 0.9104, Accuracy: 0.6432\n",
      "Epoch [389/500], Loss: 0.9268, Accuracy: 0.6395\n",
      "Epoch [390/500], Loss: 0.8963, Accuracy: 0.6518\n",
      "Epoch [391/500], Loss: 0.8915, Accuracy: 0.6568\n",
      "Epoch [392/500], Loss: 0.8888, Accuracy: 0.6593\n",
      "Epoch [393/500], Loss: 0.9368, Accuracy: 0.6365\n",
      "Epoch [394/500], Loss: 0.9138, Accuracy: 0.6437\n",
      "Epoch [395/500], Loss: 0.8957, Accuracy: 0.6538\n",
      "Epoch [396/500], Loss: 0.8978, Accuracy: 0.6558\n",
      "Epoch [397/500], Loss: 0.8815, Accuracy: 0.6593\n",
      "Epoch [398/500], Loss: 0.8970, Accuracy: 0.6560\n",
      "Epoch [399/500], Loss: 0.8996, Accuracy: 0.6449\n",
      "Epoch [400/500], Loss: 0.8930, Accuracy: 0.6496\n",
      "Epoch [401/500], Loss: 0.8848, Accuracy: 0.6598\n",
      "Epoch [402/500], Loss: 0.9298, Accuracy: 0.6457\n",
      "Epoch [403/500], Loss: 0.9654, Accuracy: 0.6232\n",
      "Epoch [404/500], Loss: 0.8902, Accuracy: 0.6607\n",
      "Epoch [405/500], Loss: 0.8951, Accuracy: 0.6573\n",
      "Epoch [406/500], Loss: 0.8969, Accuracy: 0.6548\n",
      "Epoch [407/500], Loss: 0.8682, Accuracy: 0.6642\n",
      "Epoch [408/500], Loss: 0.8733, Accuracy: 0.6613\n",
      "Epoch [409/500], Loss: 0.8895, Accuracy: 0.6580\n",
      "Epoch [410/500], Loss: 0.8841, Accuracy: 0.6561\n",
      "Epoch [411/500], Loss: 0.8777, Accuracy: 0.6558\n",
      "Epoch [412/500], Loss: 0.8687, Accuracy: 0.6610\n",
      "Epoch [413/500], Loss: 0.8766, Accuracy: 0.6619\n",
      "Epoch [414/500], Loss: 0.9059, Accuracy: 0.6550\n",
      "Epoch [415/500], Loss: 0.8794, Accuracy: 0.6645\n",
      "Epoch [416/500], Loss: 0.8734, Accuracy: 0.6624\n",
      "Epoch [417/500], Loss: 0.9043, Accuracy: 0.6429\n",
      "Epoch [418/500], Loss: 0.8677, Accuracy: 0.6622\n",
      "Epoch [419/500], Loss: 0.8922, Accuracy: 0.6603\n",
      "Epoch [420/500], Loss: 0.9016, Accuracy: 0.6582\n",
      "Epoch [421/500], Loss: 0.8877, Accuracy: 0.6566\n",
      "Epoch [422/500], Loss: 0.8898, Accuracy: 0.6570\n",
      "Epoch [423/500], Loss: 0.8976, Accuracy: 0.6514\n",
      "Epoch [424/500], Loss: 0.9063, Accuracy: 0.6482\n",
      "Epoch [425/500], Loss: 0.8887, Accuracy: 0.6511\n",
      "Epoch [426/500], Loss: 0.8744, Accuracy: 0.6563\n",
      "Epoch [427/500], Loss: 0.8842, Accuracy: 0.6573\n",
      "Epoch [428/500], Loss: 0.8825, Accuracy: 0.6521\n",
      "Epoch [429/500], Loss: 0.8707, Accuracy: 0.6652\n",
      "Epoch [430/500], Loss: 0.8573, Accuracy: 0.6650\n",
      "Epoch [431/500], Loss: 0.8636, Accuracy: 0.6689\n",
      "Epoch [432/500], Loss: 0.8843, Accuracy: 0.6610\n",
      "Epoch [433/500], Loss: 0.8751, Accuracy: 0.6625\n",
      "Epoch [434/500], Loss: 0.8643, Accuracy: 0.6703\n",
      "Epoch [435/500], Loss: 0.8762, Accuracy: 0.6595\n",
      "Epoch [436/500], Loss: 0.8749, Accuracy: 0.6610\n",
      "Epoch [437/500], Loss: 0.9151, Accuracy: 0.6427\n",
      "Epoch [438/500], Loss: 0.8498, Accuracy: 0.6708\n",
      "Epoch [439/500], Loss: 0.8434, Accuracy: 0.6736\n",
      "Epoch [440/500], Loss: 0.8469, Accuracy: 0.6697\n",
      "Epoch [441/500], Loss: 0.8820, Accuracy: 0.6575\n",
      "Epoch [442/500], Loss: 0.8627, Accuracy: 0.6624\n",
      "Epoch [443/500], Loss: 0.8600, Accuracy: 0.6691\n",
      "Epoch [444/500], Loss: 0.8611, Accuracy: 0.6625\n",
      "Epoch [445/500], Loss: 0.8585, Accuracy: 0.6603\n",
      "Epoch [446/500], Loss: 0.8559, Accuracy: 0.6691\n",
      "Epoch [447/500], Loss: 0.8570, Accuracy: 0.6624\n",
      "Epoch [448/500], Loss: 0.8517, Accuracy: 0.6728\n",
      "Epoch [449/500], Loss: 0.8515, Accuracy: 0.6697\n",
      "Epoch [450/500], Loss: 0.8421, Accuracy: 0.6741\n",
      "Epoch [451/500], Loss: 0.8426, Accuracy: 0.6713\n",
      "Epoch [452/500], Loss: 0.8570, Accuracy: 0.6666\n",
      "Epoch [453/500], Loss: 0.8519, Accuracy: 0.6687\n",
      "Epoch [454/500], Loss: 0.8511, Accuracy: 0.6713\n",
      "Epoch [455/500], Loss: 0.8514, Accuracy: 0.6684\n",
      "Epoch [456/500], Loss: 0.8678, Accuracy: 0.6610\n",
      "Epoch [457/500], Loss: 0.8419, Accuracy: 0.6671\n",
      "Epoch [458/500], Loss: 0.8426, Accuracy: 0.6733\n",
      "Epoch [459/500], Loss: 0.8324, Accuracy: 0.6744\n",
      "Epoch [460/500], Loss: 0.8521, Accuracy: 0.6689\n",
      "Epoch [461/500], Loss: 0.8567, Accuracy: 0.6692\n",
      "Epoch [462/500], Loss: 0.8629, Accuracy: 0.6634\n",
      "Epoch [463/500], Loss: 0.8449, Accuracy: 0.6733\n",
      "Epoch [464/500], Loss: 0.8446, Accuracy: 0.6761\n",
      "Epoch [465/500], Loss: 0.8284, Accuracy: 0.6783\n",
      "Epoch [466/500], Loss: 0.8293, Accuracy: 0.6739\n",
      "Epoch [467/500], Loss: 0.8376, Accuracy: 0.6797\n",
      "Epoch [468/500], Loss: 0.8436, Accuracy: 0.6748\n",
      "Epoch [469/500], Loss: 0.8356, Accuracy: 0.6765\n",
      "Epoch [470/500], Loss: 0.8280, Accuracy: 0.6832\n",
      "Epoch [471/500], Loss: 0.8607, Accuracy: 0.6743\n",
      "Epoch [472/500], Loss: 0.8510, Accuracy: 0.6713\n",
      "Epoch [473/500], Loss: 0.8357, Accuracy: 0.6755\n",
      "Epoch [474/500], Loss: 0.8532, Accuracy: 0.6701\n",
      "Epoch [475/500], Loss: 0.8337, Accuracy: 0.6773\n",
      "Epoch [476/500], Loss: 0.8349, Accuracy: 0.6718\n",
      "Epoch [477/500], Loss: 0.8213, Accuracy: 0.6750\n",
      "Epoch [478/500], Loss: 0.8228, Accuracy: 0.6797\n",
      "Epoch [479/500], Loss: 0.8294, Accuracy: 0.6795\n",
      "Epoch [480/500], Loss: 0.8118, Accuracy: 0.6854\n",
      "Epoch [481/500], Loss: 0.8327, Accuracy: 0.6780\n",
      "Epoch [482/500], Loss: 0.9546, Accuracy: 0.6283\n",
      "Epoch [483/500], Loss: 0.8905, Accuracy: 0.6657\n",
      "Epoch [484/500], Loss: 0.9046, Accuracy: 0.6444\n",
      "Epoch [485/500], Loss: 0.8507, Accuracy: 0.6691\n",
      "Epoch [486/500], Loss: 0.8020, Accuracy: 0.6943\n",
      "Epoch [487/500], Loss: 0.8078, Accuracy: 0.6876\n",
      "Epoch [488/500], Loss: 0.8196, Accuracy: 0.6817\n",
      "Epoch [489/500], Loss: 0.8171, Accuracy: 0.6857\n",
      "Epoch [490/500], Loss: 0.8221, Accuracy: 0.6807\n",
      "Epoch [491/500], Loss: 0.8199, Accuracy: 0.6876\n",
      "Epoch [492/500], Loss: 0.8043, Accuracy: 0.6899\n",
      "Epoch [493/500], Loss: 0.8251, Accuracy: 0.6813\n",
      "Epoch [494/500], Loss: 0.8822, Accuracy: 0.6595\n",
      "Epoch [495/500], Loss: 0.8225, Accuracy: 0.6808\n",
      "Epoch [496/500], Loss: 0.8256, Accuracy: 0.6835\n",
      "Epoch [497/500], Loss: 0.8384, Accuracy: 0.6748\n",
      "Epoch [498/500], Loss: 0.8095, Accuracy: 0.6855\n",
      "Epoch [499/500], Loss: 0.8202, Accuracy: 0.6839\n",
      "Epoch [500/500], Loss: 0.8302, Accuracy: 0.6751\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "lstm_model = LSTMModel(input_size[0], hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "train(lstm_model, train_loaderLSTM, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.6638, Accuracy: 0.2861\n",
      "Epoch [2/500], Loss: 1.5629, Accuracy: 0.3395\n",
      "Epoch [3/500], Loss: 1.5366, Accuracy: 0.3576\n",
      "Epoch [4/500], Loss: 1.5258, Accuracy: 0.3593\n",
      "Epoch [5/500], Loss: 1.4951, Accuracy: 0.3790\n",
      "Epoch [6/500], Loss: 1.4913, Accuracy: 0.3822\n",
      "Epoch [7/500], Loss: 1.4556, Accuracy: 0.3976\n",
      "Epoch [8/500], Loss: 1.4489, Accuracy: 0.3995\n",
      "Epoch [9/500], Loss: 1.4334, Accuracy: 0.4084\n",
      "Epoch [10/500], Loss: 1.4430, Accuracy: 0.4104\n",
      "Epoch [11/500], Loss: 1.4253, Accuracy: 0.4220\n",
      "Epoch [12/500], Loss: 1.4167, Accuracy: 0.4221\n",
      "Epoch [13/500], Loss: 1.4112, Accuracy: 0.4215\n",
      "Epoch [14/500], Loss: 1.4225, Accuracy: 0.4102\n",
      "Epoch [15/500], Loss: 1.3929, Accuracy: 0.4250\n",
      "Epoch [16/500], Loss: 1.3937, Accuracy: 0.4297\n",
      "Epoch [17/500], Loss: 1.4005, Accuracy: 0.4255\n",
      "Epoch [18/500], Loss: 1.3770, Accuracy: 0.4403\n",
      "Epoch [19/500], Loss: 1.3792, Accuracy: 0.4369\n",
      "Epoch [20/500], Loss: 1.3718, Accuracy: 0.4378\n",
      "Epoch [21/500], Loss: 1.3773, Accuracy: 0.4415\n",
      "Epoch [22/500], Loss: 1.3779, Accuracy: 0.4418\n",
      "Epoch [23/500], Loss: 1.3772, Accuracy: 0.4352\n",
      "Epoch [24/500], Loss: 1.3656, Accuracy: 0.4453\n",
      "Epoch [25/500], Loss: 1.3580, Accuracy: 0.4470\n",
      "Epoch [26/500], Loss: 1.3555, Accuracy: 0.4507\n",
      "Epoch [27/500], Loss: 1.3399, Accuracy: 0.4583\n",
      "Epoch [28/500], Loss: 1.3563, Accuracy: 0.4539\n",
      "Epoch [29/500], Loss: 1.3542, Accuracy: 0.4567\n",
      "Epoch [30/500], Loss: 1.3421, Accuracy: 0.4547\n",
      "Epoch [31/500], Loss: 1.3439, Accuracy: 0.4591\n",
      "Epoch [32/500], Loss: 1.3516, Accuracy: 0.4536\n",
      "Epoch [33/500], Loss: 1.3359, Accuracy: 0.4613\n",
      "Epoch [34/500], Loss: 1.3519, Accuracy: 0.4556\n",
      "Epoch [35/500], Loss: 1.3256, Accuracy: 0.4682\n",
      "Epoch [36/500], Loss: 1.3220, Accuracy: 0.4695\n",
      "Epoch [37/500], Loss: 1.3622, Accuracy: 0.4537\n",
      "Epoch [38/500], Loss: 1.3720, Accuracy: 0.4504\n",
      "Epoch [39/500], Loss: 1.3497, Accuracy: 0.4603\n",
      "Epoch [40/500], Loss: 1.3407, Accuracy: 0.4591\n",
      "Epoch [41/500], Loss: 1.3407, Accuracy: 0.4613\n",
      "Epoch [42/500], Loss: 1.3308, Accuracy: 0.4655\n",
      "Epoch [43/500], Loss: 1.3273, Accuracy: 0.4725\n",
      "Epoch [44/500], Loss: 1.3295, Accuracy: 0.4673\n",
      "Epoch [45/500], Loss: 1.3306, Accuracy: 0.4655\n",
      "Epoch [46/500], Loss: 1.3209, Accuracy: 0.4722\n",
      "Epoch [47/500], Loss: 1.3204, Accuracy: 0.4734\n",
      "Epoch [48/500], Loss: 1.3220, Accuracy: 0.4739\n",
      "Epoch [49/500], Loss: 1.3465, Accuracy: 0.4557\n",
      "Epoch [50/500], Loss: 1.3446, Accuracy: 0.4576\n",
      "Epoch [51/500], Loss: 1.3310, Accuracy: 0.4655\n",
      "Epoch [52/500], Loss: 1.3305, Accuracy: 0.4628\n",
      "Epoch [53/500], Loss: 1.3313, Accuracy: 0.4683\n",
      "Epoch [54/500], Loss: 1.3202, Accuracy: 0.4715\n",
      "Epoch [55/500], Loss: 1.3165, Accuracy: 0.4707\n",
      "Epoch [56/500], Loss: 1.3283, Accuracy: 0.4720\n",
      "Epoch [57/500], Loss: 1.3218, Accuracy: 0.4702\n",
      "Epoch [58/500], Loss: 1.3066, Accuracy: 0.4788\n",
      "Epoch [59/500], Loss: 1.3017, Accuracy: 0.4816\n",
      "Epoch [60/500], Loss: 1.3116, Accuracy: 0.4751\n",
      "Epoch [61/500], Loss: 1.2980, Accuracy: 0.4744\n",
      "Epoch [62/500], Loss: 1.3001, Accuracy: 0.4838\n",
      "Epoch [63/500], Loss: 1.3119, Accuracy: 0.4695\n",
      "Epoch [64/500], Loss: 1.2964, Accuracy: 0.4793\n",
      "Epoch [65/500], Loss: 1.2778, Accuracy: 0.4875\n",
      "Epoch [66/500], Loss: 1.2884, Accuracy: 0.4850\n",
      "Epoch [67/500], Loss: 1.2896, Accuracy: 0.4903\n",
      "Epoch [68/500], Loss: 1.2976, Accuracy: 0.4845\n",
      "Epoch [69/500], Loss: 1.2828, Accuracy: 0.4835\n",
      "Epoch [70/500], Loss: 1.2761, Accuracy: 0.4917\n",
      "Epoch [71/500], Loss: 1.2701, Accuracy: 0.4969\n",
      "Epoch [72/500], Loss: 1.2683, Accuracy: 0.4930\n",
      "Epoch [73/500], Loss: 1.2519, Accuracy: 0.5036\n",
      "Epoch [74/500], Loss: 1.2634, Accuracy: 0.4982\n",
      "Epoch [75/500], Loss: 1.2557, Accuracy: 0.4913\n",
      "Epoch [76/500], Loss: 1.2479, Accuracy: 0.4974\n",
      "Epoch [77/500], Loss: 1.2573, Accuracy: 0.4920\n",
      "Epoch [78/500], Loss: 1.2573, Accuracy: 0.5023\n",
      "Epoch [79/500], Loss: 1.2910, Accuracy: 0.4756\n",
      "Epoch [80/500], Loss: 1.2590, Accuracy: 0.4964\n",
      "Epoch [81/500], Loss: 1.2691, Accuracy: 0.4878\n",
      "Epoch [82/500], Loss: 1.2881, Accuracy: 0.4840\n",
      "Epoch [83/500], Loss: 1.2676, Accuracy: 0.4866\n",
      "Epoch [84/500], Loss: 1.2605, Accuracy: 0.4851\n",
      "Epoch [85/500], Loss: 1.2698, Accuracy: 0.4945\n",
      "Epoch [86/500], Loss: 1.2530, Accuracy: 0.4937\n",
      "Epoch [87/500], Loss: 1.2579, Accuracy: 0.4949\n",
      "Epoch [88/500], Loss: 1.2439, Accuracy: 0.4962\n",
      "Epoch [89/500], Loss: 1.2339, Accuracy: 0.5085\n",
      "Epoch [90/500], Loss: 1.2294, Accuracy: 0.5085\n",
      "Epoch [91/500], Loss: 1.2514, Accuracy: 0.4932\n",
      "Epoch [92/500], Loss: 1.2477, Accuracy: 0.4949\n",
      "Epoch [93/500], Loss: 1.2242, Accuracy: 0.5090\n",
      "Epoch [94/500], Loss: 1.2273, Accuracy: 0.5081\n",
      "Epoch [95/500], Loss: 1.2509, Accuracy: 0.4969\n",
      "Epoch [96/500], Loss: 1.2286, Accuracy: 0.5088\n",
      "Epoch [97/500], Loss: 1.2281, Accuracy: 0.5097\n",
      "Epoch [98/500], Loss: 1.2288, Accuracy: 0.5083\n",
      "Epoch [99/500], Loss: 1.2088, Accuracy: 0.5140\n",
      "Epoch [100/500], Loss: 1.2249, Accuracy: 0.5075\n",
      "Epoch [101/500], Loss: 1.2150, Accuracy: 0.5189\n",
      "Epoch [102/500], Loss: 1.2169, Accuracy: 0.5144\n",
      "Epoch [103/500], Loss: 1.2044, Accuracy: 0.5181\n",
      "Epoch [104/500], Loss: 1.1976, Accuracy: 0.5177\n",
      "Epoch [105/500], Loss: 1.2025, Accuracy: 0.5243\n",
      "Epoch [106/500], Loss: 1.2553, Accuracy: 0.5019\n",
      "Epoch [107/500], Loss: 1.2135, Accuracy: 0.5088\n",
      "Epoch [108/500], Loss: 1.2153, Accuracy: 0.5171\n",
      "Epoch [109/500], Loss: 1.2492, Accuracy: 0.4996\n",
      "Epoch [110/500], Loss: 1.2198, Accuracy: 0.5080\n",
      "Epoch [111/500], Loss: 1.2076, Accuracy: 0.5182\n",
      "Epoch [112/500], Loss: 1.1955, Accuracy: 0.5196\n",
      "Epoch [113/500], Loss: 1.2121, Accuracy: 0.5191\n",
      "Epoch [114/500], Loss: 1.1974, Accuracy: 0.5176\n",
      "Epoch [115/500], Loss: 1.1819, Accuracy: 0.5251\n",
      "Epoch [116/500], Loss: 1.1813, Accuracy: 0.5243\n",
      "Epoch [117/500], Loss: 1.1818, Accuracy: 0.5266\n",
      "Epoch [118/500], Loss: 1.1845, Accuracy: 0.5212\n",
      "Epoch [119/500], Loss: 1.1804, Accuracy: 0.5280\n",
      "Epoch [120/500], Loss: 1.1924, Accuracy: 0.5254\n",
      "Epoch [121/500], Loss: 1.1917, Accuracy: 0.5223\n",
      "Epoch [122/500], Loss: 1.1783, Accuracy: 0.5296\n",
      "Epoch [123/500], Loss: 1.1676, Accuracy: 0.5310\n",
      "Epoch [124/500], Loss: 1.1824, Accuracy: 0.5253\n",
      "Epoch [125/500], Loss: 1.2083, Accuracy: 0.5226\n",
      "Epoch [126/500], Loss: 1.1765, Accuracy: 0.5285\n",
      "Epoch [127/500], Loss: 1.1726, Accuracy: 0.5360\n",
      "Epoch [128/500], Loss: 1.1607, Accuracy: 0.5433\n",
      "Epoch [129/500], Loss: 1.1713, Accuracy: 0.5308\n",
      "Epoch [130/500], Loss: 1.1887, Accuracy: 0.5308\n",
      "Epoch [131/500], Loss: 1.1755, Accuracy: 0.5256\n",
      "Epoch [132/500], Loss: 1.1574, Accuracy: 0.5426\n",
      "Epoch [133/500], Loss: 1.1572, Accuracy: 0.5422\n",
      "Epoch [134/500], Loss: 1.1489, Accuracy: 0.5456\n",
      "Epoch [135/500], Loss: 1.1588, Accuracy: 0.5406\n",
      "Epoch [136/500], Loss: 1.1554, Accuracy: 0.5369\n",
      "Epoch [137/500], Loss: 1.1477, Accuracy: 0.5424\n",
      "Epoch [138/500], Loss: 1.1837, Accuracy: 0.5197\n",
      "Epoch [139/500], Loss: 1.1546, Accuracy: 0.5426\n",
      "Epoch [140/500], Loss: 1.1425, Accuracy: 0.5500\n",
      "Epoch [141/500], Loss: 1.1527, Accuracy: 0.5379\n",
      "Epoch [142/500], Loss: 1.1509, Accuracy: 0.5406\n",
      "Epoch [143/500], Loss: 1.1365, Accuracy: 0.5441\n",
      "Epoch [144/500], Loss: 1.1430, Accuracy: 0.5392\n",
      "Epoch [145/500], Loss: 1.1272, Accuracy: 0.5433\n",
      "Epoch [146/500], Loss: 1.1310, Accuracy: 0.5463\n",
      "Epoch [147/500], Loss: 1.1347, Accuracy: 0.5515\n",
      "Epoch [148/500], Loss: 1.1342, Accuracy: 0.5535\n",
      "Epoch [149/500], Loss: 1.1349, Accuracy: 0.5486\n",
      "Epoch [150/500], Loss: 1.1295, Accuracy: 0.5495\n",
      "Epoch [151/500], Loss: 1.1386, Accuracy: 0.5501\n",
      "Epoch [152/500], Loss: 1.1324, Accuracy: 0.5500\n",
      "Epoch [153/500], Loss: 1.1197, Accuracy: 0.5548\n",
      "Epoch [154/500], Loss: 1.1183, Accuracy: 0.5584\n",
      "Epoch [155/500], Loss: 1.1208, Accuracy: 0.5565\n",
      "Epoch [156/500], Loss: 1.1436, Accuracy: 0.5453\n",
      "Epoch [157/500], Loss: 1.1500, Accuracy: 0.5433\n",
      "Epoch [158/500], Loss: 1.1185, Accuracy: 0.5557\n",
      "Epoch [159/500], Loss: 1.1226, Accuracy: 0.5567\n",
      "Epoch [160/500], Loss: 1.1136, Accuracy: 0.5607\n",
      "Epoch [161/500], Loss: 1.1217, Accuracy: 0.5517\n",
      "Epoch [162/500], Loss: 1.1071, Accuracy: 0.5643\n",
      "Epoch [163/500], Loss: 1.1071, Accuracy: 0.5639\n",
      "Epoch [164/500], Loss: 1.1089, Accuracy: 0.5622\n",
      "Epoch [165/500], Loss: 1.1139, Accuracy: 0.5639\n",
      "Epoch [166/500], Loss: 1.1558, Accuracy: 0.5392\n",
      "Epoch [167/500], Loss: 1.1086, Accuracy: 0.5595\n",
      "Epoch [168/500], Loss: 1.0986, Accuracy: 0.5612\n",
      "Epoch [169/500], Loss: 1.1074, Accuracy: 0.5678\n",
      "Epoch [170/500], Loss: 1.1356, Accuracy: 0.5424\n",
      "Epoch [171/500], Loss: 1.0898, Accuracy: 0.5636\n",
      "Epoch [172/500], Loss: 1.1038, Accuracy: 0.5592\n",
      "Epoch [173/500], Loss: 1.1022, Accuracy: 0.5637\n",
      "Epoch [174/500], Loss: 1.0989, Accuracy: 0.5668\n",
      "Epoch [175/500], Loss: 1.1205, Accuracy: 0.5565\n",
      "Epoch [176/500], Loss: 1.0994, Accuracy: 0.5661\n",
      "Epoch [177/500], Loss: 1.0996, Accuracy: 0.5636\n",
      "Epoch [178/500], Loss: 1.0921, Accuracy: 0.5661\n",
      "Epoch [179/500], Loss: 1.1033, Accuracy: 0.5599\n",
      "Epoch [180/500], Loss: 1.1032, Accuracy: 0.5574\n",
      "Epoch [181/500], Loss: 1.0916, Accuracy: 0.5654\n",
      "Epoch [182/500], Loss: 1.0815, Accuracy: 0.5716\n",
      "Epoch [183/500], Loss: 1.0916, Accuracy: 0.5653\n",
      "Epoch [184/500], Loss: 1.1085, Accuracy: 0.5646\n",
      "Epoch [185/500], Loss: 1.1033, Accuracy: 0.5641\n",
      "Epoch [186/500], Loss: 1.0831, Accuracy: 0.5772\n",
      "Epoch [187/500], Loss: 1.1211, Accuracy: 0.5654\n",
      "Epoch [188/500], Loss: 1.1032, Accuracy: 0.5646\n",
      "Epoch [189/500], Loss: 1.0807, Accuracy: 0.5683\n",
      "Epoch [190/500], Loss: 1.0732, Accuracy: 0.5737\n",
      "Epoch [191/500], Loss: 1.0854, Accuracy: 0.5716\n",
      "Epoch [192/500], Loss: 1.0809, Accuracy: 0.5723\n",
      "Epoch [193/500], Loss: 1.1008, Accuracy: 0.5703\n",
      "Epoch [194/500], Loss: 1.1016, Accuracy: 0.5636\n",
      "Epoch [195/500], Loss: 1.0972, Accuracy: 0.5631\n",
      "Epoch [196/500], Loss: 1.0956, Accuracy: 0.5695\n",
      "Epoch [197/500], Loss: 1.0905, Accuracy: 0.5705\n",
      "Epoch [198/500], Loss: 1.0752, Accuracy: 0.5780\n",
      "Epoch [199/500], Loss: 1.0656, Accuracy: 0.5784\n",
      "Epoch [200/500], Loss: 1.0764, Accuracy: 0.5723\n",
      "Epoch [201/500], Loss: 1.0660, Accuracy: 0.5827\n",
      "Epoch [202/500], Loss: 1.0794, Accuracy: 0.5758\n",
      "Epoch [203/500], Loss: 1.0697, Accuracy: 0.5720\n",
      "Epoch [204/500], Loss: 1.0629, Accuracy: 0.5721\n",
      "Epoch [205/500], Loss: 1.0599, Accuracy: 0.5900\n",
      "Epoch [206/500], Loss: 1.0683, Accuracy: 0.5758\n",
      "Epoch [207/500], Loss: 1.0667, Accuracy: 0.5785\n",
      "Epoch [208/500], Loss: 1.0762, Accuracy: 0.5824\n",
      "Epoch [209/500], Loss: 1.0547, Accuracy: 0.5812\n",
      "Epoch [210/500], Loss: 1.0662, Accuracy: 0.5767\n",
      "Epoch [211/500], Loss: 1.0526, Accuracy: 0.5827\n",
      "Epoch [212/500], Loss: 1.0562, Accuracy: 0.5851\n",
      "Epoch [213/500], Loss: 1.0577, Accuracy: 0.5853\n",
      "Epoch [214/500], Loss: 1.0607, Accuracy: 0.5831\n",
      "Epoch [215/500], Loss: 1.0912, Accuracy: 0.5737\n",
      "Epoch [216/500], Loss: 1.0697, Accuracy: 0.5842\n",
      "Epoch [217/500], Loss: 1.0544, Accuracy: 0.5839\n",
      "Epoch [218/500], Loss: 1.0539, Accuracy: 0.5822\n",
      "Epoch [219/500], Loss: 1.0517, Accuracy: 0.5925\n",
      "Epoch [220/500], Loss: 1.0668, Accuracy: 0.5839\n",
      "Epoch [221/500], Loss: 1.0430, Accuracy: 0.5918\n",
      "Epoch [222/500], Loss: 1.0727, Accuracy: 0.5755\n",
      "Epoch [223/500], Loss: 1.0446, Accuracy: 0.5871\n",
      "Epoch [224/500], Loss: 1.0596, Accuracy: 0.5827\n",
      "Epoch [225/500], Loss: 1.0426, Accuracy: 0.5933\n",
      "Epoch [226/500], Loss: 1.0409, Accuracy: 0.5841\n",
      "Epoch [227/500], Loss: 1.0395, Accuracy: 0.5960\n",
      "Epoch [228/500], Loss: 1.0459, Accuracy: 0.5817\n",
      "Epoch [229/500], Loss: 1.0402, Accuracy: 0.5943\n",
      "Epoch [230/500], Loss: 1.0548, Accuracy: 0.5923\n",
      "Epoch [231/500], Loss: 1.0723, Accuracy: 0.5728\n",
      "Epoch [232/500], Loss: 1.0551, Accuracy: 0.5819\n",
      "Epoch [233/500], Loss: 1.0803, Accuracy: 0.5789\n",
      "Epoch [234/500], Loss: 1.0665, Accuracy: 0.5824\n",
      "Epoch [235/500], Loss: 1.0410, Accuracy: 0.5928\n",
      "Epoch [236/500], Loss: 1.0503, Accuracy: 0.5846\n",
      "Epoch [237/500], Loss: 1.0430, Accuracy: 0.5911\n",
      "Epoch [238/500], Loss: 1.0644, Accuracy: 0.5799\n",
      "Epoch [239/500], Loss: 1.0451, Accuracy: 0.5925\n",
      "Epoch [240/500], Loss: 1.0213, Accuracy: 0.5960\n",
      "Epoch [241/500], Loss: 1.0250, Accuracy: 0.5995\n",
      "Epoch [242/500], Loss: 1.0799, Accuracy: 0.5774\n",
      "Epoch [243/500], Loss: 1.0759, Accuracy: 0.5780\n",
      "Epoch [244/500], Loss: 1.0348, Accuracy: 0.5906\n",
      "Epoch [245/500], Loss: 1.0270, Accuracy: 0.5930\n",
      "Epoch [246/500], Loss: 1.0261, Accuracy: 0.6000\n",
      "Epoch [247/500], Loss: 1.0335, Accuracy: 0.5978\n",
      "Epoch [248/500], Loss: 1.0162, Accuracy: 0.5999\n",
      "Epoch [249/500], Loss: 1.0324, Accuracy: 0.5931\n",
      "Epoch [250/500], Loss: 1.0284, Accuracy: 0.5940\n",
      "Epoch [251/500], Loss: 1.0227, Accuracy: 0.5973\n",
      "Epoch [252/500], Loss: 1.0191, Accuracy: 0.5958\n",
      "Epoch [253/500], Loss: 1.0065, Accuracy: 0.6041\n",
      "Epoch [254/500], Loss: 1.0124, Accuracy: 0.6047\n",
      "Epoch [255/500], Loss: 1.0470, Accuracy: 0.5942\n",
      "Epoch [256/500], Loss: 1.0231, Accuracy: 0.5978\n",
      "Epoch [257/500], Loss: 1.0339, Accuracy: 0.5968\n",
      "Epoch [258/500], Loss: 1.0177, Accuracy: 0.5992\n",
      "Epoch [259/500], Loss: 1.0255, Accuracy: 0.5997\n",
      "Epoch [260/500], Loss: 1.0138, Accuracy: 0.5962\n",
      "Epoch [261/500], Loss: 1.0220, Accuracy: 0.5972\n",
      "Epoch [262/500], Loss: 1.0192, Accuracy: 0.5978\n",
      "Epoch [263/500], Loss: 1.0412, Accuracy: 0.5905\n",
      "Epoch [264/500], Loss: 1.0183, Accuracy: 0.5984\n",
      "Epoch [265/500], Loss: 1.0199, Accuracy: 0.6005\n",
      "Epoch [266/500], Loss: 1.0164, Accuracy: 0.5913\n",
      "Epoch [267/500], Loss: 1.0086, Accuracy: 0.6039\n",
      "Epoch [268/500], Loss: 1.0200, Accuracy: 0.6009\n",
      "Epoch [269/500], Loss: 1.0129, Accuracy: 0.6020\n",
      "Epoch [270/500], Loss: 1.0090, Accuracy: 0.6027\n",
      "Epoch [271/500], Loss: 1.0299, Accuracy: 0.5910\n",
      "Epoch [272/500], Loss: 0.9988, Accuracy: 0.5992\n",
      "Epoch [273/500], Loss: 0.9940, Accuracy: 0.6032\n",
      "Epoch [274/500], Loss: 1.0097, Accuracy: 0.6051\n",
      "Epoch [275/500], Loss: 1.0377, Accuracy: 0.5871\n",
      "Epoch [276/500], Loss: 0.9957, Accuracy: 0.6022\n",
      "Epoch [277/500], Loss: 1.0008, Accuracy: 0.6037\n",
      "Epoch [278/500], Loss: 1.0077, Accuracy: 0.6034\n",
      "Epoch [279/500], Loss: 1.0100, Accuracy: 0.6046\n",
      "Epoch [280/500], Loss: 1.0142, Accuracy: 0.5963\n",
      "Epoch [281/500], Loss: 1.0073, Accuracy: 0.6091\n",
      "Epoch [282/500], Loss: 1.0603, Accuracy: 0.5814\n",
      "Epoch [283/500], Loss: 1.0024, Accuracy: 0.6111\n",
      "Epoch [284/500], Loss: 1.0028, Accuracy: 0.6020\n",
      "Epoch [285/500], Loss: 0.9929, Accuracy: 0.6094\n",
      "Epoch [286/500], Loss: 0.9883, Accuracy: 0.6126\n",
      "Epoch [287/500], Loss: 0.9965, Accuracy: 0.6047\n",
      "Epoch [288/500], Loss: 0.9894, Accuracy: 0.6099\n",
      "Epoch [289/500], Loss: 0.9889, Accuracy: 0.6123\n",
      "Epoch [290/500], Loss: 0.9998, Accuracy: 0.6106\n",
      "Epoch [291/500], Loss: 1.0182, Accuracy: 0.6017\n",
      "Epoch [292/500], Loss: 1.0130, Accuracy: 0.6037\n",
      "Epoch [293/500], Loss: 0.9981, Accuracy: 0.6083\n",
      "Epoch [294/500], Loss: 1.0043, Accuracy: 0.6088\n",
      "Epoch [295/500], Loss: 0.9816, Accuracy: 0.6125\n",
      "Epoch [296/500], Loss: 0.9944, Accuracy: 0.6084\n",
      "Epoch [297/500], Loss: 0.9932, Accuracy: 0.6076\n",
      "Epoch [298/500], Loss: 0.9952, Accuracy: 0.6074\n",
      "Epoch [299/500], Loss: 0.9891, Accuracy: 0.6120\n",
      "Epoch [300/500], Loss: 0.9974, Accuracy: 0.6076\n",
      "Epoch [301/500], Loss: 0.9858, Accuracy: 0.6148\n",
      "Epoch [302/500], Loss: 0.9970, Accuracy: 0.6094\n",
      "Epoch [303/500], Loss: 0.9896, Accuracy: 0.6118\n",
      "Epoch [304/500], Loss: 0.9929, Accuracy: 0.6106\n",
      "Epoch [305/500], Loss: 0.9852, Accuracy: 0.6180\n",
      "Epoch [306/500], Loss: 0.9975, Accuracy: 0.6098\n",
      "Epoch [307/500], Loss: 1.0415, Accuracy: 0.5854\n",
      "Epoch [308/500], Loss: 0.9773, Accuracy: 0.6153\n",
      "Epoch [309/500], Loss: 0.9790, Accuracy: 0.6167\n",
      "Epoch [310/500], Loss: 0.9859, Accuracy: 0.6138\n",
      "Epoch [311/500], Loss: 0.9648, Accuracy: 0.6177\n",
      "Epoch [312/500], Loss: 0.9738, Accuracy: 0.6172\n",
      "Epoch [313/500], Loss: 0.9650, Accuracy: 0.6236\n",
      "Epoch [314/500], Loss: 0.9677, Accuracy: 0.6224\n",
      "Epoch [315/500], Loss: 0.9819, Accuracy: 0.6247\n",
      "Epoch [316/500], Loss: 0.9680, Accuracy: 0.6244\n",
      "Epoch [317/500], Loss: 0.9714, Accuracy: 0.6244\n",
      "Epoch [318/500], Loss: 1.0171, Accuracy: 0.5982\n",
      "Epoch [319/500], Loss: 0.9633, Accuracy: 0.6200\n",
      "Epoch [320/500], Loss: 0.9753, Accuracy: 0.6190\n",
      "Epoch [321/500], Loss: 0.9689, Accuracy: 0.6207\n",
      "Epoch [322/500], Loss: 0.9765, Accuracy: 0.6192\n",
      "Epoch [323/500], Loss: 0.9696, Accuracy: 0.6187\n",
      "Epoch [324/500], Loss: 0.9692, Accuracy: 0.6284\n",
      "Epoch [325/500], Loss: 0.9588, Accuracy: 0.6271\n",
      "Epoch [326/500], Loss: 0.9521, Accuracy: 0.6239\n",
      "Epoch [327/500], Loss: 0.9532, Accuracy: 0.6261\n",
      "Epoch [328/500], Loss: 0.9461, Accuracy: 0.6293\n",
      "Epoch [329/500], Loss: 1.0214, Accuracy: 0.5935\n",
      "Epoch [330/500], Loss: 0.9617, Accuracy: 0.6303\n",
      "Epoch [331/500], Loss: 0.9526, Accuracy: 0.6326\n",
      "Epoch [332/500], Loss: 0.9583, Accuracy: 0.6227\n",
      "Epoch [333/500], Loss: 0.9717, Accuracy: 0.6306\n",
      "Epoch [334/500], Loss: 0.9759, Accuracy: 0.6153\n",
      "Epoch [335/500], Loss: 0.9759, Accuracy: 0.6227\n",
      "Epoch [336/500], Loss: 0.9811, Accuracy: 0.6190\n",
      "Epoch [337/500], Loss: 0.9671, Accuracy: 0.6306\n",
      "Epoch [338/500], Loss: 0.9723, Accuracy: 0.6195\n",
      "Epoch [339/500], Loss: 0.9460, Accuracy: 0.6351\n",
      "Epoch [340/500], Loss: 0.9767, Accuracy: 0.6217\n",
      "Epoch [341/500], Loss: 0.9322, Accuracy: 0.6351\n",
      "Epoch [342/500], Loss: 0.9466, Accuracy: 0.6320\n",
      "Epoch [343/500], Loss: 0.9323, Accuracy: 0.6424\n",
      "Epoch [344/500], Loss: 0.9433, Accuracy: 0.6306\n",
      "Epoch [345/500], Loss: 0.9477, Accuracy: 0.6314\n",
      "Epoch [346/500], Loss: 0.9353, Accuracy: 0.6331\n",
      "Epoch [347/500], Loss: 0.9323, Accuracy: 0.6410\n",
      "Epoch [348/500], Loss: 0.9546, Accuracy: 0.6316\n",
      "Epoch [349/500], Loss: 0.9569, Accuracy: 0.6199\n",
      "Epoch [350/500], Loss: 0.9229, Accuracy: 0.6385\n",
      "Epoch [351/500], Loss: 0.9239, Accuracy: 0.6390\n",
      "Epoch [352/500], Loss: 0.9558, Accuracy: 0.6309\n",
      "Epoch [353/500], Loss: 0.9573, Accuracy: 0.6279\n",
      "Epoch [354/500], Loss: 0.9495, Accuracy: 0.6336\n",
      "Epoch [355/500], Loss: 0.9328, Accuracy: 0.6325\n",
      "Epoch [356/500], Loss: 0.9281, Accuracy: 0.6356\n",
      "Epoch [357/500], Loss: 0.9487, Accuracy: 0.6304\n",
      "Epoch [358/500], Loss: 0.9273, Accuracy: 0.6444\n",
      "Epoch [359/500], Loss: 0.9238, Accuracy: 0.6445\n",
      "Epoch [360/500], Loss: 0.9402, Accuracy: 0.6299\n",
      "Epoch [361/500], Loss: 0.9226, Accuracy: 0.6385\n",
      "Epoch [362/500], Loss: 0.9194, Accuracy: 0.6445\n",
      "Epoch [363/500], Loss: 0.9429, Accuracy: 0.6304\n",
      "Epoch [364/500], Loss: 0.9584, Accuracy: 0.6323\n",
      "Epoch [365/500], Loss: 0.9108, Accuracy: 0.6471\n",
      "Epoch [366/500], Loss: 0.9267, Accuracy: 0.6449\n",
      "Epoch [367/500], Loss: 0.9196, Accuracy: 0.6412\n",
      "Epoch [368/500], Loss: 0.8983, Accuracy: 0.6511\n",
      "Epoch [369/500], Loss: 0.9110, Accuracy: 0.6447\n",
      "Epoch [370/500], Loss: 0.9134, Accuracy: 0.6506\n",
      "Epoch [371/500], Loss: 0.9061, Accuracy: 0.6509\n",
      "Epoch [372/500], Loss: 0.9343, Accuracy: 0.6335\n",
      "Epoch [373/500], Loss: 0.9520, Accuracy: 0.6293\n",
      "Epoch [374/500], Loss: 0.9493, Accuracy: 0.6269\n",
      "Epoch [375/500], Loss: 0.9514, Accuracy: 0.6301\n",
      "Epoch [376/500], Loss: 0.9222, Accuracy: 0.6435\n",
      "Epoch [377/500], Loss: 0.9363, Accuracy: 0.6373\n",
      "Epoch [378/500], Loss: 0.9244, Accuracy: 0.6385\n",
      "Epoch [379/500], Loss: 0.9190, Accuracy: 0.6444\n",
      "Epoch [380/500], Loss: 0.9246, Accuracy: 0.6432\n",
      "Epoch [381/500], Loss: 0.9136, Accuracy: 0.6481\n",
      "Epoch [382/500], Loss: 0.9317, Accuracy: 0.6419\n",
      "Epoch [383/500], Loss: 0.9568, Accuracy: 0.6289\n",
      "Epoch [384/500], Loss: 0.9979, Accuracy: 0.6081\n",
      "Epoch [385/500], Loss: 0.9303, Accuracy: 0.6402\n",
      "Epoch [386/500], Loss: 0.9291, Accuracy: 0.6412\n",
      "Epoch [387/500], Loss: 0.9129, Accuracy: 0.6508\n",
      "Epoch [388/500], Loss: 0.9032, Accuracy: 0.6511\n",
      "Epoch [389/500], Loss: 0.8939, Accuracy: 0.6541\n",
      "Epoch [390/500], Loss: 0.8910, Accuracy: 0.6551\n",
      "Epoch [391/500], Loss: 0.8965, Accuracy: 0.6504\n",
      "Epoch [392/500], Loss: 0.9028, Accuracy: 0.6513\n",
      "Epoch [393/500], Loss: 0.8959, Accuracy: 0.6509\n",
      "Epoch [394/500], Loss: 0.8983, Accuracy: 0.6484\n",
      "Epoch [395/500], Loss: 0.9059, Accuracy: 0.6491\n",
      "Epoch [396/500], Loss: 0.8918, Accuracy: 0.6531\n",
      "Epoch [397/500], Loss: 0.8852, Accuracy: 0.6593\n",
      "Epoch [398/500], Loss: 0.8842, Accuracy: 0.6597\n",
      "Epoch [399/500], Loss: 0.9019, Accuracy: 0.6560\n",
      "Epoch [400/500], Loss: 0.8931, Accuracy: 0.6563\n",
      "Epoch [401/500], Loss: 0.9202, Accuracy: 0.6454\n",
      "Epoch [402/500], Loss: 0.8865, Accuracy: 0.6563\n",
      "Epoch [403/500], Loss: 0.8870, Accuracy: 0.6496\n",
      "Epoch [404/500], Loss: 0.8699, Accuracy: 0.6649\n",
      "Epoch [405/500], Loss: 0.8745, Accuracy: 0.6624\n",
      "Epoch [406/500], Loss: 0.8800, Accuracy: 0.6661\n",
      "Epoch [407/500], Loss: 0.8927, Accuracy: 0.6523\n",
      "Epoch [408/500], Loss: 0.8936, Accuracy: 0.6501\n",
      "Epoch [409/500], Loss: 0.8758, Accuracy: 0.6578\n",
      "Epoch [410/500], Loss: 0.8798, Accuracy: 0.6588\n",
      "Epoch [411/500], Loss: 0.8713, Accuracy: 0.6613\n",
      "Epoch [412/500], Loss: 0.8701, Accuracy: 0.6619\n",
      "Epoch [413/500], Loss: 0.8802, Accuracy: 0.6635\n",
      "Epoch [414/500], Loss: 0.9022, Accuracy: 0.6566\n",
      "Epoch [415/500], Loss: 0.9001, Accuracy: 0.6526\n",
      "Epoch [416/500], Loss: 0.8878, Accuracy: 0.6565\n",
      "Epoch [417/500], Loss: 0.8762, Accuracy: 0.6603\n",
      "Epoch [418/500], Loss: 0.8696, Accuracy: 0.6666\n",
      "Epoch [419/500], Loss: 0.8687, Accuracy: 0.6620\n",
      "Epoch [420/500], Loss: 0.8884, Accuracy: 0.6516\n",
      "Epoch [421/500], Loss: 0.8763, Accuracy: 0.6565\n",
      "Epoch [422/500], Loss: 0.9002, Accuracy: 0.6541\n",
      "Epoch [423/500], Loss: 0.8839, Accuracy: 0.6580\n",
      "Epoch [424/500], Loss: 0.8608, Accuracy: 0.6691\n",
      "Epoch [425/500], Loss: 0.8649, Accuracy: 0.6640\n",
      "Epoch [426/500], Loss: 0.8607, Accuracy: 0.6721\n",
      "Epoch [427/500], Loss: 0.8798, Accuracy: 0.6630\n",
      "Epoch [428/500], Loss: 0.8869, Accuracy: 0.6523\n",
      "Epoch [429/500], Loss: 0.9031, Accuracy: 0.6531\n",
      "Epoch [430/500], Loss: 0.8755, Accuracy: 0.6645\n",
      "Epoch [431/500], Loss: 0.8750, Accuracy: 0.6644\n",
      "Epoch [432/500], Loss: 0.8914, Accuracy: 0.6536\n",
      "Epoch [433/500], Loss: 0.8835, Accuracy: 0.6573\n",
      "Epoch [434/500], Loss: 0.9115, Accuracy: 0.6531\n",
      "Epoch [435/500], Loss: 0.8602, Accuracy: 0.6647\n",
      "Epoch [436/500], Loss: 0.8843, Accuracy: 0.6563\n",
      "Epoch [437/500], Loss: 0.8660, Accuracy: 0.6661\n",
      "Epoch [438/500], Loss: 0.8649, Accuracy: 0.6657\n",
      "Epoch [439/500], Loss: 0.8500, Accuracy: 0.6679\n",
      "Epoch [440/500], Loss: 0.8460, Accuracy: 0.6726\n",
      "Epoch [441/500], Loss: 0.8472, Accuracy: 0.6661\n",
      "Epoch [442/500], Loss: 0.8437, Accuracy: 0.6708\n",
      "Epoch [443/500], Loss: 0.8483, Accuracy: 0.6711\n",
      "Epoch [444/500], Loss: 0.8454, Accuracy: 0.6706\n",
      "Epoch [445/500], Loss: 0.8570, Accuracy: 0.6647\n",
      "Epoch [446/500], Loss: 0.8532, Accuracy: 0.6697\n",
      "Epoch [447/500], Loss: 0.8508, Accuracy: 0.6792\n",
      "Epoch [448/500], Loss: 0.9116, Accuracy: 0.6535\n",
      "Epoch [449/500], Loss: 0.8706, Accuracy: 0.6669\n",
      "Epoch [450/500], Loss: 0.8651, Accuracy: 0.6733\n",
      "Epoch [451/500], Loss: 0.8518, Accuracy: 0.6756\n",
      "Epoch [452/500], Loss: 0.8564, Accuracy: 0.6689\n",
      "Epoch [453/500], Loss: 0.8502, Accuracy: 0.6694\n",
      "Epoch [454/500], Loss: 0.8552, Accuracy: 0.6632\n",
      "Epoch [455/500], Loss: 0.8425, Accuracy: 0.6739\n",
      "Epoch [456/500], Loss: 0.8388, Accuracy: 0.6748\n",
      "Epoch [457/500], Loss: 0.8397, Accuracy: 0.6763\n",
      "Epoch [458/500], Loss: 0.8525, Accuracy: 0.6699\n",
      "Epoch [459/500], Loss: 0.8307, Accuracy: 0.6786\n",
      "Epoch [460/500], Loss: 0.8460, Accuracy: 0.6719\n",
      "Epoch [461/500], Loss: 0.8367, Accuracy: 0.6800\n",
      "Epoch [462/500], Loss: 0.8179, Accuracy: 0.6835\n",
      "Epoch [463/500], Loss: 0.8342, Accuracy: 0.6739\n",
      "Epoch [464/500], Loss: 0.8415, Accuracy: 0.6657\n",
      "Epoch [465/500], Loss: 0.8178, Accuracy: 0.6834\n",
      "Epoch [466/500], Loss: 0.8205, Accuracy: 0.6872\n",
      "Epoch [467/500], Loss: 0.8016, Accuracy: 0.6928\n",
      "Epoch [468/500], Loss: 0.8235, Accuracy: 0.6802\n",
      "Epoch [469/500], Loss: 0.8391, Accuracy: 0.6760\n",
      "Epoch [470/500], Loss: 0.8575, Accuracy: 0.6726\n",
      "Epoch [471/500], Loss: 0.8278, Accuracy: 0.6800\n",
      "Epoch [472/500], Loss: 0.8334, Accuracy: 0.6818\n",
      "Epoch [473/500], Loss: 0.8560, Accuracy: 0.6639\n",
      "Epoch [474/500], Loss: 0.8177, Accuracy: 0.6839\n",
      "Epoch [475/500], Loss: 0.8204, Accuracy: 0.6822\n",
      "Epoch [476/500], Loss: 0.8139, Accuracy: 0.6855\n",
      "Epoch [477/500], Loss: 0.8503, Accuracy: 0.6734\n",
      "Epoch [478/500], Loss: 0.8240, Accuracy: 0.6785\n",
      "Epoch [479/500], Loss: 0.8194, Accuracy: 0.6817\n",
      "Epoch [480/500], Loss: 0.8354, Accuracy: 0.6803\n",
      "Epoch [481/500], Loss: 0.8194, Accuracy: 0.6849\n",
      "Epoch [482/500], Loss: 0.8548, Accuracy: 0.6719\n",
      "Epoch [483/500], Loss: 0.8316, Accuracy: 0.6741\n",
      "Epoch [484/500], Loss: 0.8605, Accuracy: 0.6661\n",
      "Epoch [485/500], Loss: 0.8029, Accuracy: 0.6916\n",
      "Epoch [486/500], Loss: 0.8012, Accuracy: 0.6931\n",
      "Epoch [487/500], Loss: 0.7937, Accuracy: 0.6907\n",
      "Epoch [488/500], Loss: 0.8193, Accuracy: 0.6865\n",
      "Epoch [489/500], Loss: 0.8307, Accuracy: 0.6807\n",
      "Epoch [490/500], Loss: 0.8285, Accuracy: 0.6800\n",
      "Epoch [491/500], Loss: 0.8095, Accuracy: 0.6896\n",
      "Epoch [492/500], Loss: 0.8101, Accuracy: 0.6862\n",
      "Epoch [493/500], Loss: 0.7955, Accuracy: 0.6941\n",
      "Epoch [494/500], Loss: 0.8046, Accuracy: 0.6884\n",
      "Epoch [495/500], Loss: 0.8043, Accuracy: 0.6882\n",
      "Epoch [496/500], Loss: 0.7913, Accuracy: 0.6996\n",
      "Epoch [497/500], Loss: 0.7925, Accuracy: 0.6943\n",
      "Epoch [498/500], Loss: 0.7861, Accuracy: 0.6971\n",
      "Epoch [499/500], Loss: 0.7999, Accuracy: 0.6939\n",
      "Epoch [500/500], Loss: 0.7993, Accuracy: 0.6887\n"
     ]
    }
   ],
   "source": [
    "# LSTM with Attention\n",
    "lstm_atn_model = LSTMAttention(input_size[0], hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_atn_model.parameters(), lr=0.001)\n",
    "train(lstm_atn_model, train_loaderLSTM, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.7172, Accuracy: 0.2668\n",
      "Epoch [2/500], Loss: 1.6129, Accuracy: 0.3057\n",
      "Epoch [3/500], Loss: 1.5917, Accuracy: 0.3156\n",
      "Epoch [4/500], Loss: 1.5699, Accuracy: 0.3301\n",
      "Epoch [5/500], Loss: 1.5563, Accuracy: 0.3331\n",
      "Epoch [6/500], Loss: 1.5521, Accuracy: 0.3328\n",
      "Epoch [7/500], Loss: 1.5397, Accuracy: 0.3380\n",
      "Epoch [8/500], Loss: 1.5352, Accuracy: 0.3486\n",
      "Epoch [9/500], Loss: 1.5365, Accuracy: 0.3442\n",
      "Epoch [10/500], Loss: 1.5158, Accuracy: 0.3457\n",
      "Epoch [11/500], Loss: 1.5150, Accuracy: 0.3595\n",
      "Epoch [12/500], Loss: 1.5219, Accuracy: 0.3548\n",
      "Epoch [13/500], Loss: 1.5273, Accuracy: 0.3484\n",
      "Epoch [14/500], Loss: 1.5159, Accuracy: 0.3533\n",
      "Epoch [15/500], Loss: 1.5046, Accuracy: 0.3669\n",
      "Epoch [16/500], Loss: 1.5048, Accuracy: 0.3591\n",
      "Epoch [17/500], Loss: 1.4893, Accuracy: 0.3714\n",
      "Epoch [18/500], Loss: 1.5006, Accuracy: 0.3687\n",
      "Epoch [19/500], Loss: 1.4858, Accuracy: 0.3776\n",
      "Epoch [20/500], Loss: 1.4824, Accuracy: 0.3791\n",
      "Epoch [21/500], Loss: 1.4703, Accuracy: 0.3796\n",
      "Epoch [22/500], Loss: 1.4641, Accuracy: 0.3783\n",
      "Epoch [23/500], Loss: 1.4795, Accuracy: 0.3785\n",
      "Epoch [24/500], Loss: 1.4674, Accuracy: 0.3823\n",
      "Epoch [25/500], Loss: 1.4500, Accuracy: 0.3894\n",
      "Epoch [26/500], Loss: 1.4503, Accuracy: 0.3880\n",
      "Epoch [27/500], Loss: 1.4463, Accuracy: 0.3954\n",
      "Epoch [28/500], Loss: 1.4414, Accuracy: 0.3924\n",
      "Epoch [29/500], Loss: 1.4344, Accuracy: 0.3986\n",
      "Epoch [30/500], Loss: 1.4359, Accuracy: 0.3921\n",
      "Epoch [31/500], Loss: 1.4231, Accuracy: 0.4008\n",
      "Epoch [32/500], Loss: 1.4149, Accuracy: 0.3993\n",
      "Epoch [33/500], Loss: 1.4152, Accuracy: 0.3973\n",
      "Epoch [34/500], Loss: 1.4163, Accuracy: 0.4203\n",
      "Epoch [35/500], Loss: 1.4060, Accuracy: 0.4062\n",
      "Epoch [36/500], Loss: 1.4064, Accuracy: 0.4149\n",
      "Epoch [37/500], Loss: 1.4030, Accuracy: 0.4126\n",
      "Epoch [38/500], Loss: 1.3972, Accuracy: 0.4174\n",
      "Epoch [39/500], Loss: 1.3969, Accuracy: 0.4243\n",
      "Epoch [40/500], Loss: 1.3938, Accuracy: 0.4238\n",
      "Epoch [41/500], Loss: 1.3913, Accuracy: 0.4228\n",
      "Epoch [42/500], Loss: 1.3752, Accuracy: 0.4250\n",
      "Epoch [43/500], Loss: 1.3748, Accuracy: 0.4321\n",
      "Epoch [44/500], Loss: 1.3751, Accuracy: 0.4267\n",
      "Epoch [45/500], Loss: 1.3902, Accuracy: 0.4213\n",
      "Epoch [46/500], Loss: 1.3825, Accuracy: 0.4289\n",
      "Epoch [47/500], Loss: 1.3784, Accuracy: 0.4336\n",
      "Epoch [48/500], Loss: 1.3637, Accuracy: 0.4329\n",
      "Epoch [49/500], Loss: 1.3723, Accuracy: 0.4267\n",
      "Epoch [50/500], Loss: 1.3689, Accuracy: 0.4292\n",
      "Epoch [51/500], Loss: 1.3746, Accuracy: 0.4389\n",
      "Epoch [52/500], Loss: 1.3658, Accuracy: 0.4378\n",
      "Epoch [53/500], Loss: 1.3723, Accuracy: 0.4327\n",
      "Epoch [54/500], Loss: 1.3584, Accuracy: 0.4361\n",
      "Epoch [55/500], Loss: 1.3633, Accuracy: 0.4351\n",
      "Epoch [56/500], Loss: 1.3555, Accuracy: 0.4393\n",
      "Epoch [57/500], Loss: 1.3446, Accuracy: 0.4504\n",
      "Epoch [58/500], Loss: 1.3566, Accuracy: 0.4329\n",
      "Epoch [59/500], Loss: 1.3571, Accuracy: 0.4416\n",
      "Epoch [60/500], Loss: 1.3457, Accuracy: 0.4457\n",
      "Epoch [61/500], Loss: 1.3403, Accuracy: 0.4401\n",
      "Epoch [62/500], Loss: 1.3383, Accuracy: 0.4483\n",
      "Epoch [63/500], Loss: 1.3478, Accuracy: 0.4468\n",
      "Epoch [64/500], Loss: 1.3440, Accuracy: 0.4416\n",
      "Epoch [65/500], Loss: 1.3363, Accuracy: 0.4463\n",
      "Epoch [66/500], Loss: 1.3480, Accuracy: 0.4446\n",
      "Epoch [67/500], Loss: 1.3374, Accuracy: 0.4441\n",
      "Epoch [68/500], Loss: 1.3424, Accuracy: 0.4502\n",
      "Epoch [69/500], Loss: 1.3376, Accuracy: 0.4517\n",
      "Epoch [70/500], Loss: 1.3396, Accuracy: 0.4426\n",
      "Epoch [71/500], Loss: 1.3412, Accuracy: 0.4473\n",
      "Epoch [72/500], Loss: 1.3318, Accuracy: 0.4488\n",
      "Epoch [73/500], Loss: 1.3355, Accuracy: 0.4502\n",
      "Epoch [74/500], Loss: 1.3411, Accuracy: 0.4421\n",
      "Epoch [75/500], Loss: 1.3293, Accuracy: 0.4510\n",
      "Epoch [76/500], Loss: 1.3210, Accuracy: 0.4525\n",
      "Epoch [77/500], Loss: 1.3228, Accuracy: 0.4584\n",
      "Epoch [78/500], Loss: 1.3184, Accuracy: 0.4520\n",
      "Epoch [79/500], Loss: 1.3271, Accuracy: 0.4559\n",
      "Epoch [80/500], Loss: 1.3206, Accuracy: 0.4527\n",
      "Epoch [81/500], Loss: 1.3183, Accuracy: 0.4581\n",
      "Epoch [82/500], Loss: 1.3062, Accuracy: 0.4588\n",
      "Epoch [83/500], Loss: 1.3087, Accuracy: 0.4593\n",
      "Epoch [84/500], Loss: 1.3147, Accuracy: 0.4572\n",
      "Epoch [85/500], Loss: 1.3118, Accuracy: 0.4537\n",
      "Epoch [86/500], Loss: 1.3110, Accuracy: 0.4567\n",
      "Epoch [87/500], Loss: 1.3065, Accuracy: 0.4606\n",
      "Epoch [88/500], Loss: 1.3113, Accuracy: 0.4598\n",
      "Epoch [89/500], Loss: 1.3198, Accuracy: 0.4549\n",
      "Epoch [90/500], Loss: 1.3122, Accuracy: 0.4678\n",
      "Epoch [91/500], Loss: 1.3095, Accuracy: 0.4578\n",
      "Epoch [92/500], Loss: 1.3177, Accuracy: 0.4505\n",
      "Epoch [93/500], Loss: 1.3046, Accuracy: 0.4630\n",
      "Epoch [94/500], Loss: 1.3217, Accuracy: 0.4567\n",
      "Epoch [95/500], Loss: 1.3110, Accuracy: 0.4598\n",
      "Epoch [96/500], Loss: 1.3023, Accuracy: 0.4584\n",
      "Epoch [97/500], Loss: 1.3148, Accuracy: 0.4667\n",
      "Epoch [98/500], Loss: 1.2890, Accuracy: 0.4729\n",
      "Epoch [99/500], Loss: 1.3020, Accuracy: 0.4651\n",
      "Epoch [100/500], Loss: 1.3126, Accuracy: 0.4665\n",
      "Epoch [101/500], Loss: 1.3049, Accuracy: 0.4675\n",
      "Epoch [102/500], Loss: 1.3089, Accuracy: 0.4599\n",
      "Epoch [103/500], Loss: 1.2896, Accuracy: 0.4702\n",
      "Epoch [104/500], Loss: 1.3016, Accuracy: 0.4724\n",
      "Epoch [105/500], Loss: 1.3183, Accuracy: 0.4566\n",
      "Epoch [106/500], Loss: 1.2891, Accuracy: 0.4730\n",
      "Epoch [107/500], Loss: 1.2975, Accuracy: 0.4635\n",
      "Epoch [108/500], Loss: 1.2874, Accuracy: 0.4680\n",
      "Epoch [109/500], Loss: 1.3030, Accuracy: 0.4651\n",
      "Epoch [110/500], Loss: 1.2965, Accuracy: 0.4656\n",
      "Epoch [111/500], Loss: 1.2834, Accuracy: 0.4771\n",
      "Epoch [112/500], Loss: 1.2878, Accuracy: 0.4767\n",
      "Epoch [113/500], Loss: 1.2908, Accuracy: 0.4746\n",
      "Epoch [114/500], Loss: 1.2966, Accuracy: 0.4690\n",
      "Epoch [115/500], Loss: 1.2974, Accuracy: 0.4759\n",
      "Epoch [116/500], Loss: 1.2824, Accuracy: 0.4740\n",
      "Epoch [117/500], Loss: 1.2982, Accuracy: 0.4668\n",
      "Epoch [118/500], Loss: 1.2972, Accuracy: 0.4746\n",
      "Epoch [119/500], Loss: 1.3017, Accuracy: 0.4682\n",
      "Epoch [120/500], Loss: 1.3262, Accuracy: 0.4630\n",
      "Epoch [121/500], Loss: 1.3091, Accuracy: 0.4636\n",
      "Epoch [122/500], Loss: 1.2906, Accuracy: 0.4734\n",
      "Epoch [123/500], Loss: 1.2755, Accuracy: 0.4771\n",
      "Epoch [124/500], Loss: 1.2920, Accuracy: 0.4690\n",
      "Epoch [125/500], Loss: 1.2804, Accuracy: 0.4811\n",
      "Epoch [126/500], Loss: 1.2763, Accuracy: 0.4818\n",
      "Epoch [127/500], Loss: 1.2960, Accuracy: 0.4660\n",
      "Epoch [128/500], Loss: 1.2834, Accuracy: 0.4715\n",
      "Epoch [129/500], Loss: 1.2893, Accuracy: 0.4670\n",
      "Epoch [130/500], Loss: 1.2898, Accuracy: 0.4730\n",
      "Epoch [131/500], Loss: 1.2956, Accuracy: 0.4710\n",
      "Epoch [132/500], Loss: 1.2699, Accuracy: 0.4782\n",
      "Epoch [133/500], Loss: 1.2755, Accuracy: 0.4806\n",
      "Epoch [134/500], Loss: 1.2718, Accuracy: 0.4809\n",
      "Epoch [135/500], Loss: 1.2737, Accuracy: 0.4813\n",
      "Epoch [136/500], Loss: 1.2843, Accuracy: 0.4789\n",
      "Epoch [137/500], Loss: 1.2836, Accuracy: 0.4777\n",
      "Epoch [138/500], Loss: 1.2802, Accuracy: 0.4784\n",
      "Epoch [139/500], Loss: 1.2741, Accuracy: 0.4683\n",
      "Epoch [140/500], Loss: 1.2782, Accuracy: 0.4860\n",
      "Epoch [141/500], Loss: 1.2723, Accuracy: 0.4808\n",
      "Epoch [142/500], Loss: 1.2745, Accuracy: 0.4816\n",
      "Epoch [143/500], Loss: 1.2740, Accuracy: 0.4814\n",
      "Epoch [144/500], Loss: 1.2622, Accuracy: 0.4855\n",
      "Epoch [145/500], Loss: 1.2740, Accuracy: 0.4838\n",
      "Epoch [146/500], Loss: 1.2674, Accuracy: 0.4818\n",
      "Epoch [147/500], Loss: 1.2784, Accuracy: 0.4855\n",
      "Epoch [148/500], Loss: 1.3081, Accuracy: 0.4593\n",
      "Epoch [149/500], Loss: 1.2716, Accuracy: 0.4824\n",
      "Epoch [150/500], Loss: 1.2723, Accuracy: 0.4801\n",
      "Epoch [151/500], Loss: 1.2593, Accuracy: 0.4892\n",
      "Epoch [152/500], Loss: 1.3128, Accuracy: 0.4821\n",
      "Epoch [153/500], Loss: 1.2772, Accuracy: 0.4781\n",
      "Epoch [154/500], Loss: 1.2554, Accuracy: 0.4964\n",
      "Epoch [155/500], Loss: 1.2630, Accuracy: 0.4945\n",
      "Epoch [156/500], Loss: 1.2614, Accuracy: 0.4883\n",
      "Epoch [157/500], Loss: 1.2686, Accuracy: 0.4863\n",
      "Epoch [158/500], Loss: 1.2668, Accuracy: 0.4892\n",
      "Epoch [159/500], Loss: 1.2611, Accuracy: 0.4883\n",
      "Epoch [160/500], Loss: 1.2698, Accuracy: 0.4818\n",
      "Epoch [161/500], Loss: 1.2532, Accuracy: 0.4900\n",
      "Epoch [162/500], Loss: 1.2651, Accuracy: 0.4865\n",
      "Epoch [163/500], Loss: 1.2650, Accuracy: 0.4823\n",
      "Epoch [164/500], Loss: 1.2577, Accuracy: 0.4961\n",
      "Epoch [165/500], Loss: 1.2668, Accuracy: 0.4858\n",
      "Epoch [166/500], Loss: 1.2638, Accuracy: 0.4829\n",
      "Epoch [167/500], Loss: 1.2757, Accuracy: 0.4777\n",
      "Epoch [168/500], Loss: 1.2639, Accuracy: 0.4871\n",
      "Epoch [169/500], Loss: 1.2685, Accuracy: 0.4809\n",
      "Epoch [170/500], Loss: 1.2675, Accuracy: 0.4858\n",
      "Epoch [171/500], Loss: 1.2878, Accuracy: 0.4821\n",
      "Epoch [172/500], Loss: 1.2767, Accuracy: 0.4707\n",
      "Epoch [173/500], Loss: 1.2664, Accuracy: 0.4866\n",
      "Epoch [174/500], Loss: 1.2688, Accuracy: 0.4794\n",
      "Epoch [175/500], Loss: 1.2581, Accuracy: 0.4858\n",
      "Epoch [176/500], Loss: 1.2558, Accuracy: 0.4962\n",
      "Epoch [177/500], Loss: 1.2803, Accuracy: 0.4739\n",
      "Epoch [178/500], Loss: 1.2455, Accuracy: 0.4971\n",
      "Epoch [179/500], Loss: 1.2542, Accuracy: 0.4833\n",
      "Epoch [180/500], Loss: 1.2677, Accuracy: 0.4893\n",
      "Epoch [181/500], Loss: 1.2481, Accuracy: 0.4944\n",
      "Epoch [182/500], Loss: 1.2569, Accuracy: 0.4853\n",
      "Epoch [183/500], Loss: 1.2590, Accuracy: 0.4925\n",
      "Epoch [184/500], Loss: 1.2509, Accuracy: 0.4925\n",
      "Epoch [185/500], Loss: 1.2659, Accuracy: 0.4913\n",
      "Epoch [186/500], Loss: 1.3673, Accuracy: 0.4443\n",
      "Epoch [187/500], Loss: 1.2917, Accuracy: 0.4730\n",
      "Epoch [188/500], Loss: 1.2817, Accuracy: 0.4700\n",
      "Epoch [189/500], Loss: 1.2580, Accuracy: 0.4791\n",
      "Epoch [190/500], Loss: 1.2526, Accuracy: 0.4860\n",
      "Epoch [191/500], Loss: 1.2495, Accuracy: 0.4877\n",
      "Epoch [192/500], Loss: 1.2387, Accuracy: 0.4919\n",
      "Epoch [193/500], Loss: 1.2573, Accuracy: 0.4900\n",
      "Epoch [194/500], Loss: 1.2606, Accuracy: 0.4877\n",
      "Epoch [195/500], Loss: 1.2651, Accuracy: 0.4826\n",
      "Epoch [196/500], Loss: 1.2575, Accuracy: 0.4833\n",
      "Epoch [197/500], Loss: 1.2584, Accuracy: 0.4908\n",
      "Epoch [198/500], Loss: 1.2538, Accuracy: 0.4961\n",
      "Epoch [199/500], Loss: 1.2572, Accuracy: 0.4868\n",
      "Epoch [200/500], Loss: 1.2498, Accuracy: 0.4927\n",
      "Epoch [201/500], Loss: 1.2413, Accuracy: 0.4972\n",
      "Epoch [202/500], Loss: 1.2651, Accuracy: 0.4865\n",
      "Epoch [203/500], Loss: 1.2457, Accuracy: 0.4856\n",
      "Epoch [204/500], Loss: 1.2426, Accuracy: 0.4927\n",
      "Epoch [205/500], Loss: 1.2429, Accuracy: 0.4940\n",
      "Epoch [206/500], Loss: 1.2500, Accuracy: 0.5019\n",
      "Epoch [207/500], Loss: 1.2470, Accuracy: 0.4922\n",
      "Epoch [208/500], Loss: 1.2429, Accuracy: 0.4917\n",
      "Epoch [209/500], Loss: 1.2419, Accuracy: 0.4912\n",
      "Epoch [210/500], Loss: 1.2396, Accuracy: 0.4942\n",
      "Epoch [211/500], Loss: 1.2309, Accuracy: 0.5065\n",
      "Epoch [212/500], Loss: 1.2510, Accuracy: 0.4955\n",
      "Epoch [213/500], Loss: 1.2438, Accuracy: 0.4987\n",
      "Epoch [214/500], Loss: 1.2358, Accuracy: 0.4942\n",
      "Epoch [215/500], Loss: 1.2477, Accuracy: 0.4912\n",
      "Epoch [216/500], Loss: 1.2317, Accuracy: 0.4999\n",
      "Epoch [217/500], Loss: 1.2293, Accuracy: 0.4957\n",
      "Epoch [218/500], Loss: 1.2407, Accuracy: 0.4967\n",
      "Epoch [219/500], Loss: 1.2379, Accuracy: 0.5004\n",
      "Epoch [220/500], Loss: 1.2359, Accuracy: 0.4940\n",
      "Epoch [221/500], Loss: 1.2371, Accuracy: 0.4947\n",
      "Epoch [222/500], Loss: 1.2502, Accuracy: 0.4893\n",
      "Epoch [223/500], Loss: 1.2481, Accuracy: 0.4967\n",
      "Epoch [224/500], Loss: 1.2674, Accuracy: 0.4919\n",
      "Epoch [225/500], Loss: 1.2427, Accuracy: 0.4969\n",
      "Epoch [226/500], Loss: 1.2428, Accuracy: 0.4910\n",
      "Epoch [227/500], Loss: 1.2474, Accuracy: 0.4940\n",
      "Epoch [228/500], Loss: 1.2584, Accuracy: 0.4870\n",
      "Epoch [229/500], Loss: 1.2459, Accuracy: 0.4961\n",
      "Epoch [230/500], Loss: 1.2343, Accuracy: 0.4992\n",
      "Epoch [231/500], Loss: 1.2392, Accuracy: 0.4974\n",
      "Epoch [232/500], Loss: 1.2369, Accuracy: 0.4940\n",
      "Epoch [233/500], Loss: 1.2329, Accuracy: 0.4922\n",
      "Epoch [234/500], Loss: 1.2390, Accuracy: 0.4949\n",
      "Epoch [235/500], Loss: 1.2362, Accuracy: 0.4976\n",
      "Epoch [236/500], Loss: 1.2401, Accuracy: 0.4945\n",
      "Epoch [237/500], Loss: 1.2359, Accuracy: 0.4944\n",
      "Epoch [238/500], Loss: 1.2231, Accuracy: 0.4945\n",
      "Epoch [239/500], Loss: 1.2234, Accuracy: 0.5038\n",
      "Epoch [240/500], Loss: 1.2232, Accuracy: 0.4986\n",
      "Epoch [241/500], Loss: 1.2301, Accuracy: 0.4972\n",
      "Epoch [242/500], Loss: 1.2618, Accuracy: 0.4892\n",
      "Epoch [243/500], Loss: 1.2519, Accuracy: 0.4907\n",
      "Epoch [244/500], Loss: 1.2231, Accuracy: 0.5008\n",
      "Epoch [245/500], Loss: 1.2502, Accuracy: 0.4922\n",
      "Epoch [246/500], Loss: 1.2261, Accuracy: 0.5009\n",
      "Epoch [247/500], Loss: 1.2316, Accuracy: 0.5024\n",
      "Epoch [248/500], Loss: 1.2309, Accuracy: 0.5019\n",
      "Epoch [249/500], Loss: 1.2402, Accuracy: 0.4984\n",
      "Epoch [250/500], Loss: 1.2241, Accuracy: 0.5021\n",
      "Epoch [251/500], Loss: 1.2283, Accuracy: 0.5006\n",
      "Epoch [252/500], Loss: 1.2230, Accuracy: 0.5093\n",
      "Epoch [253/500], Loss: 1.2286, Accuracy: 0.5041\n",
      "Epoch [254/500], Loss: 1.2291, Accuracy: 0.4994\n",
      "Epoch [255/500], Loss: 1.2207, Accuracy: 0.4992\n",
      "Epoch [256/500], Loss: 1.2149, Accuracy: 0.5098\n",
      "Epoch [257/500], Loss: 1.2215, Accuracy: 0.5085\n",
      "Epoch [258/500], Loss: 1.2317, Accuracy: 0.5039\n",
      "Epoch [259/500], Loss: 1.2284, Accuracy: 0.5001\n",
      "Epoch [260/500], Loss: 1.2331, Accuracy: 0.4997\n",
      "Epoch [261/500], Loss: 1.2365, Accuracy: 0.4977\n",
      "Epoch [262/500], Loss: 1.2165, Accuracy: 0.5006\n",
      "Epoch [263/500], Loss: 1.2180, Accuracy: 0.5066\n",
      "Epoch [264/500], Loss: 1.2207, Accuracy: 0.5063\n",
      "Epoch [265/500], Loss: 1.2168, Accuracy: 0.5018\n",
      "Epoch [266/500], Loss: 1.2235, Accuracy: 0.5024\n",
      "Epoch [267/500], Loss: 1.2354, Accuracy: 0.4969\n",
      "Epoch [268/500], Loss: 1.2280, Accuracy: 0.5014\n",
      "Epoch [269/500], Loss: 1.2222, Accuracy: 0.5004\n",
      "Epoch [270/500], Loss: 1.2169, Accuracy: 0.5063\n",
      "Epoch [271/500], Loss: 1.2155, Accuracy: 0.5066\n",
      "Epoch [272/500], Loss: 1.2211, Accuracy: 0.5036\n",
      "Epoch [273/500], Loss: 1.2313, Accuracy: 0.5003\n",
      "Epoch [274/500], Loss: 1.2408, Accuracy: 0.4982\n",
      "Epoch [275/500], Loss: 1.2414, Accuracy: 0.4947\n",
      "Epoch [276/500], Loss: 1.2288, Accuracy: 0.5038\n",
      "Epoch [277/500], Loss: 1.2184, Accuracy: 0.5006\n",
      "Epoch [278/500], Loss: 1.2261, Accuracy: 0.5055\n",
      "Epoch [279/500], Loss: 1.2276, Accuracy: 0.4992\n",
      "Epoch [280/500], Loss: 1.2290, Accuracy: 0.5004\n",
      "Epoch [281/500], Loss: 1.2212, Accuracy: 0.5081\n",
      "Epoch [282/500], Loss: 1.2407, Accuracy: 0.4986\n",
      "Epoch [283/500], Loss: 1.2333, Accuracy: 0.4986\n",
      "Epoch [284/500], Loss: 1.2382, Accuracy: 0.4927\n",
      "Epoch [285/500], Loss: 1.2236, Accuracy: 0.5053\n",
      "Epoch [286/500], Loss: 1.2234, Accuracy: 0.5033\n",
      "Epoch [287/500], Loss: 1.2199, Accuracy: 0.5093\n",
      "Epoch [288/500], Loss: 1.2091, Accuracy: 0.5041\n",
      "Epoch [289/500], Loss: 1.2150, Accuracy: 0.5112\n",
      "Epoch [290/500], Loss: 1.2205, Accuracy: 0.5081\n",
      "Epoch [291/500], Loss: 1.2480, Accuracy: 0.4950\n",
      "Epoch [292/500], Loss: 1.2195, Accuracy: 0.5021\n",
      "Epoch [293/500], Loss: 1.2087, Accuracy: 0.5120\n",
      "Epoch [294/500], Loss: 1.2176, Accuracy: 0.5046\n",
      "Epoch [295/500], Loss: 1.2179, Accuracy: 0.5036\n",
      "Epoch [296/500], Loss: 1.2097, Accuracy: 0.5006\n",
      "Epoch [297/500], Loss: 1.2210, Accuracy: 0.5083\n",
      "Epoch [298/500], Loss: 1.2180, Accuracy: 0.5046\n",
      "Epoch [299/500], Loss: 1.2167, Accuracy: 0.5036\n",
      "Epoch [300/500], Loss: 1.2123, Accuracy: 0.5009\n",
      "Epoch [301/500], Loss: 1.2145, Accuracy: 0.5092\n",
      "Epoch [302/500], Loss: 1.2066, Accuracy: 0.5058\n",
      "Epoch [303/500], Loss: 1.2112, Accuracy: 0.5071\n",
      "Epoch [304/500], Loss: 1.2119, Accuracy: 0.5060\n",
      "Epoch [305/500], Loss: 1.2080, Accuracy: 0.5070\n",
      "Epoch [306/500], Loss: 1.2099, Accuracy: 0.5081\n",
      "Epoch [307/500], Loss: 1.2207, Accuracy: 0.5063\n",
      "Epoch [308/500], Loss: 1.2297, Accuracy: 0.4967\n",
      "Epoch [309/500], Loss: 1.2198, Accuracy: 0.5041\n",
      "Epoch [310/500], Loss: 1.2269, Accuracy: 0.5066\n",
      "Epoch [311/500], Loss: 1.2148, Accuracy: 0.5019\n",
      "Epoch [312/500], Loss: 1.2237, Accuracy: 0.5100\n",
      "Epoch [313/500], Loss: 1.2189, Accuracy: 0.5019\n",
      "Epoch [314/500], Loss: 1.2141, Accuracy: 0.5145\n",
      "Epoch [315/500], Loss: 1.2046, Accuracy: 0.5102\n",
      "Epoch [316/500], Loss: 1.2126, Accuracy: 0.5073\n",
      "Epoch [317/500], Loss: 1.2048, Accuracy: 0.5092\n",
      "Epoch [318/500], Loss: 1.1988, Accuracy: 0.5120\n",
      "Epoch [319/500], Loss: 1.2085, Accuracy: 0.5087\n",
      "Epoch [320/500], Loss: 1.2058, Accuracy: 0.5013\n",
      "Epoch [321/500], Loss: 1.2033, Accuracy: 0.5038\n",
      "Epoch [322/500], Loss: 1.2000, Accuracy: 0.5154\n",
      "Epoch [323/500], Loss: 1.2005, Accuracy: 0.5033\n",
      "Epoch [324/500], Loss: 1.2062, Accuracy: 0.5055\n",
      "Epoch [325/500], Loss: 1.2224, Accuracy: 0.4969\n",
      "Epoch [326/500], Loss: 1.2112, Accuracy: 0.5090\n",
      "Epoch [327/500], Loss: 1.2093, Accuracy: 0.5112\n",
      "Epoch [328/500], Loss: 1.2103, Accuracy: 0.5061\n",
      "Epoch [329/500], Loss: 1.2169, Accuracy: 0.5110\n",
      "Epoch [330/500], Loss: 1.2059, Accuracy: 0.5080\n",
      "Epoch [331/500], Loss: 1.1997, Accuracy: 0.5073\n",
      "Epoch [332/500], Loss: 1.2010, Accuracy: 0.5122\n",
      "Epoch [333/500], Loss: 1.2185, Accuracy: 0.5043\n",
      "Epoch [334/500], Loss: 1.2212, Accuracy: 0.5026\n",
      "Epoch [335/500], Loss: 1.2033, Accuracy: 0.5150\n",
      "Epoch [336/500], Loss: 1.2139, Accuracy: 0.5088\n",
      "Epoch [337/500], Loss: 1.2036, Accuracy: 0.5123\n",
      "Epoch [338/500], Loss: 1.2062, Accuracy: 0.5060\n",
      "Epoch [339/500], Loss: 1.1898, Accuracy: 0.5192\n",
      "Epoch [340/500], Loss: 1.2005, Accuracy: 0.5167\n",
      "Epoch [341/500], Loss: 1.2078, Accuracy: 0.5024\n",
      "Epoch [342/500], Loss: 1.2084, Accuracy: 0.5150\n",
      "Epoch [343/500], Loss: 1.2036, Accuracy: 0.5132\n",
      "Epoch [344/500], Loss: 1.2031, Accuracy: 0.5137\n",
      "Epoch [345/500], Loss: 1.2331, Accuracy: 0.5090\n",
      "Epoch [346/500], Loss: 1.2147, Accuracy: 0.5061\n",
      "Epoch [347/500], Loss: 1.2011, Accuracy: 0.5115\n",
      "Epoch [348/500], Loss: 1.2158, Accuracy: 0.5187\n",
      "Epoch [349/500], Loss: 1.2153, Accuracy: 0.5093\n",
      "Epoch [350/500], Loss: 1.1973, Accuracy: 0.5174\n",
      "Epoch [351/500], Loss: 1.2058, Accuracy: 0.5056\n",
      "Epoch [352/500], Loss: 1.1890, Accuracy: 0.5194\n",
      "Epoch [353/500], Loss: 1.2057, Accuracy: 0.5093\n",
      "Epoch [354/500], Loss: 1.2123, Accuracy: 0.5075\n",
      "Epoch [355/500], Loss: 1.2008, Accuracy: 0.5071\n",
      "Epoch [356/500], Loss: 1.1992, Accuracy: 0.5140\n",
      "Epoch [357/500], Loss: 1.2063, Accuracy: 0.5075\n",
      "Epoch [358/500], Loss: 1.1930, Accuracy: 0.5117\n",
      "Epoch [359/500], Loss: 1.2088, Accuracy: 0.5113\n",
      "Epoch [360/500], Loss: 1.1898, Accuracy: 0.5132\n",
      "Epoch [361/500], Loss: 1.2031, Accuracy: 0.5120\n",
      "Epoch [362/500], Loss: 1.1860, Accuracy: 0.5192\n",
      "Epoch [363/500], Loss: 1.1925, Accuracy: 0.5078\n",
      "Epoch [364/500], Loss: 1.1969, Accuracy: 0.5108\n",
      "Epoch [365/500], Loss: 1.1959, Accuracy: 0.5184\n",
      "Epoch [366/500], Loss: 1.2002, Accuracy: 0.5201\n",
      "Epoch [367/500], Loss: 1.2021, Accuracy: 0.5169\n",
      "Epoch [368/500], Loss: 1.1968, Accuracy: 0.5144\n",
      "Epoch [369/500], Loss: 1.1958, Accuracy: 0.5081\n",
      "Epoch [370/500], Loss: 1.2071, Accuracy: 0.5122\n",
      "Epoch [371/500], Loss: 1.2241, Accuracy: 0.5053\n",
      "Epoch [372/500], Loss: 1.1964, Accuracy: 0.5162\n",
      "Epoch [373/500], Loss: 1.2011, Accuracy: 0.5149\n",
      "Epoch [374/500], Loss: 1.1863, Accuracy: 0.5139\n",
      "Epoch [375/500], Loss: 1.2120, Accuracy: 0.5080\n",
      "Epoch [376/500], Loss: 1.2160, Accuracy: 0.5095\n",
      "Epoch [377/500], Loss: 1.1993, Accuracy: 0.5192\n",
      "Epoch [378/500], Loss: 1.2231, Accuracy: 0.5026\n",
      "Epoch [379/500], Loss: 1.2297, Accuracy: 0.5019\n",
      "Epoch [380/500], Loss: 1.2194, Accuracy: 0.5139\n",
      "Epoch [381/500], Loss: 1.2115, Accuracy: 0.5051\n",
      "Epoch [382/500], Loss: 1.2097, Accuracy: 0.5056\n",
      "Epoch [383/500], Loss: 1.2026, Accuracy: 0.5132\n",
      "Epoch [384/500], Loss: 1.2000, Accuracy: 0.5102\n",
      "Epoch [385/500], Loss: 1.1874, Accuracy: 0.5144\n",
      "Epoch [386/500], Loss: 1.1884, Accuracy: 0.5142\n",
      "Epoch [387/500], Loss: 1.1939, Accuracy: 0.5159\n",
      "Epoch [388/500], Loss: 1.2078, Accuracy: 0.5134\n",
      "Epoch [389/500], Loss: 1.1948, Accuracy: 0.5152\n",
      "Epoch [390/500], Loss: 1.1965, Accuracy: 0.5144\n",
      "Epoch [391/500], Loss: 1.1895, Accuracy: 0.5218\n",
      "Epoch [392/500], Loss: 1.2101, Accuracy: 0.5093\n",
      "Epoch [393/500], Loss: 1.2077, Accuracy: 0.5102\n",
      "Epoch [394/500], Loss: 1.1969, Accuracy: 0.5115\n",
      "Epoch [395/500], Loss: 1.1884, Accuracy: 0.5194\n",
      "Epoch [396/500], Loss: 1.1841, Accuracy: 0.5202\n",
      "Epoch [397/500], Loss: 1.2077, Accuracy: 0.5212\n",
      "Epoch [398/500], Loss: 1.1981, Accuracy: 0.5150\n",
      "Epoch [399/500], Loss: 1.1925, Accuracy: 0.5179\n",
      "Epoch [400/500], Loss: 1.1878, Accuracy: 0.5097\n",
      "Epoch [401/500], Loss: 1.1959, Accuracy: 0.5122\n",
      "Epoch [402/500], Loss: 1.1922, Accuracy: 0.5087\n",
      "Epoch [403/500], Loss: 1.2009, Accuracy: 0.5159\n",
      "Epoch [404/500], Loss: 1.1966, Accuracy: 0.5113\n",
      "Epoch [405/500], Loss: 1.1974, Accuracy: 0.5137\n",
      "Epoch [406/500], Loss: 1.2009, Accuracy: 0.5100\n",
      "Epoch [407/500], Loss: 1.1924, Accuracy: 0.5117\n",
      "Epoch [408/500], Loss: 1.1921, Accuracy: 0.5108\n",
      "Epoch [409/500], Loss: 1.1848, Accuracy: 0.5088\n",
      "Epoch [410/500], Loss: 1.2031, Accuracy: 0.5187\n",
      "Epoch [411/500], Loss: 1.1859, Accuracy: 0.5201\n",
      "Epoch [412/500], Loss: 1.1811, Accuracy: 0.5212\n",
      "Epoch [413/500], Loss: 1.1696, Accuracy: 0.5260\n",
      "Epoch [414/500], Loss: 1.1867, Accuracy: 0.5244\n",
      "Epoch [415/500], Loss: 1.1907, Accuracy: 0.5065\n",
      "Epoch [416/500], Loss: 1.1905, Accuracy: 0.5102\n",
      "Epoch [417/500], Loss: 1.1943, Accuracy: 0.5184\n",
      "Epoch [418/500], Loss: 1.1942, Accuracy: 0.5191\n",
      "Epoch [419/500], Loss: 1.1995, Accuracy: 0.5123\n",
      "Epoch [420/500], Loss: 1.1887, Accuracy: 0.5176\n",
      "Epoch [421/500], Loss: 1.1936, Accuracy: 0.5102\n",
      "Epoch [422/500], Loss: 1.1866, Accuracy: 0.5187\n",
      "Epoch [423/500], Loss: 1.1942, Accuracy: 0.5191\n",
      "Epoch [424/500], Loss: 1.1986, Accuracy: 0.5118\n",
      "Epoch [425/500], Loss: 1.1912, Accuracy: 0.5172\n",
      "Epoch [426/500], Loss: 1.1879, Accuracy: 0.5199\n",
      "Epoch [427/500], Loss: 1.1897, Accuracy: 0.5122\n",
      "Epoch [428/500], Loss: 1.1978, Accuracy: 0.5145\n",
      "Epoch [429/500], Loss: 1.1845, Accuracy: 0.5139\n",
      "Epoch [430/500], Loss: 1.2151, Accuracy: 0.5219\n",
      "Epoch [431/500], Loss: 1.1893, Accuracy: 0.5164\n",
      "Epoch [432/500], Loss: 1.2012, Accuracy: 0.5071\n",
      "Epoch [433/500], Loss: 1.1723, Accuracy: 0.5171\n",
      "Epoch [434/500], Loss: 1.1858, Accuracy: 0.5204\n",
      "Epoch [435/500], Loss: 1.1754, Accuracy: 0.5204\n",
      "Epoch [436/500], Loss: 1.1819, Accuracy: 0.5165\n",
      "Epoch [437/500], Loss: 1.2294, Accuracy: 0.4954\n",
      "Epoch [438/500], Loss: 1.1929, Accuracy: 0.5076\n",
      "Epoch [439/500], Loss: 1.1806, Accuracy: 0.5177\n",
      "Epoch [440/500], Loss: 1.1785, Accuracy: 0.5209\n",
      "Epoch [441/500], Loss: 1.1814, Accuracy: 0.5288\n",
      "Epoch [442/500], Loss: 1.1890, Accuracy: 0.5149\n",
      "Epoch [443/500], Loss: 1.2197, Accuracy: 0.5004\n",
      "Epoch [444/500], Loss: 1.1847, Accuracy: 0.5181\n",
      "Epoch [445/500], Loss: 1.1861, Accuracy: 0.5117\n",
      "Epoch [446/500], Loss: 1.1685, Accuracy: 0.5320\n",
      "Epoch [447/500], Loss: 1.1840, Accuracy: 0.5192\n",
      "Epoch [448/500], Loss: 1.1900, Accuracy: 0.5197\n",
      "Epoch [449/500], Loss: 1.1846, Accuracy: 0.5169\n",
      "Epoch [450/500], Loss: 1.2043, Accuracy: 0.5140\n",
      "Epoch [451/500], Loss: 1.1815, Accuracy: 0.5204\n",
      "Epoch [452/500], Loss: 1.1817, Accuracy: 0.5202\n",
      "Epoch [453/500], Loss: 1.1867, Accuracy: 0.5171\n",
      "Epoch [454/500], Loss: 1.1778, Accuracy: 0.5179\n",
      "Epoch [455/500], Loss: 1.1927, Accuracy: 0.5140\n",
      "Epoch [456/500], Loss: 1.1829, Accuracy: 0.5202\n",
      "Epoch [457/500], Loss: 1.1829, Accuracy: 0.5189\n",
      "Epoch [458/500], Loss: 1.1903, Accuracy: 0.5150\n",
      "Epoch [459/500], Loss: 1.2198, Accuracy: 0.5090\n",
      "Epoch [460/500], Loss: 1.1876, Accuracy: 0.5081\n",
      "Epoch [461/500], Loss: 1.1872, Accuracy: 0.5211\n",
      "Epoch [462/500], Loss: 1.1805, Accuracy: 0.5209\n",
      "Epoch [463/500], Loss: 1.1876, Accuracy: 0.5134\n",
      "Epoch [464/500], Loss: 1.1829, Accuracy: 0.5164\n",
      "Epoch [465/500], Loss: 1.1959, Accuracy: 0.5154\n",
      "Epoch [466/500], Loss: 1.1771, Accuracy: 0.5197\n",
      "Epoch [467/500], Loss: 1.1898, Accuracy: 0.5162\n",
      "Epoch [468/500], Loss: 1.1769, Accuracy: 0.5218\n",
      "Epoch [469/500], Loss: 1.1705, Accuracy: 0.5186\n",
      "Epoch [470/500], Loss: 1.1948, Accuracy: 0.5196\n",
      "Epoch [471/500], Loss: 1.1758, Accuracy: 0.5253\n",
      "Epoch [472/500], Loss: 1.1805, Accuracy: 0.5179\n",
      "Epoch [473/500], Loss: 1.1821, Accuracy: 0.5270\n",
      "Epoch [474/500], Loss: 1.1737, Accuracy: 0.5224\n",
      "Epoch [475/500], Loss: 1.1826, Accuracy: 0.5202\n",
      "Epoch [476/500], Loss: 1.1942, Accuracy: 0.5140\n",
      "Epoch [477/500], Loss: 1.1873, Accuracy: 0.5189\n",
      "Epoch [478/500], Loss: 1.1846, Accuracy: 0.5187\n",
      "Epoch [479/500], Loss: 1.1976, Accuracy: 0.5154\n",
      "Epoch [480/500], Loss: 1.1761, Accuracy: 0.5221\n",
      "Epoch [481/500], Loss: 1.1908, Accuracy: 0.5160\n",
      "Epoch [482/500], Loss: 1.2525, Accuracy: 0.5019\n",
      "Epoch [483/500], Loss: 1.1668, Accuracy: 0.5249\n",
      "Epoch [484/500], Loss: 1.1855, Accuracy: 0.5224\n",
      "Epoch [485/500], Loss: 1.1900, Accuracy: 0.5169\n",
      "Epoch [486/500], Loss: 1.1763, Accuracy: 0.5236\n",
      "Epoch [487/500], Loss: 1.1780, Accuracy: 0.5172\n",
      "Epoch [488/500], Loss: 1.1880, Accuracy: 0.5212\n",
      "Epoch [489/500], Loss: 1.1736, Accuracy: 0.5233\n",
      "Epoch [490/500], Loss: 1.1918, Accuracy: 0.5145\n",
      "Epoch [491/500], Loss: 1.1738, Accuracy: 0.5238\n",
      "Epoch [492/500], Loss: 1.1799, Accuracy: 0.5199\n",
      "Epoch [493/500], Loss: 1.1665, Accuracy: 0.5261\n",
      "Epoch [494/500], Loss: 1.1758, Accuracy: 0.5209\n",
      "Epoch [495/500], Loss: 1.1781, Accuracy: 0.5181\n",
      "Epoch [496/500], Loss: 1.1740, Accuracy: 0.5184\n",
      "Epoch [497/500], Loss: 1.1878, Accuracy: 0.5246\n",
      "Epoch [498/500], Loss: 1.1899, Accuracy: 0.5199\n",
      "Epoch [499/500], Loss: 1.2020, Accuracy: 0.5169\n",
      "Epoch [500/500], Loss: 1.1739, Accuracy: 0.5216\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network\n",
    "cnn_model = CNNModel(input_size[0],num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "train(cnn_model, train_loaderCNN, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.6519, Accuracy: 0.2973\n",
      "Epoch [2/500], Loss: 1.5633, Accuracy: 0.3492\n",
      "Epoch [3/500], Loss: 1.5330, Accuracy: 0.3622\n",
      "Epoch [4/500], Loss: 1.5072, Accuracy: 0.3793\n",
      "Epoch [5/500], Loss: 1.4887, Accuracy: 0.3828\n",
      "Epoch [6/500], Loss: 1.4801, Accuracy: 0.3890\n",
      "Epoch [7/500], Loss: 1.4613, Accuracy: 0.3998\n",
      "Epoch [8/500], Loss: 1.4469, Accuracy: 0.4033\n",
      "Epoch [9/500], Loss: 1.4372, Accuracy: 0.4087\n",
      "Epoch [10/500], Loss: 1.4247, Accuracy: 0.4129\n",
      "Epoch [11/500], Loss: 1.4175, Accuracy: 0.4223\n",
      "Epoch [12/500], Loss: 1.4114, Accuracy: 0.4196\n",
      "Epoch [13/500], Loss: 1.3934, Accuracy: 0.4280\n",
      "Epoch [14/500], Loss: 1.3965, Accuracy: 0.4356\n",
      "Epoch [15/500], Loss: 1.3880, Accuracy: 0.4361\n",
      "Epoch [16/500], Loss: 1.4011, Accuracy: 0.4237\n",
      "Epoch [17/500], Loss: 1.3936, Accuracy: 0.4322\n",
      "Epoch [18/500], Loss: 1.3838, Accuracy: 0.4341\n",
      "Epoch [19/500], Loss: 1.3676, Accuracy: 0.4467\n",
      "Epoch [20/500], Loss: 1.3517, Accuracy: 0.4440\n",
      "Epoch [21/500], Loss: 1.3435, Accuracy: 0.4536\n",
      "Epoch [22/500], Loss: 1.3452, Accuracy: 0.4445\n",
      "Epoch [23/500], Loss: 1.3341, Accuracy: 0.4569\n",
      "Epoch [24/500], Loss: 1.3339, Accuracy: 0.4556\n",
      "Epoch [25/500], Loss: 1.3302, Accuracy: 0.4549\n",
      "Epoch [26/500], Loss: 1.3165, Accuracy: 0.4633\n",
      "Epoch [27/500], Loss: 1.3115, Accuracy: 0.4667\n",
      "Epoch [28/500], Loss: 1.3130, Accuracy: 0.4640\n",
      "Epoch [29/500], Loss: 1.3036, Accuracy: 0.4698\n",
      "Epoch [30/500], Loss: 1.3077, Accuracy: 0.4752\n",
      "Epoch [31/500], Loss: 1.3187, Accuracy: 0.4651\n",
      "Epoch [32/500], Loss: 1.2923, Accuracy: 0.4771\n",
      "Epoch [33/500], Loss: 1.2742, Accuracy: 0.4779\n",
      "Epoch [34/500], Loss: 1.2787, Accuracy: 0.4786\n",
      "Epoch [35/500], Loss: 1.2779, Accuracy: 0.4796\n",
      "Epoch [36/500], Loss: 1.2865, Accuracy: 0.4776\n",
      "Epoch [37/500], Loss: 1.2712, Accuracy: 0.4878\n",
      "Epoch [38/500], Loss: 1.2684, Accuracy: 0.4863\n",
      "Epoch [39/500], Loss: 1.2649, Accuracy: 0.4855\n",
      "Epoch [40/500], Loss: 1.2831, Accuracy: 0.4882\n",
      "Epoch [41/500], Loss: 1.2547, Accuracy: 0.4878\n",
      "Epoch [42/500], Loss: 1.2606, Accuracy: 0.4870\n",
      "Epoch [43/500], Loss: 1.2482, Accuracy: 0.4913\n",
      "Epoch [44/500], Loss: 1.2444, Accuracy: 0.4961\n",
      "Epoch [45/500], Loss: 1.2423, Accuracy: 0.4957\n",
      "Epoch [46/500], Loss: 1.2350, Accuracy: 0.5016\n",
      "Epoch [47/500], Loss: 1.2234, Accuracy: 0.5006\n",
      "Epoch [48/500], Loss: 1.2188, Accuracy: 0.5073\n",
      "Epoch [49/500], Loss: 1.2252, Accuracy: 0.5053\n",
      "Epoch [50/500], Loss: 1.2259, Accuracy: 0.5028\n",
      "Epoch [51/500], Loss: 1.2140, Accuracy: 0.5181\n",
      "Epoch [52/500], Loss: 1.2196, Accuracy: 0.5039\n",
      "Epoch [53/500], Loss: 1.2137, Accuracy: 0.5112\n",
      "Epoch [54/500], Loss: 1.2093, Accuracy: 0.5080\n",
      "Epoch [55/500], Loss: 1.2122, Accuracy: 0.5075\n",
      "Epoch [56/500], Loss: 1.1956, Accuracy: 0.5139\n",
      "Epoch [57/500], Loss: 1.1984, Accuracy: 0.5176\n",
      "Epoch [58/500], Loss: 1.1957, Accuracy: 0.5228\n",
      "Epoch [59/500], Loss: 1.1951, Accuracy: 0.5184\n",
      "Epoch [60/500], Loss: 1.1846, Accuracy: 0.5270\n",
      "Epoch [61/500], Loss: 1.1836, Accuracy: 0.5202\n",
      "Epoch [62/500], Loss: 1.1801, Accuracy: 0.5223\n",
      "Epoch [63/500], Loss: 1.1663, Accuracy: 0.5273\n",
      "Epoch [64/500], Loss: 1.1726, Accuracy: 0.5322\n",
      "Epoch [65/500], Loss: 1.1673, Accuracy: 0.5296\n",
      "Epoch [66/500], Loss: 1.1700, Accuracy: 0.5286\n",
      "Epoch [67/500], Loss: 1.1574, Accuracy: 0.5283\n",
      "Epoch [68/500], Loss: 1.1752, Accuracy: 0.5268\n",
      "Epoch [69/500], Loss: 1.1837, Accuracy: 0.5261\n",
      "Epoch [70/500], Loss: 1.1587, Accuracy: 0.5322\n",
      "Epoch [71/500], Loss: 1.1618, Accuracy: 0.5401\n",
      "Epoch [72/500], Loss: 1.1878, Accuracy: 0.5174\n",
      "Epoch [73/500], Loss: 1.1555, Accuracy: 0.5308\n",
      "Epoch [74/500], Loss: 1.1612, Accuracy: 0.5330\n",
      "Epoch [75/500], Loss: 1.1724, Accuracy: 0.5290\n",
      "Epoch [76/500], Loss: 1.1576, Accuracy: 0.5303\n",
      "Epoch [77/500], Loss: 1.1536, Accuracy: 0.5349\n",
      "Epoch [78/500], Loss: 1.1483, Accuracy: 0.5387\n",
      "Epoch [79/500], Loss: 1.1615, Accuracy: 0.5325\n",
      "Epoch [80/500], Loss: 1.1396, Accuracy: 0.5364\n",
      "Epoch [81/500], Loss: 1.1397, Accuracy: 0.5396\n",
      "Epoch [82/500], Loss: 1.1256, Accuracy: 0.5355\n",
      "Epoch [83/500], Loss: 1.1308, Accuracy: 0.5446\n",
      "Epoch [84/500], Loss: 1.1299, Accuracy: 0.5386\n",
      "Epoch [85/500], Loss: 1.1307, Accuracy: 0.5412\n",
      "Epoch [86/500], Loss: 1.1196, Accuracy: 0.5490\n",
      "Epoch [87/500], Loss: 1.1169, Accuracy: 0.5433\n",
      "Epoch [88/500], Loss: 1.1253, Accuracy: 0.5466\n",
      "Epoch [89/500], Loss: 1.1225, Accuracy: 0.5505\n",
      "Epoch [90/500], Loss: 1.1354, Accuracy: 0.5412\n",
      "Epoch [91/500], Loss: 1.1188, Accuracy: 0.5493\n",
      "Epoch [92/500], Loss: 1.1185, Accuracy: 0.5438\n",
      "Epoch [93/500], Loss: 1.1144, Accuracy: 0.5491\n",
      "Epoch [94/500], Loss: 1.1142, Accuracy: 0.5522\n",
      "Epoch [95/500], Loss: 1.1098, Accuracy: 0.5590\n",
      "Epoch [96/500], Loss: 1.1169, Accuracy: 0.5543\n",
      "Epoch [97/500], Loss: 1.1183, Accuracy: 0.5454\n",
      "Epoch [98/500], Loss: 1.1152, Accuracy: 0.5512\n",
      "Epoch [99/500], Loss: 1.1198, Accuracy: 0.5441\n",
      "Epoch [100/500], Loss: 1.1033, Accuracy: 0.5520\n",
      "Epoch [101/500], Loss: 1.0970, Accuracy: 0.5590\n",
      "Epoch [102/500], Loss: 1.0998, Accuracy: 0.5498\n",
      "Epoch [103/500], Loss: 1.0925, Accuracy: 0.5599\n",
      "Epoch [104/500], Loss: 1.0864, Accuracy: 0.5601\n",
      "Epoch [105/500], Loss: 1.0917, Accuracy: 0.5589\n",
      "Epoch [106/500], Loss: 1.0874, Accuracy: 0.5562\n",
      "Epoch [107/500], Loss: 1.0845, Accuracy: 0.5649\n",
      "Epoch [108/500], Loss: 1.0941, Accuracy: 0.5619\n",
      "Epoch [109/500], Loss: 1.1053, Accuracy: 0.5564\n",
      "Epoch [110/500], Loss: 1.0920, Accuracy: 0.5584\n",
      "Epoch [111/500], Loss: 1.0807, Accuracy: 0.5643\n",
      "Epoch [112/500], Loss: 1.0795, Accuracy: 0.5649\n",
      "Epoch [113/500], Loss: 1.0855, Accuracy: 0.5636\n",
      "Epoch [114/500], Loss: 1.0850, Accuracy: 0.5624\n",
      "Epoch [115/500], Loss: 1.0959, Accuracy: 0.5636\n",
      "Epoch [116/500], Loss: 1.0875, Accuracy: 0.5705\n",
      "Epoch [117/500], Loss: 1.0793, Accuracy: 0.5612\n",
      "Epoch [118/500], Loss: 1.1002, Accuracy: 0.5554\n",
      "Epoch [119/500], Loss: 1.0784, Accuracy: 0.5696\n",
      "Epoch [120/500], Loss: 1.0686, Accuracy: 0.5691\n",
      "Epoch [121/500], Loss: 1.0687, Accuracy: 0.5683\n",
      "Epoch [122/500], Loss: 1.0630, Accuracy: 0.5738\n",
      "Epoch [123/500], Loss: 1.0686, Accuracy: 0.5685\n",
      "Epoch [124/500], Loss: 1.0605, Accuracy: 0.5777\n",
      "Epoch [125/500], Loss: 1.0608, Accuracy: 0.5716\n",
      "Epoch [126/500], Loss: 1.0573, Accuracy: 0.5728\n",
      "Epoch [127/500], Loss: 1.0480, Accuracy: 0.5721\n",
      "Epoch [128/500], Loss: 1.0524, Accuracy: 0.5728\n",
      "Epoch [129/500], Loss: 1.0630, Accuracy: 0.5691\n",
      "Epoch [130/500], Loss: 1.0569, Accuracy: 0.5792\n",
      "Epoch [131/500], Loss: 1.0549, Accuracy: 0.5769\n",
      "Epoch [132/500], Loss: 1.0586, Accuracy: 0.5747\n",
      "Epoch [133/500], Loss: 1.0702, Accuracy: 0.5742\n",
      "Epoch [134/500], Loss: 1.0660, Accuracy: 0.5706\n",
      "Epoch [135/500], Loss: 1.0495, Accuracy: 0.5752\n",
      "Epoch [136/500], Loss: 1.0450, Accuracy: 0.5747\n",
      "Epoch [137/500], Loss: 1.0432, Accuracy: 0.5789\n",
      "Epoch [138/500], Loss: 1.0345, Accuracy: 0.5834\n",
      "Epoch [139/500], Loss: 1.0411, Accuracy: 0.5792\n",
      "Epoch [140/500], Loss: 1.0319, Accuracy: 0.5809\n",
      "Epoch [141/500], Loss: 1.0426, Accuracy: 0.5775\n",
      "Epoch [142/500], Loss: 1.0440, Accuracy: 0.5767\n",
      "Epoch [143/500], Loss: 1.0412, Accuracy: 0.5775\n",
      "Epoch [144/500], Loss: 1.0459, Accuracy: 0.5752\n",
      "Epoch [145/500], Loss: 1.0545, Accuracy: 0.5752\n",
      "Epoch [146/500], Loss: 1.0419, Accuracy: 0.5807\n",
      "Epoch [147/500], Loss: 1.0420, Accuracy: 0.5767\n",
      "Epoch [148/500], Loss: 1.0450, Accuracy: 0.5849\n",
      "Epoch [149/500], Loss: 1.0506, Accuracy: 0.5794\n",
      "Epoch [150/500], Loss: 1.0693, Accuracy: 0.5775\n",
      "Epoch [151/500], Loss: 1.0386, Accuracy: 0.5807\n",
      "Epoch [152/500], Loss: 1.0310, Accuracy: 0.5841\n",
      "Epoch [153/500], Loss: 1.0167, Accuracy: 0.5889\n",
      "Epoch [154/500], Loss: 1.0210, Accuracy: 0.5874\n",
      "Epoch [155/500], Loss: 1.0397, Accuracy: 0.5819\n",
      "Epoch [156/500], Loss: 1.0663, Accuracy: 0.5713\n",
      "Epoch [157/500], Loss: 1.0220, Accuracy: 0.5898\n",
      "Epoch [158/500], Loss: 1.0235, Accuracy: 0.5916\n",
      "Epoch [159/500], Loss: 1.0838, Accuracy: 0.5612\n",
      "Epoch [160/500], Loss: 1.0136, Accuracy: 0.5963\n",
      "Epoch [161/500], Loss: 1.0164, Accuracy: 0.5861\n",
      "Epoch [162/500], Loss: 1.0018, Accuracy: 0.5972\n",
      "Epoch [163/500], Loss: 1.0195, Accuracy: 0.5952\n",
      "Epoch [164/500], Loss: 1.0163, Accuracy: 0.5978\n",
      "Epoch [165/500], Loss: 1.0244, Accuracy: 0.5905\n",
      "Epoch [166/500], Loss: 1.0313, Accuracy: 0.5931\n",
      "Epoch [167/500], Loss: 1.0512, Accuracy: 0.5785\n",
      "Epoch [168/500], Loss: 1.0298, Accuracy: 0.5847\n",
      "Epoch [169/500], Loss: 1.0190, Accuracy: 0.5834\n",
      "Epoch [170/500], Loss: 1.0051, Accuracy: 0.5984\n",
      "Epoch [171/500], Loss: 1.0232, Accuracy: 0.5832\n",
      "Epoch [172/500], Loss: 1.0167, Accuracy: 0.5896\n",
      "Epoch [173/500], Loss: 1.0171, Accuracy: 0.6004\n",
      "Epoch [174/500], Loss: 1.0275, Accuracy: 0.5849\n",
      "Epoch [175/500], Loss: 1.0136, Accuracy: 0.5997\n",
      "Epoch [176/500], Loss: 1.0202, Accuracy: 0.5889\n",
      "Epoch [177/500], Loss: 1.0222, Accuracy: 0.5933\n",
      "Epoch [178/500], Loss: 1.0061, Accuracy: 0.5978\n",
      "Epoch [179/500], Loss: 1.0010, Accuracy: 0.5975\n",
      "Epoch [180/500], Loss: 0.9975, Accuracy: 0.5997\n",
      "Epoch [181/500], Loss: 1.0052, Accuracy: 0.5945\n",
      "Epoch [182/500], Loss: 1.0054, Accuracy: 0.5960\n",
      "Epoch [183/500], Loss: 1.0033, Accuracy: 0.5972\n",
      "Epoch [184/500], Loss: 0.9935, Accuracy: 0.6012\n",
      "Epoch [185/500], Loss: 0.9948, Accuracy: 0.6054\n",
      "Epoch [186/500], Loss: 1.0147, Accuracy: 0.5953\n",
      "Epoch [187/500], Loss: 0.9905, Accuracy: 0.5997\n",
      "Epoch [188/500], Loss: 1.0001, Accuracy: 0.5987\n",
      "Epoch [189/500], Loss: 0.9894, Accuracy: 0.6099\n",
      "Epoch [190/500], Loss: 1.0084, Accuracy: 0.5935\n",
      "Epoch [191/500], Loss: 1.0114, Accuracy: 0.5889\n",
      "Epoch [192/500], Loss: 0.9848, Accuracy: 0.6009\n",
      "Epoch [193/500], Loss: 0.9939, Accuracy: 0.6066\n",
      "Epoch [194/500], Loss: 0.9976, Accuracy: 0.6020\n",
      "Epoch [195/500], Loss: 0.9968, Accuracy: 0.6031\n",
      "Epoch [196/500], Loss: 1.0594, Accuracy: 0.5767\n",
      "Epoch [197/500], Loss: 0.9894, Accuracy: 0.6002\n",
      "Epoch [198/500], Loss: 1.0126, Accuracy: 0.5900\n",
      "Epoch [199/500], Loss: 1.0269, Accuracy: 0.5777\n",
      "Epoch [200/500], Loss: 1.0006, Accuracy: 0.6052\n",
      "Epoch [201/500], Loss: 0.9793, Accuracy: 0.6020\n",
      "Epoch [202/500], Loss: 0.9818, Accuracy: 0.6084\n",
      "Epoch [203/500], Loss: 0.9921, Accuracy: 0.6010\n",
      "Epoch [204/500], Loss: 0.9848, Accuracy: 0.6041\n",
      "Epoch [205/500], Loss: 0.9903, Accuracy: 0.6029\n",
      "Epoch [206/500], Loss: 1.0324, Accuracy: 0.5849\n",
      "Epoch [207/500], Loss: 0.9927, Accuracy: 0.5982\n",
      "Epoch [208/500], Loss: 0.9847, Accuracy: 0.6031\n",
      "Epoch [209/500], Loss: 0.9808, Accuracy: 0.6110\n",
      "Epoch [210/500], Loss: 0.9800, Accuracy: 0.6026\n",
      "Epoch [211/500], Loss: 0.9941, Accuracy: 0.6069\n",
      "Epoch [212/500], Loss: 0.9793, Accuracy: 0.6037\n",
      "Epoch [213/500], Loss: 0.9774, Accuracy: 0.6068\n",
      "Epoch [214/500], Loss: 0.9868, Accuracy: 0.6034\n",
      "Epoch [215/500], Loss: 0.9717, Accuracy: 0.6121\n",
      "Epoch [216/500], Loss: 0.9771, Accuracy: 0.6088\n",
      "Epoch [217/500], Loss: 0.9717, Accuracy: 0.6108\n",
      "Epoch [218/500], Loss: 0.9655, Accuracy: 0.6106\n",
      "Epoch [219/500], Loss: 0.9893, Accuracy: 0.5987\n",
      "Epoch [220/500], Loss: 0.9634, Accuracy: 0.6143\n",
      "Epoch [221/500], Loss: 0.9670, Accuracy: 0.6111\n",
      "Epoch [222/500], Loss: 0.9754, Accuracy: 0.6126\n",
      "Epoch [223/500], Loss: 0.9868, Accuracy: 0.6138\n",
      "Epoch [224/500], Loss: 0.9763, Accuracy: 0.6034\n",
      "Epoch [225/500], Loss: 0.9699, Accuracy: 0.6145\n",
      "Epoch [226/500], Loss: 0.9833, Accuracy: 0.6064\n",
      "Epoch [227/500], Loss: 0.9733, Accuracy: 0.6103\n",
      "Epoch [228/500], Loss: 0.9661, Accuracy: 0.6089\n",
      "Epoch [229/500], Loss: 0.9729, Accuracy: 0.6158\n",
      "Epoch [230/500], Loss: 0.9807, Accuracy: 0.6120\n",
      "Epoch [231/500], Loss: 0.9877, Accuracy: 0.6084\n",
      "Epoch [232/500], Loss: 0.9592, Accuracy: 0.6104\n",
      "Epoch [233/500], Loss: 0.9625, Accuracy: 0.6111\n",
      "Epoch [234/500], Loss: 0.9646, Accuracy: 0.6205\n",
      "Epoch [235/500], Loss: 1.0199, Accuracy: 0.5879\n",
      "Epoch [236/500], Loss: 0.9783, Accuracy: 0.6068\n",
      "Epoch [237/500], Loss: 0.9838, Accuracy: 0.6138\n",
      "Epoch [238/500], Loss: 0.9999, Accuracy: 0.6029\n",
      "Epoch [239/500], Loss: 1.0089, Accuracy: 0.5995\n",
      "Epoch [240/500], Loss: 0.9565, Accuracy: 0.6214\n",
      "Epoch [241/500], Loss: 0.9613, Accuracy: 0.6148\n",
      "Epoch [242/500], Loss: 0.9536, Accuracy: 0.6188\n",
      "Epoch [243/500], Loss: 0.9513, Accuracy: 0.6220\n",
      "Epoch [244/500], Loss: 0.9566, Accuracy: 0.6158\n",
      "Epoch [245/500], Loss: 0.9601, Accuracy: 0.6185\n",
      "Epoch [246/500], Loss: 0.9942, Accuracy: 0.6041\n",
      "Epoch [247/500], Loss: 0.9562, Accuracy: 0.6170\n",
      "Epoch [248/500], Loss: 0.9472, Accuracy: 0.6178\n",
      "Epoch [249/500], Loss: 0.9545, Accuracy: 0.6167\n",
      "Epoch [250/500], Loss: 0.9516, Accuracy: 0.6188\n",
      "Epoch [251/500], Loss: 0.9682, Accuracy: 0.6194\n",
      "Epoch [252/500], Loss: 0.9656, Accuracy: 0.6160\n",
      "Epoch [253/500], Loss: 0.9620, Accuracy: 0.6141\n",
      "Epoch [254/500], Loss: 0.9934, Accuracy: 0.6096\n",
      "Epoch [255/500], Loss: 0.9607, Accuracy: 0.6162\n",
      "Epoch [256/500], Loss: 0.9470, Accuracy: 0.6246\n",
      "Epoch [257/500], Loss: 0.9489, Accuracy: 0.6143\n",
      "Epoch [258/500], Loss: 0.9553, Accuracy: 0.6187\n",
      "Epoch [259/500], Loss: 0.9849, Accuracy: 0.6110\n",
      "Epoch [260/500], Loss: 0.9738, Accuracy: 0.6131\n",
      "Epoch [261/500], Loss: 0.9559, Accuracy: 0.6177\n",
      "Epoch [262/500], Loss: 0.9386, Accuracy: 0.6244\n",
      "Epoch [263/500], Loss: 0.9545, Accuracy: 0.6209\n",
      "Epoch [264/500], Loss: 0.9547, Accuracy: 0.6162\n",
      "Epoch [265/500], Loss: 0.9514, Accuracy: 0.6214\n",
      "Epoch [266/500], Loss: 0.9445, Accuracy: 0.6220\n",
      "Epoch [267/500], Loss: 0.9536, Accuracy: 0.6230\n",
      "Epoch [268/500], Loss: 0.9533, Accuracy: 0.6222\n",
      "Epoch [269/500], Loss: 0.9430, Accuracy: 0.6230\n",
      "Epoch [270/500], Loss: 0.9763, Accuracy: 0.6069\n",
      "Epoch [271/500], Loss: 0.9340, Accuracy: 0.6276\n",
      "Epoch [272/500], Loss: 0.9333, Accuracy: 0.6259\n",
      "Epoch [273/500], Loss: 0.9536, Accuracy: 0.6178\n",
      "Epoch [274/500], Loss: 0.9490, Accuracy: 0.6200\n",
      "Epoch [275/500], Loss: 0.9623, Accuracy: 0.6178\n",
      "Epoch [276/500], Loss: 0.9561, Accuracy: 0.6170\n",
      "Epoch [277/500], Loss: 1.0046, Accuracy: 0.5955\n",
      "Epoch [278/500], Loss: 0.9390, Accuracy: 0.6242\n",
      "Epoch [279/500], Loss: 0.9300, Accuracy: 0.6234\n",
      "Epoch [280/500], Loss: 0.9398, Accuracy: 0.6281\n",
      "Epoch [281/500], Loss: 0.9318, Accuracy: 0.6320\n",
      "Epoch [282/500], Loss: 0.9444, Accuracy: 0.6271\n",
      "Epoch [283/500], Loss: 0.9369, Accuracy: 0.6272\n",
      "Epoch [284/500], Loss: 0.9509, Accuracy: 0.6210\n",
      "Epoch [285/500], Loss: 0.9384, Accuracy: 0.6304\n",
      "Epoch [286/500], Loss: 0.9555, Accuracy: 0.6192\n",
      "Epoch [287/500], Loss: 0.9493, Accuracy: 0.6167\n",
      "Epoch [288/500], Loss: 0.9447, Accuracy: 0.6249\n",
      "Epoch [289/500], Loss: 0.9464, Accuracy: 0.6261\n",
      "Epoch [290/500], Loss: 0.9418, Accuracy: 0.6249\n",
      "Epoch [291/500], Loss: 0.9265, Accuracy: 0.6318\n",
      "Epoch [292/500], Loss: 0.9395, Accuracy: 0.6313\n",
      "Epoch [293/500], Loss: 0.9648, Accuracy: 0.6229\n",
      "Epoch [294/500], Loss: 0.9353, Accuracy: 0.6269\n",
      "Epoch [295/500], Loss: 0.9490, Accuracy: 0.6242\n",
      "Epoch [296/500], Loss: 0.9286, Accuracy: 0.6283\n",
      "Epoch [297/500], Loss: 0.9256, Accuracy: 0.6249\n",
      "Epoch [298/500], Loss: 0.9332, Accuracy: 0.6251\n",
      "Epoch [299/500], Loss: 0.9508, Accuracy: 0.6239\n",
      "Epoch [300/500], Loss: 0.9421, Accuracy: 0.6241\n",
      "Epoch [301/500], Loss: 0.9440, Accuracy: 0.6279\n",
      "Epoch [302/500], Loss: 0.9300, Accuracy: 0.6237\n",
      "Epoch [303/500], Loss: 0.9220, Accuracy: 0.6308\n",
      "Epoch [304/500], Loss: 0.9305, Accuracy: 0.6304\n",
      "Epoch [305/500], Loss: 0.9357, Accuracy: 0.6227\n",
      "Epoch [306/500], Loss: 0.9247, Accuracy: 0.6306\n",
      "Epoch [307/500], Loss: 0.9342, Accuracy: 0.6301\n",
      "Epoch [308/500], Loss: 0.9235, Accuracy: 0.6353\n",
      "Epoch [309/500], Loss: 0.9253, Accuracy: 0.6286\n",
      "Epoch [310/500], Loss: 0.9189, Accuracy: 0.6296\n",
      "Epoch [311/500], Loss: 0.9248, Accuracy: 0.6293\n",
      "Epoch [312/500], Loss: 0.9600, Accuracy: 0.6152\n",
      "Epoch [313/500], Loss: 0.9379, Accuracy: 0.6284\n",
      "Epoch [314/500], Loss: 0.9349, Accuracy: 0.6227\n",
      "Epoch [315/500], Loss: 0.9262, Accuracy: 0.6276\n",
      "Epoch [316/500], Loss: 0.9167, Accuracy: 0.6355\n",
      "Epoch [317/500], Loss: 0.9232, Accuracy: 0.6267\n",
      "Epoch [318/500], Loss: 0.9166, Accuracy: 0.6262\n",
      "Epoch [319/500], Loss: 0.9098, Accuracy: 0.6395\n",
      "Epoch [320/500], Loss: 0.9289, Accuracy: 0.6286\n",
      "Epoch [321/500], Loss: 0.9445, Accuracy: 0.6328\n",
      "Epoch [322/500], Loss: 1.0416, Accuracy: 0.5935\n",
      "Epoch [323/500], Loss: 0.9736, Accuracy: 0.6155\n",
      "Epoch [324/500], Loss: 0.9263, Accuracy: 0.6286\n",
      "Epoch [325/500], Loss: 0.9183, Accuracy: 0.6397\n",
      "Epoch [326/500], Loss: 0.9171, Accuracy: 0.6269\n",
      "Epoch [327/500], Loss: 0.9234, Accuracy: 0.6279\n",
      "Epoch [328/500], Loss: 0.8972, Accuracy: 0.6456\n",
      "Epoch [329/500], Loss: 0.9046, Accuracy: 0.6420\n",
      "Epoch [330/500], Loss: 0.9328, Accuracy: 0.6335\n",
      "Epoch [331/500], Loss: 0.9206, Accuracy: 0.6402\n",
      "Epoch [332/500], Loss: 0.9384, Accuracy: 0.6252\n",
      "Epoch [333/500], Loss: 0.9181, Accuracy: 0.6350\n",
      "Epoch [334/500], Loss: 0.9184, Accuracy: 0.6320\n",
      "Epoch [335/500], Loss: 0.9341, Accuracy: 0.6314\n",
      "Epoch [336/500], Loss: 0.9109, Accuracy: 0.6361\n",
      "Epoch [337/500], Loss: 0.9170, Accuracy: 0.6330\n",
      "Epoch [338/500], Loss: 1.0064, Accuracy: 0.5967\n",
      "Epoch [339/500], Loss: 0.9209, Accuracy: 0.6335\n",
      "Epoch [340/500], Loss: 0.9045, Accuracy: 0.6398\n",
      "Epoch [341/500], Loss: 0.9074, Accuracy: 0.6358\n",
      "Epoch [342/500], Loss: 0.9265, Accuracy: 0.6313\n",
      "Epoch [343/500], Loss: 0.9105, Accuracy: 0.6363\n",
      "Epoch [344/500], Loss: 0.9220, Accuracy: 0.6353\n",
      "Epoch [345/500], Loss: 0.9266, Accuracy: 0.6259\n",
      "Epoch [346/500], Loss: 0.9099, Accuracy: 0.6360\n",
      "Epoch [347/500], Loss: 0.9079, Accuracy: 0.6360\n",
      "Epoch [348/500], Loss: 0.8967, Accuracy: 0.6486\n",
      "Epoch [349/500], Loss: 0.9056, Accuracy: 0.6346\n",
      "Epoch [350/500], Loss: 0.9307, Accuracy: 0.6343\n",
      "Epoch [351/500], Loss: 0.9097, Accuracy: 0.6356\n",
      "Epoch [352/500], Loss: 0.9119, Accuracy: 0.6368\n",
      "Epoch [353/500], Loss: 0.9225, Accuracy: 0.6320\n",
      "Epoch [354/500], Loss: 0.9094, Accuracy: 0.6378\n",
      "Epoch [355/500], Loss: 0.9075, Accuracy: 0.6385\n",
      "Epoch [356/500], Loss: 0.9102, Accuracy: 0.6383\n",
      "Epoch [357/500], Loss: 0.9104, Accuracy: 0.6375\n",
      "Epoch [358/500], Loss: 0.9102, Accuracy: 0.6373\n",
      "Epoch [359/500], Loss: 0.9044, Accuracy: 0.6375\n",
      "Epoch [360/500], Loss: 0.8921, Accuracy: 0.6420\n",
      "Epoch [361/500], Loss: 0.9033, Accuracy: 0.6437\n",
      "Epoch [362/500], Loss: 0.9188, Accuracy: 0.6304\n",
      "Epoch [363/500], Loss: 0.9008, Accuracy: 0.6440\n",
      "Epoch [364/500], Loss: 0.8928, Accuracy: 0.6429\n",
      "Epoch [365/500], Loss: 0.9029, Accuracy: 0.6427\n",
      "Epoch [366/500], Loss: 0.9056, Accuracy: 0.6417\n",
      "Epoch [367/500], Loss: 0.9144, Accuracy: 0.6323\n",
      "Epoch [368/500], Loss: 0.9127, Accuracy: 0.6361\n",
      "Epoch [369/500], Loss: 0.9214, Accuracy: 0.6296\n",
      "Epoch [370/500], Loss: 0.9002, Accuracy: 0.6432\n",
      "Epoch [371/500], Loss: 0.9417, Accuracy: 0.6170\n",
      "Epoch [372/500], Loss: 0.9082, Accuracy: 0.6400\n",
      "Epoch [373/500], Loss: 0.9188, Accuracy: 0.6335\n",
      "Epoch [374/500], Loss: 0.8868, Accuracy: 0.6462\n",
      "Epoch [375/500], Loss: 0.9177, Accuracy: 0.6385\n",
      "Epoch [376/500], Loss: 0.9071, Accuracy: 0.6338\n",
      "Epoch [377/500], Loss: 0.9038, Accuracy: 0.6456\n",
      "Epoch [378/500], Loss: 0.9053, Accuracy: 0.6392\n",
      "Epoch [379/500], Loss: 0.9197, Accuracy: 0.6370\n",
      "Epoch [380/500], Loss: 0.9062, Accuracy: 0.6444\n",
      "Epoch [381/500], Loss: 0.9273, Accuracy: 0.6286\n",
      "Epoch [382/500], Loss: 0.9176, Accuracy: 0.6415\n",
      "Epoch [383/500], Loss: 0.9057, Accuracy: 0.6370\n",
      "Epoch [384/500], Loss: 0.9220, Accuracy: 0.6358\n",
      "Epoch [385/500], Loss: 0.8991, Accuracy: 0.6409\n",
      "Epoch [386/500], Loss: 0.8937, Accuracy: 0.6442\n",
      "Epoch [387/500], Loss: 0.9058, Accuracy: 0.6422\n",
      "Epoch [388/500], Loss: 0.9052, Accuracy: 0.6308\n",
      "Epoch [389/500], Loss: 0.8909, Accuracy: 0.6464\n",
      "Epoch [390/500], Loss: 0.8925, Accuracy: 0.6464\n",
      "Epoch [391/500], Loss: 0.9289, Accuracy: 0.6353\n",
      "Epoch [392/500], Loss: 0.8988, Accuracy: 0.6414\n",
      "Epoch [393/500], Loss: 0.9060, Accuracy: 0.6355\n",
      "Epoch [394/500], Loss: 0.8968, Accuracy: 0.6494\n",
      "Epoch [395/500], Loss: 0.9077, Accuracy: 0.6403\n",
      "Epoch [396/500], Loss: 0.9023, Accuracy: 0.6385\n",
      "Epoch [397/500], Loss: 0.9069, Accuracy: 0.6370\n",
      "Epoch [398/500], Loss: 0.8953, Accuracy: 0.6439\n",
      "Epoch [399/500], Loss: 0.8865, Accuracy: 0.6474\n",
      "Epoch [400/500], Loss: 0.8869, Accuracy: 0.6504\n",
      "Epoch [401/500], Loss: 0.8953, Accuracy: 0.6414\n",
      "Epoch [402/500], Loss: 0.8839, Accuracy: 0.6439\n",
      "Epoch [403/500], Loss: 0.8925, Accuracy: 0.6442\n",
      "Epoch [404/500], Loss: 0.8979, Accuracy: 0.6491\n",
      "Epoch [405/500], Loss: 0.9068, Accuracy: 0.6375\n",
      "Epoch [406/500], Loss: 0.8915, Accuracy: 0.6459\n",
      "Epoch [407/500], Loss: 0.8852, Accuracy: 0.6481\n",
      "Epoch [408/500], Loss: 0.8826, Accuracy: 0.6464\n",
      "Epoch [409/500], Loss: 0.8960, Accuracy: 0.6457\n",
      "Epoch [410/500], Loss: 0.8904, Accuracy: 0.6422\n",
      "Epoch [411/500], Loss: 0.8796, Accuracy: 0.6484\n",
      "Epoch [412/500], Loss: 0.8868, Accuracy: 0.6412\n",
      "Epoch [413/500], Loss: 0.8786, Accuracy: 0.6501\n",
      "Epoch [414/500], Loss: 0.8798, Accuracy: 0.6540\n",
      "Epoch [415/500], Loss: 0.8771, Accuracy: 0.6513\n",
      "Epoch [416/500], Loss: 0.8868, Accuracy: 0.6422\n",
      "Epoch [417/500], Loss: 0.8863, Accuracy: 0.6444\n",
      "Epoch [418/500], Loss: 0.8854, Accuracy: 0.6491\n",
      "Epoch [419/500], Loss: 0.8957, Accuracy: 0.6420\n",
      "Epoch [420/500], Loss: 0.9061, Accuracy: 0.6403\n",
      "Epoch [421/500], Loss: 0.8870, Accuracy: 0.6489\n",
      "Epoch [422/500], Loss: 0.8765, Accuracy: 0.6489\n",
      "Epoch [423/500], Loss: 0.8914, Accuracy: 0.6440\n",
      "Epoch [424/500], Loss: 0.8975, Accuracy: 0.6420\n",
      "Epoch [425/500], Loss: 0.8729, Accuracy: 0.6469\n",
      "Epoch [426/500], Loss: 0.8749, Accuracy: 0.6472\n",
      "Epoch [427/500], Loss: 0.9079, Accuracy: 0.6414\n",
      "Epoch [428/500], Loss: 0.8963, Accuracy: 0.6410\n",
      "Epoch [429/500], Loss: 0.8888, Accuracy: 0.6445\n",
      "Epoch [430/500], Loss: 0.9073, Accuracy: 0.6387\n",
      "Epoch [431/500], Loss: 0.8932, Accuracy: 0.6444\n",
      "Epoch [432/500], Loss: 0.8868, Accuracy: 0.6472\n",
      "Epoch [433/500], Loss: 0.9102, Accuracy: 0.6393\n",
      "Epoch [434/500], Loss: 0.8822, Accuracy: 0.6504\n",
      "Epoch [435/500], Loss: 0.8745, Accuracy: 0.6514\n",
      "Epoch [436/500], Loss: 0.8837, Accuracy: 0.6464\n",
      "Epoch [437/500], Loss: 0.8930, Accuracy: 0.6472\n",
      "Epoch [438/500], Loss: 0.8778, Accuracy: 0.6472\n",
      "Epoch [439/500], Loss: 0.8731, Accuracy: 0.6540\n",
      "Epoch [440/500], Loss: 0.8669, Accuracy: 0.6593\n",
      "Epoch [441/500], Loss: 0.8970, Accuracy: 0.6414\n",
      "Epoch [442/500], Loss: 0.8868, Accuracy: 0.6409\n",
      "Epoch [443/500], Loss: 0.8913, Accuracy: 0.6474\n",
      "Epoch [444/500], Loss: 0.8788, Accuracy: 0.6479\n",
      "Epoch [445/500], Loss: 0.8937, Accuracy: 0.6451\n",
      "Epoch [446/500], Loss: 0.8637, Accuracy: 0.6595\n",
      "Epoch [447/500], Loss: 0.8787, Accuracy: 0.6531\n",
      "Epoch [448/500], Loss: 0.9073, Accuracy: 0.6375\n",
      "Epoch [449/500], Loss: 0.9170, Accuracy: 0.6375\n",
      "Epoch [450/500], Loss: 0.8796, Accuracy: 0.6462\n",
      "Epoch [451/500], Loss: 0.8753, Accuracy: 0.6516\n",
      "Epoch [452/500], Loss: 0.8697, Accuracy: 0.6563\n",
      "Epoch [453/500], Loss: 0.8844, Accuracy: 0.6393\n",
      "Epoch [454/500], Loss: 0.8872, Accuracy: 0.6501\n",
      "Epoch [455/500], Loss: 0.8934, Accuracy: 0.6410\n",
      "Epoch [456/500], Loss: 0.8769, Accuracy: 0.6555\n",
      "Epoch [457/500], Loss: 0.8993, Accuracy: 0.6496\n",
      "Epoch [458/500], Loss: 0.9352, Accuracy: 0.6286\n",
      "Epoch [459/500], Loss: 0.9176, Accuracy: 0.6377\n",
      "Epoch [460/500], Loss: 0.8950, Accuracy: 0.6397\n",
      "Epoch [461/500], Loss: 0.8647, Accuracy: 0.6570\n",
      "Epoch [462/500], Loss: 0.8896, Accuracy: 0.6451\n",
      "Epoch [463/500], Loss: 0.9455, Accuracy: 0.6264\n",
      "Epoch [464/500], Loss: 0.8496, Accuracy: 0.6645\n",
      "Epoch [465/500], Loss: 0.8654, Accuracy: 0.6617\n",
      "Epoch [466/500], Loss: 0.8651, Accuracy: 0.6531\n",
      "Epoch [467/500], Loss: 0.8669, Accuracy: 0.6538\n",
      "Epoch [468/500], Loss: 0.8637, Accuracy: 0.6498\n",
      "Epoch [469/500], Loss: 0.8704, Accuracy: 0.6523\n",
      "Epoch [470/500], Loss: 0.8680, Accuracy: 0.6521\n",
      "Epoch [471/500], Loss: 0.8759, Accuracy: 0.6509\n",
      "Epoch [472/500], Loss: 0.8852, Accuracy: 0.6451\n",
      "Epoch [473/500], Loss: 0.9000, Accuracy: 0.6487\n",
      "Epoch [474/500], Loss: 1.0469, Accuracy: 0.5861\n",
      "Epoch [475/500], Loss: 0.8853, Accuracy: 0.6434\n",
      "Epoch [476/500], Loss: 0.8813, Accuracy: 0.6481\n",
      "Epoch [477/500], Loss: 0.9786, Accuracy: 0.6125\n",
      "Epoch [478/500], Loss: 0.8574, Accuracy: 0.6577\n",
      "Epoch [479/500], Loss: 0.8796, Accuracy: 0.6464\n",
      "Epoch [480/500], Loss: 0.8843, Accuracy: 0.6459\n",
      "Epoch [481/500], Loss: 0.8959, Accuracy: 0.6454\n",
      "Epoch [482/500], Loss: 0.8606, Accuracy: 0.6558\n",
      "Epoch [483/500], Loss: 0.8655, Accuracy: 0.6533\n",
      "Epoch [484/500], Loss: 0.8538, Accuracy: 0.6625\n",
      "Epoch [485/500], Loss: 0.8753, Accuracy: 0.6533\n",
      "Epoch [486/500], Loss: 0.8697, Accuracy: 0.6545\n",
      "Epoch [487/500], Loss: 0.8669, Accuracy: 0.6546\n",
      "Epoch [488/500], Loss: 0.8868, Accuracy: 0.6513\n",
      "Epoch [489/500], Loss: 0.8821, Accuracy: 0.6521\n",
      "Epoch [490/500], Loss: 0.8495, Accuracy: 0.6640\n",
      "Epoch [491/500], Loss: 0.8538, Accuracy: 0.6607\n",
      "Epoch [492/500], Loss: 0.8687, Accuracy: 0.6597\n",
      "Epoch [493/500], Loss: 0.8806, Accuracy: 0.6494\n",
      "Epoch [494/500], Loss: 0.8682, Accuracy: 0.6528\n",
      "Epoch [495/500], Loss: 0.8753, Accuracy: 0.6528\n",
      "Epoch [496/500], Loss: 0.8831, Accuracy: 0.6459\n",
      "Epoch [497/500], Loss: 0.8941, Accuracy: 0.6471\n",
      "Epoch [498/500], Loss: 0.8778, Accuracy: 0.6553\n",
      "Epoch [499/500], Loss: 0.8897, Accuracy: 0.6437\n",
      "Epoch [500/500], Loss: 0.8781, Accuracy: 0.6518\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network with Attention\n",
    "cnn_atn_model = CNNAttention(input_size[0],num_classes).to(device)\n",
    "optimizer = optim.Adam(cnn_atn_model.parameters(), lr=0.001)\n",
    "train(cnn_atn_model, train_loaderCNN, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para teste\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n",
    "\n",
    "    test_loss = running_loss / len(test_loader)\n",
    "    test_accuracy = correct / total\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SimpleDNN:\n",
      "Test Loss: 1.4043, Test Accuracy: 0.4332\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing SimpleDNN:\")\n",
    "test(sdnn_model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing LSTMModel:\n",
      "Test Loss: 2.1206, Test Accuracy: 0.4043\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting LSTMModel:\")\n",
    "test(lstm_model, test_loaderLSTM, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing LSTMAttention:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.2299, Test Accuracy: 0.4063\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting LSTMAttention:\")\n",
    "test(lstm_atn_model, test_loaderLSTM, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing CNNModel:\n",
      "Test Loss: 1.4930, Test Accuracy: 0.4117\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting CNNModel:\")\n",
    "test(cnn_model, test_loaderCNN, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing CNNAttention:\n",
      "Test Loss: 2.1666, Test Accuracy: 0.4144\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting CNNAttention:\")\n",
    "test(cnn_atn_model, test_loaderCNN, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
