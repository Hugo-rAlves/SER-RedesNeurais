{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3718</th>\n",
       "      <td>./AudioWAV/1046_IWW_DIS_XX.wav</td>\n",
       "      <td>disgust.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>./AudioWAV/1012_WSI_HAP_XX.wav</td>\n",
       "      <td>happy.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>./AudioWAV/1012_IWW_NEU_XX.wav</td>\n",
       "      <td>neutral.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4752</th>\n",
       "      <td>./AudioWAV/1059_IEO_HAP_HI.wav</td>\n",
       "      <td>happy.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>./AudioWAV/1038_IOM_SAD_XX.wav</td>\n",
       "      <td>sad.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              speech        label\n",
       "3718  ./AudioWAV/1046_IWW_DIS_XX.wav  disgust.wav\n",
       "968   ./AudioWAV/1012_WSI_HAP_XX.wav    happy.wav\n",
       "939   ./AudioWAV/1012_IWW_NEU_XX.wav  neutral.wav\n",
       "4752  ./AudioWAV/1059_IEO_HAP_HI.wav    happy.wav\n",
       "3042  ./AudioWAV/1038_IOM_SAD_XX.wav      sad.wav"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths=[]\n",
    "labels=[]\n",
    "for filename in os.listdir('./AudioWAV'):\n",
    "    \n",
    "    paths.append('./AudioWAV/' + filename)\n",
    "    file = filename.split('.')[0]\n",
    "   \n",
    "    label = file.split('_')[2]\n",
    "    if label == 'ANG':\n",
    "        labels.append('angry.wav')\n",
    "    elif label == 'DIS':\n",
    "        labels.append('disgust.wav')\n",
    "    elif label == 'FEA':\n",
    "        labels.append('fear.wav')\n",
    "    elif label == 'HAP':\n",
    "        labels.append('happy.wav')\n",
    "    elif label == 'NEU':\n",
    "        labels.append('neutral.wav')\n",
    "    elif label == 'SAD':\n",
    "        labels.append('sad.wav')\n",
    "        \n",
    "\n",
    "df_cremad = pd.DataFrame({'speech':paths,'label':labels})\n",
    "df_cremad.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFCC(filename):\n",
    "    y, sr = librosa.load(filename,duration=3,offset=0.5)\n",
    "    return np.mean(librosa.feature.mfcc(y=y,sr=sr,n_mfcc=40).T,axis=0)\n",
    "\n",
    "mfcc_cremad = df_cremad['speech'].apply(lambda x:MFCC(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7442, 40, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X =[x for x in mfcc_cremad]\n",
    "X =np.array(X)\n",
    "X.shape\n",
    "X =np.expand_dims(X,-1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe=OneHotEncoder()\n",
    "y = ohe.fit_transform(df_cremad[['label']] )\n",
    "y = y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7442, 40, 1), (7442, 6))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry.wav', 'disgust.wav', 'fear.wav', 'happy.wav', 'neutral.wav',\n",
       "       'sad.wav'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cremad['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Definindo os modelos\n",
    "\n",
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class LSTMAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
    "        out = torch.sum(attn_weights * out, dim=1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
    "        self.fc_input_size = 32 * 1 * 1\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, self.fc_input_size)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNNAttention(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNNAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
    "        self.attention = nn.Linear(32, 1)\n",
    "        self.fc = nn.Linear(32, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        attn_weights = self.softmax(self.attention(x.permute(0, 2, 1))).squeeze(-1)\n",
    "        attn_weights = attn_weights.unsqueeze(-1)\n",
    "        x = torch.sum(attn_weights * x, dim=2)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "# Construindo e treinando os modelos\n",
    "\n",
    "input_size = X.shape[1:]\n",
    "num_classes = y.shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Convertendo os dados para tensores PyTorch\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "# Definindo o tamanho do lote\n",
    "batch_size = 32\n",
    "\n",
    "# Criando conjuntos de dados PyTorch\n",
    "dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Definindo tensor para o LSTM\n",
    "X_tensorLSTM = X_tensor.permute(0, 2, 1)\n",
    "\n",
    "# Criando conjuntos de dados PyTorch para LSTM\n",
    "datasetLSTM = torch.utils.data.TensorDataset(X_tensorLSTM, y_tensor)\n",
    "train_sizeLSTM = int(0.8 * len(datasetLSTM))\n",
    "test_sizeLSTM = len(datasetLSTM) - train_sizeLSTM\n",
    "train_datasetLSTM, test_datasetLSTM = torch.utils.data.random_split(datasetLSTM, [train_sizeLSTM, test_sizeLSTM])\n",
    "\n",
    "# DataLoader para o LSTM\n",
    "train_loaderLSTM = DataLoader(train_datasetLSTM, batch_size=batch_size, shuffle=True)\n",
    "test_loaderLSTM = DataLoader(test_datasetLSTM, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Convertendo os dados para tensores PyTorch do CNN\n",
    "X_tensorCNN = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "\n",
    "# Criando conjuntos de dados PyTorch do CNN\n",
    "datasetCNN = torch.utils.data.TensorDataset(X_tensorCNN, y_tensor)\n",
    "train_sizeCNN = int(0.8 * len(datasetCNN))\n",
    "test_sizeCNN = len(datasetCNN) - train_sizeCNN\n",
    "train_datasetCNN, test_datasetCNN = torch.utils.data.random_split(datasetCNN, [train_sizeCNN, test_sizeCNN])\n",
    "\n",
    "# DataLoader para o CNN\n",
    "train_loaderCNN = DataLoader(train_datasetCNN, batch_size=batch_size, shuffle=True)\n",
    "test_loaderCNN = DataLoader(test_datasetCNN, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Função para treinamento\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs=500):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            #print(outputs.shape)\n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        accuracy = correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 6.6548, Accuracy: 0.1697\n",
      "Epoch [2/500], Loss: 3.6167, Accuracy: 0.1678\n",
      "Epoch [3/500], Loss: 2.7739, Accuracy: 0.1663\n",
      "Epoch [4/500], Loss: 2.3615, Accuracy: 0.1757\n",
      "Epoch [5/500], Loss: 2.1861, Accuracy: 0.1705\n",
      "Epoch [6/500], Loss: 2.0788, Accuracy: 0.1722\n",
      "Epoch [7/500], Loss: 2.0399, Accuracy: 0.1698\n",
      "Epoch [8/500], Loss: 2.0074, Accuracy: 0.1660\n",
      "Epoch [9/500], Loss: 1.9552, Accuracy: 0.1779\n",
      "Epoch [10/500], Loss: 1.9438, Accuracy: 0.1646\n",
      "Epoch [11/500], Loss: 1.9134, Accuracy: 0.1744\n",
      "Epoch [12/500], Loss: 1.9107, Accuracy: 0.1692\n",
      "Epoch [13/500], Loss: 1.9018, Accuracy: 0.1640\n",
      "Epoch [14/500], Loss: 1.8810, Accuracy: 0.1660\n",
      "Epoch [15/500], Loss: 1.8778, Accuracy: 0.1713\n",
      "Epoch [16/500], Loss: 1.8693, Accuracy: 0.1745\n",
      "Epoch [17/500], Loss: 1.8697, Accuracy: 0.1737\n",
      "Epoch [18/500], Loss: 1.8527, Accuracy: 0.1697\n",
      "Epoch [19/500], Loss: 1.8488, Accuracy: 0.1789\n",
      "Epoch [20/500], Loss: 1.8393, Accuracy: 0.1762\n",
      "Epoch [21/500], Loss: 1.8511, Accuracy: 0.1744\n",
      "Epoch [22/500], Loss: 1.8363, Accuracy: 0.1708\n",
      "Epoch [23/500], Loss: 1.8600, Accuracy: 0.1740\n",
      "Epoch [24/500], Loss: 1.8381, Accuracy: 0.1698\n",
      "Epoch [25/500], Loss: 1.8442, Accuracy: 0.1715\n",
      "Epoch [26/500], Loss: 1.8390, Accuracy: 0.1688\n",
      "Epoch [27/500], Loss: 1.8341, Accuracy: 0.1693\n",
      "Epoch [28/500], Loss: 1.8312, Accuracy: 0.1698\n",
      "Epoch [29/500], Loss: 1.8195, Accuracy: 0.1735\n",
      "Epoch [30/500], Loss: 1.8291, Accuracy: 0.1668\n",
      "Epoch [31/500], Loss: 1.8285, Accuracy: 0.1722\n",
      "Epoch [32/500], Loss: 1.8217, Accuracy: 0.1727\n",
      "Epoch [33/500], Loss: 1.8233, Accuracy: 0.1671\n",
      "Epoch [34/500], Loss: 1.8218, Accuracy: 0.1735\n",
      "Epoch [35/500], Loss: 1.8168, Accuracy: 0.1717\n",
      "Epoch [36/500], Loss: 1.8189, Accuracy: 0.1776\n",
      "Epoch [37/500], Loss: 1.8260, Accuracy: 0.1700\n",
      "Epoch [38/500], Loss: 1.8199, Accuracy: 0.1739\n",
      "Epoch [39/500], Loss: 1.8175, Accuracy: 0.1690\n",
      "Epoch [40/500], Loss: 1.8155, Accuracy: 0.1727\n",
      "Epoch [41/500], Loss: 1.8160, Accuracy: 0.1713\n",
      "Epoch [42/500], Loss: 1.8147, Accuracy: 0.1744\n",
      "Epoch [43/500], Loss: 1.8155, Accuracy: 0.1710\n",
      "Epoch [44/500], Loss: 1.8159, Accuracy: 0.1660\n",
      "Epoch [45/500], Loss: 1.8135, Accuracy: 0.1722\n",
      "Epoch [46/500], Loss: 1.8107, Accuracy: 0.1755\n",
      "Epoch [47/500], Loss: 1.8081, Accuracy: 0.1745\n",
      "Epoch [48/500], Loss: 1.8134, Accuracy: 0.1671\n",
      "Epoch [49/500], Loss: 1.8079, Accuracy: 0.1725\n",
      "Epoch [50/500], Loss: 1.8096, Accuracy: 0.1712\n",
      "Epoch [51/500], Loss: 1.8101, Accuracy: 0.1703\n",
      "Epoch [52/500], Loss: 1.8062, Accuracy: 0.1725\n",
      "Epoch [53/500], Loss: 1.8094, Accuracy: 0.1688\n",
      "Epoch [54/500], Loss: 1.8152, Accuracy: 0.1675\n",
      "Epoch [55/500], Loss: 1.8110, Accuracy: 0.1713\n",
      "Epoch [56/500], Loss: 1.8100, Accuracy: 0.1685\n",
      "Epoch [57/500], Loss: 1.8027, Accuracy: 0.1745\n",
      "Epoch [58/500], Loss: 1.8105, Accuracy: 0.1705\n",
      "Epoch [59/500], Loss: 1.8135, Accuracy: 0.1693\n",
      "Epoch [60/500], Loss: 1.8071, Accuracy: 0.1715\n",
      "Epoch [61/500], Loss: 1.8029, Accuracy: 0.1739\n",
      "Epoch [62/500], Loss: 1.8014, Accuracy: 0.1700\n",
      "Epoch [63/500], Loss: 1.8059, Accuracy: 0.1698\n",
      "Epoch [64/500], Loss: 1.8052, Accuracy: 0.1734\n",
      "Epoch [65/500], Loss: 1.8079, Accuracy: 0.1755\n",
      "Epoch [66/500], Loss: 1.8049, Accuracy: 0.1666\n",
      "Epoch [67/500], Loss: 1.8028, Accuracy: 0.1724\n",
      "Epoch [68/500], Loss: 1.8035, Accuracy: 0.1715\n",
      "Epoch [69/500], Loss: 1.8026, Accuracy: 0.1762\n",
      "Epoch [70/500], Loss: 1.8070, Accuracy: 0.1685\n",
      "Epoch [71/500], Loss: 1.8045, Accuracy: 0.1710\n",
      "Epoch [72/500], Loss: 1.8044, Accuracy: 0.1717\n",
      "Epoch [73/500], Loss: 1.8058, Accuracy: 0.1707\n",
      "Epoch [74/500], Loss: 1.8026, Accuracy: 0.1708\n",
      "Epoch [75/500], Loss: 1.8035, Accuracy: 0.1717\n",
      "Epoch [76/500], Loss: 1.8026, Accuracy: 0.1727\n",
      "Epoch [77/500], Loss: 1.8048, Accuracy: 0.1718\n",
      "Epoch [78/500], Loss: 1.8004, Accuracy: 0.1757\n",
      "Epoch [79/500], Loss: 1.8001, Accuracy: 0.1712\n",
      "Epoch [80/500], Loss: 1.8057, Accuracy: 0.1678\n",
      "Epoch [81/500], Loss: 1.8010, Accuracy: 0.1747\n",
      "Epoch [82/500], Loss: 1.8011, Accuracy: 0.1737\n",
      "Epoch [83/500], Loss: 1.8050, Accuracy: 0.1703\n",
      "Epoch [84/500], Loss: 1.8050, Accuracy: 0.1707\n",
      "Epoch [85/500], Loss: 1.8016, Accuracy: 0.1712\n",
      "Epoch [86/500], Loss: 1.7993, Accuracy: 0.1729\n",
      "Epoch [87/500], Loss: 1.7980, Accuracy: 0.1750\n",
      "Epoch [88/500], Loss: 1.8050, Accuracy: 0.1703\n",
      "Epoch [89/500], Loss: 1.7997, Accuracy: 0.1729\n",
      "Epoch [90/500], Loss: 1.7999, Accuracy: 0.1722\n",
      "Epoch [91/500], Loss: 1.7976, Accuracy: 0.1732\n",
      "Epoch [92/500], Loss: 1.7956, Accuracy: 0.1772\n",
      "Epoch [93/500], Loss: 1.7979, Accuracy: 0.1693\n",
      "Epoch [94/500], Loss: 1.8000, Accuracy: 0.1712\n",
      "Epoch [95/500], Loss: 1.8002, Accuracy: 0.1737\n",
      "Epoch [96/500], Loss: 1.8007, Accuracy: 0.1735\n",
      "Epoch [97/500], Loss: 1.7980, Accuracy: 0.1774\n",
      "Epoch [98/500], Loss: 1.7958, Accuracy: 0.1760\n",
      "Epoch [99/500], Loss: 1.7993, Accuracy: 0.1705\n",
      "Epoch [100/500], Loss: 1.7969, Accuracy: 0.1690\n",
      "Epoch [101/500], Loss: 1.8002, Accuracy: 0.1708\n",
      "Epoch [102/500], Loss: 1.7992, Accuracy: 0.1715\n",
      "Epoch [103/500], Loss: 1.7988, Accuracy: 0.1777\n",
      "Epoch [104/500], Loss: 1.7977, Accuracy: 0.1720\n",
      "Epoch [105/500], Loss: 1.8020, Accuracy: 0.1712\n",
      "Epoch [106/500], Loss: 1.7992, Accuracy: 0.1729\n",
      "Epoch [107/500], Loss: 1.7981, Accuracy: 0.1693\n",
      "Epoch [108/500], Loss: 1.7996, Accuracy: 0.1713\n",
      "Epoch [109/500], Loss: 1.7953, Accuracy: 0.1742\n",
      "Epoch [110/500], Loss: 1.7989, Accuracy: 0.1724\n",
      "Epoch [111/500], Loss: 1.8026, Accuracy: 0.1747\n",
      "Epoch [112/500], Loss: 1.8002, Accuracy: 0.1710\n",
      "Epoch [113/500], Loss: 1.7978, Accuracy: 0.1732\n",
      "Epoch [114/500], Loss: 1.8007, Accuracy: 0.1735\n",
      "Epoch [115/500], Loss: 1.7969, Accuracy: 0.1713\n",
      "Epoch [116/500], Loss: 1.7951, Accuracy: 0.1755\n",
      "Epoch [117/500], Loss: 1.7975, Accuracy: 0.1713\n",
      "Epoch [118/500], Loss: 1.8016, Accuracy: 0.1718\n",
      "Epoch [119/500], Loss: 1.8001, Accuracy: 0.1759\n",
      "Epoch [120/500], Loss: 1.7973, Accuracy: 0.1739\n",
      "Epoch [121/500], Loss: 1.7951, Accuracy: 0.1732\n",
      "Epoch [122/500], Loss: 1.8003, Accuracy: 0.1724\n",
      "Epoch [123/500], Loss: 1.7998, Accuracy: 0.1722\n",
      "Epoch [124/500], Loss: 1.7989, Accuracy: 0.1742\n",
      "Epoch [125/500], Loss: 1.7949, Accuracy: 0.1697\n",
      "Epoch [126/500], Loss: 1.7960, Accuracy: 0.1739\n",
      "Epoch [127/500], Loss: 1.7995, Accuracy: 0.1710\n",
      "Epoch [128/500], Loss: 1.7941, Accuracy: 0.1722\n",
      "Epoch [129/500], Loss: 1.8000, Accuracy: 0.1725\n",
      "Epoch [130/500], Loss: 1.7972, Accuracy: 0.1708\n",
      "Epoch [131/500], Loss: 1.7949, Accuracy: 0.1720\n",
      "Epoch [132/500], Loss: 1.7999, Accuracy: 0.1732\n",
      "Epoch [133/500], Loss: 1.7931, Accuracy: 0.1749\n",
      "Epoch [134/500], Loss: 1.7964, Accuracy: 0.1722\n",
      "Epoch [135/500], Loss: 1.7957, Accuracy: 0.1724\n",
      "Epoch [136/500], Loss: 1.7976, Accuracy: 0.1752\n",
      "Epoch [137/500], Loss: 1.7992, Accuracy: 0.1693\n",
      "Epoch [138/500], Loss: 1.7965, Accuracy: 0.1745\n",
      "Epoch [139/500], Loss: 1.7953, Accuracy: 0.1718\n",
      "Epoch [140/500], Loss: 1.7962, Accuracy: 0.1744\n",
      "Epoch [141/500], Loss: 1.7973, Accuracy: 0.1730\n",
      "Epoch [142/500], Loss: 1.7938, Accuracy: 0.1720\n",
      "Epoch [143/500], Loss: 1.7950, Accuracy: 0.1749\n",
      "Epoch [144/500], Loss: 1.7970, Accuracy: 0.1734\n",
      "Epoch [145/500], Loss: 1.7985, Accuracy: 0.1712\n",
      "Epoch [146/500], Loss: 1.7977, Accuracy: 0.1708\n",
      "Epoch [147/500], Loss: 1.7973, Accuracy: 0.1712\n",
      "Epoch [148/500], Loss: 1.8007, Accuracy: 0.1720\n",
      "Epoch [149/500], Loss: 1.7979, Accuracy: 0.1715\n",
      "Epoch [150/500], Loss: 1.7962, Accuracy: 0.1742\n",
      "Epoch [151/500], Loss: 1.7969, Accuracy: 0.1703\n",
      "Epoch [152/500], Loss: 1.7949, Accuracy: 0.1732\n",
      "Epoch [153/500], Loss: 1.7972, Accuracy: 0.1725\n",
      "Epoch [154/500], Loss: 1.7939, Accuracy: 0.1737\n",
      "Epoch [155/500], Loss: 1.7955, Accuracy: 0.1727\n",
      "Epoch [156/500], Loss: 1.7974, Accuracy: 0.1713\n",
      "Epoch [157/500], Loss: 1.7966, Accuracy: 0.1722\n",
      "Epoch [158/500], Loss: 1.7947, Accuracy: 0.1749\n",
      "Epoch [159/500], Loss: 1.7965, Accuracy: 0.1737\n",
      "Epoch [160/500], Loss: 1.7951, Accuracy: 0.1718\n",
      "Epoch [161/500], Loss: 1.7954, Accuracy: 0.1740\n",
      "Epoch [162/500], Loss: 1.7959, Accuracy: 0.1712\n",
      "Epoch [163/500], Loss: 1.7949, Accuracy: 0.1762\n",
      "Epoch [164/500], Loss: 1.7980, Accuracy: 0.1718\n",
      "Epoch [165/500], Loss: 1.7965, Accuracy: 0.1745\n",
      "Epoch [166/500], Loss: 1.7952, Accuracy: 0.1717\n",
      "Epoch [167/500], Loss: 1.7955, Accuracy: 0.1724\n",
      "Epoch [168/500], Loss: 1.7954, Accuracy: 0.1715\n",
      "Epoch [169/500], Loss: 1.7938, Accuracy: 0.1750\n",
      "Epoch [170/500], Loss: 1.8002, Accuracy: 0.1724\n",
      "Epoch [171/500], Loss: 1.7962, Accuracy: 0.1697\n",
      "Epoch [172/500], Loss: 1.7936, Accuracy: 0.1722\n",
      "Epoch [173/500], Loss: 1.7933, Accuracy: 0.1718\n",
      "Epoch [174/500], Loss: 1.7963, Accuracy: 0.1708\n",
      "Epoch [175/500], Loss: 1.7958, Accuracy: 0.1713\n",
      "Epoch [176/500], Loss: 1.7954, Accuracy: 0.1724\n",
      "Epoch [177/500], Loss: 1.7950, Accuracy: 0.1727\n",
      "Epoch [178/500], Loss: 1.7951, Accuracy: 0.1727\n",
      "Epoch [179/500], Loss: 1.7949, Accuracy: 0.1735\n",
      "Epoch [180/500], Loss: 1.7953, Accuracy: 0.1732\n",
      "Epoch [181/500], Loss: 1.7952, Accuracy: 0.1745\n",
      "Epoch [182/500], Loss: 1.7917, Accuracy: 0.1740\n",
      "Epoch [183/500], Loss: 1.7967, Accuracy: 0.1712\n",
      "Epoch [184/500], Loss: 1.7944, Accuracy: 0.1732\n",
      "Epoch [185/500], Loss: 1.7935, Accuracy: 0.1760\n",
      "Epoch [186/500], Loss: 1.7947, Accuracy: 0.1757\n",
      "Epoch [187/500], Loss: 1.7959, Accuracy: 0.1759\n",
      "Epoch [188/500], Loss: 1.7944, Accuracy: 0.1729\n",
      "Epoch [189/500], Loss: 1.7934, Accuracy: 0.1755\n",
      "Epoch [190/500], Loss: 1.7932, Accuracy: 0.1703\n",
      "Epoch [191/500], Loss: 1.7961, Accuracy: 0.1717\n",
      "Epoch [192/500], Loss: 1.7956, Accuracy: 0.1729\n",
      "Epoch [193/500], Loss: 1.7945, Accuracy: 0.1720\n",
      "Epoch [194/500], Loss: 1.7940, Accuracy: 0.1727\n",
      "Epoch [195/500], Loss: 1.7938, Accuracy: 0.1737\n",
      "Epoch [196/500], Loss: 1.7947, Accuracy: 0.1735\n",
      "Epoch [197/500], Loss: 1.7951, Accuracy: 0.1730\n",
      "Epoch [198/500], Loss: 1.7917, Accuracy: 0.1720\n",
      "Epoch [199/500], Loss: 1.7937, Accuracy: 0.1734\n",
      "Epoch [200/500], Loss: 1.7945, Accuracy: 0.1752\n",
      "Epoch [201/500], Loss: 1.7955, Accuracy: 0.1740\n",
      "Epoch [202/500], Loss: 1.7916, Accuracy: 0.1727\n",
      "Epoch [203/500], Loss: 1.7938, Accuracy: 0.1752\n",
      "Epoch [204/500], Loss: 1.7930, Accuracy: 0.1740\n",
      "Epoch [205/500], Loss: 1.7926, Accuracy: 0.1729\n",
      "Epoch [206/500], Loss: 1.7933, Accuracy: 0.1750\n",
      "Epoch [207/500], Loss: 1.7936, Accuracy: 0.1792\n",
      "Epoch [208/500], Loss: 1.7944, Accuracy: 0.1734\n",
      "Epoch [209/500], Loss: 1.7920, Accuracy: 0.1739\n",
      "Epoch [210/500], Loss: 1.7977, Accuracy: 0.1718\n",
      "Epoch [211/500], Loss: 1.7967, Accuracy: 0.1747\n",
      "Epoch [212/500], Loss: 1.7917, Accuracy: 0.1754\n",
      "Epoch [213/500], Loss: 1.7921, Accuracy: 0.1742\n",
      "Epoch [214/500], Loss: 1.7950, Accuracy: 0.1717\n",
      "Epoch [215/500], Loss: 1.7972, Accuracy: 0.1735\n",
      "Epoch [216/500], Loss: 1.7912, Accuracy: 0.1730\n",
      "Epoch [217/500], Loss: 1.7929, Accuracy: 0.1725\n",
      "Epoch [218/500], Loss: 1.7926, Accuracy: 0.1734\n",
      "Epoch [219/500], Loss: 1.7925, Accuracy: 0.1774\n",
      "Epoch [220/500], Loss: 1.7940, Accuracy: 0.1764\n",
      "Epoch [221/500], Loss: 1.7921, Accuracy: 0.1750\n",
      "Epoch [222/500], Loss: 1.7924, Accuracy: 0.1757\n",
      "Epoch [223/500], Loss: 1.7938, Accuracy: 0.1752\n",
      "Epoch [224/500], Loss: 1.7947, Accuracy: 0.1757\n",
      "Epoch [225/500], Loss: 1.7925, Accuracy: 0.1745\n",
      "Epoch [226/500], Loss: 1.7924, Accuracy: 0.1749\n",
      "Epoch [227/500], Loss: 1.7957, Accuracy: 0.1715\n",
      "Epoch [228/500], Loss: 1.7968, Accuracy: 0.1727\n",
      "Epoch [229/500], Loss: 1.7949, Accuracy: 0.1752\n",
      "Epoch [230/500], Loss: 1.7935, Accuracy: 0.1752\n",
      "Epoch [231/500], Loss: 1.7902, Accuracy: 0.1765\n",
      "Epoch [232/500], Loss: 1.7909, Accuracy: 0.1759\n",
      "Epoch [233/500], Loss: 1.7916, Accuracy: 0.1772\n",
      "Epoch [234/500], Loss: 1.7927, Accuracy: 0.1772\n",
      "Epoch [235/500], Loss: 1.7933, Accuracy: 0.1781\n",
      "Epoch [236/500], Loss: 1.7935, Accuracy: 0.1750\n",
      "Epoch [237/500], Loss: 1.7920, Accuracy: 0.1786\n",
      "Epoch [238/500], Loss: 1.7914, Accuracy: 0.1791\n",
      "Epoch [239/500], Loss: 1.7906, Accuracy: 0.1789\n",
      "Epoch [240/500], Loss: 1.7914, Accuracy: 0.1752\n",
      "Epoch [241/500], Loss: 1.7929, Accuracy: 0.1765\n",
      "Epoch [242/500], Loss: 1.7908, Accuracy: 0.1796\n",
      "Epoch [243/500], Loss: 1.7921, Accuracy: 0.1765\n",
      "Epoch [244/500], Loss: 1.7884, Accuracy: 0.1792\n",
      "Epoch [245/500], Loss: 1.7887, Accuracy: 0.1792\n",
      "Epoch [246/500], Loss: 1.7930, Accuracy: 0.1739\n",
      "Epoch [247/500], Loss: 1.7921, Accuracy: 0.1765\n",
      "Epoch [248/500], Loss: 1.7901, Accuracy: 0.1774\n",
      "Epoch [249/500], Loss: 1.7900, Accuracy: 0.1781\n",
      "Epoch [250/500], Loss: 1.7899, Accuracy: 0.1735\n",
      "Epoch [251/500], Loss: 1.7901, Accuracy: 0.1784\n",
      "Epoch [252/500], Loss: 1.7894, Accuracy: 0.1809\n",
      "Epoch [253/500], Loss: 1.7905, Accuracy: 0.1782\n",
      "Epoch [254/500], Loss: 1.7902, Accuracy: 0.1769\n",
      "Epoch [255/500], Loss: 1.7891, Accuracy: 0.1804\n",
      "Epoch [256/500], Loss: 1.7872, Accuracy: 0.1789\n",
      "Epoch [257/500], Loss: 1.7890, Accuracy: 0.1816\n",
      "Epoch [258/500], Loss: 1.7907, Accuracy: 0.1799\n",
      "Epoch [259/500], Loss: 1.7902, Accuracy: 0.1776\n",
      "Epoch [260/500], Loss: 1.7880, Accuracy: 0.1801\n",
      "Epoch [261/500], Loss: 1.7912, Accuracy: 0.1804\n",
      "Epoch [262/500], Loss: 1.7894, Accuracy: 0.1792\n",
      "Epoch [263/500], Loss: 1.7910, Accuracy: 0.1792\n",
      "Epoch [264/500], Loss: 1.7900, Accuracy: 0.1789\n",
      "Epoch [265/500], Loss: 1.7891, Accuracy: 0.1781\n",
      "Epoch [266/500], Loss: 1.7910, Accuracy: 0.1786\n",
      "Epoch [267/500], Loss: 1.7881, Accuracy: 0.1760\n",
      "Epoch [268/500], Loss: 1.7898, Accuracy: 0.1814\n",
      "Epoch [269/500], Loss: 1.7864, Accuracy: 0.1797\n",
      "Epoch [270/500], Loss: 1.7876, Accuracy: 0.1807\n",
      "Epoch [271/500], Loss: 1.7915, Accuracy: 0.1781\n",
      "Epoch [272/500], Loss: 1.7849, Accuracy: 0.1829\n",
      "Epoch [273/500], Loss: 1.7892, Accuracy: 0.1848\n",
      "Epoch [274/500], Loss: 1.7840, Accuracy: 0.1824\n",
      "Epoch [275/500], Loss: 1.7916, Accuracy: 0.1831\n",
      "Epoch [276/500], Loss: 1.7864, Accuracy: 0.1836\n",
      "Epoch [277/500], Loss: 1.7879, Accuracy: 0.1823\n",
      "Epoch [278/500], Loss: 1.7867, Accuracy: 0.1791\n",
      "Epoch [279/500], Loss: 1.7864, Accuracy: 0.1806\n",
      "Epoch [280/500], Loss: 1.7888, Accuracy: 0.1818\n",
      "Epoch [281/500], Loss: 1.7865, Accuracy: 0.1781\n",
      "Epoch [282/500], Loss: 1.7869, Accuracy: 0.1802\n",
      "Epoch [283/500], Loss: 1.7861, Accuracy: 0.1848\n",
      "Epoch [284/500], Loss: 1.7829, Accuracy: 0.1870\n",
      "Epoch [285/500], Loss: 1.7862, Accuracy: 0.1799\n",
      "Epoch [286/500], Loss: 1.7861, Accuracy: 0.1828\n",
      "Epoch [287/500], Loss: 1.7822, Accuracy: 0.1851\n",
      "Epoch [288/500], Loss: 1.7860, Accuracy: 0.1781\n",
      "Epoch [289/500], Loss: 1.7840, Accuracy: 0.1848\n",
      "Epoch [290/500], Loss: 1.7849, Accuracy: 0.1863\n",
      "Epoch [291/500], Loss: 1.7853, Accuracy: 0.1831\n",
      "Epoch [292/500], Loss: 1.7831, Accuracy: 0.1849\n",
      "Epoch [293/500], Loss: 1.7818, Accuracy: 0.1844\n",
      "Epoch [294/500], Loss: 1.7851, Accuracy: 0.1834\n",
      "Epoch [295/500], Loss: 1.7826, Accuracy: 0.1849\n",
      "Epoch [296/500], Loss: 1.7816, Accuracy: 0.1870\n",
      "Epoch [297/500], Loss: 1.7842, Accuracy: 0.1858\n",
      "Epoch [298/500], Loss: 1.7840, Accuracy: 0.1848\n",
      "Epoch [299/500], Loss: 1.7865, Accuracy: 0.1841\n",
      "Epoch [300/500], Loss: 1.7829, Accuracy: 0.1819\n",
      "Epoch [301/500], Loss: 1.7854, Accuracy: 0.1807\n",
      "Epoch [302/500], Loss: 1.7827, Accuracy: 0.1838\n",
      "Epoch [303/500], Loss: 1.7819, Accuracy: 0.1870\n",
      "Epoch [304/500], Loss: 1.7782, Accuracy: 0.1819\n",
      "Epoch [305/500], Loss: 1.7807, Accuracy: 0.1821\n",
      "Epoch [306/500], Loss: 1.7809, Accuracy: 0.1816\n",
      "Epoch [307/500], Loss: 1.7767, Accuracy: 0.1895\n",
      "Epoch [308/500], Loss: 1.7804, Accuracy: 0.1833\n",
      "Epoch [309/500], Loss: 1.7829, Accuracy: 0.1888\n",
      "Epoch [310/500], Loss: 1.7816, Accuracy: 0.1813\n",
      "Epoch [311/500], Loss: 1.7790, Accuracy: 0.1880\n",
      "Epoch [312/500], Loss: 1.7800, Accuracy: 0.1868\n",
      "Epoch [313/500], Loss: 1.7798, Accuracy: 0.1861\n",
      "Epoch [314/500], Loss: 1.7799, Accuracy: 0.1871\n",
      "Epoch [315/500], Loss: 1.7780, Accuracy: 0.1843\n",
      "Epoch [316/500], Loss: 1.7762, Accuracy: 0.1856\n",
      "Epoch [317/500], Loss: 1.7791, Accuracy: 0.1834\n",
      "Epoch [318/500], Loss: 1.7755, Accuracy: 0.1871\n",
      "Epoch [319/500], Loss: 1.7781, Accuracy: 0.1861\n",
      "Epoch [320/500], Loss: 1.7787, Accuracy: 0.1843\n",
      "Epoch [321/500], Loss: 1.7785, Accuracy: 0.1843\n",
      "Epoch [322/500], Loss: 1.7757, Accuracy: 0.1829\n",
      "Epoch [323/500], Loss: 1.7771, Accuracy: 0.1849\n",
      "Epoch [324/500], Loss: 1.7797, Accuracy: 0.1839\n",
      "Epoch [325/500], Loss: 1.7784, Accuracy: 0.1823\n",
      "Epoch [326/500], Loss: 1.7721, Accuracy: 0.1903\n",
      "Epoch [327/500], Loss: 1.7774, Accuracy: 0.1863\n",
      "Epoch [328/500], Loss: 1.7793, Accuracy: 0.1898\n",
      "Epoch [329/500], Loss: 1.7784, Accuracy: 0.1863\n",
      "Epoch [330/500], Loss: 1.7743, Accuracy: 0.1897\n",
      "Epoch [331/500], Loss: 1.7750, Accuracy: 0.1858\n",
      "Epoch [332/500], Loss: 1.7791, Accuracy: 0.1871\n",
      "Epoch [333/500], Loss: 1.7776, Accuracy: 0.1878\n",
      "Epoch [334/500], Loss: 1.7765, Accuracy: 0.1868\n",
      "Epoch [335/500], Loss: 1.7769, Accuracy: 0.1858\n",
      "Epoch [336/500], Loss: 1.7763, Accuracy: 0.1871\n",
      "Epoch [337/500], Loss: 1.7751, Accuracy: 0.1878\n",
      "Epoch [338/500], Loss: 1.7751, Accuracy: 0.1838\n",
      "Epoch [339/500], Loss: 1.7707, Accuracy: 0.1903\n",
      "Epoch [340/500], Loss: 1.7726, Accuracy: 0.1849\n",
      "Epoch [341/500], Loss: 1.7748, Accuracy: 0.1890\n",
      "Epoch [342/500], Loss: 1.7733, Accuracy: 0.1878\n",
      "Epoch [343/500], Loss: 1.7745, Accuracy: 0.1856\n",
      "Epoch [344/500], Loss: 1.7723, Accuracy: 0.1863\n",
      "Epoch [345/500], Loss: 1.7726, Accuracy: 0.1883\n",
      "Epoch [346/500], Loss: 1.7707, Accuracy: 0.1863\n",
      "Epoch [347/500], Loss: 1.7724, Accuracy: 0.1954\n",
      "Epoch [348/500], Loss: 1.7655, Accuracy: 0.1944\n",
      "Epoch [349/500], Loss: 1.7758, Accuracy: 0.1898\n",
      "Epoch [350/500], Loss: 1.7759, Accuracy: 0.1917\n",
      "Epoch [351/500], Loss: 1.7713, Accuracy: 0.1839\n",
      "Epoch [352/500], Loss: 1.7688, Accuracy: 0.1912\n",
      "Epoch [353/500], Loss: 1.7715, Accuracy: 0.1880\n",
      "Epoch [354/500], Loss: 1.7745, Accuracy: 0.1888\n",
      "Epoch [355/500], Loss: 1.7681, Accuracy: 0.1930\n",
      "Epoch [356/500], Loss: 1.7672, Accuracy: 0.1918\n",
      "Epoch [357/500], Loss: 1.7671, Accuracy: 0.1925\n",
      "Epoch [358/500], Loss: 1.7705, Accuracy: 0.1902\n",
      "Epoch [359/500], Loss: 1.7694, Accuracy: 0.1868\n",
      "Epoch [360/500], Loss: 1.7720, Accuracy: 0.1843\n",
      "Epoch [361/500], Loss: 1.7657, Accuracy: 0.1937\n",
      "Epoch [362/500], Loss: 1.7710, Accuracy: 0.1888\n",
      "Epoch [363/500], Loss: 1.7745, Accuracy: 0.1849\n",
      "Epoch [364/500], Loss: 1.7654, Accuracy: 0.1890\n",
      "Epoch [365/500], Loss: 1.7721, Accuracy: 0.1875\n",
      "Epoch [366/500], Loss: 1.7663, Accuracy: 0.1925\n",
      "Epoch [367/500], Loss: 1.7700, Accuracy: 0.1870\n",
      "Epoch [368/500], Loss: 1.7673, Accuracy: 0.1922\n",
      "Epoch [369/500], Loss: 1.7704, Accuracy: 0.1928\n",
      "Epoch [370/500], Loss: 1.7721, Accuracy: 0.1878\n",
      "Epoch [371/500], Loss: 1.7674, Accuracy: 0.1893\n",
      "Epoch [372/500], Loss: 1.7677, Accuracy: 0.1918\n",
      "Epoch [373/500], Loss: 1.7649, Accuracy: 0.1932\n",
      "Epoch [374/500], Loss: 1.7649, Accuracy: 0.1863\n",
      "Epoch [375/500], Loss: 1.7676, Accuracy: 0.1917\n",
      "Epoch [376/500], Loss: 1.7674, Accuracy: 0.1865\n",
      "Epoch [377/500], Loss: 1.7665, Accuracy: 0.1897\n",
      "Epoch [378/500], Loss: 1.7673, Accuracy: 0.1834\n",
      "Epoch [379/500], Loss: 1.7690, Accuracy: 0.1883\n",
      "Epoch [380/500], Loss: 1.7692, Accuracy: 0.1871\n",
      "Epoch [381/500], Loss: 1.7646, Accuracy: 0.1870\n",
      "Epoch [382/500], Loss: 1.7573, Accuracy: 0.1920\n",
      "Epoch [383/500], Loss: 1.7654, Accuracy: 0.1858\n",
      "Epoch [384/500], Loss: 1.7696, Accuracy: 0.1898\n",
      "Epoch [385/500], Loss: 1.7654, Accuracy: 0.1871\n",
      "Epoch [386/500], Loss: 1.7644, Accuracy: 0.1883\n",
      "Epoch [387/500], Loss: 1.7647, Accuracy: 0.1937\n",
      "Epoch [388/500], Loss: 1.7697, Accuracy: 0.1910\n",
      "Epoch [389/500], Loss: 1.7632, Accuracy: 0.1970\n",
      "Epoch [390/500], Loss: 1.7655, Accuracy: 0.1851\n",
      "Epoch [391/500], Loss: 1.7655, Accuracy: 0.1898\n",
      "Epoch [392/500], Loss: 1.7618, Accuracy: 0.1895\n",
      "Epoch [393/500], Loss: 1.7626, Accuracy: 0.1908\n",
      "Epoch [394/500], Loss: 1.7640, Accuracy: 0.1935\n",
      "Epoch [395/500], Loss: 1.7650, Accuracy: 0.1895\n",
      "Epoch [396/500], Loss: 1.7618, Accuracy: 0.1944\n",
      "Epoch [397/500], Loss: 1.7626, Accuracy: 0.1925\n",
      "Epoch [398/500], Loss: 1.7628, Accuracy: 0.1927\n",
      "Epoch [399/500], Loss: 1.7615, Accuracy: 0.1883\n",
      "Epoch [400/500], Loss: 1.7704, Accuracy: 0.1863\n",
      "Epoch [401/500], Loss: 1.7624, Accuracy: 0.1903\n",
      "Epoch [402/500], Loss: 1.7620, Accuracy: 0.1964\n",
      "Epoch [403/500], Loss: 1.7637, Accuracy: 0.1880\n",
      "Epoch [404/500], Loss: 1.7617, Accuracy: 0.1928\n",
      "Epoch [405/500], Loss: 1.7630, Accuracy: 0.1898\n",
      "Epoch [406/500], Loss: 1.7638, Accuracy: 0.1876\n",
      "Epoch [407/500], Loss: 1.7622, Accuracy: 0.1920\n",
      "Epoch [408/500], Loss: 1.7643, Accuracy: 0.1898\n",
      "Epoch [409/500], Loss: 1.7623, Accuracy: 0.1870\n",
      "Epoch [410/500], Loss: 1.7592, Accuracy: 0.1933\n",
      "Epoch [411/500], Loss: 1.7648, Accuracy: 0.1870\n",
      "Epoch [412/500], Loss: 1.7617, Accuracy: 0.1942\n",
      "Epoch [413/500], Loss: 1.7585, Accuracy: 0.1925\n",
      "Epoch [414/500], Loss: 1.7618, Accuracy: 0.1902\n",
      "Epoch [415/500], Loss: 1.7623, Accuracy: 0.1860\n",
      "Epoch [416/500], Loss: 1.7587, Accuracy: 0.1960\n",
      "Epoch [417/500], Loss: 1.7601, Accuracy: 0.1900\n",
      "Epoch [418/500], Loss: 1.7597, Accuracy: 0.1893\n",
      "Epoch [419/500], Loss: 1.7573, Accuracy: 0.1957\n",
      "Epoch [420/500], Loss: 1.7585, Accuracy: 0.1930\n",
      "Epoch [421/500], Loss: 1.7642, Accuracy: 0.1839\n",
      "Epoch [422/500], Loss: 1.7614, Accuracy: 0.1878\n",
      "Epoch [423/500], Loss: 1.7591, Accuracy: 0.1883\n",
      "Epoch [424/500], Loss: 1.7563, Accuracy: 0.1912\n",
      "Epoch [425/500], Loss: 1.7628, Accuracy: 0.1890\n",
      "Epoch [426/500], Loss: 1.7612, Accuracy: 0.1910\n",
      "Epoch [427/500], Loss: 1.7607, Accuracy: 0.1942\n",
      "Epoch [428/500], Loss: 1.7568, Accuracy: 0.1922\n",
      "Epoch [429/500], Loss: 1.7599, Accuracy: 0.1937\n",
      "Epoch [430/500], Loss: 1.7579, Accuracy: 0.1905\n",
      "Epoch [431/500], Loss: 1.7589, Accuracy: 0.1895\n",
      "Epoch [432/500], Loss: 1.7586, Accuracy: 0.1927\n",
      "Epoch [433/500], Loss: 1.7599, Accuracy: 0.1866\n",
      "Epoch [434/500], Loss: 1.7555, Accuracy: 0.1900\n",
      "Epoch [435/500], Loss: 1.7568, Accuracy: 0.1927\n",
      "Epoch [436/500], Loss: 1.7566, Accuracy: 0.1922\n",
      "Epoch [437/500], Loss: 1.7602, Accuracy: 0.1891\n",
      "Epoch [438/500], Loss: 1.7530, Accuracy: 0.1960\n",
      "Epoch [439/500], Loss: 1.7555, Accuracy: 0.1905\n",
      "Epoch [440/500], Loss: 1.7591, Accuracy: 0.1922\n",
      "Epoch [441/500], Loss: 1.7519, Accuracy: 0.1944\n",
      "Epoch [442/500], Loss: 1.7631, Accuracy: 0.1982\n",
      "Epoch [443/500], Loss: 1.7558, Accuracy: 0.1925\n",
      "Epoch [444/500], Loss: 1.7574, Accuracy: 0.1895\n",
      "Epoch [445/500], Loss: 1.7475, Accuracy: 0.1960\n",
      "Epoch [446/500], Loss: 1.7553, Accuracy: 0.1940\n",
      "Epoch [447/500], Loss: 1.7590, Accuracy: 0.1868\n",
      "Epoch [448/500], Loss: 1.7533, Accuracy: 0.1947\n",
      "Epoch [449/500], Loss: 1.7551, Accuracy: 0.1915\n",
      "Epoch [450/500], Loss: 1.7518, Accuracy: 0.1964\n",
      "Epoch [451/500], Loss: 1.7602, Accuracy: 0.1918\n",
      "Epoch [452/500], Loss: 1.7549, Accuracy: 0.1905\n",
      "Epoch [453/500], Loss: 1.7524, Accuracy: 0.1907\n",
      "Epoch [454/500], Loss: 1.7637, Accuracy: 0.1885\n",
      "Epoch [455/500], Loss: 1.7556, Accuracy: 0.1871\n",
      "Epoch [456/500], Loss: 1.7538, Accuracy: 0.1991\n",
      "Epoch [457/500], Loss: 1.7513, Accuracy: 0.1989\n",
      "Epoch [458/500], Loss: 1.7560, Accuracy: 0.1898\n",
      "Epoch [459/500], Loss: 1.7577, Accuracy: 0.1886\n",
      "Epoch [460/500], Loss: 1.7567, Accuracy: 0.1920\n",
      "Epoch [461/500], Loss: 1.7533, Accuracy: 0.1945\n",
      "Epoch [462/500], Loss: 1.7553, Accuracy: 0.1844\n",
      "Epoch [463/500], Loss: 1.7576, Accuracy: 0.1965\n",
      "Epoch [464/500], Loss: 1.7546, Accuracy: 0.1915\n",
      "Epoch [465/500], Loss: 1.7502, Accuracy: 0.1937\n",
      "Epoch [466/500], Loss: 1.7548, Accuracy: 0.1893\n",
      "Epoch [467/500], Loss: 1.7543, Accuracy: 0.1959\n",
      "Epoch [468/500], Loss: 1.7480, Accuracy: 0.1979\n",
      "Epoch [469/500], Loss: 1.7554, Accuracy: 0.1902\n",
      "Epoch [470/500], Loss: 1.7601, Accuracy: 0.1915\n",
      "Epoch [471/500], Loss: 1.7503, Accuracy: 0.1969\n",
      "Epoch [472/500], Loss: 1.7540, Accuracy: 0.1898\n",
      "Epoch [473/500], Loss: 1.7509, Accuracy: 0.1935\n",
      "Epoch [474/500], Loss: 1.7549, Accuracy: 0.1871\n",
      "Epoch [475/500], Loss: 1.7541, Accuracy: 0.1871\n",
      "Epoch [476/500], Loss: 1.7550, Accuracy: 0.1964\n",
      "Epoch [477/500], Loss: 1.7538, Accuracy: 0.1920\n",
      "Epoch [478/500], Loss: 1.7560, Accuracy: 0.1900\n",
      "Epoch [479/500], Loss: 1.7551, Accuracy: 0.1913\n",
      "Epoch [480/500], Loss: 1.7515, Accuracy: 0.1935\n",
      "Epoch [481/500], Loss: 1.7531, Accuracy: 0.1933\n",
      "Epoch [482/500], Loss: 1.7498, Accuracy: 0.1915\n",
      "Epoch [483/500], Loss: 1.7565, Accuracy: 0.1897\n",
      "Epoch [484/500], Loss: 1.7524, Accuracy: 0.1860\n",
      "Epoch [485/500], Loss: 1.7541, Accuracy: 0.1937\n",
      "Epoch [486/500], Loss: 1.7596, Accuracy: 0.1900\n",
      "Epoch [487/500], Loss: 1.7519, Accuracy: 0.1908\n",
      "Epoch [488/500], Loss: 1.7513, Accuracy: 0.1905\n",
      "Epoch [489/500], Loss: 1.7529, Accuracy: 0.1950\n",
      "Epoch [490/500], Loss: 1.7507, Accuracy: 0.1925\n",
      "Epoch [491/500], Loss: 1.7525, Accuracy: 0.1922\n",
      "Epoch [492/500], Loss: 1.7567, Accuracy: 0.1949\n",
      "Epoch [493/500], Loss: 1.7575, Accuracy: 0.1907\n",
      "Epoch [494/500], Loss: 1.7518, Accuracy: 0.1974\n",
      "Epoch [495/500], Loss: 1.7511, Accuracy: 0.1933\n",
      "Epoch [496/500], Loss: 1.7512, Accuracy: 0.1949\n",
      "Epoch [497/500], Loss: 1.7523, Accuracy: 0.2103\n",
      "Epoch [498/500], Loss: 1.7494, Accuracy: 0.2157\n",
      "Epoch [499/500], Loss: 1.7507, Accuracy: 0.2122\n",
      "Epoch [500/500], Loss: 1.7513, Accuracy: 0.2115\n"
     ]
    }
   ],
   "source": [
    "# Standard Deep Neural Network\n",
    "sdnn_model = SimpleDNN(input_size[0], num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(sdnn_model.parameters(), lr=0.001)\n",
    "train(sdnn_model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.7774, Accuracy: 0.2316\n",
      "Epoch [2/500], Loss: 1.7418, Accuracy: 0.2636\n",
      "Epoch [3/500], Loss: 1.7033, Accuracy: 0.3133\n",
      "Epoch [4/500], Loss: 1.6691, Accuracy: 0.3128\n",
      "Epoch [5/500], Loss: 1.6460, Accuracy: 0.3114\n",
      "Epoch [6/500], Loss: 1.6289, Accuracy: 0.3131\n",
      "Epoch [7/500], Loss: 1.6184, Accuracy: 0.3151\n",
      "Epoch [8/500], Loss: 1.6034, Accuracy: 0.3188\n",
      "Epoch [9/500], Loss: 1.6020, Accuracy: 0.3193\n",
      "Epoch [10/500], Loss: 1.5901, Accuracy: 0.3266\n",
      "Epoch [11/500], Loss: 1.5912, Accuracy: 0.3296\n",
      "Epoch [12/500], Loss: 1.5876, Accuracy: 0.3301\n",
      "Epoch [13/500], Loss: 1.5837, Accuracy: 0.3326\n",
      "Epoch [14/500], Loss: 1.5802, Accuracy: 0.3338\n",
      "Epoch [15/500], Loss: 1.5771, Accuracy: 0.3355\n",
      "Epoch [16/500], Loss: 1.5699, Accuracy: 0.3388\n",
      "Epoch [17/500], Loss: 1.5696, Accuracy: 0.3387\n",
      "Epoch [18/500], Loss: 1.5689, Accuracy: 0.3417\n",
      "Epoch [19/500], Loss: 1.5691, Accuracy: 0.3403\n",
      "Epoch [20/500], Loss: 1.5656, Accuracy: 0.3434\n",
      "Epoch [21/500], Loss: 1.5599, Accuracy: 0.3440\n",
      "Epoch [22/500], Loss: 1.5609, Accuracy: 0.3435\n",
      "Epoch [23/500], Loss: 1.5610, Accuracy: 0.3430\n",
      "Epoch [24/500], Loss: 1.5578, Accuracy: 0.3464\n",
      "Epoch [25/500], Loss: 1.5560, Accuracy: 0.3469\n",
      "Epoch [26/500], Loss: 1.5479, Accuracy: 0.3469\n",
      "Epoch [27/500], Loss: 1.5489, Accuracy: 0.3491\n",
      "Epoch [28/500], Loss: 1.5511, Accuracy: 0.3481\n",
      "Epoch [29/500], Loss: 1.5488, Accuracy: 0.3496\n",
      "Epoch [30/500], Loss: 1.5477, Accuracy: 0.3521\n",
      "Epoch [31/500], Loss: 1.5434, Accuracy: 0.3536\n",
      "Epoch [32/500], Loss: 1.5479, Accuracy: 0.3539\n",
      "Epoch [33/500], Loss: 1.5456, Accuracy: 0.3538\n",
      "Epoch [34/500], Loss: 1.5421, Accuracy: 0.3531\n",
      "Epoch [35/500], Loss: 1.5440, Accuracy: 0.3549\n",
      "Epoch [36/500], Loss: 1.5414, Accuracy: 0.3555\n",
      "Epoch [37/500], Loss: 1.5390, Accuracy: 0.3555\n",
      "Epoch [38/500], Loss: 1.5374, Accuracy: 0.3566\n",
      "Epoch [39/500], Loss: 1.5388, Accuracy: 0.3560\n",
      "Epoch [40/500], Loss: 1.5350, Accuracy: 0.3561\n",
      "Epoch [41/500], Loss: 1.5408, Accuracy: 0.3541\n",
      "Epoch [42/500], Loss: 1.5358, Accuracy: 0.3558\n",
      "Epoch [43/500], Loss: 1.5288, Accuracy: 0.3548\n",
      "Epoch [44/500], Loss: 1.5320, Accuracy: 0.3556\n",
      "Epoch [45/500], Loss: 1.5267, Accuracy: 0.3555\n",
      "Epoch [46/500], Loss: 1.5295, Accuracy: 0.3536\n",
      "Epoch [47/500], Loss: 1.5303, Accuracy: 0.3555\n",
      "Epoch [48/500], Loss: 1.5316, Accuracy: 0.3551\n",
      "Epoch [49/500], Loss: 1.5275, Accuracy: 0.3588\n",
      "Epoch [50/500], Loss: 1.5302, Accuracy: 0.3573\n",
      "Epoch [51/500], Loss: 1.5303, Accuracy: 0.3586\n",
      "Epoch [52/500], Loss: 1.5258, Accuracy: 0.3590\n",
      "Epoch [53/500], Loss: 1.5231, Accuracy: 0.3578\n",
      "Epoch [54/500], Loss: 1.5204, Accuracy: 0.3595\n",
      "Epoch [55/500], Loss: 1.5220, Accuracy: 0.3590\n",
      "Epoch [56/500], Loss: 1.5196, Accuracy: 0.3591\n",
      "Epoch [57/500], Loss: 1.5208, Accuracy: 0.3607\n",
      "Epoch [58/500], Loss: 1.5210, Accuracy: 0.3603\n",
      "Epoch [59/500], Loss: 1.5144, Accuracy: 0.3598\n",
      "Epoch [60/500], Loss: 1.5188, Accuracy: 0.3613\n",
      "Epoch [61/500], Loss: 1.5181, Accuracy: 0.3620\n",
      "Epoch [62/500], Loss: 1.5148, Accuracy: 0.3630\n",
      "Epoch [63/500], Loss: 1.5146, Accuracy: 0.3637\n",
      "Epoch [64/500], Loss: 1.5170, Accuracy: 0.3640\n",
      "Epoch [65/500], Loss: 1.5186, Accuracy: 0.3647\n",
      "Epoch [66/500], Loss: 1.5159, Accuracy: 0.3649\n",
      "Epoch [67/500], Loss: 1.5101, Accuracy: 0.3657\n",
      "Epoch [68/500], Loss: 1.5135, Accuracy: 0.3655\n",
      "Epoch [69/500], Loss: 1.5097, Accuracy: 0.3682\n",
      "Epoch [70/500], Loss: 1.5125, Accuracy: 0.3674\n",
      "Epoch [71/500], Loss: 1.5115, Accuracy: 0.3659\n",
      "Epoch [72/500], Loss: 1.5128, Accuracy: 0.3667\n",
      "Epoch [73/500], Loss: 1.5149, Accuracy: 0.3696\n",
      "Epoch [74/500], Loss: 1.5115, Accuracy: 0.3696\n",
      "Epoch [75/500], Loss: 1.5099, Accuracy: 0.3667\n",
      "Epoch [76/500], Loss: 1.5042, Accuracy: 0.3686\n",
      "Epoch [77/500], Loss: 1.5082, Accuracy: 0.3711\n",
      "Epoch [78/500], Loss: 1.5042, Accuracy: 0.3709\n",
      "Epoch [79/500], Loss: 1.5088, Accuracy: 0.3717\n",
      "Epoch [80/500], Loss: 1.5077, Accuracy: 0.3738\n",
      "Epoch [81/500], Loss: 1.5002, Accuracy: 0.3731\n",
      "Epoch [82/500], Loss: 1.4993, Accuracy: 0.3726\n",
      "Epoch [83/500], Loss: 1.5017, Accuracy: 0.3741\n",
      "Epoch [84/500], Loss: 1.5039, Accuracy: 0.3746\n",
      "Epoch [85/500], Loss: 1.5018, Accuracy: 0.3734\n",
      "Epoch [86/500], Loss: 1.5016, Accuracy: 0.3746\n",
      "Epoch [87/500], Loss: 1.5023, Accuracy: 0.3768\n",
      "Epoch [88/500], Loss: 1.4985, Accuracy: 0.3766\n",
      "Epoch [89/500], Loss: 1.5024, Accuracy: 0.3743\n",
      "Epoch [90/500], Loss: 1.5027, Accuracy: 0.3761\n",
      "Epoch [91/500], Loss: 1.4969, Accuracy: 0.3773\n",
      "Epoch [92/500], Loss: 1.4980, Accuracy: 0.3766\n",
      "Epoch [93/500], Loss: 1.4959, Accuracy: 0.3763\n",
      "Epoch [94/500], Loss: 1.5010, Accuracy: 0.3771\n",
      "Epoch [95/500], Loss: 1.4972, Accuracy: 0.3763\n",
      "Epoch [96/500], Loss: 1.4986, Accuracy: 0.3766\n",
      "Epoch [97/500], Loss: 1.4985, Accuracy: 0.3768\n",
      "Epoch [98/500], Loss: 1.4963, Accuracy: 0.3783\n",
      "Epoch [99/500], Loss: 1.4940, Accuracy: 0.3798\n",
      "Epoch [100/500], Loss: 1.4958, Accuracy: 0.3791\n",
      "Epoch [101/500], Loss: 1.4945, Accuracy: 0.3806\n",
      "Epoch [102/500], Loss: 1.4943, Accuracy: 0.3805\n",
      "Epoch [103/500], Loss: 1.4910, Accuracy: 0.3786\n",
      "Epoch [104/500], Loss: 1.4910, Accuracy: 0.3813\n",
      "Epoch [105/500], Loss: 1.4996, Accuracy: 0.3788\n",
      "Epoch [106/500], Loss: 1.4913, Accuracy: 0.3798\n",
      "Epoch [107/500], Loss: 1.4890, Accuracy: 0.3813\n",
      "Epoch [108/500], Loss: 1.4891, Accuracy: 0.3833\n",
      "Epoch [109/500], Loss: 1.4922, Accuracy: 0.3827\n",
      "Epoch [110/500], Loss: 1.4852, Accuracy: 0.3848\n",
      "Epoch [111/500], Loss: 1.4880, Accuracy: 0.3859\n",
      "Epoch [112/500], Loss: 1.4963, Accuracy: 0.3852\n",
      "Epoch [113/500], Loss: 1.4814, Accuracy: 0.3869\n",
      "Epoch [114/500], Loss: 1.4907, Accuracy: 0.3847\n",
      "Epoch [115/500], Loss: 1.4825, Accuracy: 0.3855\n",
      "Epoch [116/500], Loss: 1.4871, Accuracy: 0.3855\n",
      "Epoch [117/500], Loss: 1.4820, Accuracy: 0.3862\n",
      "Epoch [118/500], Loss: 1.4862, Accuracy: 0.3860\n",
      "Epoch [119/500], Loss: 1.4864, Accuracy: 0.3872\n",
      "Epoch [120/500], Loss: 1.4819, Accuracy: 0.3865\n",
      "Epoch [121/500], Loss: 1.4794, Accuracy: 0.3855\n",
      "Epoch [122/500], Loss: 1.4828, Accuracy: 0.3869\n",
      "Epoch [123/500], Loss: 1.4777, Accuracy: 0.3869\n",
      "Epoch [124/500], Loss: 1.4821, Accuracy: 0.3887\n",
      "Epoch [125/500], Loss: 1.4826, Accuracy: 0.3855\n",
      "Epoch [126/500], Loss: 1.4801, Accuracy: 0.3885\n",
      "Epoch [127/500], Loss: 1.4823, Accuracy: 0.3874\n",
      "Epoch [128/500], Loss: 1.4793, Accuracy: 0.3894\n",
      "Epoch [129/500], Loss: 1.4796, Accuracy: 0.3892\n",
      "Epoch [130/500], Loss: 1.4762, Accuracy: 0.3899\n",
      "Epoch [131/500], Loss: 1.4769, Accuracy: 0.3907\n",
      "Epoch [132/500], Loss: 1.4877, Accuracy: 0.3902\n",
      "Epoch [133/500], Loss: 1.4741, Accuracy: 0.3907\n",
      "Epoch [134/500], Loss: 1.4782, Accuracy: 0.3904\n",
      "Epoch [135/500], Loss: 1.4698, Accuracy: 0.3911\n",
      "Epoch [136/500], Loss: 1.4764, Accuracy: 0.3922\n",
      "Epoch [137/500], Loss: 1.4751, Accuracy: 0.3919\n",
      "Epoch [138/500], Loss: 1.4770, Accuracy: 0.3927\n",
      "Epoch [139/500], Loss: 1.4766, Accuracy: 0.3926\n",
      "Epoch [140/500], Loss: 1.4762, Accuracy: 0.3926\n",
      "Epoch [141/500], Loss: 1.4749, Accuracy: 0.3922\n",
      "Epoch [142/500], Loss: 1.4766, Accuracy: 0.3932\n",
      "Epoch [143/500], Loss: 1.4681, Accuracy: 0.3948\n",
      "Epoch [144/500], Loss: 1.4723, Accuracy: 0.3941\n",
      "Epoch [145/500], Loss: 1.4728, Accuracy: 0.3924\n",
      "Epoch [146/500], Loss: 1.4725, Accuracy: 0.3926\n",
      "Epoch [147/500], Loss: 1.4766, Accuracy: 0.3951\n",
      "Epoch [148/500], Loss: 1.4666, Accuracy: 0.3953\n",
      "Epoch [149/500], Loss: 1.4630, Accuracy: 0.3956\n",
      "Epoch [150/500], Loss: 1.4696, Accuracy: 0.3954\n",
      "Epoch [151/500], Loss: 1.4689, Accuracy: 0.3954\n",
      "Epoch [152/500], Loss: 1.4622, Accuracy: 0.3961\n",
      "Epoch [153/500], Loss: 1.4685, Accuracy: 0.3963\n",
      "Epoch [154/500], Loss: 1.4657, Accuracy: 0.3973\n",
      "Epoch [155/500], Loss: 1.4677, Accuracy: 0.3974\n",
      "Epoch [156/500], Loss: 1.4703, Accuracy: 0.3966\n",
      "Epoch [157/500], Loss: 1.4697, Accuracy: 0.3968\n",
      "Epoch [158/500], Loss: 1.4647, Accuracy: 0.3958\n",
      "Epoch [159/500], Loss: 1.4619, Accuracy: 0.3981\n",
      "Epoch [160/500], Loss: 1.4692, Accuracy: 0.3993\n",
      "Epoch [161/500], Loss: 1.4649, Accuracy: 0.3985\n",
      "Epoch [162/500], Loss: 1.4670, Accuracy: 0.3988\n",
      "Epoch [163/500], Loss: 1.4678, Accuracy: 0.3983\n",
      "Epoch [164/500], Loss: 1.4674, Accuracy: 0.3976\n",
      "Epoch [165/500], Loss: 1.4662, Accuracy: 0.3995\n",
      "Epoch [166/500], Loss: 1.4690, Accuracy: 0.4001\n",
      "Epoch [167/500], Loss: 1.4653, Accuracy: 0.4008\n",
      "Epoch [168/500], Loss: 1.4581, Accuracy: 0.4008\n",
      "Epoch [169/500], Loss: 1.4646, Accuracy: 0.4018\n",
      "Epoch [170/500], Loss: 1.4612, Accuracy: 0.4025\n",
      "Epoch [171/500], Loss: 1.4585, Accuracy: 0.4013\n",
      "Epoch [172/500], Loss: 1.4640, Accuracy: 0.4001\n",
      "Epoch [173/500], Loss: 1.4557, Accuracy: 0.4011\n",
      "Epoch [174/500], Loss: 1.4593, Accuracy: 0.4003\n",
      "Epoch [175/500], Loss: 1.4587, Accuracy: 0.4020\n",
      "Epoch [176/500], Loss: 1.4584, Accuracy: 0.4020\n",
      "Epoch [177/500], Loss: 1.4598, Accuracy: 0.4042\n",
      "Epoch [178/500], Loss: 1.4600, Accuracy: 0.4023\n",
      "Epoch [179/500], Loss: 1.4644, Accuracy: 0.4030\n",
      "Epoch [180/500], Loss: 1.4579, Accuracy: 0.4038\n",
      "Epoch [181/500], Loss: 1.4600, Accuracy: 0.4037\n",
      "Epoch [182/500], Loss: 1.4580, Accuracy: 0.4052\n",
      "Epoch [183/500], Loss: 1.4552, Accuracy: 0.4043\n",
      "Epoch [184/500], Loss: 1.4666, Accuracy: 0.4045\n",
      "Epoch [185/500], Loss: 1.4582, Accuracy: 0.4053\n",
      "Epoch [186/500], Loss: 1.4550, Accuracy: 0.4038\n",
      "Epoch [187/500], Loss: 1.4547, Accuracy: 0.4052\n",
      "Epoch [188/500], Loss: 1.4562, Accuracy: 0.4053\n",
      "Epoch [189/500], Loss: 1.4530, Accuracy: 0.4060\n",
      "Epoch [190/500], Loss: 1.4551, Accuracy: 0.4090\n",
      "Epoch [191/500], Loss: 1.4530, Accuracy: 0.4067\n",
      "Epoch [192/500], Loss: 1.4528, Accuracy: 0.4053\n",
      "Epoch [193/500], Loss: 1.4509, Accuracy: 0.4074\n",
      "Epoch [194/500], Loss: 1.4465, Accuracy: 0.4067\n",
      "Epoch [195/500], Loss: 1.4539, Accuracy: 0.4058\n",
      "Epoch [196/500], Loss: 1.4568, Accuracy: 0.4074\n",
      "Epoch [197/500], Loss: 1.4529, Accuracy: 0.4085\n",
      "Epoch [198/500], Loss: 1.4448, Accuracy: 0.4075\n",
      "Epoch [199/500], Loss: 1.4535, Accuracy: 0.4084\n",
      "Epoch [200/500], Loss: 1.4465, Accuracy: 0.4084\n",
      "Epoch [201/500], Loss: 1.4514, Accuracy: 0.4080\n",
      "Epoch [202/500], Loss: 1.4493, Accuracy: 0.4099\n",
      "Epoch [203/500], Loss: 1.4532, Accuracy: 0.4084\n",
      "Epoch [204/500], Loss: 1.4516, Accuracy: 0.4095\n",
      "Epoch [205/500], Loss: 1.4501, Accuracy: 0.4082\n",
      "Epoch [206/500], Loss: 1.4507, Accuracy: 0.4107\n",
      "Epoch [207/500], Loss: 1.4532, Accuracy: 0.4080\n",
      "Epoch [208/500], Loss: 1.4516, Accuracy: 0.4112\n",
      "Epoch [209/500], Loss: 1.4525, Accuracy: 0.4099\n",
      "Epoch [210/500], Loss: 1.4484, Accuracy: 0.4109\n",
      "Epoch [211/500], Loss: 1.4513, Accuracy: 0.4112\n",
      "Epoch [212/500], Loss: 1.4475, Accuracy: 0.4099\n",
      "Epoch [213/500], Loss: 1.4471, Accuracy: 0.4114\n",
      "Epoch [214/500], Loss: 1.4438, Accuracy: 0.4114\n",
      "Epoch [215/500], Loss: 1.4441, Accuracy: 0.4126\n",
      "Epoch [216/500], Loss: 1.4471, Accuracy: 0.4111\n",
      "Epoch [217/500], Loss: 1.4457, Accuracy: 0.4127\n",
      "Epoch [218/500], Loss: 1.4469, Accuracy: 0.4112\n",
      "Epoch [219/500], Loss: 1.4435, Accuracy: 0.4126\n",
      "Epoch [220/500], Loss: 1.4452, Accuracy: 0.4134\n",
      "Epoch [221/500], Loss: 1.4455, Accuracy: 0.4139\n",
      "Epoch [222/500], Loss: 1.4396, Accuracy: 0.4127\n",
      "Epoch [223/500], Loss: 1.4543, Accuracy: 0.4144\n",
      "Epoch [224/500], Loss: 1.4458, Accuracy: 0.4139\n",
      "Epoch [225/500], Loss: 1.4413, Accuracy: 0.4147\n",
      "Epoch [226/500], Loss: 1.4385, Accuracy: 0.4137\n",
      "Epoch [227/500], Loss: 1.4384, Accuracy: 0.4153\n",
      "Epoch [228/500], Loss: 1.4433, Accuracy: 0.4159\n",
      "Epoch [229/500], Loss: 1.4445, Accuracy: 0.4124\n",
      "Epoch [230/500], Loss: 1.4422, Accuracy: 0.4151\n",
      "Epoch [231/500], Loss: 1.4414, Accuracy: 0.4149\n",
      "Epoch [232/500], Loss: 1.4401, Accuracy: 0.4149\n",
      "Epoch [233/500], Loss: 1.4424, Accuracy: 0.4137\n",
      "Epoch [234/500], Loss: 1.4410, Accuracy: 0.4158\n",
      "Epoch [235/500], Loss: 1.4367, Accuracy: 0.4156\n",
      "Epoch [236/500], Loss: 1.4356, Accuracy: 0.4159\n",
      "Epoch [237/500], Loss: 1.4455, Accuracy: 0.4174\n",
      "Epoch [238/500], Loss: 1.4403, Accuracy: 0.4147\n",
      "Epoch [239/500], Loss: 1.4413, Accuracy: 0.4178\n",
      "Epoch [240/500], Loss: 1.4431, Accuracy: 0.4166\n",
      "Epoch [241/500], Loss: 1.4378, Accuracy: 0.4149\n",
      "Epoch [242/500], Loss: 1.4367, Accuracy: 0.4174\n",
      "Epoch [243/500], Loss: 1.4382, Accuracy: 0.4164\n",
      "Epoch [244/500], Loss: 1.4439, Accuracy: 0.4169\n",
      "Epoch [245/500], Loss: 1.4497, Accuracy: 0.4164\n",
      "Epoch [246/500], Loss: 1.4386, Accuracy: 0.4174\n",
      "Epoch [247/500], Loss: 1.4370, Accuracy: 0.4163\n",
      "Epoch [248/500], Loss: 1.4302, Accuracy: 0.4169\n",
      "Epoch [249/500], Loss: 1.4382, Accuracy: 0.4173\n",
      "Epoch [250/500], Loss: 1.4390, Accuracy: 0.4161\n",
      "Epoch [251/500], Loss: 1.4360, Accuracy: 0.4173\n",
      "Epoch [252/500], Loss: 1.4361, Accuracy: 0.4169\n",
      "Epoch [253/500], Loss: 1.4365, Accuracy: 0.4179\n",
      "Epoch [254/500], Loss: 1.4358, Accuracy: 0.4181\n",
      "Epoch [255/500], Loss: 1.4379, Accuracy: 0.4186\n",
      "Epoch [256/500], Loss: 1.4345, Accuracy: 0.4191\n",
      "Epoch [257/500], Loss: 1.4355, Accuracy: 0.4186\n",
      "Epoch [258/500], Loss: 1.4340, Accuracy: 0.4186\n",
      "Epoch [259/500], Loss: 1.4339, Accuracy: 0.4186\n",
      "Epoch [260/500], Loss: 1.4299, Accuracy: 0.4200\n",
      "Epoch [261/500], Loss: 1.4404, Accuracy: 0.4205\n",
      "Epoch [262/500], Loss: 1.4325, Accuracy: 0.4184\n",
      "Epoch [263/500], Loss: 1.4324, Accuracy: 0.4196\n",
      "Epoch [264/500], Loss: 1.4314, Accuracy: 0.4196\n",
      "Epoch [265/500], Loss: 1.4311, Accuracy: 0.4205\n",
      "Epoch [266/500], Loss: 1.4283, Accuracy: 0.4201\n",
      "Epoch [267/500], Loss: 1.4310, Accuracy: 0.4195\n",
      "Epoch [268/500], Loss: 1.4315, Accuracy: 0.4200\n",
      "Epoch [269/500], Loss: 1.4316, Accuracy: 0.4215\n",
      "Epoch [270/500], Loss: 1.4309, Accuracy: 0.4200\n",
      "Epoch [271/500], Loss: 1.4307, Accuracy: 0.4184\n",
      "Epoch [272/500], Loss: 1.4300, Accuracy: 0.4193\n",
      "Epoch [273/500], Loss: 1.4301, Accuracy: 0.4198\n",
      "Epoch [274/500], Loss: 1.4297, Accuracy: 0.4189\n",
      "Epoch [275/500], Loss: 1.4312, Accuracy: 0.4203\n",
      "Epoch [276/500], Loss: 1.4263, Accuracy: 0.4195\n",
      "Epoch [277/500], Loss: 1.4348, Accuracy: 0.4198\n",
      "Epoch [278/500], Loss: 1.4238, Accuracy: 0.4191\n",
      "Epoch [279/500], Loss: 1.4336, Accuracy: 0.4195\n",
      "Epoch [280/500], Loss: 1.4263, Accuracy: 0.4179\n",
      "Epoch [281/500], Loss: 1.4303, Accuracy: 0.4201\n",
      "Epoch [282/500], Loss: 1.4215, Accuracy: 0.4208\n",
      "Epoch [283/500], Loss: 1.4227, Accuracy: 0.4198\n",
      "Epoch [284/500], Loss: 1.4280, Accuracy: 0.4196\n",
      "Epoch [285/500], Loss: 1.4250, Accuracy: 0.4201\n",
      "Epoch [286/500], Loss: 1.4277, Accuracy: 0.4191\n",
      "Epoch [287/500], Loss: 1.4270, Accuracy: 0.4189\n",
      "Epoch [288/500], Loss: 1.4260, Accuracy: 0.4203\n",
      "Epoch [289/500], Loss: 1.4238, Accuracy: 0.4176\n",
      "Epoch [290/500], Loss: 1.4268, Accuracy: 0.4188\n",
      "Epoch [291/500], Loss: 1.4247, Accuracy: 0.4196\n",
      "Epoch [292/500], Loss: 1.4289, Accuracy: 0.4191\n",
      "Epoch [293/500], Loss: 1.4275, Accuracy: 0.4211\n",
      "Epoch [294/500], Loss: 1.4241, Accuracy: 0.4186\n",
      "Epoch [295/500], Loss: 1.4208, Accuracy: 0.4191\n",
      "Epoch [296/500], Loss: 1.4183, Accuracy: 0.4191\n",
      "Epoch [297/500], Loss: 1.4230, Accuracy: 0.4193\n",
      "Epoch [298/500], Loss: 1.4252, Accuracy: 0.4196\n",
      "Epoch [299/500], Loss: 1.4208, Accuracy: 0.4195\n",
      "Epoch [300/500], Loss: 1.4229, Accuracy: 0.4198\n",
      "Epoch [301/500], Loss: 1.4269, Accuracy: 0.4205\n",
      "Epoch [302/500], Loss: 1.4207, Accuracy: 0.4205\n",
      "Epoch [303/500], Loss: 1.4287, Accuracy: 0.4198\n",
      "Epoch [304/500], Loss: 1.4161, Accuracy: 0.4198\n",
      "Epoch [305/500], Loss: 1.4213, Accuracy: 0.4205\n",
      "Epoch [306/500], Loss: 1.4230, Accuracy: 0.4203\n",
      "Epoch [307/500], Loss: 1.4155, Accuracy: 0.4201\n",
      "Epoch [308/500], Loss: 1.4236, Accuracy: 0.4203\n",
      "Epoch [309/500], Loss: 1.4283, Accuracy: 0.4210\n",
      "Epoch [310/500], Loss: 1.4188, Accuracy: 0.4203\n",
      "Epoch [311/500], Loss: 1.4271, Accuracy: 0.4201\n",
      "Epoch [312/500], Loss: 1.4231, Accuracy: 0.4198\n",
      "Epoch [313/500], Loss: 1.4184, Accuracy: 0.4195\n",
      "Epoch [314/500], Loss: 1.4207, Accuracy: 0.4198\n",
      "Epoch [315/500], Loss: 1.4180, Accuracy: 0.4218\n",
      "Epoch [316/500], Loss: 1.4147, Accuracy: 0.4208\n",
      "Epoch [317/500], Loss: 1.4182, Accuracy: 0.4216\n",
      "Epoch [318/500], Loss: 1.4251, Accuracy: 0.4206\n",
      "Epoch [319/500], Loss: 1.4193, Accuracy: 0.4211\n",
      "Epoch [320/500], Loss: 1.4262, Accuracy: 0.4206\n",
      "Epoch [321/500], Loss: 1.4212, Accuracy: 0.4221\n",
      "Epoch [322/500], Loss: 1.4176, Accuracy: 0.4196\n",
      "Epoch [323/500], Loss: 1.4205, Accuracy: 0.4203\n",
      "Epoch [324/500], Loss: 1.4137, Accuracy: 0.4201\n",
      "Epoch [325/500], Loss: 1.4165, Accuracy: 0.4213\n",
      "Epoch [326/500], Loss: 1.4163, Accuracy: 0.4210\n",
      "Epoch [327/500], Loss: 1.4108, Accuracy: 0.4203\n",
      "Epoch [328/500], Loss: 1.4169, Accuracy: 0.4210\n",
      "Epoch [329/500], Loss: 1.4247, Accuracy: 0.4228\n",
      "Epoch [330/500], Loss: 1.4149, Accuracy: 0.4218\n",
      "Epoch [331/500], Loss: 1.4140, Accuracy: 0.4210\n",
      "Epoch [332/500], Loss: 1.4172, Accuracy: 0.4216\n",
      "Epoch [333/500], Loss: 1.4129, Accuracy: 0.4221\n",
      "Epoch [334/500], Loss: 1.4153, Accuracy: 0.4228\n",
      "Epoch [335/500], Loss: 1.4124, Accuracy: 0.4223\n",
      "Epoch [336/500], Loss: 1.4141, Accuracy: 0.4223\n",
      "Epoch [337/500], Loss: 1.4162, Accuracy: 0.4218\n",
      "Epoch [338/500], Loss: 1.4147, Accuracy: 0.4220\n",
      "Epoch [339/500], Loss: 1.4143, Accuracy: 0.4233\n",
      "Epoch [340/500], Loss: 1.4176, Accuracy: 0.4215\n",
      "Epoch [341/500], Loss: 1.4141, Accuracy: 0.4230\n",
      "Epoch [342/500], Loss: 1.4156, Accuracy: 0.4228\n",
      "Epoch [343/500], Loss: 1.4117, Accuracy: 0.4223\n",
      "Epoch [344/500], Loss: 1.4168, Accuracy: 0.4237\n",
      "Epoch [345/500], Loss: 1.4183, Accuracy: 0.4233\n",
      "Epoch [346/500], Loss: 1.4149, Accuracy: 0.4237\n",
      "Epoch [347/500], Loss: 1.4209, Accuracy: 0.4238\n",
      "Epoch [348/500], Loss: 1.4159, Accuracy: 0.4263\n",
      "Epoch [349/500], Loss: 1.4161, Accuracy: 0.4248\n",
      "Epoch [350/500], Loss: 1.4102, Accuracy: 0.4243\n",
      "Epoch [351/500], Loss: 1.4102, Accuracy: 0.4252\n",
      "Epoch [352/500], Loss: 1.4119, Accuracy: 0.4260\n",
      "Epoch [353/500], Loss: 1.4133, Accuracy: 0.4238\n",
      "Epoch [354/500], Loss: 1.4158, Accuracy: 0.4245\n",
      "Epoch [355/500], Loss: 1.4188, Accuracy: 0.4248\n",
      "Epoch [356/500], Loss: 1.4081, Accuracy: 0.4247\n",
      "Epoch [357/500], Loss: 1.4061, Accuracy: 0.4233\n",
      "Epoch [358/500], Loss: 1.4169, Accuracy: 0.4252\n",
      "Epoch [359/500], Loss: 1.4137, Accuracy: 0.4230\n",
      "Epoch [360/500], Loss: 1.4139, Accuracy: 0.4255\n",
      "Epoch [361/500], Loss: 1.4063, Accuracy: 0.4258\n",
      "Epoch [362/500], Loss: 1.4140, Accuracy: 0.4250\n",
      "Epoch [363/500], Loss: 1.4080, Accuracy: 0.4260\n",
      "Epoch [364/500], Loss: 1.4103, Accuracy: 0.4262\n",
      "Epoch [365/500], Loss: 1.4130, Accuracy: 0.4250\n",
      "Epoch [366/500], Loss: 1.4074, Accuracy: 0.4243\n",
      "Epoch [367/500], Loss: 1.4119, Accuracy: 0.4265\n",
      "Epoch [368/500], Loss: 1.4083, Accuracy: 0.4268\n",
      "Epoch [369/500], Loss: 1.4074, Accuracy: 0.4272\n",
      "Epoch [370/500], Loss: 1.4103, Accuracy: 0.4253\n",
      "Epoch [371/500], Loss: 1.4055, Accuracy: 0.4263\n",
      "Epoch [372/500], Loss: 1.4058, Accuracy: 0.4253\n",
      "Epoch [373/500], Loss: 1.4093, Accuracy: 0.4248\n",
      "Epoch [374/500], Loss: 1.4131, Accuracy: 0.4265\n",
      "Epoch [375/500], Loss: 1.4076, Accuracy: 0.4252\n",
      "Epoch [376/500], Loss: 1.4084, Accuracy: 0.4258\n",
      "Epoch [377/500], Loss: 1.4079, Accuracy: 0.4265\n",
      "Epoch [378/500], Loss: 1.4101, Accuracy: 0.4262\n",
      "Epoch [379/500], Loss: 1.4067, Accuracy: 0.4270\n",
      "Epoch [380/500], Loss: 1.4046, Accuracy: 0.4277\n",
      "Epoch [381/500], Loss: 1.4067, Accuracy: 0.4275\n",
      "Epoch [382/500], Loss: 1.4068, Accuracy: 0.4265\n",
      "Epoch [383/500], Loss: 1.4100, Accuracy: 0.4277\n",
      "Epoch [384/500], Loss: 1.4057, Accuracy: 0.4265\n",
      "Epoch [385/500], Loss: 1.4083, Accuracy: 0.4268\n",
      "Epoch [386/500], Loss: 1.4057, Accuracy: 0.4255\n",
      "Epoch [387/500], Loss: 1.4080, Accuracy: 0.4275\n",
      "Epoch [388/500], Loss: 1.4044, Accuracy: 0.4284\n",
      "Epoch [389/500], Loss: 1.4045, Accuracy: 0.4265\n",
      "Epoch [390/500], Loss: 1.4034, Accuracy: 0.4268\n",
      "Epoch [391/500], Loss: 1.4074, Accuracy: 0.4267\n",
      "Epoch [392/500], Loss: 1.4063, Accuracy: 0.4270\n",
      "Epoch [393/500], Loss: 1.4032, Accuracy: 0.4292\n",
      "Epoch [394/500], Loss: 1.4036, Accuracy: 0.4287\n",
      "Epoch [395/500], Loss: 1.4087, Accuracy: 0.4287\n",
      "Epoch [396/500], Loss: 1.4019, Accuracy: 0.4289\n",
      "Epoch [397/500], Loss: 1.4031, Accuracy: 0.4284\n",
      "Epoch [398/500], Loss: 1.4027, Accuracy: 0.4279\n",
      "Epoch [399/500], Loss: 1.4022, Accuracy: 0.4277\n",
      "Epoch [400/500], Loss: 1.4046, Accuracy: 0.4284\n",
      "Epoch [401/500], Loss: 1.3973, Accuracy: 0.4284\n",
      "Epoch [402/500], Loss: 1.4044, Accuracy: 0.4273\n",
      "Epoch [403/500], Loss: 1.4013, Accuracy: 0.4292\n",
      "Epoch [404/500], Loss: 1.4050, Accuracy: 0.4294\n",
      "Epoch [405/500], Loss: 1.3999, Accuracy: 0.4270\n",
      "Epoch [406/500], Loss: 1.4013, Accuracy: 0.4289\n",
      "Epoch [407/500], Loss: 1.3999, Accuracy: 0.4292\n",
      "Epoch [408/500], Loss: 1.4005, Accuracy: 0.4297\n",
      "Epoch [409/500], Loss: 1.3980, Accuracy: 0.4290\n",
      "Epoch [410/500], Loss: 1.3972, Accuracy: 0.4300\n",
      "Epoch [411/500], Loss: 1.4019, Accuracy: 0.4294\n",
      "Epoch [412/500], Loss: 1.4016, Accuracy: 0.4290\n",
      "Epoch [413/500], Loss: 1.3984, Accuracy: 0.4284\n",
      "Epoch [414/500], Loss: 1.4036, Accuracy: 0.4292\n",
      "Epoch [415/500], Loss: 1.4001, Accuracy: 0.4292\n",
      "Epoch [416/500], Loss: 1.4039, Accuracy: 0.4292\n",
      "Epoch [417/500], Loss: 1.4034, Accuracy: 0.4292\n",
      "Epoch [418/500], Loss: 1.3982, Accuracy: 0.4304\n",
      "Epoch [419/500], Loss: 1.3991, Accuracy: 0.4285\n",
      "Epoch [420/500], Loss: 1.4000, Accuracy: 0.4297\n",
      "Epoch [421/500], Loss: 1.4009, Accuracy: 0.4302\n",
      "Epoch [422/500], Loss: 1.4023, Accuracy: 0.4294\n",
      "Epoch [423/500], Loss: 1.4043, Accuracy: 0.4309\n",
      "Epoch [424/500], Loss: 1.4019, Accuracy: 0.4279\n",
      "Epoch [425/500], Loss: 1.3985, Accuracy: 0.4282\n",
      "Epoch [426/500], Loss: 1.3962, Accuracy: 0.4295\n",
      "Epoch [427/500], Loss: 1.3981, Accuracy: 0.4280\n",
      "Epoch [428/500], Loss: 1.4008, Accuracy: 0.4304\n",
      "Epoch [429/500], Loss: 1.3954, Accuracy: 0.4300\n",
      "Epoch [430/500], Loss: 1.4039, Accuracy: 0.4302\n",
      "Epoch [431/500], Loss: 1.4005, Accuracy: 0.4302\n",
      "Epoch [432/500], Loss: 1.3963, Accuracy: 0.4299\n",
      "Epoch [433/500], Loss: 1.3992, Accuracy: 0.4290\n",
      "Epoch [434/500], Loss: 1.4062, Accuracy: 0.4294\n",
      "Epoch [435/500], Loss: 1.3969, Accuracy: 0.4294\n",
      "Epoch [436/500], Loss: 1.3905, Accuracy: 0.4297\n",
      "Epoch [437/500], Loss: 1.4005, Accuracy: 0.4310\n",
      "Epoch [438/500], Loss: 1.3952, Accuracy: 0.4302\n",
      "Epoch [439/500], Loss: 1.3990, Accuracy: 0.4312\n",
      "Epoch [440/500], Loss: 1.4003, Accuracy: 0.4310\n",
      "Epoch [441/500], Loss: 1.3958, Accuracy: 0.4312\n",
      "Epoch [442/500], Loss: 1.3934, Accuracy: 0.4312\n",
      "Epoch [443/500], Loss: 1.4021, Accuracy: 0.4310\n",
      "Epoch [444/500], Loss: 1.3981, Accuracy: 0.4319\n",
      "Epoch [445/500], Loss: 1.3927, Accuracy: 0.4314\n",
      "Epoch [446/500], Loss: 1.3948, Accuracy: 0.4317\n",
      "Epoch [447/500], Loss: 1.4004, Accuracy: 0.4312\n",
      "Epoch [448/500], Loss: 1.3947, Accuracy: 0.4309\n",
      "Epoch [449/500], Loss: 1.3986, Accuracy: 0.4321\n",
      "Epoch [450/500], Loss: 1.3888, Accuracy: 0.4307\n",
      "Epoch [451/500], Loss: 1.3931, Accuracy: 0.4315\n",
      "Epoch [452/500], Loss: 1.3948, Accuracy: 0.4322\n",
      "Epoch [453/500], Loss: 1.3927, Accuracy: 0.4315\n",
      "Epoch [454/500], Loss: 1.3969, Accuracy: 0.4314\n",
      "Epoch [455/500], Loss: 1.3931, Accuracy: 0.4331\n",
      "Epoch [456/500], Loss: 1.3916, Accuracy: 0.4309\n",
      "Epoch [457/500], Loss: 1.3966, Accuracy: 0.4322\n",
      "Epoch [458/500], Loss: 1.4001, Accuracy: 0.4331\n",
      "Epoch [459/500], Loss: 1.3915, Accuracy: 0.4344\n",
      "Epoch [460/500], Loss: 1.4226, Accuracy: 0.4322\n",
      "Epoch [461/500], Loss: 1.3936, Accuracy: 0.4332\n",
      "Epoch [462/500], Loss: 1.3925, Accuracy: 0.4326\n",
      "Epoch [463/500], Loss: 1.3900, Accuracy: 0.4342\n",
      "Epoch [464/500], Loss: 1.3938, Accuracy: 0.4334\n",
      "Epoch [465/500], Loss: 1.3935, Accuracy: 0.4341\n",
      "Epoch [466/500], Loss: 1.3885, Accuracy: 0.4337\n",
      "Epoch [467/500], Loss: 1.3932, Accuracy: 0.4331\n",
      "Epoch [468/500], Loss: 1.3905, Accuracy: 0.4332\n",
      "Epoch [469/500], Loss: 1.3926, Accuracy: 0.4322\n",
      "Epoch [470/500], Loss: 1.3938, Accuracy: 0.4329\n",
      "Epoch [471/500], Loss: 1.3903, Accuracy: 0.4354\n",
      "Epoch [472/500], Loss: 1.3962, Accuracy: 0.4336\n",
      "Epoch [473/500], Loss: 1.3926, Accuracy: 0.4346\n",
      "Epoch [474/500], Loss: 1.3866, Accuracy: 0.4342\n",
      "Epoch [475/500], Loss: 1.3927, Accuracy: 0.4347\n",
      "Epoch [476/500], Loss: 1.3939, Accuracy: 0.4347\n",
      "Epoch [477/500], Loss: 1.3902, Accuracy: 0.4352\n",
      "Epoch [478/500], Loss: 1.3934, Accuracy: 0.4344\n",
      "Epoch [479/500], Loss: 1.3885, Accuracy: 0.4354\n",
      "Epoch [480/500], Loss: 1.3944, Accuracy: 0.4347\n",
      "Epoch [481/500], Loss: 1.3867, Accuracy: 0.4354\n",
      "Epoch [482/500], Loss: 1.3929, Accuracy: 0.4347\n",
      "Epoch [483/500], Loss: 1.3943, Accuracy: 0.4357\n",
      "Epoch [484/500], Loss: 1.3867, Accuracy: 0.4351\n",
      "Epoch [485/500], Loss: 1.3868, Accuracy: 0.4356\n",
      "Epoch [486/500], Loss: 1.3883, Accuracy: 0.4349\n",
      "Epoch [487/500], Loss: 1.3882, Accuracy: 0.4349\n",
      "Epoch [488/500], Loss: 1.3905, Accuracy: 0.4361\n",
      "Epoch [489/500], Loss: 1.3921, Accuracy: 0.4368\n",
      "Epoch [490/500], Loss: 1.3896, Accuracy: 0.4359\n",
      "Epoch [491/500], Loss: 1.4001, Accuracy: 0.4361\n",
      "Epoch [492/500], Loss: 1.3862, Accuracy: 0.4368\n",
      "Epoch [493/500], Loss: 1.3890, Accuracy: 0.4381\n",
      "Epoch [494/500], Loss: 1.3880, Accuracy: 0.4374\n",
      "Epoch [495/500], Loss: 1.3829, Accuracy: 0.4369\n",
      "Epoch [496/500], Loss: 1.3929, Accuracy: 0.4373\n",
      "Epoch [497/500], Loss: 1.3899, Accuracy: 0.4374\n",
      "Epoch [498/500], Loss: 1.3881, Accuracy: 0.4376\n",
      "Epoch [499/500], Loss: 1.3875, Accuracy: 0.4381\n",
      "Epoch [500/500], Loss: 1.3805, Accuracy: 0.4386\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "lstm_model = LSTMModel(input_size[0], hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(lstm_model.parameters(), lr=0.001)\n",
    "train(lstm_model, train_loaderLSTM, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.7773, Accuracy: 0.2380\n",
      "Epoch [2/500], Loss: 1.7455, Accuracy: 0.2953\n",
      "Epoch [3/500], Loss: 1.7124, Accuracy: 0.3151\n",
      "Epoch [4/500], Loss: 1.6835, Accuracy: 0.3166\n",
      "Epoch [5/500], Loss: 1.6585, Accuracy: 0.3166\n",
      "Epoch [6/500], Loss: 1.6337, Accuracy: 0.3197\n",
      "Epoch [7/500], Loss: 1.6189, Accuracy: 0.3215\n",
      "Epoch [8/500], Loss: 1.6077, Accuracy: 0.3247\n",
      "Epoch [9/500], Loss: 1.5956, Accuracy: 0.3252\n",
      "Epoch [10/500], Loss: 1.5918, Accuracy: 0.3284\n",
      "Epoch [11/500], Loss: 1.5875, Accuracy: 0.3319\n",
      "Epoch [12/500], Loss: 1.5849, Accuracy: 0.3331\n",
      "Epoch [13/500], Loss: 1.5786, Accuracy: 0.3375\n",
      "Epoch [14/500], Loss: 1.5689, Accuracy: 0.3403\n",
      "Epoch [15/500], Loss: 1.5714, Accuracy: 0.3413\n",
      "Epoch [16/500], Loss: 1.5689, Accuracy: 0.3445\n",
      "Epoch [17/500], Loss: 1.5650, Accuracy: 0.3430\n",
      "Epoch [18/500], Loss: 1.5608, Accuracy: 0.3445\n",
      "Epoch [19/500], Loss: 1.5584, Accuracy: 0.3474\n",
      "Epoch [20/500], Loss: 1.5574, Accuracy: 0.3467\n",
      "Epoch [21/500], Loss: 1.5584, Accuracy: 0.3487\n",
      "Epoch [22/500], Loss: 1.5546, Accuracy: 0.3506\n",
      "Epoch [23/500], Loss: 1.5499, Accuracy: 0.3496\n",
      "Epoch [24/500], Loss: 1.5489, Accuracy: 0.3518\n",
      "Epoch [25/500], Loss: 1.5462, Accuracy: 0.3548\n",
      "Epoch [26/500], Loss: 1.5452, Accuracy: 0.3526\n",
      "Epoch [27/500], Loss: 1.5447, Accuracy: 0.3548\n",
      "Epoch [28/500], Loss: 1.5449, Accuracy: 0.3578\n",
      "Epoch [29/500], Loss: 1.5400, Accuracy: 0.3590\n",
      "Epoch [30/500], Loss: 1.5400, Accuracy: 0.3628\n",
      "Epoch [31/500], Loss: 1.5391, Accuracy: 0.3620\n",
      "Epoch [32/500], Loss: 1.5351, Accuracy: 0.3617\n",
      "Epoch [33/500], Loss: 1.5367, Accuracy: 0.3632\n",
      "Epoch [34/500], Loss: 1.5289, Accuracy: 0.3665\n",
      "Epoch [35/500], Loss: 1.5310, Accuracy: 0.3640\n",
      "Epoch [36/500], Loss: 1.5229, Accuracy: 0.3645\n",
      "Epoch [37/500], Loss: 1.5288, Accuracy: 0.3649\n",
      "Epoch [38/500], Loss: 1.5286, Accuracy: 0.3644\n",
      "Epoch [39/500], Loss: 1.5263, Accuracy: 0.3660\n",
      "Epoch [40/500], Loss: 1.5247, Accuracy: 0.3659\n",
      "Epoch [41/500], Loss: 1.5191, Accuracy: 0.3667\n",
      "Epoch [42/500], Loss: 1.5185, Accuracy: 0.3665\n",
      "Epoch [43/500], Loss: 1.5169, Accuracy: 0.3679\n",
      "Epoch [44/500], Loss: 1.5176, Accuracy: 0.3697\n",
      "Epoch [45/500], Loss: 1.5233, Accuracy: 0.3680\n",
      "Epoch [46/500], Loss: 1.5152, Accuracy: 0.3719\n",
      "Epoch [47/500], Loss: 1.5168, Accuracy: 0.3717\n",
      "Epoch [48/500], Loss: 1.5170, Accuracy: 0.3726\n",
      "Epoch [49/500], Loss: 1.5160, Accuracy: 0.3749\n",
      "Epoch [50/500], Loss: 1.5141, Accuracy: 0.3741\n",
      "Epoch [51/500], Loss: 1.5131, Accuracy: 0.3738\n",
      "Epoch [52/500], Loss: 1.5120, Accuracy: 0.3746\n",
      "Epoch [53/500], Loss: 1.5116, Accuracy: 0.3758\n",
      "Epoch [54/500], Loss: 1.5114, Accuracy: 0.3770\n",
      "Epoch [55/500], Loss: 1.5100, Accuracy: 0.3768\n",
      "Epoch [56/500], Loss: 1.5056, Accuracy: 0.3783\n",
      "Epoch [57/500], Loss: 1.5004, Accuracy: 0.3786\n",
      "Epoch [58/500], Loss: 1.5089, Accuracy: 0.3768\n",
      "Epoch [59/500], Loss: 1.5022, Accuracy: 0.3786\n",
      "Epoch [60/500], Loss: 1.5057, Accuracy: 0.3778\n",
      "Epoch [61/500], Loss: 1.4993, Accuracy: 0.3785\n",
      "Epoch [62/500], Loss: 1.5026, Accuracy: 0.3798\n",
      "Epoch [63/500], Loss: 1.5039, Accuracy: 0.3817\n",
      "Epoch [64/500], Loss: 1.5021, Accuracy: 0.3815\n",
      "Epoch [65/500], Loss: 1.4997, Accuracy: 0.3806\n",
      "Epoch [66/500], Loss: 1.5026, Accuracy: 0.3817\n",
      "Epoch [67/500], Loss: 1.4940, Accuracy: 0.3845\n",
      "Epoch [68/500], Loss: 1.5002, Accuracy: 0.3837\n",
      "Epoch [69/500], Loss: 1.4993, Accuracy: 0.3813\n",
      "Epoch [70/500], Loss: 1.4902, Accuracy: 0.3837\n",
      "Epoch [71/500], Loss: 1.4979, Accuracy: 0.3847\n",
      "Epoch [72/500], Loss: 1.4934, Accuracy: 0.3857\n",
      "Epoch [73/500], Loss: 1.5010, Accuracy: 0.3830\n",
      "Epoch [74/500], Loss: 1.4932, Accuracy: 0.3867\n",
      "Epoch [75/500], Loss: 1.4952, Accuracy: 0.3864\n",
      "Epoch [76/500], Loss: 1.4939, Accuracy: 0.3874\n",
      "Epoch [77/500], Loss: 1.4940, Accuracy: 0.3887\n",
      "Epoch [78/500], Loss: 1.4851, Accuracy: 0.3875\n",
      "Epoch [79/500], Loss: 1.4926, Accuracy: 0.3892\n",
      "Epoch [80/500], Loss: 1.4929, Accuracy: 0.3885\n",
      "Epoch [81/500], Loss: 1.4855, Accuracy: 0.3892\n",
      "Epoch [82/500], Loss: 1.4904, Accuracy: 0.3882\n",
      "Epoch [83/500], Loss: 1.4909, Accuracy: 0.3892\n",
      "Epoch [84/500], Loss: 1.4849, Accuracy: 0.3894\n",
      "Epoch [85/500], Loss: 1.4881, Accuracy: 0.3907\n",
      "Epoch [86/500], Loss: 1.4847, Accuracy: 0.3914\n",
      "Epoch [87/500], Loss: 1.4848, Accuracy: 0.3894\n",
      "Epoch [88/500], Loss: 1.4844, Accuracy: 0.3912\n",
      "Epoch [89/500], Loss: 1.4853, Accuracy: 0.3909\n",
      "Epoch [90/500], Loss: 1.4867, Accuracy: 0.3926\n",
      "Epoch [91/500], Loss: 1.4864, Accuracy: 0.3907\n",
      "Epoch [92/500], Loss: 1.4764, Accuracy: 0.3912\n",
      "Epoch [93/500], Loss: 1.4835, Accuracy: 0.3956\n",
      "Epoch [94/500], Loss: 1.4810, Accuracy: 0.3949\n",
      "Epoch [95/500], Loss: 1.4808, Accuracy: 0.3938\n",
      "Epoch [96/500], Loss: 1.4796, Accuracy: 0.3946\n",
      "Epoch [97/500], Loss: 1.4810, Accuracy: 0.3948\n",
      "Epoch [98/500], Loss: 1.4809, Accuracy: 0.3938\n",
      "Epoch [99/500], Loss: 1.4802, Accuracy: 0.3954\n",
      "Epoch [100/500], Loss: 1.4713, Accuracy: 0.3938\n",
      "Epoch [101/500], Loss: 1.4707, Accuracy: 0.3953\n",
      "Epoch [102/500], Loss: 1.4760, Accuracy: 0.3976\n",
      "Epoch [103/500], Loss: 1.4792, Accuracy: 0.3959\n",
      "Epoch [104/500], Loss: 1.4823, Accuracy: 0.3978\n",
      "Epoch [105/500], Loss: 1.4723, Accuracy: 0.3981\n",
      "Epoch [106/500], Loss: 1.4762, Accuracy: 0.3985\n",
      "Epoch [107/500], Loss: 1.4810, Accuracy: 0.3988\n",
      "Epoch [108/500], Loss: 1.4733, Accuracy: 0.3981\n",
      "Epoch [109/500], Loss: 1.4709, Accuracy: 0.3988\n",
      "Epoch [110/500], Loss: 1.4758, Accuracy: 0.3998\n",
      "Epoch [111/500], Loss: 1.4695, Accuracy: 0.3959\n",
      "Epoch [112/500], Loss: 1.4694, Accuracy: 0.3991\n",
      "Epoch [113/500], Loss: 1.4657, Accuracy: 0.3998\n",
      "Epoch [114/500], Loss: 1.4707, Accuracy: 0.4003\n",
      "Epoch [115/500], Loss: 1.4699, Accuracy: 0.4006\n",
      "Epoch [116/500], Loss: 1.4686, Accuracy: 0.4005\n",
      "Epoch [117/500], Loss: 1.4704, Accuracy: 0.4016\n",
      "Epoch [118/500], Loss: 1.4676, Accuracy: 0.4000\n",
      "Epoch [119/500], Loss: 1.4611, Accuracy: 0.4011\n",
      "Epoch [120/500], Loss: 1.4675, Accuracy: 0.4003\n",
      "Epoch [121/500], Loss: 1.4688, Accuracy: 0.4001\n",
      "Epoch [122/500], Loss: 1.4667, Accuracy: 0.4003\n",
      "Epoch [123/500], Loss: 1.4643, Accuracy: 0.4010\n",
      "Epoch [124/500], Loss: 1.4680, Accuracy: 0.4008\n",
      "Epoch [125/500], Loss: 1.4661, Accuracy: 0.4016\n",
      "Epoch [126/500], Loss: 1.4626, Accuracy: 0.4005\n",
      "Epoch [127/500], Loss: 1.4629, Accuracy: 0.4011\n",
      "Epoch [128/500], Loss: 1.4585, Accuracy: 0.4023\n",
      "Epoch [129/500], Loss: 1.4662, Accuracy: 0.4023\n",
      "Epoch [130/500], Loss: 1.4604, Accuracy: 0.4015\n",
      "Epoch [131/500], Loss: 1.4570, Accuracy: 0.4033\n",
      "Epoch [132/500], Loss: 1.4564, Accuracy: 0.4006\n",
      "Epoch [133/500], Loss: 1.4635, Accuracy: 0.4018\n",
      "Epoch [134/500], Loss: 1.4553, Accuracy: 0.4035\n",
      "Epoch [135/500], Loss: 1.4548, Accuracy: 0.4022\n",
      "Epoch [136/500], Loss: 1.4565, Accuracy: 0.4043\n",
      "Epoch [137/500], Loss: 1.4600, Accuracy: 0.4030\n",
      "Epoch [138/500], Loss: 1.4599, Accuracy: 0.4032\n",
      "Epoch [139/500], Loss: 1.4597, Accuracy: 0.4032\n",
      "Epoch [140/500], Loss: 1.4637, Accuracy: 0.4035\n",
      "Epoch [141/500], Loss: 1.4566, Accuracy: 0.4058\n",
      "Epoch [142/500], Loss: 1.4504, Accuracy: 0.4040\n",
      "Epoch [143/500], Loss: 1.4550, Accuracy: 0.4065\n",
      "Epoch [144/500], Loss: 1.4594, Accuracy: 0.4055\n",
      "Epoch [145/500], Loss: 1.4547, Accuracy: 0.4043\n",
      "Epoch [146/500], Loss: 1.4541, Accuracy: 0.4057\n",
      "Epoch [147/500], Loss: 1.4582, Accuracy: 0.4057\n",
      "Epoch [148/500], Loss: 1.4477, Accuracy: 0.4062\n",
      "Epoch [149/500], Loss: 1.4480, Accuracy: 0.4058\n",
      "Epoch [150/500], Loss: 1.4526, Accuracy: 0.4067\n",
      "Epoch [151/500], Loss: 1.4499, Accuracy: 0.4063\n",
      "Epoch [152/500], Loss: 1.4534, Accuracy: 0.4075\n",
      "Epoch [153/500], Loss: 1.4470, Accuracy: 0.4065\n",
      "Epoch [154/500], Loss: 1.4551, Accuracy: 0.4087\n",
      "Epoch [155/500], Loss: 1.4500, Accuracy: 0.4084\n",
      "Epoch [156/500], Loss: 1.4494, Accuracy: 0.4092\n",
      "Epoch [157/500], Loss: 1.4449, Accuracy: 0.4090\n",
      "Epoch [158/500], Loss: 1.4512, Accuracy: 0.4089\n",
      "Epoch [159/500], Loss: 1.4508, Accuracy: 0.4094\n",
      "Epoch [160/500], Loss: 1.4460, Accuracy: 0.4102\n",
      "Epoch [161/500], Loss: 1.4537, Accuracy: 0.4104\n",
      "Epoch [162/500], Loss: 1.4536, Accuracy: 0.4107\n",
      "Epoch [163/500], Loss: 1.4500, Accuracy: 0.4100\n",
      "Epoch [164/500], Loss: 1.4457, Accuracy: 0.4116\n",
      "Epoch [165/500], Loss: 1.4483, Accuracy: 0.4104\n",
      "Epoch [166/500], Loss: 1.4490, Accuracy: 0.4092\n",
      "Epoch [167/500], Loss: 1.4495, Accuracy: 0.4100\n",
      "Epoch [168/500], Loss: 1.4480, Accuracy: 0.4116\n",
      "Epoch [169/500], Loss: 1.4475, Accuracy: 0.4099\n",
      "Epoch [170/500], Loss: 1.4430, Accuracy: 0.4131\n",
      "Epoch [171/500], Loss: 1.4461, Accuracy: 0.4092\n",
      "Epoch [172/500], Loss: 1.4467, Accuracy: 0.4114\n",
      "Epoch [173/500], Loss: 1.4458, Accuracy: 0.4114\n",
      "Epoch [174/500], Loss: 1.4588, Accuracy: 0.4119\n",
      "Epoch [175/500], Loss: 1.4465, Accuracy: 0.4124\n",
      "Epoch [176/500], Loss: 1.4401, Accuracy: 0.4105\n",
      "Epoch [177/500], Loss: 1.4439, Accuracy: 0.4127\n",
      "Epoch [178/500], Loss: 1.4439, Accuracy: 0.4117\n",
      "Epoch [179/500], Loss: 1.4440, Accuracy: 0.4126\n",
      "Epoch [180/500], Loss: 1.4386, Accuracy: 0.4127\n",
      "Epoch [181/500], Loss: 1.4443, Accuracy: 0.4126\n",
      "Epoch [182/500], Loss: 1.4544, Accuracy: 0.4126\n",
      "Epoch [183/500], Loss: 1.4500, Accuracy: 0.4134\n",
      "Epoch [184/500], Loss: 1.4405, Accuracy: 0.4139\n",
      "Epoch [185/500], Loss: 1.4393, Accuracy: 0.4151\n",
      "Epoch [186/500], Loss: 1.4386, Accuracy: 0.4142\n",
      "Epoch [187/500], Loss: 1.4436, Accuracy: 0.4147\n",
      "Epoch [188/500], Loss: 1.4359, Accuracy: 0.4149\n",
      "Epoch [189/500], Loss: 1.4413, Accuracy: 0.4137\n",
      "Epoch [190/500], Loss: 1.4327, Accuracy: 0.4151\n",
      "Epoch [191/500], Loss: 1.4431, Accuracy: 0.4151\n",
      "Epoch [192/500], Loss: 1.4394, Accuracy: 0.4132\n",
      "Epoch [193/500], Loss: 1.4349, Accuracy: 0.4161\n",
      "Epoch [194/500], Loss: 1.4383, Accuracy: 0.4168\n",
      "Epoch [195/500], Loss: 1.4331, Accuracy: 0.4149\n",
      "Epoch [196/500], Loss: 1.4441, Accuracy: 0.4142\n",
      "Epoch [197/500], Loss: 1.4363, Accuracy: 0.4156\n",
      "Epoch [198/500], Loss: 1.4327, Accuracy: 0.4159\n",
      "Epoch [199/500], Loss: 1.4381, Accuracy: 0.4164\n",
      "Epoch [200/500], Loss: 1.4384, Accuracy: 0.4173\n",
      "Epoch [201/500], Loss: 1.4359, Accuracy: 0.4164\n",
      "Epoch [202/500], Loss: 1.4368, Accuracy: 0.4181\n",
      "Epoch [203/500], Loss: 1.4315, Accuracy: 0.4159\n",
      "Epoch [204/500], Loss: 1.4441, Accuracy: 0.4164\n",
      "Epoch [205/500], Loss: 1.4374, Accuracy: 0.4188\n",
      "Epoch [206/500], Loss: 1.4331, Accuracy: 0.4159\n",
      "Epoch [207/500], Loss: 1.4305, Accuracy: 0.4176\n",
      "Epoch [208/500], Loss: 1.4351, Accuracy: 0.4174\n",
      "Epoch [209/500], Loss: 1.4367, Accuracy: 0.4184\n",
      "Epoch [210/500], Loss: 1.4321, Accuracy: 0.4189\n",
      "Epoch [211/500], Loss: 1.4353, Accuracy: 0.4184\n",
      "Epoch [212/500], Loss: 1.4323, Accuracy: 0.4191\n",
      "Epoch [213/500], Loss: 1.4337, Accuracy: 0.4205\n",
      "Epoch [214/500], Loss: 1.4373, Accuracy: 0.4206\n",
      "Epoch [215/500], Loss: 1.4307, Accuracy: 0.4201\n",
      "Epoch [216/500], Loss: 1.4313, Accuracy: 0.4205\n",
      "Epoch [217/500], Loss: 1.4284, Accuracy: 0.4216\n",
      "Epoch [218/500], Loss: 1.4324, Accuracy: 0.4206\n",
      "Epoch [219/500], Loss: 1.4301, Accuracy: 0.4213\n",
      "Epoch [220/500], Loss: 1.4254, Accuracy: 0.4196\n",
      "Epoch [221/500], Loss: 1.4298, Accuracy: 0.4203\n",
      "Epoch [222/500], Loss: 1.4325, Accuracy: 0.4200\n",
      "Epoch [223/500], Loss: 1.4324, Accuracy: 0.4208\n",
      "Epoch [224/500], Loss: 1.4293, Accuracy: 0.4210\n",
      "Epoch [225/500], Loss: 1.4297, Accuracy: 0.4216\n",
      "Epoch [226/500], Loss: 1.4256, Accuracy: 0.4201\n",
      "Epoch [227/500], Loss: 1.4262, Accuracy: 0.4208\n",
      "Epoch [228/500], Loss: 1.4302, Accuracy: 0.4216\n",
      "Epoch [229/500], Loss: 1.4255, Accuracy: 0.4225\n",
      "Epoch [230/500], Loss: 1.4271, Accuracy: 0.4216\n",
      "Epoch [231/500], Loss: 1.4295, Accuracy: 0.4201\n",
      "Epoch [232/500], Loss: 1.4260, Accuracy: 0.4200\n",
      "Epoch [233/500], Loss: 1.4277, Accuracy: 0.4220\n",
      "Epoch [234/500], Loss: 1.4202, Accuracy: 0.4205\n",
      "Epoch [235/500], Loss: 1.4240, Accuracy: 0.4195\n",
      "Epoch [236/500], Loss: 1.4252, Accuracy: 0.4220\n",
      "Epoch [237/500], Loss: 1.4275, Accuracy: 0.4218\n",
      "Epoch [238/500], Loss: 1.4244, Accuracy: 0.4218\n",
      "Epoch [239/500], Loss: 1.4265, Accuracy: 0.4216\n",
      "Epoch [240/500], Loss: 1.4278, Accuracy: 0.4223\n",
      "Epoch [241/500], Loss: 1.4247, Accuracy: 0.4226\n",
      "Epoch [242/500], Loss: 1.4243, Accuracy: 0.4221\n",
      "Epoch [243/500], Loss: 1.4228, Accuracy: 0.4221\n",
      "Epoch [244/500], Loss: 1.4228, Accuracy: 0.4221\n",
      "Epoch [245/500], Loss: 1.4257, Accuracy: 0.4225\n",
      "Epoch [246/500], Loss: 1.4253, Accuracy: 0.4223\n",
      "Epoch [247/500], Loss: 1.4223, Accuracy: 0.4216\n",
      "Epoch [248/500], Loss: 1.4202, Accuracy: 0.4228\n",
      "Epoch [249/500], Loss: 1.4221, Accuracy: 0.4216\n",
      "Epoch [250/500], Loss: 1.4159, Accuracy: 0.4206\n",
      "Epoch [251/500], Loss: 1.4193, Accuracy: 0.4218\n",
      "Epoch [252/500], Loss: 1.4242, Accuracy: 0.4218\n",
      "Epoch [253/500], Loss: 1.4215, Accuracy: 0.4225\n",
      "Epoch [254/500], Loss: 1.4219, Accuracy: 0.4216\n",
      "Epoch [255/500], Loss: 1.4187, Accuracy: 0.4225\n",
      "Epoch [256/500], Loss: 1.4187, Accuracy: 0.4216\n",
      "Epoch [257/500], Loss: 1.4245, Accuracy: 0.4218\n",
      "Epoch [258/500], Loss: 1.4199, Accuracy: 0.4211\n",
      "Epoch [259/500], Loss: 1.4212, Accuracy: 0.4216\n",
      "Epoch [260/500], Loss: 1.4172, Accuracy: 0.4238\n",
      "Epoch [261/500], Loss: 1.4238, Accuracy: 0.4218\n",
      "Epoch [262/500], Loss: 1.4126, Accuracy: 0.4233\n",
      "Epoch [263/500], Loss: 1.4210, Accuracy: 0.4225\n",
      "Epoch [264/500], Loss: 1.4187, Accuracy: 0.4242\n",
      "Epoch [265/500], Loss: 1.4149, Accuracy: 0.4218\n",
      "Epoch [266/500], Loss: 1.4130, Accuracy: 0.4233\n",
      "Epoch [267/500], Loss: 1.4163, Accuracy: 0.4216\n",
      "Epoch [268/500], Loss: 1.4119, Accuracy: 0.4233\n",
      "Epoch [269/500], Loss: 1.4189, Accuracy: 0.4228\n",
      "Epoch [270/500], Loss: 1.4157, Accuracy: 0.4231\n",
      "Epoch [271/500], Loss: 1.4144, Accuracy: 0.4235\n",
      "Epoch [272/500], Loss: 1.4150, Accuracy: 0.4226\n",
      "Epoch [273/500], Loss: 1.4237, Accuracy: 0.4243\n",
      "Epoch [274/500], Loss: 1.4212, Accuracy: 0.4243\n",
      "Epoch [275/500], Loss: 1.4159, Accuracy: 0.4242\n",
      "Epoch [276/500], Loss: 1.4124, Accuracy: 0.4225\n",
      "Epoch [277/500], Loss: 1.4186, Accuracy: 0.4237\n",
      "Epoch [278/500], Loss: 1.4108, Accuracy: 0.4233\n",
      "Epoch [279/500], Loss: 1.4168, Accuracy: 0.4240\n",
      "Epoch [280/500], Loss: 1.4075, Accuracy: 0.4233\n",
      "Epoch [281/500], Loss: 1.4144, Accuracy: 0.4233\n",
      "Epoch [282/500], Loss: 1.4114, Accuracy: 0.4258\n",
      "Epoch [283/500], Loss: 1.4170, Accuracy: 0.4228\n",
      "Epoch [284/500], Loss: 1.4119, Accuracy: 0.4238\n",
      "Epoch [285/500], Loss: 1.4060, Accuracy: 0.4230\n",
      "Epoch [286/500], Loss: 1.4121, Accuracy: 0.4237\n",
      "Epoch [287/500], Loss: 1.4192, Accuracy: 0.4237\n",
      "Epoch [288/500], Loss: 1.4058, Accuracy: 0.4242\n",
      "Epoch [289/500], Loss: 1.4064, Accuracy: 0.4225\n",
      "Epoch [290/500], Loss: 1.4060, Accuracy: 0.4238\n",
      "Epoch [291/500], Loss: 1.4135, Accuracy: 0.4230\n",
      "Epoch [292/500], Loss: 1.4099, Accuracy: 0.4233\n",
      "Epoch [293/500], Loss: 1.4142, Accuracy: 0.4253\n",
      "Epoch [294/500], Loss: 1.4092, Accuracy: 0.4243\n",
      "Epoch [295/500], Loss: 1.4135, Accuracy: 0.4240\n",
      "Epoch [296/500], Loss: 1.4083, Accuracy: 0.4248\n",
      "Epoch [297/500], Loss: 1.4072, Accuracy: 0.4258\n",
      "Epoch [298/500], Loss: 1.4128, Accuracy: 0.4240\n",
      "Epoch [299/500], Loss: 1.4083, Accuracy: 0.4265\n",
      "Epoch [300/500], Loss: 1.4120, Accuracy: 0.4237\n",
      "Epoch [301/500], Loss: 1.4027, Accuracy: 0.4237\n",
      "Epoch [302/500], Loss: 1.4098, Accuracy: 0.4252\n",
      "Epoch [303/500], Loss: 1.4177, Accuracy: 0.4247\n",
      "Epoch [304/500], Loss: 1.4025, Accuracy: 0.4262\n",
      "Epoch [305/500], Loss: 1.4079, Accuracy: 0.4253\n",
      "Epoch [306/500], Loss: 1.4056, Accuracy: 0.4247\n",
      "Epoch [307/500], Loss: 1.4076, Accuracy: 0.4247\n",
      "Epoch [308/500], Loss: 1.4086, Accuracy: 0.4235\n",
      "Epoch [309/500], Loss: 1.4164, Accuracy: 0.4255\n",
      "Epoch [310/500], Loss: 1.4050, Accuracy: 0.4243\n",
      "Epoch [311/500], Loss: 1.4084, Accuracy: 0.4252\n",
      "Epoch [312/500], Loss: 1.4088, Accuracy: 0.4248\n",
      "Epoch [313/500], Loss: 1.4138, Accuracy: 0.4265\n",
      "Epoch [314/500], Loss: 1.4053, Accuracy: 0.4257\n",
      "Epoch [315/500], Loss: 1.4053, Accuracy: 0.4253\n",
      "Epoch [316/500], Loss: 1.4069, Accuracy: 0.4258\n",
      "Epoch [317/500], Loss: 1.4077, Accuracy: 0.4255\n",
      "Epoch [318/500], Loss: 1.4049, Accuracy: 0.4248\n",
      "Epoch [319/500], Loss: 1.4081, Accuracy: 0.4258\n",
      "Epoch [320/500], Loss: 1.4110, Accuracy: 0.4273\n",
      "Epoch [321/500], Loss: 1.4060, Accuracy: 0.4282\n",
      "Epoch [322/500], Loss: 1.4090, Accuracy: 0.4279\n",
      "Epoch [323/500], Loss: 1.4002, Accuracy: 0.4287\n",
      "Epoch [324/500], Loss: 1.3991, Accuracy: 0.4273\n",
      "Epoch [325/500], Loss: 1.4036, Accuracy: 0.4282\n",
      "Epoch [326/500], Loss: 1.4057, Accuracy: 0.4279\n",
      "Epoch [327/500], Loss: 1.4017, Accuracy: 0.4284\n",
      "Epoch [328/500], Loss: 1.4024, Accuracy: 0.4277\n",
      "Epoch [329/500], Loss: 1.4022, Accuracy: 0.4270\n",
      "Epoch [330/500], Loss: 1.3982, Accuracy: 0.4277\n",
      "Epoch [331/500], Loss: 1.4022, Accuracy: 0.4275\n",
      "Epoch [332/500], Loss: 1.4002, Accuracy: 0.4284\n",
      "Epoch [333/500], Loss: 1.4022, Accuracy: 0.4280\n",
      "Epoch [334/500], Loss: 1.4030, Accuracy: 0.4300\n",
      "Epoch [335/500], Loss: 1.3972, Accuracy: 0.4284\n",
      "Epoch [336/500], Loss: 1.4054, Accuracy: 0.4285\n",
      "Epoch [337/500], Loss: 1.3998, Accuracy: 0.4295\n",
      "Epoch [338/500], Loss: 1.4037, Accuracy: 0.4289\n",
      "Epoch [339/500], Loss: 1.3999, Accuracy: 0.4294\n",
      "Epoch [340/500], Loss: 1.3948, Accuracy: 0.4297\n",
      "Epoch [341/500], Loss: 1.3989, Accuracy: 0.4295\n",
      "Epoch [342/500], Loss: 1.3973, Accuracy: 0.4292\n",
      "Epoch [343/500], Loss: 1.4016, Accuracy: 0.4289\n",
      "Epoch [344/500], Loss: 1.4013, Accuracy: 0.4294\n",
      "Epoch [345/500], Loss: 1.4012, Accuracy: 0.4290\n",
      "Epoch [346/500], Loss: 1.3958, Accuracy: 0.4290\n",
      "Epoch [347/500], Loss: 1.3941, Accuracy: 0.4284\n",
      "Epoch [348/500], Loss: 1.3974, Accuracy: 0.4304\n",
      "Epoch [349/500], Loss: 1.3989, Accuracy: 0.4289\n",
      "Epoch [350/500], Loss: 1.3966, Accuracy: 0.4307\n",
      "Epoch [351/500], Loss: 1.3984, Accuracy: 0.4295\n",
      "Epoch [352/500], Loss: 1.3959, Accuracy: 0.4292\n",
      "Epoch [353/500], Loss: 1.3997, Accuracy: 0.4295\n",
      "Epoch [354/500], Loss: 1.3940, Accuracy: 0.4309\n",
      "Epoch [355/500], Loss: 1.3953, Accuracy: 0.4299\n",
      "Epoch [356/500], Loss: 1.3980, Accuracy: 0.4294\n",
      "Epoch [357/500], Loss: 1.3974, Accuracy: 0.4310\n",
      "Epoch [358/500], Loss: 1.3960, Accuracy: 0.4324\n",
      "Epoch [359/500], Loss: 1.3971, Accuracy: 0.4302\n",
      "Epoch [360/500], Loss: 1.3979, Accuracy: 0.4310\n",
      "Epoch [361/500], Loss: 1.3941, Accuracy: 0.4295\n",
      "Epoch [362/500], Loss: 1.3969, Accuracy: 0.4310\n",
      "Epoch [363/500], Loss: 1.3885, Accuracy: 0.4310\n",
      "Epoch [364/500], Loss: 1.3923, Accuracy: 0.4304\n",
      "Epoch [365/500], Loss: 1.4063, Accuracy: 0.4314\n",
      "Epoch [366/500], Loss: 1.3912, Accuracy: 0.4312\n",
      "Epoch [367/500], Loss: 1.3913, Accuracy: 0.4317\n",
      "Epoch [368/500], Loss: 1.3952, Accuracy: 0.4324\n",
      "Epoch [369/500], Loss: 1.3917, Accuracy: 0.4336\n",
      "Epoch [370/500], Loss: 1.3934, Accuracy: 0.4331\n",
      "Epoch [371/500], Loss: 1.3917, Accuracy: 0.4312\n",
      "Epoch [372/500], Loss: 1.3927, Accuracy: 0.4315\n",
      "Epoch [373/500], Loss: 1.3932, Accuracy: 0.4337\n",
      "Epoch [374/500], Loss: 1.3954, Accuracy: 0.4314\n",
      "Epoch [375/500], Loss: 1.3961, Accuracy: 0.4317\n",
      "Epoch [376/500], Loss: 1.3898, Accuracy: 0.4327\n",
      "Epoch [377/500], Loss: 1.3924, Accuracy: 0.4324\n",
      "Epoch [378/500], Loss: 1.3919, Accuracy: 0.4322\n",
      "Epoch [379/500], Loss: 1.3889, Accuracy: 0.4336\n",
      "Epoch [380/500], Loss: 1.3925, Accuracy: 0.4334\n",
      "Epoch [381/500], Loss: 1.3976, Accuracy: 0.4324\n",
      "Epoch [382/500], Loss: 1.3914, Accuracy: 0.4326\n",
      "Epoch [383/500], Loss: 1.3913, Accuracy: 0.4336\n",
      "Epoch [384/500], Loss: 1.3946, Accuracy: 0.4331\n",
      "Epoch [385/500], Loss: 1.3864, Accuracy: 0.4342\n",
      "Epoch [386/500], Loss: 1.3949, Accuracy: 0.4334\n",
      "Epoch [387/500], Loss: 1.3910, Accuracy: 0.4342\n",
      "Epoch [388/500], Loss: 1.3832, Accuracy: 0.4337\n",
      "Epoch [389/500], Loss: 1.3866, Accuracy: 0.4336\n",
      "Epoch [390/500], Loss: 1.3820, Accuracy: 0.4346\n",
      "Epoch [391/500], Loss: 1.3887, Accuracy: 0.4347\n",
      "Epoch [392/500], Loss: 1.3855, Accuracy: 0.4347\n",
      "Epoch [393/500], Loss: 1.3835, Accuracy: 0.4347\n",
      "Epoch [394/500], Loss: 1.3884, Accuracy: 0.4336\n",
      "Epoch [395/500], Loss: 1.3855, Accuracy: 0.4341\n",
      "Epoch [396/500], Loss: 1.3889, Accuracy: 0.4349\n",
      "Epoch [397/500], Loss: 1.3860, Accuracy: 0.4356\n",
      "Epoch [398/500], Loss: 1.3872, Accuracy: 0.4342\n",
      "Epoch [399/500], Loss: 1.3860, Accuracy: 0.4357\n",
      "Epoch [400/500], Loss: 1.3844, Accuracy: 0.4347\n",
      "Epoch [401/500], Loss: 1.3816, Accuracy: 0.4346\n",
      "Epoch [402/500], Loss: 1.3884, Accuracy: 0.4364\n",
      "Epoch [403/500], Loss: 1.3847, Accuracy: 0.4337\n",
      "Epoch [404/500], Loss: 1.3950, Accuracy: 0.4361\n",
      "Epoch [405/500], Loss: 1.3859, Accuracy: 0.4349\n",
      "Epoch [406/500], Loss: 1.3876, Accuracy: 0.4363\n",
      "Epoch [407/500], Loss: 1.3850, Accuracy: 0.4363\n",
      "Epoch [408/500], Loss: 1.3945, Accuracy: 0.4356\n",
      "Epoch [409/500], Loss: 1.3889, Accuracy: 0.4369\n",
      "Epoch [410/500], Loss: 1.3829, Accuracy: 0.4374\n",
      "Epoch [411/500], Loss: 1.3824, Accuracy: 0.4363\n",
      "Epoch [412/500], Loss: 1.3823, Accuracy: 0.4374\n",
      "Epoch [413/500], Loss: 1.3856, Accuracy: 0.4369\n",
      "Epoch [414/500], Loss: 1.3836, Accuracy: 0.4368\n",
      "Epoch [415/500], Loss: 1.3841, Accuracy: 0.4359\n",
      "Epoch [416/500], Loss: 1.3840, Accuracy: 0.4378\n",
      "Epoch [417/500], Loss: 1.3847, Accuracy: 0.4366\n",
      "Epoch [418/500], Loss: 1.3820, Accuracy: 0.4373\n",
      "Epoch [419/500], Loss: 1.3793, Accuracy: 0.4371\n",
      "Epoch [420/500], Loss: 1.3764, Accuracy: 0.4381\n",
      "Epoch [421/500], Loss: 1.3804, Accuracy: 0.4378\n",
      "Epoch [422/500], Loss: 1.3764, Accuracy: 0.4376\n",
      "Epoch [423/500], Loss: 1.3823, Accuracy: 0.4363\n",
      "Epoch [424/500], Loss: 1.3848, Accuracy: 0.4388\n",
      "Epoch [425/500], Loss: 1.3815, Accuracy: 0.4368\n",
      "Epoch [426/500], Loss: 1.3818, Accuracy: 0.4373\n",
      "Epoch [427/500], Loss: 1.3769, Accuracy: 0.4374\n",
      "Epoch [428/500], Loss: 1.3820, Accuracy: 0.4381\n",
      "Epoch [429/500], Loss: 1.3741, Accuracy: 0.4369\n",
      "Epoch [430/500], Loss: 1.3835, Accuracy: 0.4381\n",
      "Epoch [431/500], Loss: 1.3852, Accuracy: 0.4368\n",
      "Epoch [432/500], Loss: 1.3797, Accuracy: 0.4378\n",
      "Epoch [433/500], Loss: 1.3736, Accuracy: 0.4371\n",
      "Epoch [434/500], Loss: 1.3789, Accuracy: 0.4374\n",
      "Epoch [435/500], Loss: 1.3784, Accuracy: 0.4374\n",
      "Epoch [436/500], Loss: 1.3744, Accuracy: 0.4389\n",
      "Epoch [437/500], Loss: 1.3790, Accuracy: 0.4383\n",
      "Epoch [438/500], Loss: 1.3824, Accuracy: 0.4386\n",
      "Epoch [439/500], Loss: 1.3794, Accuracy: 0.4396\n",
      "Epoch [440/500], Loss: 1.3738, Accuracy: 0.4386\n",
      "Epoch [441/500], Loss: 1.3831, Accuracy: 0.4391\n",
      "Epoch [442/500], Loss: 1.3853, Accuracy: 0.4398\n",
      "Epoch [443/500], Loss: 1.3751, Accuracy: 0.4386\n",
      "Epoch [444/500], Loss: 1.3755, Accuracy: 0.4388\n",
      "Epoch [445/500], Loss: 1.3876, Accuracy: 0.4401\n",
      "Epoch [446/500], Loss: 1.3725, Accuracy: 0.4393\n",
      "Epoch [447/500], Loss: 1.3798, Accuracy: 0.4379\n",
      "Epoch [448/500], Loss: 1.3769, Accuracy: 0.4376\n",
      "Epoch [449/500], Loss: 1.3819, Accuracy: 0.4394\n",
      "Epoch [450/500], Loss: 1.3780, Accuracy: 0.4403\n",
      "Epoch [451/500], Loss: 1.3771, Accuracy: 0.4394\n",
      "Epoch [452/500], Loss: 1.3775, Accuracy: 0.4401\n",
      "Epoch [453/500], Loss: 1.3733, Accuracy: 0.4379\n",
      "Epoch [454/500], Loss: 1.3793, Accuracy: 0.4401\n",
      "Epoch [455/500], Loss: 1.3734, Accuracy: 0.4411\n",
      "Epoch [456/500], Loss: 1.3770, Accuracy: 0.4403\n",
      "Epoch [457/500], Loss: 1.3773, Accuracy: 0.4383\n",
      "Epoch [458/500], Loss: 1.3748, Accuracy: 0.4393\n",
      "Epoch [459/500], Loss: 1.3785, Accuracy: 0.4403\n",
      "Epoch [460/500], Loss: 1.3760, Accuracy: 0.4396\n",
      "Epoch [461/500], Loss: 1.3743, Accuracy: 0.4406\n",
      "Epoch [462/500], Loss: 1.3678, Accuracy: 0.4394\n",
      "Epoch [463/500], Loss: 1.3747, Accuracy: 0.4401\n",
      "Epoch [464/500], Loss: 1.3783, Accuracy: 0.4396\n",
      "Epoch [465/500], Loss: 1.3751, Accuracy: 0.4405\n",
      "Epoch [466/500], Loss: 1.3746, Accuracy: 0.4415\n",
      "Epoch [467/500], Loss: 1.3795, Accuracy: 0.4401\n",
      "Epoch [468/500], Loss: 1.3680, Accuracy: 0.4401\n",
      "Epoch [469/500], Loss: 1.3775, Accuracy: 0.4396\n",
      "Epoch [470/500], Loss: 1.3734, Accuracy: 0.4396\n",
      "Epoch [471/500], Loss: 1.3728, Accuracy: 0.4406\n",
      "Epoch [472/500], Loss: 1.3730, Accuracy: 0.4398\n",
      "Epoch [473/500], Loss: 1.3733, Accuracy: 0.4410\n",
      "Epoch [474/500], Loss: 1.3724, Accuracy: 0.4396\n",
      "Epoch [475/500], Loss: 1.3795, Accuracy: 0.4398\n",
      "Epoch [476/500], Loss: 1.3703, Accuracy: 0.4416\n",
      "Epoch [477/500], Loss: 1.3718, Accuracy: 0.4389\n",
      "Epoch [478/500], Loss: 1.3731, Accuracy: 0.4398\n",
      "Epoch [479/500], Loss: 1.3715, Accuracy: 0.4393\n",
      "Epoch [480/500], Loss: 1.3750, Accuracy: 0.4420\n",
      "Epoch [481/500], Loss: 1.3704, Accuracy: 0.4401\n",
      "Epoch [482/500], Loss: 1.3703, Accuracy: 0.4403\n",
      "Epoch [483/500], Loss: 1.3712, Accuracy: 0.4398\n",
      "Epoch [484/500], Loss: 1.3747, Accuracy: 0.4401\n",
      "Epoch [485/500], Loss: 1.3703, Accuracy: 0.4416\n",
      "Epoch [486/500], Loss: 1.3703, Accuracy: 0.4426\n",
      "Epoch [487/500], Loss: 1.3695, Accuracy: 0.4406\n",
      "Epoch [488/500], Loss: 1.3747, Accuracy: 0.4408\n",
      "Epoch [489/500], Loss: 1.3658, Accuracy: 0.4411\n",
      "Epoch [490/500], Loss: 1.3692, Accuracy: 0.4413\n",
      "Epoch [491/500], Loss: 1.3710, Accuracy: 0.4410\n",
      "Epoch [492/500], Loss: 1.3651, Accuracy: 0.4428\n",
      "Epoch [493/500], Loss: 1.3757, Accuracy: 0.4428\n",
      "Epoch [494/500], Loss: 1.3651, Accuracy: 0.4403\n",
      "Epoch [495/500], Loss: 1.3703, Accuracy: 0.4410\n",
      "Epoch [496/500], Loss: 1.3687, Accuracy: 0.4423\n",
      "Epoch [497/500], Loss: 1.3710, Accuracy: 0.4450\n",
      "Epoch [498/500], Loss: 1.3684, Accuracy: 0.4428\n",
      "Epoch [499/500], Loss: 1.3693, Accuracy: 0.4410\n",
      "Epoch [500/500], Loss: 1.3710, Accuracy: 0.4413\n"
     ]
    }
   ],
   "source": [
    "# LSTM with Attention\n",
    "lstm_atn_model = LSTMAttention(input_size[0], hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(lstm_atn_model.parameters(), lr=0.001)\n",
    "train(lstm_atn_model, train_loaderLSTM, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.8022, Accuracy: 0.1841\n",
      "Epoch [2/500], Loss: 1.7688, Accuracy: 0.2019\n",
      "Epoch [3/500], Loss: 1.7491, Accuracy: 0.2429\n",
      "Epoch [4/500], Loss: 1.7279, Accuracy: 0.2621\n",
      "Epoch [5/500], Loss: 1.7041, Accuracy: 0.2856\n",
      "Epoch [6/500], Loss: 1.6848, Accuracy: 0.2930\n",
      "Epoch [7/500], Loss: 1.6699, Accuracy: 0.2903\n",
      "Epoch [8/500], Loss: 1.6517, Accuracy: 0.3014\n",
      "Epoch [9/500], Loss: 1.6453, Accuracy: 0.3000\n",
      "Epoch [10/500], Loss: 1.6404, Accuracy: 0.3046\n",
      "Epoch [11/500], Loss: 1.6366, Accuracy: 0.2980\n",
      "Epoch [12/500], Loss: 1.6270, Accuracy: 0.3077\n",
      "Epoch [13/500], Loss: 1.6166, Accuracy: 0.3061\n",
      "Epoch [14/500], Loss: 1.6149, Accuracy: 0.3128\n",
      "Epoch [15/500], Loss: 1.6255, Accuracy: 0.3057\n",
      "Epoch [16/500], Loss: 1.6127, Accuracy: 0.3126\n",
      "Epoch [17/500], Loss: 1.6057, Accuracy: 0.3076\n",
      "Epoch [18/500], Loss: 1.6048, Accuracy: 0.3123\n",
      "Epoch [19/500], Loss: 1.6106, Accuracy: 0.3116\n",
      "Epoch [20/500], Loss: 1.6056, Accuracy: 0.3126\n",
      "Epoch [21/500], Loss: 1.6016, Accuracy: 0.3136\n",
      "Epoch [22/500], Loss: 1.5981, Accuracy: 0.3178\n",
      "Epoch [23/500], Loss: 1.5909, Accuracy: 0.3183\n",
      "Epoch [24/500], Loss: 1.5972, Accuracy: 0.3161\n",
      "Epoch [25/500], Loss: 1.5964, Accuracy: 0.3202\n",
      "Epoch [26/500], Loss: 1.5912, Accuracy: 0.3193\n",
      "Epoch [27/500], Loss: 1.5906, Accuracy: 0.3244\n",
      "Epoch [28/500], Loss: 1.5930, Accuracy: 0.3165\n",
      "Epoch [29/500], Loss: 1.5926, Accuracy: 0.3297\n",
      "Epoch [30/500], Loss: 1.5950, Accuracy: 0.3166\n",
      "Epoch [31/500], Loss: 1.5801, Accuracy: 0.3259\n",
      "Epoch [32/500], Loss: 1.5768, Accuracy: 0.3245\n",
      "Epoch [33/500], Loss: 1.5782, Accuracy: 0.3242\n",
      "Epoch [34/500], Loss: 1.5792, Accuracy: 0.3210\n",
      "Epoch [35/500], Loss: 1.5856, Accuracy: 0.3168\n",
      "Epoch [36/500], Loss: 1.5854, Accuracy: 0.3269\n",
      "Epoch [37/500], Loss: 1.5812, Accuracy: 0.3297\n",
      "Epoch [38/500], Loss: 1.5777, Accuracy: 0.3274\n",
      "Epoch [39/500], Loss: 1.5798, Accuracy: 0.3215\n",
      "Epoch [40/500], Loss: 1.5816, Accuracy: 0.3266\n",
      "Epoch [41/500], Loss: 1.5772, Accuracy: 0.3291\n",
      "Epoch [42/500], Loss: 1.5791, Accuracy: 0.3205\n",
      "Epoch [43/500], Loss: 1.5741, Accuracy: 0.3331\n",
      "Epoch [44/500], Loss: 1.5728, Accuracy: 0.3328\n",
      "Epoch [45/500], Loss: 1.5751, Accuracy: 0.3358\n",
      "Epoch [46/500], Loss: 1.5736, Accuracy: 0.3306\n",
      "Epoch [47/500], Loss: 1.5762, Accuracy: 0.3256\n",
      "Epoch [48/500], Loss: 1.5691, Accuracy: 0.3264\n",
      "Epoch [49/500], Loss: 1.5746, Accuracy: 0.3341\n",
      "Epoch [50/500], Loss: 1.5692, Accuracy: 0.3329\n",
      "Epoch [51/500], Loss: 1.5691, Accuracy: 0.3287\n",
      "Epoch [52/500], Loss: 1.5707, Accuracy: 0.3368\n",
      "Epoch [53/500], Loss: 1.5683, Accuracy: 0.3294\n",
      "Epoch [54/500], Loss: 1.5681, Accuracy: 0.3345\n",
      "Epoch [55/500], Loss: 1.5712, Accuracy: 0.3323\n",
      "Epoch [56/500], Loss: 1.5621, Accuracy: 0.3262\n",
      "Epoch [57/500], Loss: 1.5688, Accuracy: 0.3348\n",
      "Epoch [58/500], Loss: 1.5651, Accuracy: 0.3371\n",
      "Epoch [59/500], Loss: 1.5639, Accuracy: 0.3345\n",
      "Epoch [60/500], Loss: 1.5656, Accuracy: 0.3378\n",
      "Epoch [61/500], Loss: 1.5592, Accuracy: 0.3333\n",
      "Epoch [62/500], Loss: 1.5624, Accuracy: 0.3339\n",
      "Epoch [63/500], Loss: 1.5668, Accuracy: 0.3333\n",
      "Epoch [64/500], Loss: 1.5653, Accuracy: 0.3420\n",
      "Epoch [65/500], Loss: 1.5655, Accuracy: 0.3343\n",
      "Epoch [66/500], Loss: 1.5633, Accuracy: 0.3368\n",
      "Epoch [67/500], Loss: 1.5604, Accuracy: 0.3371\n",
      "Epoch [68/500], Loss: 1.5594, Accuracy: 0.3408\n",
      "Epoch [69/500], Loss: 1.5639, Accuracy: 0.3361\n",
      "Epoch [70/500], Loss: 1.5633, Accuracy: 0.3425\n",
      "Epoch [71/500], Loss: 1.5555, Accuracy: 0.3355\n",
      "Epoch [72/500], Loss: 1.5541, Accuracy: 0.3423\n",
      "Epoch [73/500], Loss: 1.5560, Accuracy: 0.3348\n",
      "Epoch [74/500], Loss: 1.5581, Accuracy: 0.3385\n",
      "Epoch [75/500], Loss: 1.5606, Accuracy: 0.3405\n",
      "Epoch [76/500], Loss: 1.5564, Accuracy: 0.3427\n",
      "Epoch [77/500], Loss: 1.5557, Accuracy: 0.3350\n",
      "Epoch [78/500], Loss: 1.5530, Accuracy: 0.3465\n",
      "Epoch [79/500], Loss: 1.5559, Accuracy: 0.3395\n",
      "Epoch [80/500], Loss: 1.5555, Accuracy: 0.3336\n",
      "Epoch [81/500], Loss: 1.5539, Accuracy: 0.3370\n",
      "Epoch [82/500], Loss: 1.5498, Accuracy: 0.3418\n",
      "Epoch [83/500], Loss: 1.5634, Accuracy: 0.3447\n",
      "Epoch [84/500], Loss: 1.5562, Accuracy: 0.3479\n",
      "Epoch [85/500], Loss: 1.5528, Accuracy: 0.3496\n",
      "Epoch [86/500], Loss: 1.5521, Accuracy: 0.3400\n",
      "Epoch [87/500], Loss: 1.5570, Accuracy: 0.3358\n",
      "Epoch [88/500], Loss: 1.5423, Accuracy: 0.3388\n",
      "Epoch [89/500], Loss: 1.5518, Accuracy: 0.3393\n",
      "Epoch [90/500], Loss: 1.5529, Accuracy: 0.3439\n",
      "Epoch [91/500], Loss: 1.5468, Accuracy: 0.3442\n",
      "Epoch [92/500], Loss: 1.5529, Accuracy: 0.3460\n",
      "Epoch [93/500], Loss: 1.5523, Accuracy: 0.3454\n",
      "Epoch [94/500], Loss: 1.5433, Accuracy: 0.3408\n",
      "Epoch [95/500], Loss: 1.5521, Accuracy: 0.3408\n",
      "Epoch [96/500], Loss: 1.5442, Accuracy: 0.3464\n",
      "Epoch [97/500], Loss: 1.5442, Accuracy: 0.3504\n",
      "Epoch [98/500], Loss: 1.5563, Accuracy: 0.3442\n",
      "Epoch [99/500], Loss: 1.5509, Accuracy: 0.3459\n",
      "Epoch [100/500], Loss: 1.5478, Accuracy: 0.3460\n",
      "Epoch [101/500], Loss: 1.5438, Accuracy: 0.3479\n",
      "Epoch [102/500], Loss: 1.5497, Accuracy: 0.3489\n",
      "Epoch [103/500], Loss: 1.5444, Accuracy: 0.3516\n",
      "Epoch [104/500], Loss: 1.5511, Accuracy: 0.3437\n",
      "Epoch [105/500], Loss: 1.5467, Accuracy: 0.3450\n",
      "Epoch [106/500], Loss: 1.5493, Accuracy: 0.3425\n",
      "Epoch [107/500], Loss: 1.5563, Accuracy: 0.3444\n",
      "Epoch [108/500], Loss: 1.5492, Accuracy: 0.3523\n",
      "Epoch [109/500], Loss: 1.5499, Accuracy: 0.3496\n",
      "Epoch [110/500], Loss: 1.5425, Accuracy: 0.3471\n",
      "Epoch [111/500], Loss: 1.5495, Accuracy: 0.3511\n",
      "Epoch [112/500], Loss: 1.5496, Accuracy: 0.3445\n",
      "Epoch [113/500], Loss: 1.5455, Accuracy: 0.3534\n",
      "Epoch [114/500], Loss: 1.5328, Accuracy: 0.3501\n",
      "Epoch [115/500], Loss: 1.5409, Accuracy: 0.3496\n",
      "Epoch [116/500], Loss: 1.5472, Accuracy: 0.3560\n",
      "Epoch [117/500], Loss: 1.5523, Accuracy: 0.3447\n",
      "Epoch [118/500], Loss: 1.5390, Accuracy: 0.3511\n",
      "Epoch [119/500], Loss: 1.5426, Accuracy: 0.3546\n",
      "Epoch [120/500], Loss: 1.5393, Accuracy: 0.3578\n",
      "Epoch [121/500], Loss: 1.5406, Accuracy: 0.3504\n",
      "Epoch [122/500], Loss: 1.5495, Accuracy: 0.3469\n",
      "Epoch [123/500], Loss: 1.5460, Accuracy: 0.3523\n",
      "Epoch [124/500], Loss: 1.5422, Accuracy: 0.3496\n",
      "Epoch [125/500], Loss: 1.5466, Accuracy: 0.3479\n",
      "Epoch [126/500], Loss: 1.5400, Accuracy: 0.3450\n",
      "Epoch [127/500], Loss: 1.5428, Accuracy: 0.3529\n",
      "Epoch [128/500], Loss: 1.5278, Accuracy: 0.3622\n",
      "Epoch [129/500], Loss: 1.5367, Accuracy: 0.3507\n",
      "Epoch [130/500], Loss: 1.5383, Accuracy: 0.3521\n",
      "Epoch [131/500], Loss: 1.5507, Accuracy: 0.3543\n",
      "Epoch [132/500], Loss: 1.5364, Accuracy: 0.3617\n",
      "Epoch [133/500], Loss: 1.5335, Accuracy: 0.3576\n",
      "Epoch [134/500], Loss: 1.5372, Accuracy: 0.3553\n",
      "Epoch [135/500], Loss: 1.5403, Accuracy: 0.3534\n",
      "Epoch [136/500], Loss: 1.5464, Accuracy: 0.3501\n",
      "Epoch [137/500], Loss: 1.5393, Accuracy: 0.3538\n",
      "Epoch [138/500], Loss: 1.5542, Accuracy: 0.3472\n",
      "Epoch [139/500], Loss: 1.5381, Accuracy: 0.3551\n",
      "Epoch [140/500], Loss: 1.5344, Accuracy: 0.3526\n",
      "Epoch [141/500], Loss: 1.5411, Accuracy: 0.3549\n",
      "Epoch [142/500], Loss: 1.5407, Accuracy: 0.3533\n",
      "Epoch [143/500], Loss: 1.5354, Accuracy: 0.3588\n",
      "Epoch [144/500], Loss: 1.5392, Accuracy: 0.3563\n",
      "Epoch [145/500], Loss: 1.5368, Accuracy: 0.3534\n",
      "Epoch [146/500], Loss: 1.5302, Accuracy: 0.3602\n",
      "Epoch [147/500], Loss: 1.5330, Accuracy: 0.3566\n",
      "Epoch [148/500], Loss: 1.5346, Accuracy: 0.3546\n",
      "Epoch [149/500], Loss: 1.5347, Accuracy: 0.3549\n",
      "Epoch [150/500], Loss: 1.5323, Accuracy: 0.3538\n",
      "Epoch [151/500], Loss: 1.5401, Accuracy: 0.3518\n",
      "Epoch [152/500], Loss: 1.5354, Accuracy: 0.3565\n",
      "Epoch [153/500], Loss: 1.5348, Accuracy: 0.3529\n",
      "Epoch [154/500], Loss: 1.5374, Accuracy: 0.3615\n",
      "Epoch [155/500], Loss: 1.5295, Accuracy: 0.3576\n",
      "Epoch [156/500], Loss: 1.5307, Accuracy: 0.3560\n",
      "Epoch [157/500], Loss: 1.5352, Accuracy: 0.3528\n",
      "Epoch [158/500], Loss: 1.5300, Accuracy: 0.3578\n",
      "Epoch [159/500], Loss: 1.5305, Accuracy: 0.3546\n",
      "Epoch [160/500], Loss: 1.5391, Accuracy: 0.3546\n",
      "Epoch [161/500], Loss: 1.5328, Accuracy: 0.3565\n",
      "Epoch [162/500], Loss: 1.5327, Accuracy: 0.3637\n",
      "Epoch [163/500], Loss: 1.5385, Accuracy: 0.3585\n",
      "Epoch [164/500], Loss: 1.5372, Accuracy: 0.3526\n",
      "Epoch [165/500], Loss: 1.5317, Accuracy: 0.3590\n",
      "Epoch [166/500], Loss: 1.5237, Accuracy: 0.3586\n",
      "Epoch [167/500], Loss: 1.5360, Accuracy: 0.3519\n",
      "Epoch [168/500], Loss: 1.5339, Accuracy: 0.3560\n",
      "Epoch [169/500], Loss: 1.5305, Accuracy: 0.3602\n",
      "Epoch [170/500], Loss: 1.5339, Accuracy: 0.3580\n",
      "Epoch [171/500], Loss: 1.5273, Accuracy: 0.3541\n",
      "Epoch [172/500], Loss: 1.5288, Accuracy: 0.3598\n",
      "Epoch [173/500], Loss: 1.5299, Accuracy: 0.3602\n",
      "Epoch [174/500], Loss: 1.5298, Accuracy: 0.3607\n",
      "Epoch [175/500], Loss: 1.5327, Accuracy: 0.3632\n",
      "Epoch [176/500], Loss: 1.5317, Accuracy: 0.3583\n",
      "Epoch [177/500], Loss: 1.5296, Accuracy: 0.3600\n",
      "Epoch [178/500], Loss: 1.5443, Accuracy: 0.3548\n",
      "Epoch [179/500], Loss: 1.5346, Accuracy: 0.3608\n",
      "Epoch [180/500], Loss: 1.5346, Accuracy: 0.3560\n",
      "Epoch [181/500], Loss: 1.5320, Accuracy: 0.3531\n",
      "Epoch [182/500], Loss: 1.5294, Accuracy: 0.3654\n",
      "Epoch [183/500], Loss: 1.5315, Accuracy: 0.3556\n",
      "Epoch [184/500], Loss: 1.5271, Accuracy: 0.3647\n",
      "Epoch [185/500], Loss: 1.5255, Accuracy: 0.3633\n",
      "Epoch [186/500], Loss: 1.5275, Accuracy: 0.3642\n",
      "Epoch [187/500], Loss: 1.5232, Accuracy: 0.3607\n",
      "Epoch [188/500], Loss: 1.5275, Accuracy: 0.3538\n",
      "Epoch [189/500], Loss: 1.5378, Accuracy: 0.3597\n",
      "Epoch [190/500], Loss: 1.5321, Accuracy: 0.3581\n",
      "Epoch [191/500], Loss: 1.5262, Accuracy: 0.3640\n",
      "Epoch [192/500], Loss: 1.5255, Accuracy: 0.3541\n",
      "Epoch [193/500], Loss: 1.5211, Accuracy: 0.3630\n",
      "Epoch [194/500], Loss: 1.5191, Accuracy: 0.3637\n",
      "Epoch [195/500], Loss: 1.5270, Accuracy: 0.3667\n",
      "Epoch [196/500], Loss: 1.5200, Accuracy: 0.3706\n",
      "Epoch [197/500], Loss: 1.5253, Accuracy: 0.3620\n",
      "Epoch [198/500], Loss: 1.5299, Accuracy: 0.3531\n",
      "Epoch [199/500], Loss: 1.5368, Accuracy: 0.3605\n",
      "Epoch [200/500], Loss: 1.5290, Accuracy: 0.3607\n",
      "Epoch [201/500], Loss: 1.5199, Accuracy: 0.3639\n",
      "Epoch [202/500], Loss: 1.5196, Accuracy: 0.3556\n",
      "Epoch [203/500], Loss: 1.5303, Accuracy: 0.3610\n",
      "Epoch [204/500], Loss: 1.5220, Accuracy: 0.3608\n",
      "Epoch [205/500], Loss: 1.5250, Accuracy: 0.3662\n",
      "Epoch [206/500], Loss: 1.5266, Accuracy: 0.3622\n",
      "Epoch [207/500], Loss: 1.5273, Accuracy: 0.3672\n",
      "Epoch [208/500], Loss: 1.5263, Accuracy: 0.3701\n",
      "Epoch [209/500], Loss: 1.5226, Accuracy: 0.3687\n",
      "Epoch [210/500], Loss: 1.5244, Accuracy: 0.3555\n",
      "Epoch [211/500], Loss: 1.5320, Accuracy: 0.3583\n",
      "Epoch [212/500], Loss: 1.5274, Accuracy: 0.3647\n",
      "Epoch [213/500], Loss: 1.5203, Accuracy: 0.3625\n",
      "Epoch [214/500], Loss: 1.5226, Accuracy: 0.3603\n",
      "Epoch [215/500], Loss: 1.5212, Accuracy: 0.3650\n",
      "Epoch [216/500], Loss: 1.5197, Accuracy: 0.3613\n",
      "Epoch [217/500], Loss: 1.5237, Accuracy: 0.3660\n",
      "Epoch [218/500], Loss: 1.5202, Accuracy: 0.3697\n",
      "Epoch [219/500], Loss: 1.5135, Accuracy: 0.3590\n",
      "Epoch [220/500], Loss: 1.5268, Accuracy: 0.3635\n",
      "Epoch [221/500], Loss: 1.5202, Accuracy: 0.3697\n",
      "Epoch [222/500], Loss: 1.5210, Accuracy: 0.3639\n",
      "Epoch [223/500], Loss: 1.5246, Accuracy: 0.3575\n",
      "Epoch [224/500], Loss: 1.5295, Accuracy: 0.3670\n",
      "Epoch [225/500], Loss: 1.5202, Accuracy: 0.3625\n",
      "Epoch [226/500], Loss: 1.5211, Accuracy: 0.3633\n",
      "Epoch [227/500], Loss: 1.5161, Accuracy: 0.3664\n",
      "Epoch [228/500], Loss: 1.5237, Accuracy: 0.3628\n",
      "Epoch [229/500], Loss: 1.5165, Accuracy: 0.3598\n",
      "Epoch [230/500], Loss: 1.5068, Accuracy: 0.3679\n",
      "Epoch [231/500], Loss: 1.5149, Accuracy: 0.3640\n",
      "Epoch [232/500], Loss: 1.5190, Accuracy: 0.3640\n",
      "Epoch [233/500], Loss: 1.5104, Accuracy: 0.3728\n",
      "Epoch [234/500], Loss: 1.5255, Accuracy: 0.3602\n",
      "Epoch [235/500], Loss: 1.5193, Accuracy: 0.3694\n",
      "Epoch [236/500], Loss: 1.5271, Accuracy: 0.3664\n",
      "Epoch [237/500], Loss: 1.5207, Accuracy: 0.3664\n",
      "Epoch [238/500], Loss: 1.5146, Accuracy: 0.3652\n",
      "Epoch [239/500], Loss: 1.5150, Accuracy: 0.3699\n",
      "Epoch [240/500], Loss: 1.5124, Accuracy: 0.3670\n",
      "Epoch [241/500], Loss: 1.5159, Accuracy: 0.3610\n",
      "Epoch [242/500], Loss: 1.5209, Accuracy: 0.3602\n",
      "Epoch [243/500], Loss: 1.5155, Accuracy: 0.3682\n",
      "Epoch [244/500], Loss: 1.5186, Accuracy: 0.3702\n",
      "Epoch [245/500], Loss: 1.5200, Accuracy: 0.3610\n",
      "Epoch [246/500], Loss: 1.5184, Accuracy: 0.3675\n",
      "Epoch [247/500], Loss: 1.5189, Accuracy: 0.3618\n",
      "Epoch [248/500], Loss: 1.5111, Accuracy: 0.3719\n",
      "Epoch [249/500], Loss: 1.5129, Accuracy: 0.3603\n",
      "Epoch [250/500], Loss: 1.5183, Accuracy: 0.3655\n",
      "Epoch [251/500], Loss: 1.5052, Accuracy: 0.3744\n",
      "Epoch [252/500], Loss: 1.5170, Accuracy: 0.3687\n",
      "Epoch [253/500], Loss: 1.5205, Accuracy: 0.3649\n",
      "Epoch [254/500], Loss: 1.5135, Accuracy: 0.3696\n",
      "Epoch [255/500], Loss: 1.5149, Accuracy: 0.3672\n",
      "Epoch [256/500], Loss: 1.5188, Accuracy: 0.3565\n",
      "Epoch [257/500], Loss: 1.5160, Accuracy: 0.3680\n",
      "Epoch [258/500], Loss: 1.5125, Accuracy: 0.3607\n",
      "Epoch [259/500], Loss: 1.5081, Accuracy: 0.3689\n",
      "Epoch [260/500], Loss: 1.5055, Accuracy: 0.3691\n",
      "Epoch [261/500], Loss: 1.5120, Accuracy: 0.3630\n",
      "Epoch [262/500], Loss: 1.5110, Accuracy: 0.3699\n",
      "Epoch [263/500], Loss: 1.5134, Accuracy: 0.3722\n",
      "Epoch [264/500], Loss: 1.5139, Accuracy: 0.3699\n",
      "Epoch [265/500], Loss: 1.5121, Accuracy: 0.3625\n",
      "Epoch [266/500], Loss: 1.5177, Accuracy: 0.3714\n",
      "Epoch [267/500], Loss: 1.5131, Accuracy: 0.3741\n",
      "Epoch [268/500], Loss: 1.5097, Accuracy: 0.3660\n",
      "Epoch [269/500], Loss: 1.5145, Accuracy: 0.3655\n",
      "Epoch [270/500], Loss: 1.5111, Accuracy: 0.3677\n",
      "Epoch [271/500], Loss: 1.5114, Accuracy: 0.3722\n",
      "Epoch [272/500], Loss: 1.5166, Accuracy: 0.3677\n",
      "Epoch [273/500], Loss: 1.5080, Accuracy: 0.3691\n",
      "Epoch [274/500], Loss: 1.5269, Accuracy: 0.3630\n",
      "Epoch [275/500], Loss: 1.5164, Accuracy: 0.3644\n",
      "Epoch [276/500], Loss: 1.5099, Accuracy: 0.3719\n",
      "Epoch [277/500], Loss: 1.5130, Accuracy: 0.3639\n",
      "Epoch [278/500], Loss: 1.5073, Accuracy: 0.3686\n",
      "Epoch [279/500], Loss: 1.5057, Accuracy: 0.3791\n",
      "Epoch [280/500], Loss: 1.5175, Accuracy: 0.3644\n",
      "Epoch [281/500], Loss: 1.5130, Accuracy: 0.3620\n",
      "Epoch [282/500], Loss: 1.5077, Accuracy: 0.3744\n",
      "Epoch [283/500], Loss: 1.5152, Accuracy: 0.3613\n",
      "Epoch [284/500], Loss: 1.5103, Accuracy: 0.3680\n",
      "Epoch [285/500], Loss: 1.5104, Accuracy: 0.3684\n",
      "Epoch [286/500], Loss: 1.5105, Accuracy: 0.3649\n",
      "Epoch [287/500], Loss: 1.5103, Accuracy: 0.3736\n",
      "Epoch [288/500], Loss: 1.5088, Accuracy: 0.3706\n",
      "Epoch [289/500], Loss: 1.5036, Accuracy: 0.3697\n",
      "Epoch [290/500], Loss: 1.5119, Accuracy: 0.3677\n",
      "Epoch [291/500], Loss: 1.5144, Accuracy: 0.3667\n",
      "Epoch [292/500], Loss: 1.5128, Accuracy: 0.3711\n",
      "Epoch [293/500], Loss: 1.5048, Accuracy: 0.3770\n",
      "Epoch [294/500], Loss: 1.5147, Accuracy: 0.3675\n",
      "Epoch [295/500], Loss: 1.5094, Accuracy: 0.3654\n",
      "Epoch [296/500], Loss: 1.5087, Accuracy: 0.3719\n",
      "Epoch [297/500], Loss: 1.5087, Accuracy: 0.3722\n",
      "Epoch [298/500], Loss: 1.5084, Accuracy: 0.3692\n",
      "Epoch [299/500], Loss: 1.5049, Accuracy: 0.3766\n",
      "Epoch [300/500], Loss: 1.5074, Accuracy: 0.3818\n",
      "Epoch [301/500], Loss: 1.5030, Accuracy: 0.3712\n",
      "Epoch [302/500], Loss: 1.5057, Accuracy: 0.3724\n",
      "Epoch [303/500], Loss: 1.5061, Accuracy: 0.3717\n",
      "Epoch [304/500], Loss: 1.5133, Accuracy: 0.3664\n",
      "Epoch [305/500], Loss: 1.5173, Accuracy: 0.3633\n",
      "Epoch [306/500], Loss: 1.5152, Accuracy: 0.3689\n",
      "Epoch [307/500], Loss: 1.5061, Accuracy: 0.3751\n",
      "Epoch [308/500], Loss: 1.5056, Accuracy: 0.3650\n",
      "Epoch [309/500], Loss: 1.5103, Accuracy: 0.3707\n",
      "Epoch [310/500], Loss: 1.5075, Accuracy: 0.3754\n",
      "Epoch [311/500], Loss: 1.5086, Accuracy: 0.3758\n",
      "Epoch [312/500], Loss: 1.5095, Accuracy: 0.3691\n",
      "Epoch [313/500], Loss: 1.5001, Accuracy: 0.3780\n",
      "Epoch [314/500], Loss: 1.5067, Accuracy: 0.3644\n",
      "Epoch [315/500], Loss: 1.5072, Accuracy: 0.3692\n",
      "Epoch [316/500], Loss: 1.4945, Accuracy: 0.3714\n",
      "Epoch [317/500], Loss: 1.5034, Accuracy: 0.3805\n",
      "Epoch [318/500], Loss: 1.5069, Accuracy: 0.3717\n",
      "Epoch [319/500], Loss: 1.5046, Accuracy: 0.3692\n",
      "Epoch [320/500], Loss: 1.5072, Accuracy: 0.3682\n",
      "Epoch [321/500], Loss: 1.5076, Accuracy: 0.3709\n",
      "Epoch [322/500], Loss: 1.5048, Accuracy: 0.3728\n",
      "Epoch [323/500], Loss: 1.5085, Accuracy: 0.3726\n",
      "Epoch [324/500], Loss: 1.5142, Accuracy: 0.3697\n",
      "Epoch [325/500], Loss: 1.5066, Accuracy: 0.3736\n",
      "Epoch [326/500], Loss: 1.5010, Accuracy: 0.3736\n",
      "Epoch [327/500], Loss: 1.5081, Accuracy: 0.3677\n",
      "Epoch [328/500], Loss: 1.5087, Accuracy: 0.3714\n",
      "Epoch [329/500], Loss: 1.5113, Accuracy: 0.3675\n",
      "Epoch [330/500], Loss: 1.5026, Accuracy: 0.3753\n",
      "Epoch [331/500], Loss: 1.5227, Accuracy: 0.3748\n",
      "Epoch [332/500], Loss: 1.5056, Accuracy: 0.3724\n",
      "Epoch [333/500], Loss: 1.5055, Accuracy: 0.3746\n",
      "Epoch [334/500], Loss: 1.5043, Accuracy: 0.3712\n",
      "Epoch [335/500], Loss: 1.5019, Accuracy: 0.3702\n",
      "Epoch [336/500], Loss: 1.4995, Accuracy: 0.3652\n",
      "Epoch [337/500], Loss: 1.4996, Accuracy: 0.3806\n",
      "Epoch [338/500], Loss: 1.5064, Accuracy: 0.3595\n",
      "Epoch [339/500], Loss: 1.5029, Accuracy: 0.3699\n",
      "Epoch [340/500], Loss: 1.5100, Accuracy: 0.3790\n",
      "Epoch [341/500], Loss: 1.5139, Accuracy: 0.3776\n",
      "Epoch [342/500], Loss: 1.5023, Accuracy: 0.3692\n",
      "Epoch [343/500], Loss: 1.5025, Accuracy: 0.3748\n",
      "Epoch [344/500], Loss: 1.5123, Accuracy: 0.3679\n",
      "Epoch [345/500], Loss: 1.4946, Accuracy: 0.3801\n",
      "Epoch [346/500], Loss: 1.5040, Accuracy: 0.3761\n",
      "Epoch [347/500], Loss: 1.5061, Accuracy: 0.3711\n",
      "Epoch [348/500], Loss: 1.5082, Accuracy: 0.3768\n",
      "Epoch [349/500], Loss: 1.5029, Accuracy: 0.3751\n",
      "Epoch [350/500], Loss: 1.5010, Accuracy: 0.3721\n",
      "Epoch [351/500], Loss: 1.5055, Accuracy: 0.3743\n",
      "Epoch [352/500], Loss: 1.4997, Accuracy: 0.3761\n",
      "Epoch [353/500], Loss: 1.5060, Accuracy: 0.3697\n",
      "Epoch [354/500], Loss: 1.5041, Accuracy: 0.3733\n",
      "Epoch [355/500], Loss: 1.5056, Accuracy: 0.3759\n",
      "Epoch [356/500], Loss: 1.5073, Accuracy: 0.3701\n",
      "Epoch [357/500], Loss: 1.4996, Accuracy: 0.3778\n",
      "Epoch [358/500], Loss: 1.5082, Accuracy: 0.3731\n",
      "Epoch [359/500], Loss: 1.5033, Accuracy: 0.3778\n",
      "Epoch [360/500], Loss: 1.5140, Accuracy: 0.3711\n",
      "Epoch [361/500], Loss: 1.4991, Accuracy: 0.3704\n",
      "Epoch [362/500], Loss: 1.5039, Accuracy: 0.3738\n",
      "Epoch [363/500], Loss: 1.5027, Accuracy: 0.3798\n",
      "Epoch [364/500], Loss: 1.4998, Accuracy: 0.3791\n",
      "Epoch [365/500], Loss: 1.5075, Accuracy: 0.3672\n",
      "Epoch [366/500], Loss: 1.4999, Accuracy: 0.3689\n",
      "Epoch [367/500], Loss: 1.5048, Accuracy: 0.3759\n",
      "Epoch [368/500], Loss: 1.4986, Accuracy: 0.3798\n",
      "Epoch [369/500], Loss: 1.4962, Accuracy: 0.3736\n",
      "Epoch [370/500], Loss: 1.5044, Accuracy: 0.3687\n",
      "Epoch [371/500], Loss: 1.5065, Accuracy: 0.3733\n",
      "Epoch [372/500], Loss: 1.4985, Accuracy: 0.3759\n",
      "Epoch [373/500], Loss: 1.4968, Accuracy: 0.3788\n",
      "Epoch [374/500], Loss: 1.5071, Accuracy: 0.3795\n",
      "Epoch [375/500], Loss: 1.5009, Accuracy: 0.3744\n",
      "Epoch [376/500], Loss: 1.5016, Accuracy: 0.3733\n",
      "Epoch [377/500], Loss: 1.5043, Accuracy: 0.3719\n",
      "Epoch [378/500], Loss: 1.4964, Accuracy: 0.3739\n",
      "Epoch [379/500], Loss: 1.5014, Accuracy: 0.3754\n",
      "Epoch [380/500], Loss: 1.4970, Accuracy: 0.3832\n",
      "Epoch [381/500], Loss: 1.5004, Accuracy: 0.3706\n",
      "Epoch [382/500], Loss: 1.4956, Accuracy: 0.3746\n",
      "Epoch [383/500], Loss: 1.4930, Accuracy: 0.3764\n",
      "Epoch [384/500], Loss: 1.5043, Accuracy: 0.3660\n",
      "Epoch [385/500], Loss: 1.4947, Accuracy: 0.3721\n",
      "Epoch [386/500], Loss: 1.5023, Accuracy: 0.3771\n",
      "Epoch [387/500], Loss: 1.4930, Accuracy: 0.3786\n",
      "Epoch [388/500], Loss: 1.5024, Accuracy: 0.3733\n",
      "Epoch [389/500], Loss: 1.5059, Accuracy: 0.3734\n",
      "Epoch [390/500], Loss: 1.5012, Accuracy: 0.3706\n",
      "Epoch [391/500], Loss: 1.4962, Accuracy: 0.3825\n",
      "Epoch [392/500], Loss: 1.4966, Accuracy: 0.3812\n",
      "Epoch [393/500], Loss: 1.5002, Accuracy: 0.3780\n",
      "Epoch [394/500], Loss: 1.5009, Accuracy: 0.3754\n",
      "Epoch [395/500], Loss: 1.5006, Accuracy: 0.3743\n",
      "Epoch [396/500], Loss: 1.4994, Accuracy: 0.3822\n",
      "Epoch [397/500], Loss: 1.5014, Accuracy: 0.3726\n",
      "Epoch [398/500], Loss: 1.4981, Accuracy: 0.3749\n",
      "Epoch [399/500], Loss: 1.5008, Accuracy: 0.3776\n",
      "Epoch [400/500], Loss: 1.4935, Accuracy: 0.3879\n",
      "Epoch [401/500], Loss: 1.4982, Accuracy: 0.3780\n",
      "Epoch [402/500], Loss: 1.5044, Accuracy: 0.3753\n",
      "Epoch [403/500], Loss: 1.4951, Accuracy: 0.3743\n",
      "Epoch [404/500], Loss: 1.5033, Accuracy: 0.3704\n",
      "Epoch [405/500], Loss: 1.4937, Accuracy: 0.3721\n",
      "Epoch [406/500], Loss: 1.4961, Accuracy: 0.3795\n",
      "Epoch [407/500], Loss: 1.5008, Accuracy: 0.3754\n",
      "Epoch [408/500], Loss: 1.5004, Accuracy: 0.3890\n",
      "Epoch [409/500], Loss: 1.4925, Accuracy: 0.3738\n",
      "Epoch [410/500], Loss: 1.4938, Accuracy: 0.3743\n",
      "Epoch [411/500], Loss: 1.5008, Accuracy: 0.3770\n",
      "Epoch [412/500], Loss: 1.5003, Accuracy: 0.3812\n",
      "Epoch [413/500], Loss: 1.4960, Accuracy: 0.3793\n",
      "Epoch [414/500], Loss: 1.4919, Accuracy: 0.3837\n",
      "Epoch [415/500], Loss: 1.4862, Accuracy: 0.3850\n",
      "Epoch [416/500], Loss: 1.4992, Accuracy: 0.3832\n",
      "Epoch [417/500], Loss: 1.4998, Accuracy: 0.3753\n",
      "Epoch [418/500], Loss: 1.5046, Accuracy: 0.3728\n",
      "Epoch [419/500], Loss: 1.4966, Accuracy: 0.3654\n",
      "Epoch [420/500], Loss: 1.4921, Accuracy: 0.3815\n",
      "Epoch [421/500], Loss: 1.4944, Accuracy: 0.3815\n",
      "Epoch [422/500], Loss: 1.4937, Accuracy: 0.3788\n",
      "Epoch [423/500], Loss: 1.4948, Accuracy: 0.3806\n",
      "Epoch [424/500], Loss: 1.4979, Accuracy: 0.3640\n",
      "Epoch [425/500], Loss: 1.4937, Accuracy: 0.3827\n",
      "Epoch [426/500], Loss: 1.4969, Accuracy: 0.3813\n",
      "Epoch [427/500], Loss: 1.4955, Accuracy: 0.3830\n",
      "Epoch [428/500], Loss: 1.4936, Accuracy: 0.3815\n",
      "Epoch [429/500], Loss: 1.4933, Accuracy: 0.3808\n",
      "Epoch [430/500], Loss: 1.4997, Accuracy: 0.3733\n",
      "Epoch [431/500], Loss: 1.5011, Accuracy: 0.3845\n",
      "Epoch [432/500], Loss: 1.4891, Accuracy: 0.3776\n",
      "Epoch [433/500], Loss: 1.4947, Accuracy: 0.3860\n",
      "Epoch [434/500], Loss: 1.4950, Accuracy: 0.3801\n",
      "Epoch [435/500], Loss: 1.4987, Accuracy: 0.3726\n",
      "Epoch [436/500], Loss: 1.4958, Accuracy: 0.3775\n",
      "Epoch [437/500], Loss: 1.4966, Accuracy: 0.3874\n",
      "Epoch [438/500], Loss: 1.4892, Accuracy: 0.3796\n",
      "Epoch [439/500], Loss: 1.4963, Accuracy: 0.3793\n",
      "Epoch [440/500], Loss: 1.4944, Accuracy: 0.3733\n",
      "Epoch [441/500], Loss: 1.4885, Accuracy: 0.3739\n",
      "Epoch [442/500], Loss: 1.4906, Accuracy: 0.3716\n",
      "Epoch [443/500], Loss: 1.4901, Accuracy: 0.3783\n",
      "Epoch [444/500], Loss: 1.4973, Accuracy: 0.3796\n",
      "Epoch [445/500], Loss: 1.4907, Accuracy: 0.3785\n",
      "Epoch [446/500], Loss: 1.4925, Accuracy: 0.3766\n",
      "Epoch [447/500], Loss: 1.4944, Accuracy: 0.3746\n",
      "Epoch [448/500], Loss: 1.4910, Accuracy: 0.3785\n",
      "Epoch [449/500], Loss: 1.4991, Accuracy: 0.3810\n",
      "Epoch [450/500], Loss: 1.4904, Accuracy: 0.3884\n",
      "Epoch [451/500], Loss: 1.4969, Accuracy: 0.3744\n",
      "Epoch [452/500], Loss: 1.4923, Accuracy: 0.3842\n",
      "Epoch [453/500], Loss: 1.4981, Accuracy: 0.3796\n",
      "Epoch [454/500], Loss: 1.4872, Accuracy: 0.3813\n",
      "Epoch [455/500], Loss: 1.4901, Accuracy: 0.3758\n",
      "Epoch [456/500], Loss: 1.4995, Accuracy: 0.3808\n",
      "Epoch [457/500], Loss: 1.4955, Accuracy: 0.3766\n",
      "Epoch [458/500], Loss: 1.4924, Accuracy: 0.3820\n",
      "Epoch [459/500], Loss: 1.4999, Accuracy: 0.3771\n",
      "Epoch [460/500], Loss: 1.4900, Accuracy: 0.3835\n",
      "Epoch [461/500], Loss: 1.5070, Accuracy: 0.3786\n",
      "Epoch [462/500], Loss: 1.4918, Accuracy: 0.3859\n",
      "Epoch [463/500], Loss: 1.4953, Accuracy: 0.3731\n",
      "Epoch [464/500], Loss: 1.4910, Accuracy: 0.3812\n",
      "Epoch [465/500], Loss: 1.4818, Accuracy: 0.3865\n",
      "Epoch [466/500], Loss: 1.4936, Accuracy: 0.3790\n",
      "Epoch [467/500], Loss: 1.4897, Accuracy: 0.3773\n",
      "Epoch [468/500], Loss: 1.4927, Accuracy: 0.3764\n",
      "Epoch [469/500], Loss: 1.4940, Accuracy: 0.3780\n",
      "Epoch [470/500], Loss: 1.4958, Accuracy: 0.3828\n",
      "Epoch [471/500], Loss: 1.5000, Accuracy: 0.3748\n",
      "Epoch [472/500], Loss: 1.4954, Accuracy: 0.3773\n",
      "Epoch [473/500], Loss: 1.4905, Accuracy: 0.3781\n",
      "Epoch [474/500], Loss: 1.5012, Accuracy: 0.3736\n",
      "Epoch [475/500], Loss: 1.4894, Accuracy: 0.3808\n",
      "Epoch [476/500], Loss: 1.4923, Accuracy: 0.3763\n",
      "Epoch [477/500], Loss: 1.4900, Accuracy: 0.3865\n",
      "Epoch [478/500], Loss: 1.4959, Accuracy: 0.3731\n",
      "Epoch [479/500], Loss: 1.4881, Accuracy: 0.3820\n",
      "Epoch [480/500], Loss: 1.4871, Accuracy: 0.3756\n",
      "Epoch [481/500], Loss: 1.4921, Accuracy: 0.3791\n",
      "Epoch [482/500], Loss: 1.4911, Accuracy: 0.3812\n",
      "Epoch [483/500], Loss: 1.4941, Accuracy: 0.3766\n",
      "Epoch [484/500], Loss: 1.4937, Accuracy: 0.3815\n",
      "Epoch [485/500], Loss: 1.4923, Accuracy: 0.3835\n",
      "Epoch [486/500], Loss: 1.4922, Accuracy: 0.3800\n",
      "Epoch [487/500], Loss: 1.4934, Accuracy: 0.3808\n",
      "Epoch [488/500], Loss: 1.4834, Accuracy: 0.3830\n",
      "Epoch [489/500], Loss: 1.4881, Accuracy: 0.3721\n",
      "Epoch [490/500], Loss: 1.4868, Accuracy: 0.3776\n",
      "Epoch [491/500], Loss: 1.4969, Accuracy: 0.3818\n",
      "Epoch [492/500], Loss: 1.4919, Accuracy: 0.3778\n",
      "Epoch [493/500], Loss: 1.4893, Accuracy: 0.3786\n",
      "Epoch [494/500], Loss: 1.4923, Accuracy: 0.3793\n",
      "Epoch [495/500], Loss: 1.4841, Accuracy: 0.3887\n",
      "Epoch [496/500], Loss: 1.4913, Accuracy: 0.3820\n",
      "Epoch [497/500], Loss: 1.4907, Accuracy: 0.3770\n",
      "Epoch [498/500], Loss: 1.4848, Accuracy: 0.3867\n",
      "Epoch [499/500], Loss: 1.4873, Accuracy: 0.3815\n",
      "Epoch [500/500], Loss: 1.4906, Accuracy: 0.3806\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network\n",
    "cnn_model = CNNModel(input_size[0],num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(cnn_model.parameters(), lr=0.001)\n",
    "train(cnn_model, train_loaderCNN, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.7491, Accuracy: 0.2661\n",
      "Epoch [2/500], Loss: 1.6718, Accuracy: 0.3168\n",
      "Epoch [3/500], Loss: 1.6445, Accuracy: 0.3287\n",
      "Epoch [4/500], Loss: 1.6264, Accuracy: 0.3358\n",
      "Epoch [5/500], Loss: 1.6103, Accuracy: 0.3418\n",
      "Epoch [6/500], Loss: 1.5989, Accuracy: 0.3447\n",
      "Epoch [7/500], Loss: 1.5937, Accuracy: 0.3437\n",
      "Epoch [8/500], Loss: 1.5849, Accuracy: 0.3568\n",
      "Epoch [9/500], Loss: 1.5758, Accuracy: 0.3555\n",
      "Epoch [10/500], Loss: 1.5721, Accuracy: 0.3585\n",
      "Epoch [11/500], Loss: 1.5666, Accuracy: 0.3630\n",
      "Epoch [12/500], Loss: 1.5636, Accuracy: 0.3603\n",
      "Epoch [13/500], Loss: 1.5584, Accuracy: 0.3659\n",
      "Epoch [14/500], Loss: 1.5592, Accuracy: 0.3633\n",
      "Epoch [15/500], Loss: 1.5542, Accuracy: 0.3684\n",
      "Epoch [16/500], Loss: 1.5505, Accuracy: 0.3702\n",
      "Epoch [17/500], Loss: 1.5555, Accuracy: 0.3716\n",
      "Epoch [18/500], Loss: 1.5551, Accuracy: 0.3704\n",
      "Epoch [19/500], Loss: 1.5461, Accuracy: 0.3748\n",
      "Epoch [20/500], Loss: 1.5411, Accuracy: 0.3699\n",
      "Epoch [21/500], Loss: 1.5435, Accuracy: 0.3741\n",
      "Epoch [22/500], Loss: 1.5431, Accuracy: 0.3808\n",
      "Epoch [23/500], Loss: 1.5417, Accuracy: 0.3722\n",
      "Epoch [24/500], Loss: 1.5321, Accuracy: 0.3775\n",
      "Epoch [25/500], Loss: 1.5361, Accuracy: 0.3766\n",
      "Epoch [26/500], Loss: 1.5356, Accuracy: 0.3768\n",
      "Epoch [27/500], Loss: 1.5406, Accuracy: 0.3780\n",
      "Epoch [28/500], Loss: 1.5288, Accuracy: 0.3793\n",
      "Epoch [29/500], Loss: 1.5367, Accuracy: 0.3815\n",
      "Epoch [30/500], Loss: 1.5279, Accuracy: 0.3806\n",
      "Epoch [31/500], Loss: 1.5281, Accuracy: 0.3788\n",
      "Epoch [32/500], Loss: 1.5290, Accuracy: 0.3768\n",
      "Epoch [33/500], Loss: 1.5256, Accuracy: 0.3828\n",
      "Epoch [34/500], Loss: 1.5269, Accuracy: 0.3806\n",
      "Epoch [35/500], Loss: 1.5213, Accuracy: 0.3803\n",
      "Epoch [36/500], Loss: 1.5210, Accuracy: 0.3842\n",
      "Epoch [37/500], Loss: 1.5176, Accuracy: 0.3827\n",
      "Epoch [38/500], Loss: 1.5199, Accuracy: 0.3843\n",
      "Epoch [39/500], Loss: 1.5188, Accuracy: 0.3820\n",
      "Epoch [40/500], Loss: 1.5183, Accuracy: 0.3835\n",
      "Epoch [41/500], Loss: 1.5173, Accuracy: 0.3827\n",
      "Epoch [42/500], Loss: 1.5126, Accuracy: 0.3848\n",
      "Epoch [43/500], Loss: 1.5110, Accuracy: 0.3820\n",
      "Epoch [44/500], Loss: 1.5147, Accuracy: 0.3872\n",
      "Epoch [45/500], Loss: 1.5136, Accuracy: 0.3885\n",
      "Epoch [46/500], Loss: 1.5137, Accuracy: 0.3855\n",
      "Epoch [47/500], Loss: 1.5112, Accuracy: 0.3855\n",
      "Epoch [48/500], Loss: 1.5155, Accuracy: 0.3864\n",
      "Epoch [49/500], Loss: 1.5098, Accuracy: 0.3880\n",
      "Epoch [50/500], Loss: 1.5064, Accuracy: 0.3874\n",
      "Epoch [51/500], Loss: 1.5111, Accuracy: 0.3889\n",
      "Epoch [52/500], Loss: 1.5066, Accuracy: 0.3877\n",
      "Epoch [53/500], Loss: 1.5020, Accuracy: 0.3875\n",
      "Epoch [54/500], Loss: 1.5080, Accuracy: 0.3875\n",
      "Epoch [55/500], Loss: 1.5033, Accuracy: 0.3879\n",
      "Epoch [56/500], Loss: 1.5078, Accuracy: 0.3902\n",
      "Epoch [57/500], Loss: 1.5060, Accuracy: 0.3902\n",
      "Epoch [58/500], Loss: 1.5026, Accuracy: 0.3877\n",
      "Epoch [59/500], Loss: 1.5007, Accuracy: 0.3901\n",
      "Epoch [60/500], Loss: 1.5100, Accuracy: 0.3901\n",
      "Epoch [61/500], Loss: 1.5031, Accuracy: 0.3909\n",
      "Epoch [62/500], Loss: 1.4991, Accuracy: 0.3911\n",
      "Epoch [63/500], Loss: 1.5004, Accuracy: 0.3907\n",
      "Epoch [64/500], Loss: 1.4955, Accuracy: 0.3922\n",
      "Epoch [65/500], Loss: 1.4975, Accuracy: 0.3909\n",
      "Epoch [66/500], Loss: 1.4954, Accuracy: 0.3902\n",
      "Epoch [67/500], Loss: 1.4962, Accuracy: 0.3922\n",
      "Epoch [68/500], Loss: 1.5001, Accuracy: 0.3909\n",
      "Epoch [69/500], Loss: 1.4970, Accuracy: 0.3907\n",
      "Epoch [70/500], Loss: 1.4985, Accuracy: 0.3916\n",
      "Epoch [71/500], Loss: 1.4944, Accuracy: 0.3934\n",
      "Epoch [72/500], Loss: 1.4969, Accuracy: 0.3901\n",
      "Epoch [73/500], Loss: 1.4924, Accuracy: 0.3939\n",
      "Epoch [74/500], Loss: 1.4916, Accuracy: 0.3922\n",
      "Epoch [75/500], Loss: 1.4984, Accuracy: 0.3941\n",
      "Epoch [76/500], Loss: 1.4939, Accuracy: 0.3934\n",
      "Epoch [77/500], Loss: 1.4910, Accuracy: 0.3949\n",
      "Epoch [78/500], Loss: 1.4890, Accuracy: 0.3931\n",
      "Epoch [79/500], Loss: 1.4872, Accuracy: 0.3926\n",
      "Epoch [80/500], Loss: 1.4923, Accuracy: 0.3956\n",
      "Epoch [81/500], Loss: 1.4888, Accuracy: 0.3958\n",
      "Epoch [82/500], Loss: 1.4883, Accuracy: 0.3934\n",
      "Epoch [83/500], Loss: 1.4874, Accuracy: 0.3904\n",
      "Epoch [84/500], Loss: 1.4860, Accuracy: 0.3941\n",
      "Epoch [85/500], Loss: 1.4870, Accuracy: 0.3959\n",
      "Epoch [86/500], Loss: 1.4868, Accuracy: 0.3943\n",
      "Epoch [87/500], Loss: 1.4795, Accuracy: 0.3943\n",
      "Epoch [88/500], Loss: 1.4856, Accuracy: 0.3953\n",
      "Epoch [89/500], Loss: 1.4809, Accuracy: 0.3958\n",
      "Epoch [90/500], Loss: 1.4845, Accuracy: 0.3939\n",
      "Epoch [91/500], Loss: 1.4831, Accuracy: 0.3986\n",
      "Epoch [92/500], Loss: 1.4844, Accuracy: 0.3954\n",
      "Epoch [93/500], Loss: 1.4829, Accuracy: 0.3966\n",
      "Epoch [94/500], Loss: 1.4809, Accuracy: 0.3971\n",
      "Epoch [95/500], Loss: 1.4825, Accuracy: 0.3958\n",
      "Epoch [96/500], Loss: 1.4780, Accuracy: 0.3964\n",
      "Epoch [97/500], Loss: 1.4815, Accuracy: 0.3959\n",
      "Epoch [98/500], Loss: 1.4808, Accuracy: 0.3988\n",
      "Epoch [99/500], Loss: 1.4773, Accuracy: 0.3988\n",
      "Epoch [100/500], Loss: 1.4802, Accuracy: 0.3954\n",
      "Epoch [101/500], Loss: 1.4772, Accuracy: 0.3974\n",
      "Epoch [102/500], Loss: 1.4816, Accuracy: 0.3983\n",
      "Epoch [103/500], Loss: 1.4874, Accuracy: 0.3976\n",
      "Epoch [104/500], Loss: 1.4781, Accuracy: 0.3991\n",
      "Epoch [105/500], Loss: 1.4762, Accuracy: 0.3976\n",
      "Epoch [106/500], Loss: 1.4809, Accuracy: 0.3988\n",
      "Epoch [107/500], Loss: 1.4808, Accuracy: 0.3990\n",
      "Epoch [108/500], Loss: 1.4758, Accuracy: 0.3996\n",
      "Epoch [109/500], Loss: 1.4744, Accuracy: 0.3980\n",
      "Epoch [110/500], Loss: 1.4762, Accuracy: 0.3986\n",
      "Epoch [111/500], Loss: 1.4754, Accuracy: 0.4003\n",
      "Epoch [112/500], Loss: 1.4769, Accuracy: 0.4003\n",
      "Epoch [113/500], Loss: 1.4800, Accuracy: 0.3990\n",
      "Epoch [114/500], Loss: 1.4763, Accuracy: 0.4006\n",
      "Epoch [115/500], Loss: 1.4832, Accuracy: 0.4010\n",
      "Epoch [116/500], Loss: 1.4708, Accuracy: 0.3983\n",
      "Epoch [117/500], Loss: 1.4729, Accuracy: 0.4008\n",
      "Epoch [118/500], Loss: 1.4750, Accuracy: 0.3988\n",
      "Epoch [119/500], Loss: 1.4844, Accuracy: 0.4020\n",
      "Epoch [120/500], Loss: 1.4776, Accuracy: 0.4010\n",
      "Epoch [121/500], Loss: 1.4756, Accuracy: 0.3996\n",
      "Epoch [122/500], Loss: 1.4728, Accuracy: 0.3996\n",
      "Epoch [123/500], Loss: 1.4716, Accuracy: 0.4020\n",
      "Epoch [124/500], Loss: 1.4681, Accuracy: 0.4016\n",
      "Epoch [125/500], Loss: 1.4707, Accuracy: 0.4006\n",
      "Epoch [126/500], Loss: 1.4664, Accuracy: 0.4015\n",
      "Epoch [127/500], Loss: 1.4669, Accuracy: 0.4018\n",
      "Epoch [128/500], Loss: 1.4682, Accuracy: 0.4000\n",
      "Epoch [129/500], Loss: 1.4679, Accuracy: 0.4010\n",
      "Epoch [130/500], Loss: 1.4701, Accuracy: 0.4018\n",
      "Epoch [131/500], Loss: 1.4684, Accuracy: 0.4006\n",
      "Epoch [132/500], Loss: 1.4691, Accuracy: 0.4023\n",
      "Epoch [133/500], Loss: 1.4700, Accuracy: 0.4010\n",
      "Epoch [134/500], Loss: 1.4640, Accuracy: 0.4045\n",
      "Epoch [135/500], Loss: 1.4660, Accuracy: 0.4035\n",
      "Epoch [136/500], Loss: 1.4635, Accuracy: 0.4011\n",
      "Epoch [137/500], Loss: 1.4631, Accuracy: 0.4038\n",
      "Epoch [138/500], Loss: 1.4667, Accuracy: 0.4015\n",
      "Epoch [139/500], Loss: 1.4667, Accuracy: 0.4018\n",
      "Epoch [140/500], Loss: 1.4644, Accuracy: 0.4030\n",
      "Epoch [141/500], Loss: 1.4652, Accuracy: 0.4042\n",
      "Epoch [142/500], Loss: 1.4602, Accuracy: 0.4043\n",
      "Epoch [143/500], Loss: 1.4597, Accuracy: 0.4038\n",
      "Epoch [144/500], Loss: 1.4675, Accuracy: 0.4050\n",
      "Epoch [145/500], Loss: 1.4604, Accuracy: 0.4045\n",
      "Epoch [146/500], Loss: 1.4606, Accuracy: 0.4042\n",
      "Epoch [147/500], Loss: 1.4600, Accuracy: 0.4050\n",
      "Epoch [148/500], Loss: 1.4613, Accuracy: 0.4043\n",
      "Epoch [149/500], Loss: 1.4630, Accuracy: 0.4022\n",
      "Epoch [150/500], Loss: 1.4637, Accuracy: 0.4079\n",
      "Epoch [151/500], Loss: 1.4572, Accuracy: 0.4055\n",
      "Epoch [152/500], Loss: 1.4649, Accuracy: 0.4047\n",
      "Epoch [153/500], Loss: 1.4608, Accuracy: 0.4070\n",
      "Epoch [154/500], Loss: 1.4613, Accuracy: 0.4069\n",
      "Epoch [155/500], Loss: 1.4620, Accuracy: 0.4065\n",
      "Epoch [156/500], Loss: 1.4576, Accuracy: 0.4060\n",
      "Epoch [157/500], Loss: 1.4608, Accuracy: 0.4067\n",
      "Epoch [158/500], Loss: 1.4610, Accuracy: 0.4062\n",
      "Epoch [159/500], Loss: 1.4618, Accuracy: 0.4060\n",
      "Epoch [160/500], Loss: 1.4586, Accuracy: 0.4057\n",
      "Epoch [161/500], Loss: 1.4604, Accuracy: 0.4053\n",
      "Epoch [162/500], Loss: 1.4580, Accuracy: 0.4070\n",
      "Epoch [163/500], Loss: 1.4599, Accuracy: 0.4069\n",
      "Epoch [164/500], Loss: 1.4606, Accuracy: 0.4089\n",
      "Epoch [165/500], Loss: 1.4589, Accuracy: 0.4067\n",
      "Epoch [166/500], Loss: 1.4554, Accuracy: 0.4079\n",
      "Epoch [167/500], Loss: 1.4539, Accuracy: 0.4070\n",
      "Epoch [168/500], Loss: 1.4499, Accuracy: 0.4074\n",
      "Epoch [169/500], Loss: 1.4599, Accuracy: 0.4080\n",
      "Epoch [170/500], Loss: 1.4526, Accuracy: 0.4079\n",
      "Epoch [171/500], Loss: 1.4529, Accuracy: 0.4070\n",
      "Epoch [172/500], Loss: 1.4558, Accuracy: 0.4094\n",
      "Epoch [173/500], Loss: 1.4530, Accuracy: 0.4080\n",
      "Epoch [174/500], Loss: 1.4515, Accuracy: 0.4074\n",
      "Epoch [175/500], Loss: 1.4520, Accuracy: 0.4089\n",
      "Epoch [176/500], Loss: 1.4508, Accuracy: 0.4087\n",
      "Epoch [177/500], Loss: 1.4563, Accuracy: 0.4087\n",
      "Epoch [178/500], Loss: 1.4511, Accuracy: 0.4092\n",
      "Epoch [179/500], Loss: 1.4533, Accuracy: 0.4095\n",
      "Epoch [180/500], Loss: 1.4550, Accuracy: 0.4105\n",
      "Epoch [181/500], Loss: 1.4488, Accuracy: 0.4084\n",
      "Epoch [182/500], Loss: 1.4561, Accuracy: 0.4092\n",
      "Epoch [183/500], Loss: 1.4542, Accuracy: 0.4100\n",
      "Epoch [184/500], Loss: 1.4534, Accuracy: 0.4107\n",
      "Epoch [185/500], Loss: 1.4550, Accuracy: 0.4084\n",
      "Epoch [186/500], Loss: 1.4504, Accuracy: 0.4116\n",
      "Epoch [187/500], Loss: 1.4480, Accuracy: 0.4122\n",
      "Epoch [188/500], Loss: 1.4534, Accuracy: 0.4111\n",
      "Epoch [189/500], Loss: 1.4567, Accuracy: 0.4085\n",
      "Epoch [190/500], Loss: 1.4520, Accuracy: 0.4102\n",
      "Epoch [191/500], Loss: 1.4512, Accuracy: 0.4094\n",
      "Epoch [192/500], Loss: 1.4514, Accuracy: 0.4092\n",
      "Epoch [193/500], Loss: 1.4467, Accuracy: 0.4099\n",
      "Epoch [194/500], Loss: 1.4581, Accuracy: 0.4109\n",
      "Epoch [195/500], Loss: 1.4444, Accuracy: 0.4102\n",
      "Epoch [196/500], Loss: 1.4436, Accuracy: 0.4122\n",
      "Epoch [197/500], Loss: 1.4516, Accuracy: 0.4107\n",
      "Epoch [198/500], Loss: 1.4504, Accuracy: 0.4117\n",
      "Epoch [199/500], Loss: 1.4477, Accuracy: 0.4129\n",
      "Epoch [200/500], Loss: 1.4446, Accuracy: 0.4111\n",
      "Epoch [201/500], Loss: 1.4462, Accuracy: 0.4136\n",
      "Epoch [202/500], Loss: 1.4588, Accuracy: 0.4089\n",
      "Epoch [203/500], Loss: 1.4504, Accuracy: 0.4116\n",
      "Epoch [204/500], Loss: 1.4475, Accuracy: 0.4092\n",
      "Epoch [205/500], Loss: 1.4494, Accuracy: 0.4119\n",
      "Epoch [206/500], Loss: 1.4477, Accuracy: 0.4134\n",
      "Epoch [207/500], Loss: 1.4579, Accuracy: 0.4117\n",
      "Epoch [208/500], Loss: 1.4437, Accuracy: 0.4132\n",
      "Epoch [209/500], Loss: 1.4422, Accuracy: 0.4137\n",
      "Epoch [210/500], Loss: 1.4505, Accuracy: 0.4136\n",
      "Epoch [211/500], Loss: 1.4448, Accuracy: 0.4121\n",
      "Epoch [212/500], Loss: 1.4463, Accuracy: 0.4131\n",
      "Epoch [213/500], Loss: 1.4449, Accuracy: 0.4126\n",
      "Epoch [214/500], Loss: 1.4414, Accuracy: 0.4129\n",
      "Epoch [215/500], Loss: 1.4493, Accuracy: 0.4116\n",
      "Epoch [216/500], Loss: 1.4444, Accuracy: 0.4139\n",
      "Epoch [217/500], Loss: 1.4495, Accuracy: 0.4132\n",
      "Epoch [218/500], Loss: 1.4460, Accuracy: 0.4137\n",
      "Epoch [219/500], Loss: 1.4467, Accuracy: 0.4144\n",
      "Epoch [220/500], Loss: 1.4408, Accuracy: 0.4131\n",
      "Epoch [221/500], Loss: 1.4482, Accuracy: 0.4134\n",
      "Epoch [222/500], Loss: 1.4475, Accuracy: 0.4137\n",
      "Epoch [223/500], Loss: 1.4465, Accuracy: 0.4124\n",
      "Epoch [224/500], Loss: 1.4477, Accuracy: 0.4146\n",
      "Epoch [225/500], Loss: 1.4456, Accuracy: 0.4141\n",
      "Epoch [226/500], Loss: 1.4445, Accuracy: 0.4144\n",
      "Epoch [227/500], Loss: 1.4456, Accuracy: 0.4144\n",
      "Epoch [228/500], Loss: 1.4521, Accuracy: 0.4141\n",
      "Epoch [229/500], Loss: 1.4462, Accuracy: 0.4151\n",
      "Epoch [230/500], Loss: 1.4468, Accuracy: 0.4163\n",
      "Epoch [231/500], Loss: 1.4462, Accuracy: 0.4141\n",
      "Epoch [232/500], Loss: 1.4422, Accuracy: 0.4154\n",
      "Epoch [233/500], Loss: 1.4412, Accuracy: 0.4139\n",
      "Epoch [234/500], Loss: 1.4506, Accuracy: 0.4149\n",
      "Epoch [235/500], Loss: 1.4435, Accuracy: 0.4151\n",
      "Epoch [236/500], Loss: 1.4411, Accuracy: 0.4153\n",
      "Epoch [237/500], Loss: 1.4432, Accuracy: 0.4161\n",
      "Epoch [238/500], Loss: 1.4402, Accuracy: 0.4163\n",
      "Epoch [239/500], Loss: 1.4433, Accuracy: 0.4166\n",
      "Epoch [240/500], Loss: 1.4465, Accuracy: 0.4164\n",
      "Epoch [241/500], Loss: 1.4380, Accuracy: 0.4163\n",
      "Epoch [242/500], Loss: 1.4390, Accuracy: 0.4134\n",
      "Epoch [243/500], Loss: 1.4409, Accuracy: 0.4159\n",
      "Epoch [244/500], Loss: 1.4391, Accuracy: 0.4163\n",
      "Epoch [245/500], Loss: 1.4349, Accuracy: 0.4164\n",
      "Epoch [246/500], Loss: 1.4381, Accuracy: 0.4154\n",
      "Epoch [247/500], Loss: 1.4408, Accuracy: 0.4169\n",
      "Epoch [248/500], Loss: 1.4391, Accuracy: 0.4153\n",
      "Epoch [249/500], Loss: 1.4395, Accuracy: 0.4173\n",
      "Epoch [250/500], Loss: 1.4416, Accuracy: 0.4168\n",
      "Epoch [251/500], Loss: 1.4384, Accuracy: 0.4164\n",
      "Epoch [252/500], Loss: 1.4392, Accuracy: 0.4161\n",
      "Epoch [253/500], Loss: 1.4460, Accuracy: 0.4166\n",
      "Epoch [254/500], Loss: 1.4398, Accuracy: 0.4164\n",
      "Epoch [255/500], Loss: 1.4346, Accuracy: 0.4176\n",
      "Epoch [256/500], Loss: 1.4392, Accuracy: 0.4173\n",
      "Epoch [257/500], Loss: 1.4486, Accuracy: 0.4166\n",
      "Epoch [258/500], Loss: 1.4379, Accuracy: 0.4166\n",
      "Epoch [259/500], Loss: 1.4392, Accuracy: 0.4173\n",
      "Epoch [260/500], Loss: 1.4438, Accuracy: 0.4188\n",
      "Epoch [261/500], Loss: 1.4401, Accuracy: 0.4181\n",
      "Epoch [262/500], Loss: 1.4376, Accuracy: 0.4176\n",
      "Epoch [263/500], Loss: 1.4341, Accuracy: 0.4164\n",
      "Epoch [264/500], Loss: 1.4322, Accuracy: 0.4176\n",
      "Epoch [265/500], Loss: 1.4316, Accuracy: 0.4191\n",
      "Epoch [266/500], Loss: 1.4364, Accuracy: 0.4188\n",
      "Epoch [267/500], Loss: 1.4407, Accuracy: 0.4184\n",
      "Epoch [268/500], Loss: 1.4401, Accuracy: 0.4178\n",
      "Epoch [269/500], Loss: 1.4335, Accuracy: 0.4178\n",
      "Epoch [270/500], Loss: 1.4401, Accuracy: 0.4183\n",
      "Epoch [271/500], Loss: 1.4370, Accuracy: 0.4163\n",
      "Epoch [272/500], Loss: 1.4418, Accuracy: 0.4181\n",
      "Epoch [273/500], Loss: 1.4385, Accuracy: 0.4179\n",
      "Epoch [274/500], Loss: 1.4367, Accuracy: 0.4161\n",
      "Epoch [275/500], Loss: 1.4373, Accuracy: 0.4181\n",
      "Epoch [276/500], Loss: 1.4371, Accuracy: 0.4178\n",
      "Epoch [277/500], Loss: 1.4387, Accuracy: 0.4158\n",
      "Epoch [278/500], Loss: 1.4316, Accuracy: 0.4173\n",
      "Epoch [279/500], Loss: 1.4360, Accuracy: 0.4183\n",
      "Epoch [280/500], Loss: 1.4383, Accuracy: 0.4174\n",
      "Epoch [281/500], Loss: 1.4357, Accuracy: 0.4183\n",
      "Epoch [282/500], Loss: 1.4381, Accuracy: 0.4191\n",
      "Epoch [283/500], Loss: 1.4375, Accuracy: 0.4179\n",
      "Epoch [284/500], Loss: 1.4392, Accuracy: 0.4178\n",
      "Epoch [285/500], Loss: 1.4349, Accuracy: 0.4181\n",
      "Epoch [286/500], Loss: 1.4325, Accuracy: 0.4198\n",
      "Epoch [287/500], Loss: 1.4381, Accuracy: 0.4193\n",
      "Epoch [288/500], Loss: 1.4318, Accuracy: 0.4186\n",
      "Epoch [289/500], Loss: 1.4346, Accuracy: 0.4188\n",
      "Epoch [290/500], Loss: 1.4367, Accuracy: 0.4206\n",
      "Epoch [291/500], Loss: 1.4333, Accuracy: 0.4183\n",
      "Epoch [292/500], Loss: 1.4347, Accuracy: 0.4188\n",
      "Epoch [293/500], Loss: 1.4364, Accuracy: 0.4191\n",
      "Epoch [294/500], Loss: 1.4324, Accuracy: 0.4186\n",
      "Epoch [295/500], Loss: 1.4345, Accuracy: 0.4181\n",
      "Epoch [296/500], Loss: 1.4345, Accuracy: 0.4159\n",
      "Epoch [297/500], Loss: 1.4383, Accuracy: 0.4206\n",
      "Epoch [298/500], Loss: 1.4362, Accuracy: 0.4191\n",
      "Epoch [299/500], Loss: 1.4387, Accuracy: 0.4186\n",
      "Epoch [300/500], Loss: 1.4311, Accuracy: 0.4181\n",
      "Epoch [301/500], Loss: 1.4318, Accuracy: 0.4191\n",
      "Epoch [302/500], Loss: 1.4365, Accuracy: 0.4195\n",
      "Epoch [303/500], Loss: 1.4345, Accuracy: 0.4195\n",
      "Epoch [304/500], Loss: 1.4364, Accuracy: 0.4188\n",
      "Epoch [305/500], Loss: 1.4309, Accuracy: 0.4195\n",
      "Epoch [306/500], Loss: 1.4347, Accuracy: 0.4188\n",
      "Epoch [307/500], Loss: 1.4321, Accuracy: 0.4178\n",
      "Epoch [308/500], Loss: 1.4323, Accuracy: 0.4213\n",
      "Epoch [309/500], Loss: 1.4395, Accuracy: 0.4208\n",
      "Epoch [310/500], Loss: 1.4274, Accuracy: 0.4213\n",
      "Epoch [311/500], Loss: 1.4323, Accuracy: 0.4188\n",
      "Epoch [312/500], Loss: 1.4349, Accuracy: 0.4208\n",
      "Epoch [313/500], Loss: 1.4366, Accuracy: 0.4210\n",
      "Epoch [314/500], Loss: 1.4360, Accuracy: 0.4213\n",
      "Epoch [315/500], Loss: 1.4282, Accuracy: 0.4213\n",
      "Epoch [316/500], Loss: 1.4367, Accuracy: 0.4203\n",
      "Epoch [317/500], Loss: 1.4272, Accuracy: 0.4193\n",
      "Epoch [318/500], Loss: 1.4315, Accuracy: 0.4205\n",
      "Epoch [319/500], Loss: 1.4323, Accuracy: 0.4211\n",
      "Epoch [320/500], Loss: 1.4302, Accuracy: 0.4201\n",
      "Epoch [321/500], Loss: 1.4317, Accuracy: 0.4206\n",
      "Epoch [322/500], Loss: 1.4261, Accuracy: 0.4206\n",
      "Epoch [323/500], Loss: 1.4283, Accuracy: 0.4213\n",
      "Epoch [324/500], Loss: 1.4296, Accuracy: 0.4203\n",
      "Epoch [325/500], Loss: 1.4427, Accuracy: 0.4218\n",
      "Epoch [326/500], Loss: 1.4299, Accuracy: 0.4220\n",
      "Epoch [327/500], Loss: 1.4362, Accuracy: 0.4230\n",
      "Epoch [328/500], Loss: 1.4291, Accuracy: 0.4205\n",
      "Epoch [329/500], Loss: 1.4267, Accuracy: 0.4206\n",
      "Epoch [330/500], Loss: 1.4260, Accuracy: 0.4215\n",
      "Epoch [331/500], Loss: 1.4399, Accuracy: 0.4216\n",
      "Epoch [332/500], Loss: 1.4312, Accuracy: 0.4228\n",
      "Epoch [333/500], Loss: 1.4288, Accuracy: 0.4230\n",
      "Epoch [334/500], Loss: 1.4305, Accuracy: 0.4223\n",
      "Epoch [335/500], Loss: 1.4240, Accuracy: 0.4215\n",
      "Epoch [336/500], Loss: 1.4317, Accuracy: 0.4203\n",
      "Epoch [337/500], Loss: 1.4306, Accuracy: 0.4231\n",
      "Epoch [338/500], Loss: 1.4230, Accuracy: 0.4218\n",
      "Epoch [339/500], Loss: 1.4306, Accuracy: 0.4215\n",
      "Epoch [340/500], Loss: 1.4290, Accuracy: 0.4210\n",
      "Epoch [341/500], Loss: 1.4294, Accuracy: 0.4218\n",
      "Epoch [342/500], Loss: 1.4246, Accuracy: 0.4220\n",
      "Epoch [343/500], Loss: 1.4332, Accuracy: 0.4216\n",
      "Epoch [344/500], Loss: 1.4284, Accuracy: 0.4225\n",
      "Epoch [345/500], Loss: 1.4255, Accuracy: 0.4211\n",
      "Epoch [346/500], Loss: 1.4377, Accuracy: 0.4221\n",
      "Epoch [347/500], Loss: 1.4291, Accuracy: 0.4201\n",
      "Epoch [348/500], Loss: 1.4263, Accuracy: 0.4226\n",
      "Epoch [349/500], Loss: 1.4278, Accuracy: 0.4231\n",
      "Epoch [350/500], Loss: 1.4262, Accuracy: 0.4215\n",
      "Epoch [351/500], Loss: 1.4362, Accuracy: 0.4223\n",
      "Epoch [352/500], Loss: 1.4224, Accuracy: 0.4206\n",
      "Epoch [353/500], Loss: 1.4280, Accuracy: 0.4225\n",
      "Epoch [354/500], Loss: 1.4250, Accuracy: 0.4233\n",
      "Epoch [355/500], Loss: 1.4289, Accuracy: 0.4221\n",
      "Epoch [356/500], Loss: 1.4283, Accuracy: 0.4223\n",
      "Epoch [357/500], Loss: 1.4302, Accuracy: 0.4215\n",
      "Epoch [358/500], Loss: 1.4270, Accuracy: 0.4220\n",
      "Epoch [359/500], Loss: 1.4270, Accuracy: 0.4221\n",
      "Epoch [360/500], Loss: 1.4241, Accuracy: 0.4228\n",
      "Epoch [361/500], Loss: 1.4240, Accuracy: 0.4225\n",
      "Epoch [362/500], Loss: 1.4336, Accuracy: 0.4231\n",
      "Epoch [363/500], Loss: 1.4344, Accuracy: 0.4238\n",
      "Epoch [364/500], Loss: 1.4338, Accuracy: 0.4223\n",
      "Epoch [365/500], Loss: 1.4382, Accuracy: 0.4231\n",
      "Epoch [366/500], Loss: 1.4293, Accuracy: 0.4237\n",
      "Epoch [367/500], Loss: 1.4250, Accuracy: 0.4213\n",
      "Epoch [368/500], Loss: 1.4257, Accuracy: 0.4247\n",
      "Epoch [369/500], Loss: 1.4255, Accuracy: 0.4226\n",
      "Epoch [370/500], Loss: 1.4301, Accuracy: 0.4221\n",
      "Epoch [371/500], Loss: 1.4235, Accuracy: 0.4230\n",
      "Epoch [372/500], Loss: 1.4233, Accuracy: 0.4225\n",
      "Epoch [373/500], Loss: 1.4264, Accuracy: 0.4248\n",
      "Epoch [374/500], Loss: 1.4290, Accuracy: 0.4216\n",
      "Epoch [375/500], Loss: 1.4245, Accuracy: 0.4240\n",
      "Epoch [376/500], Loss: 1.4216, Accuracy: 0.4225\n",
      "Epoch [377/500], Loss: 1.4228, Accuracy: 0.4242\n",
      "Epoch [378/500], Loss: 1.4261, Accuracy: 0.4247\n",
      "Epoch [379/500], Loss: 1.4269, Accuracy: 0.4231\n",
      "Epoch [380/500], Loss: 1.4231, Accuracy: 0.4235\n",
      "Epoch [381/500], Loss: 1.4270, Accuracy: 0.4242\n",
      "Epoch [382/500], Loss: 1.4215, Accuracy: 0.4233\n",
      "Epoch [383/500], Loss: 1.4259, Accuracy: 0.4243\n",
      "Epoch [384/500], Loss: 1.4226, Accuracy: 0.4247\n",
      "Epoch [385/500], Loss: 1.4204, Accuracy: 0.4252\n",
      "Epoch [386/500], Loss: 1.4209, Accuracy: 0.4231\n",
      "Epoch [387/500], Loss: 1.4181, Accuracy: 0.4242\n",
      "Epoch [388/500], Loss: 1.4287, Accuracy: 0.4245\n",
      "Epoch [389/500], Loss: 1.4257, Accuracy: 0.4267\n",
      "Epoch [390/500], Loss: 1.4242, Accuracy: 0.4247\n",
      "Epoch [391/500], Loss: 1.4221, Accuracy: 0.4245\n",
      "Epoch [392/500], Loss: 1.4195, Accuracy: 0.4245\n",
      "Epoch [393/500], Loss: 1.4248, Accuracy: 0.4243\n",
      "Epoch [394/500], Loss: 1.4206, Accuracy: 0.4237\n",
      "Epoch [395/500], Loss: 1.4281, Accuracy: 0.4240\n",
      "Epoch [396/500], Loss: 1.4236, Accuracy: 0.4240\n",
      "Epoch [397/500], Loss: 1.4244, Accuracy: 0.4240\n",
      "Epoch [398/500], Loss: 1.4253, Accuracy: 0.4260\n",
      "Epoch [399/500], Loss: 1.4222, Accuracy: 0.4240\n",
      "Epoch [400/500], Loss: 1.4193, Accuracy: 0.4238\n",
      "Epoch [401/500], Loss: 1.4271, Accuracy: 0.4253\n",
      "Epoch [402/500], Loss: 1.4224, Accuracy: 0.4242\n",
      "Epoch [403/500], Loss: 1.4236, Accuracy: 0.4231\n",
      "Epoch [404/500], Loss: 1.4230, Accuracy: 0.4226\n",
      "Epoch [405/500], Loss: 1.4178, Accuracy: 0.4267\n",
      "Epoch [406/500], Loss: 1.4259, Accuracy: 0.4258\n",
      "Epoch [407/500], Loss: 1.4226, Accuracy: 0.4228\n",
      "Epoch [408/500], Loss: 1.4249, Accuracy: 0.4240\n",
      "Epoch [409/500], Loss: 1.4174, Accuracy: 0.4253\n",
      "Epoch [410/500], Loss: 1.4189, Accuracy: 0.4248\n",
      "Epoch [411/500], Loss: 1.4217, Accuracy: 0.4253\n",
      "Epoch [412/500], Loss: 1.4196, Accuracy: 0.4262\n",
      "Epoch [413/500], Loss: 1.4221, Accuracy: 0.4242\n",
      "Epoch [414/500], Loss: 1.4249, Accuracy: 0.4267\n",
      "Epoch [415/500], Loss: 1.4262, Accuracy: 0.4245\n",
      "Epoch [416/500], Loss: 1.4237, Accuracy: 0.4235\n",
      "Epoch [417/500], Loss: 1.4216, Accuracy: 0.4265\n",
      "Epoch [418/500], Loss: 1.4206, Accuracy: 0.4247\n",
      "Epoch [419/500], Loss: 1.4228, Accuracy: 0.4245\n",
      "Epoch [420/500], Loss: 1.4189, Accuracy: 0.4250\n",
      "Epoch [421/500], Loss: 1.4207, Accuracy: 0.4248\n",
      "Epoch [422/500], Loss: 1.4179, Accuracy: 0.4273\n",
      "Epoch [423/500], Loss: 1.4186, Accuracy: 0.4262\n",
      "Epoch [424/500], Loss: 1.4252, Accuracy: 0.4252\n",
      "Epoch [425/500], Loss: 1.4238, Accuracy: 0.4272\n",
      "Epoch [426/500], Loss: 1.4207, Accuracy: 0.4263\n",
      "Epoch [427/500], Loss: 1.4262, Accuracy: 0.4248\n",
      "Epoch [428/500], Loss: 1.4227, Accuracy: 0.4257\n",
      "Epoch [429/500], Loss: 1.4248, Accuracy: 0.4257\n",
      "Epoch [430/500], Loss: 1.4221, Accuracy: 0.4253\n",
      "Epoch [431/500], Loss: 1.4198, Accuracy: 0.4263\n",
      "Epoch [432/500], Loss: 1.4213, Accuracy: 0.4272\n",
      "Epoch [433/500], Loss: 1.4153, Accuracy: 0.4257\n",
      "Epoch [434/500], Loss: 1.4186, Accuracy: 0.4272\n",
      "Epoch [435/500], Loss: 1.4191, Accuracy: 0.4257\n",
      "Epoch [436/500], Loss: 1.4186, Accuracy: 0.4263\n",
      "Epoch [437/500], Loss: 1.4231, Accuracy: 0.4262\n",
      "Epoch [438/500], Loss: 1.4205, Accuracy: 0.4255\n",
      "Epoch [439/500], Loss: 1.4209, Accuracy: 0.4257\n",
      "Epoch [440/500], Loss: 1.4193, Accuracy: 0.4242\n",
      "Epoch [441/500], Loss: 1.4204, Accuracy: 0.4257\n",
      "Epoch [442/500], Loss: 1.4184, Accuracy: 0.4255\n",
      "Epoch [443/500], Loss: 1.4176, Accuracy: 0.4252\n",
      "Epoch [444/500], Loss: 1.4219, Accuracy: 0.4257\n",
      "Epoch [445/500], Loss: 1.4326, Accuracy: 0.4258\n",
      "Epoch [446/500], Loss: 1.4191, Accuracy: 0.4265\n",
      "Epoch [447/500], Loss: 1.4186, Accuracy: 0.4252\n",
      "Epoch [448/500], Loss: 1.4171, Accuracy: 0.4255\n",
      "Epoch [449/500], Loss: 1.4200, Accuracy: 0.4268\n",
      "Epoch [450/500], Loss: 1.4179, Accuracy: 0.4258\n",
      "Epoch [451/500], Loss: 1.4157, Accuracy: 0.4284\n",
      "Epoch [452/500], Loss: 1.4158, Accuracy: 0.4250\n",
      "Epoch [453/500], Loss: 1.4199, Accuracy: 0.4258\n",
      "Epoch [454/500], Loss: 1.4164, Accuracy: 0.4270\n",
      "Epoch [455/500], Loss: 1.4193, Accuracy: 0.4265\n",
      "Epoch [456/500], Loss: 1.4183, Accuracy: 0.4284\n",
      "Epoch [457/500], Loss: 1.4192, Accuracy: 0.4255\n",
      "Epoch [458/500], Loss: 1.4185, Accuracy: 0.4284\n",
      "Epoch [459/500], Loss: 1.4186, Accuracy: 0.4273\n",
      "Epoch [460/500], Loss: 1.4107, Accuracy: 0.4265\n",
      "Epoch [461/500], Loss: 1.4135, Accuracy: 0.4277\n",
      "Epoch [462/500], Loss: 1.4165, Accuracy: 0.4258\n",
      "Epoch [463/500], Loss: 1.4285, Accuracy: 0.4252\n",
      "Epoch [464/500], Loss: 1.4103, Accuracy: 0.4262\n",
      "Epoch [465/500], Loss: 1.4146, Accuracy: 0.4260\n",
      "Epoch [466/500], Loss: 1.4164, Accuracy: 0.4265\n",
      "Epoch [467/500], Loss: 1.4161, Accuracy: 0.4277\n",
      "Epoch [468/500], Loss: 1.4154, Accuracy: 0.4268\n",
      "Epoch [469/500], Loss: 1.4198, Accuracy: 0.4262\n",
      "Epoch [470/500], Loss: 1.4193, Accuracy: 0.4260\n",
      "Epoch [471/500], Loss: 1.4198, Accuracy: 0.4273\n",
      "Epoch [472/500], Loss: 1.4144, Accuracy: 0.4268\n",
      "Epoch [473/500], Loss: 1.4224, Accuracy: 0.4262\n",
      "Epoch [474/500], Loss: 1.4233, Accuracy: 0.4267\n",
      "Epoch [475/500], Loss: 1.4129, Accuracy: 0.4247\n",
      "Epoch [476/500], Loss: 1.4122, Accuracy: 0.4257\n",
      "Epoch [477/500], Loss: 1.4172, Accuracy: 0.4268\n",
      "Epoch [478/500], Loss: 1.4111, Accuracy: 0.4257\n",
      "Epoch [479/500], Loss: 1.4186, Accuracy: 0.4270\n",
      "Epoch [480/500], Loss: 1.4154, Accuracy: 0.4272\n",
      "Epoch [481/500], Loss: 1.4123, Accuracy: 0.4280\n",
      "Epoch [482/500], Loss: 1.4202, Accuracy: 0.4265\n",
      "Epoch [483/500], Loss: 1.4135, Accuracy: 0.4268\n",
      "Epoch [484/500], Loss: 1.4173, Accuracy: 0.4257\n",
      "Epoch [485/500], Loss: 1.4257, Accuracy: 0.4282\n",
      "Epoch [486/500], Loss: 1.4113, Accuracy: 0.4275\n",
      "Epoch [487/500], Loss: 1.4161, Accuracy: 0.4267\n",
      "Epoch [488/500], Loss: 1.4133, Accuracy: 0.4270\n",
      "Epoch [489/500], Loss: 1.4128, Accuracy: 0.4275\n",
      "Epoch [490/500], Loss: 1.4133, Accuracy: 0.4280\n",
      "Epoch [491/500], Loss: 1.4151, Accuracy: 0.4255\n",
      "Epoch [492/500], Loss: 1.4164, Accuracy: 0.4273\n",
      "Epoch [493/500], Loss: 1.4190, Accuracy: 0.4255\n",
      "Epoch [494/500], Loss: 1.4102, Accuracy: 0.4263\n",
      "Epoch [495/500], Loss: 1.4173, Accuracy: 0.4272\n",
      "Epoch [496/500], Loss: 1.4162, Accuracy: 0.4263\n",
      "Epoch [497/500], Loss: 1.4094, Accuracy: 0.4285\n",
      "Epoch [498/500], Loss: 1.4127, Accuracy: 0.4258\n",
      "Epoch [499/500], Loss: 1.4197, Accuracy: 0.4292\n",
      "Epoch [500/500], Loss: 1.4147, Accuracy: 0.4258\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network with Attention\n",
    "cnn_atn_model = CNNAttention(input_size[0],num_classes).to(device)\n",
    "optimizer = optim.Adagrad(cnn_atn_model.parameters(), lr=0.001)\n",
    "train(cnn_atn_model, train_loaderCNN, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para teste\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n",
    "\n",
    "    test_loss = running_loss / len(test_loader)\n",
    "    test_accuracy = correct / total\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SimpleDNN:\n",
      "Test Loss: 1.7211, Test Accuracy: 0.2639\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing SimpleDNN:\")\n",
    "test(sdnn_model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing LSTMModel:\n",
      "Test Loss: 1.4622, Test Accuracy: 0.3835\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting LSTMModel:\")\n",
    "test(lstm_model, test_loaderLSTM, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing LSTMAttention:\n",
      "Test Loss: 1.4564, Test Accuracy: 0.3915\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting LSTMAttention:\")\n",
    "test(lstm_atn_model, test_loaderLSTM, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing CNNModel:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4881, Test Accuracy: 0.3714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting CNNModel:\")\n",
    "test(cnn_model, test_loaderCNN, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing CNNAttention:\n",
      "Test Loss: 1.4691, Test Accuracy: 0.3969\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting CNNAttention:\")\n",
    "test(cnn_atn_model, test_loaderCNN, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
