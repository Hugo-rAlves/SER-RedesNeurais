{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>./AudioWAV/1012_TIE_NEU_XX.wav</td>\n",
       "      <td>neutral.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>./AudioWAV/1037_IEO_FEA_MD.wav</td>\n",
       "      <td>fear.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>./AudioWAV/1018_WSI_FEA_XX.wav</td>\n",
       "      <td>fear.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5577</th>\n",
       "      <td>./AudioWAV/1069_IEO_SAD_LO.wav</td>\n",
       "      <td>sad.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358</th>\n",
       "      <td>./AudioWAV/1054_ITH_HAP_XX.wav</td>\n",
       "      <td>happy.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              speech        label\n",
       "957   ./AudioWAV/1012_TIE_NEU_XX.wav  neutral.wav\n",
       "2947  ./AudioWAV/1037_IEO_FEA_MD.wav     fear.wav\n",
       "1459  ./AudioWAV/1018_WSI_FEA_XX.wav     fear.wav\n",
       "5577  ./AudioWAV/1069_IEO_SAD_LO.wav      sad.wav\n",
       "4358  ./AudioWAV/1054_ITH_HAP_XX.wav    happy.wav"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths=[]\n",
    "labels=[]\n",
    "for filename in os.listdir('./AudioWAV'):\n",
    "    \n",
    "    paths.append('./AudioWAV/' + filename)\n",
    "    file = filename.split('.')[0]\n",
    "   \n",
    "    label = file.split('_')[2]\n",
    "    if label == 'ANG':\n",
    "        labels.append('angry.wav')\n",
    "    elif label == 'DIS':\n",
    "        labels.append('disgust.wav')\n",
    "    elif label == 'FEA':\n",
    "        labels.append('fear.wav')\n",
    "    elif label == 'HAP':\n",
    "        labels.append('happy.wav')\n",
    "    elif label == 'NEU':\n",
    "        labels.append('neutral.wav')\n",
    "    elif label == 'SAD':\n",
    "        labels.append('sad.wav')\n",
    "        \n",
    "\n",
    "df_cremad = pd.DataFrame({'speech':paths,'label':labels})\n",
    "df_cremad.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFCC(filename):\n",
    "    y, sr = librosa.load(filename,duration=3,offset=0.5)\n",
    "    return np.mean(librosa.feature.mfcc(y=y,sr=sr,n_mfcc=40).T,axis=0)\n",
    "\n",
    "mfcc_cremad = df_cremad['speech'].apply(lambda x:MFCC(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7442, 40, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X =[x for x in mfcc_cremad]\n",
    "X =np.array(X)\n",
    "X.shape\n",
    "X =np.expand_dims(X,-1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe=OneHotEncoder()\n",
    "y = ohe.fit_transform(df_cremad[['label']] )\n",
    "y = y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7442, 40, 1), (7442, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry.wav', 'disgust.wav', 'fear.wav', 'happy.wav', 'neutral.wav',\n",
       "       'sad.wav'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cremad['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Definindo os modelos\n",
    "\n",
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class LSTMAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
    "        out = torch.sum(attn_weights * out, dim=1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
    "        self.fc_input_size = 32 * 1 * 1\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, self.fc_input_size)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNNAttention(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNNAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
    "        self.attention = nn.Linear(32, 1)\n",
    "        self.fc = nn.Linear(32, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        attn_weights = self.softmax(self.attention(x.permute(0, 2, 1))).squeeze(-1)\n",
    "        attn_weights = attn_weights.unsqueeze(-1)\n",
    "        x = torch.sum(attn_weights * x, dim=2)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "# Construindo e treinando os modelos\n",
    "\n",
    "input_size = X.shape[1:]\n",
    "num_classes = y.shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Convertendo os dados para tensores PyTorch\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "# Definindo o tamanho do lote\n",
    "batch_size = 32\n",
    "\n",
    "# Criando conjuntos de dados PyTorch\n",
    "dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Definindo tensor para o LSTM\n",
    "X_tensorLSTM = X_tensor.permute(0, 2, 1)\n",
    "\n",
    "# Criando conjuntos de dados PyTorch para LSTM\n",
    "datasetLSTM = torch.utils.data.TensorDataset(X_tensorLSTM, y_tensor)\n",
    "train_sizeLSTM = int(0.8 * len(datasetLSTM))\n",
    "test_sizeLSTM = len(datasetLSTM) - train_sizeLSTM\n",
    "train_datasetLSTM, test_datasetLSTM = torch.utils.data.random_split(datasetLSTM, [train_sizeLSTM, test_sizeLSTM])\n",
    "\n",
    "# DataLoader para o LSTM\n",
    "train_loaderLSTM = DataLoader(train_datasetLSTM, batch_size=batch_size, shuffle=True)\n",
    "test_loaderLSTM = DataLoader(test_datasetLSTM, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Convertendo os dados para tensores PyTorch do CNN\n",
    "X_tensorCNN = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "\n",
    "# Criando conjuntos de dados PyTorch do CNN\n",
    "datasetCNN = torch.utils.data.TensorDataset(X_tensorCNN, y_tensor)\n",
    "train_sizeCNN = int(0.8 * len(datasetCNN))\n",
    "test_sizeCNN = len(datasetCNN) - train_sizeCNN\n",
    "train_datasetCNN, test_datasetCNN = torch.utils.data.random_split(datasetCNN, [train_sizeCNN, test_sizeCNN])\n",
    "\n",
    "# DataLoader para o CNN\n",
    "train_loaderCNN = DataLoader(train_datasetCNN, batch_size=batch_size, shuffle=True)\n",
    "test_loaderCNN = DataLoader(test_datasetCNN, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Função para treinamento\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            #print(outputs.shape)\n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        accuracy = correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.7603, Accuracy: 0.1708\n",
      "Epoch [2/100], Loss: 1.8016, Accuracy: 0.1730\n",
      "Epoch [3/100], Loss: 1.7951, Accuracy: 0.1774\n",
      "Epoch [4/100], Loss: 1.7817, Accuracy: 0.1907\n",
      "Epoch [5/100], Loss: 1.7577, Accuracy: 0.2201\n",
      "Epoch [6/100], Loss: 1.7215, Accuracy: 0.2342\n",
      "Epoch [7/100], Loss: 1.6921, Accuracy: 0.2585\n",
      "Epoch [8/100], Loss: 1.6724, Accuracy: 0.2676\n",
      "Epoch [9/100], Loss: 1.6760, Accuracy: 0.2718\n",
      "Epoch [10/100], Loss: 1.6504, Accuracy: 0.2804\n",
      "Epoch [11/100], Loss: 1.6290, Accuracy: 0.2972\n",
      "Epoch [12/100], Loss: 1.6183, Accuracy: 0.3049\n",
      "Epoch [13/100], Loss: 1.6011, Accuracy: 0.3177\n",
      "Epoch [14/100], Loss: 1.6020, Accuracy: 0.3158\n",
      "Epoch [15/100], Loss: 1.5925, Accuracy: 0.3214\n",
      "Epoch [16/100], Loss: 1.5861, Accuracy: 0.3229\n",
      "Epoch [17/100], Loss: 1.5869, Accuracy: 0.3259\n",
      "Epoch [18/100], Loss: 1.5733, Accuracy: 0.3313\n",
      "Epoch [19/100], Loss: 1.5693, Accuracy: 0.3339\n",
      "Epoch [20/100], Loss: 1.5734, Accuracy: 0.3429\n",
      "Epoch [21/100], Loss: 1.5605, Accuracy: 0.3350\n",
      "Epoch [22/100], Loss: 1.5664, Accuracy: 0.3368\n",
      "Epoch [23/100], Loss: 1.5556, Accuracy: 0.3413\n",
      "Epoch [24/100], Loss: 1.5599, Accuracy: 0.3390\n",
      "Epoch [25/100], Loss: 1.5388, Accuracy: 0.3502\n",
      "Epoch [26/100], Loss: 1.5399, Accuracy: 0.3501\n",
      "Epoch [27/100], Loss: 1.5444, Accuracy: 0.3457\n",
      "Epoch [28/100], Loss: 1.5485, Accuracy: 0.3465\n",
      "Epoch [29/100], Loss: 1.5351, Accuracy: 0.3454\n",
      "Epoch [30/100], Loss: 1.5344, Accuracy: 0.3519\n",
      "Epoch [31/100], Loss: 1.5339, Accuracy: 0.3627\n",
      "Epoch [32/100], Loss: 1.5373, Accuracy: 0.3499\n",
      "Epoch [33/100], Loss: 1.5259, Accuracy: 0.3519\n",
      "Epoch [34/100], Loss: 1.5206, Accuracy: 0.3536\n",
      "Epoch [35/100], Loss: 1.5438, Accuracy: 0.3528\n",
      "Epoch [36/100], Loss: 1.5260, Accuracy: 0.3586\n",
      "Epoch [37/100], Loss: 1.5287, Accuracy: 0.3497\n",
      "Epoch [38/100], Loss: 1.5219, Accuracy: 0.3514\n",
      "Epoch [39/100], Loss: 1.5295, Accuracy: 0.3583\n",
      "Epoch [40/100], Loss: 1.5317, Accuracy: 0.3524\n",
      "Epoch [41/100], Loss: 1.5213, Accuracy: 0.3571\n",
      "Epoch [42/100], Loss: 1.5149, Accuracy: 0.3612\n",
      "Epoch [43/100], Loss: 1.5199, Accuracy: 0.3573\n",
      "Epoch [44/100], Loss: 1.5168, Accuracy: 0.3586\n",
      "Epoch [45/100], Loss: 1.5012, Accuracy: 0.3610\n",
      "Epoch [46/100], Loss: 1.4982, Accuracy: 0.3699\n",
      "Epoch [47/100], Loss: 1.5221, Accuracy: 0.3541\n",
      "Epoch [48/100], Loss: 1.5092, Accuracy: 0.3627\n",
      "Epoch [49/100], Loss: 1.5100, Accuracy: 0.3618\n",
      "Epoch [50/100], Loss: 1.5027, Accuracy: 0.3639\n",
      "Epoch [51/100], Loss: 1.5017, Accuracy: 0.3729\n",
      "Epoch [52/100], Loss: 1.5013, Accuracy: 0.3618\n",
      "Epoch [53/100], Loss: 1.5033, Accuracy: 0.3591\n",
      "Epoch [54/100], Loss: 1.5010, Accuracy: 0.3692\n",
      "Epoch [55/100], Loss: 1.5014, Accuracy: 0.3670\n",
      "Epoch [56/100], Loss: 1.5011, Accuracy: 0.3697\n",
      "Epoch [57/100], Loss: 1.4947, Accuracy: 0.3707\n",
      "Epoch [58/100], Loss: 1.4987, Accuracy: 0.3647\n",
      "Epoch [59/100], Loss: 1.4909, Accuracy: 0.3701\n",
      "Epoch [60/100], Loss: 1.5005, Accuracy: 0.3675\n",
      "Epoch [61/100], Loss: 1.4974, Accuracy: 0.3701\n",
      "Epoch [62/100], Loss: 1.4922, Accuracy: 0.3754\n",
      "Epoch [63/100], Loss: 1.4875, Accuracy: 0.3785\n",
      "Epoch [64/100], Loss: 1.4808, Accuracy: 0.3748\n",
      "Epoch [65/100], Loss: 1.4903, Accuracy: 0.3753\n",
      "Epoch [66/100], Loss: 1.4851, Accuracy: 0.3744\n",
      "Epoch [67/100], Loss: 1.4791, Accuracy: 0.3838\n",
      "Epoch [68/100], Loss: 1.4738, Accuracy: 0.3812\n",
      "Epoch [69/100], Loss: 1.4738, Accuracy: 0.3832\n",
      "Epoch [70/100], Loss: 1.4898, Accuracy: 0.3748\n",
      "Epoch [71/100], Loss: 1.4725, Accuracy: 0.3837\n",
      "Epoch [72/100], Loss: 1.4786, Accuracy: 0.3796\n",
      "Epoch [73/100], Loss: 1.4811, Accuracy: 0.3754\n",
      "Epoch [74/100], Loss: 1.4801, Accuracy: 0.3724\n",
      "Epoch [75/100], Loss: 1.4747, Accuracy: 0.3773\n",
      "Epoch [76/100], Loss: 1.4749, Accuracy: 0.3791\n",
      "Epoch [77/100], Loss: 1.4777, Accuracy: 0.3770\n",
      "Epoch [78/100], Loss: 1.4746, Accuracy: 0.3825\n",
      "Epoch [79/100], Loss: 1.4834, Accuracy: 0.3791\n",
      "Epoch [80/100], Loss: 1.4835, Accuracy: 0.3806\n",
      "Epoch [81/100], Loss: 1.4730, Accuracy: 0.3823\n",
      "Epoch [82/100], Loss: 1.4670, Accuracy: 0.3791\n",
      "Epoch [83/100], Loss: 1.4771, Accuracy: 0.3864\n",
      "Epoch [84/100], Loss: 1.4769, Accuracy: 0.3838\n",
      "Epoch [85/100], Loss: 1.4724, Accuracy: 0.3830\n",
      "Epoch [86/100], Loss: 1.4616, Accuracy: 0.3904\n",
      "Epoch [87/100], Loss: 1.4767, Accuracy: 0.3906\n",
      "Epoch [88/100], Loss: 1.4641, Accuracy: 0.3959\n",
      "Epoch [89/100], Loss: 1.4610, Accuracy: 0.3890\n",
      "Epoch [90/100], Loss: 1.4555, Accuracy: 0.3931\n",
      "Epoch [91/100], Loss: 1.4515, Accuracy: 0.3912\n",
      "Epoch [92/100], Loss: 1.4638, Accuracy: 0.3872\n",
      "Epoch [93/100], Loss: 1.4612, Accuracy: 0.3887\n",
      "Epoch [94/100], Loss: 1.4564, Accuracy: 0.3954\n",
      "Epoch [95/100], Loss: 1.4685, Accuracy: 0.3828\n",
      "Epoch [96/100], Loss: 1.4616, Accuracy: 0.3885\n",
      "Epoch [97/100], Loss: 1.4527, Accuracy: 0.3855\n",
      "Epoch [98/100], Loss: 1.4543, Accuracy: 0.3916\n",
      "Epoch [99/100], Loss: 1.4660, Accuracy: 0.3848\n",
      "Epoch [100/100], Loss: 1.4541, Accuracy: 0.3966\n"
     ]
    }
   ],
   "source": [
    "# Standard Deep Neural Network\n",
    "sdnn_model = SimpleDNN(input_size[0], num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(sdnn_model.parameters(), lr=0.001)\n",
    "train(sdnn_model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.6779, Accuracy: 0.2841\n",
      "Epoch [2/100], Loss: 1.5626, Accuracy: 0.3450\n",
      "Epoch [3/100], Loss: 1.5328, Accuracy: 0.3620\n",
      "Epoch [4/100], Loss: 1.5104, Accuracy: 0.3758\n",
      "Epoch [5/100], Loss: 1.4918, Accuracy: 0.3806\n",
      "Epoch [6/100], Loss: 1.4637, Accuracy: 0.3990\n",
      "Epoch [7/100], Loss: 1.4661, Accuracy: 0.4011\n",
      "Epoch [8/100], Loss: 1.4573, Accuracy: 0.4053\n",
      "Epoch [9/100], Loss: 1.4430, Accuracy: 0.4038\n",
      "Epoch [10/100], Loss: 1.4197, Accuracy: 0.4151\n",
      "Epoch [11/100], Loss: 1.4149, Accuracy: 0.4201\n",
      "Epoch [12/100], Loss: 1.4139, Accuracy: 0.4238\n",
      "Epoch [13/100], Loss: 1.4092, Accuracy: 0.4231\n",
      "Epoch [14/100], Loss: 1.4126, Accuracy: 0.4252\n",
      "Epoch [15/100], Loss: 1.4041, Accuracy: 0.4285\n",
      "Epoch [16/100], Loss: 1.3937, Accuracy: 0.4327\n",
      "Epoch [17/100], Loss: 1.3944, Accuracy: 0.4314\n",
      "Epoch [18/100], Loss: 1.3718, Accuracy: 0.4366\n",
      "Epoch [19/100], Loss: 1.3639, Accuracy: 0.4398\n",
      "Epoch [20/100], Loss: 1.3638, Accuracy: 0.4446\n",
      "Epoch [21/100], Loss: 1.3636, Accuracy: 0.4462\n",
      "Epoch [22/100], Loss: 1.3705, Accuracy: 0.4485\n",
      "Epoch [23/100], Loss: 1.3567, Accuracy: 0.4475\n",
      "Epoch [24/100], Loss: 1.3507, Accuracy: 0.4556\n",
      "Epoch [25/100], Loss: 1.3454, Accuracy: 0.4551\n",
      "Epoch [26/100], Loss: 1.3553, Accuracy: 0.4525\n",
      "Epoch [27/100], Loss: 1.3622, Accuracy: 0.4482\n",
      "Epoch [28/100], Loss: 1.3500, Accuracy: 0.4514\n",
      "Epoch [29/100], Loss: 1.3398, Accuracy: 0.4510\n",
      "Epoch [30/100], Loss: 1.3266, Accuracy: 0.4586\n",
      "Epoch [31/100], Loss: 1.3334, Accuracy: 0.4581\n",
      "Epoch [32/100], Loss: 1.3237, Accuracy: 0.4675\n",
      "Epoch [33/100], Loss: 1.3452, Accuracy: 0.4557\n",
      "Epoch [34/100], Loss: 1.3389, Accuracy: 0.4569\n",
      "Epoch [35/100], Loss: 1.3298, Accuracy: 0.4667\n",
      "Epoch [36/100], Loss: 1.3141, Accuracy: 0.4722\n",
      "Epoch [37/100], Loss: 1.3152, Accuracy: 0.4656\n",
      "Epoch [38/100], Loss: 1.3231, Accuracy: 0.4687\n",
      "Epoch [39/100], Loss: 1.3273, Accuracy: 0.4668\n",
      "Epoch [40/100], Loss: 1.3200, Accuracy: 0.4673\n",
      "Epoch [41/100], Loss: 1.3071, Accuracy: 0.4739\n",
      "Epoch [42/100], Loss: 1.3207, Accuracy: 0.4734\n",
      "Epoch [43/100], Loss: 1.3089, Accuracy: 0.4757\n",
      "Epoch [44/100], Loss: 1.3031, Accuracy: 0.4740\n",
      "Epoch [45/100], Loss: 1.3046, Accuracy: 0.4794\n",
      "Epoch [46/100], Loss: 1.2899, Accuracy: 0.4730\n",
      "Epoch [47/100], Loss: 1.3071, Accuracy: 0.4747\n",
      "Epoch [48/100], Loss: 1.3195, Accuracy: 0.4631\n",
      "Epoch [49/100], Loss: 1.2829, Accuracy: 0.4769\n",
      "Epoch [50/100], Loss: 1.2964, Accuracy: 0.4761\n",
      "Epoch [51/100], Loss: 1.2847, Accuracy: 0.4840\n",
      "Epoch [52/100], Loss: 1.2984, Accuracy: 0.4727\n",
      "Epoch [53/100], Loss: 1.3021, Accuracy: 0.4742\n",
      "Epoch [54/100], Loss: 1.2872, Accuracy: 0.4887\n",
      "Epoch [55/100], Loss: 1.2760, Accuracy: 0.4853\n",
      "Epoch [56/100], Loss: 1.2742, Accuracy: 0.4826\n",
      "Epoch [57/100], Loss: 1.2699, Accuracy: 0.4900\n",
      "Epoch [58/100], Loss: 1.2673, Accuracy: 0.4913\n",
      "Epoch [59/100], Loss: 1.2766, Accuracy: 0.4833\n",
      "Epoch [60/100], Loss: 1.2578, Accuracy: 0.4922\n",
      "Epoch [61/100], Loss: 1.2558, Accuracy: 0.4924\n",
      "Epoch [62/100], Loss: 1.2527, Accuracy: 0.4935\n",
      "Epoch [63/100], Loss: 1.2589, Accuracy: 0.4920\n",
      "Epoch [64/100], Loss: 1.2453, Accuracy: 0.4977\n",
      "Epoch [65/100], Loss: 1.2589, Accuracy: 0.4972\n",
      "Epoch [66/100], Loss: 1.2631, Accuracy: 0.4841\n",
      "Epoch [67/100], Loss: 1.2577, Accuracy: 0.4929\n",
      "Epoch [68/100], Loss: 1.2482, Accuracy: 0.4996\n",
      "Epoch [69/100], Loss: 1.2528, Accuracy: 0.5006\n",
      "Epoch [70/100], Loss: 1.2444, Accuracy: 0.5048\n",
      "Epoch [71/100], Loss: 1.2454, Accuracy: 0.5018\n",
      "Epoch [72/100], Loss: 1.2518, Accuracy: 0.4959\n",
      "Epoch [73/100], Loss: 1.2411, Accuracy: 0.5019\n",
      "Epoch [74/100], Loss: 1.2429, Accuracy: 0.5006\n",
      "Epoch [75/100], Loss: 1.2422, Accuracy: 0.5061\n",
      "Epoch [76/100], Loss: 1.2376, Accuracy: 0.5029\n",
      "Epoch [77/100], Loss: 1.2445, Accuracy: 0.5021\n",
      "Epoch [78/100], Loss: 1.2286, Accuracy: 0.5073\n",
      "Epoch [79/100], Loss: 1.2259, Accuracy: 0.5118\n",
      "Epoch [80/100], Loss: 1.2306, Accuracy: 0.5048\n",
      "Epoch [81/100], Loss: 1.2280, Accuracy: 0.5097\n",
      "Epoch [82/100], Loss: 1.2370, Accuracy: 0.5087\n",
      "Epoch [83/100], Loss: 1.2324, Accuracy: 0.5050\n",
      "Epoch [84/100], Loss: 1.2531, Accuracy: 0.5090\n",
      "Epoch [85/100], Loss: 1.2196, Accuracy: 0.5107\n",
      "Epoch [86/100], Loss: 1.2271, Accuracy: 0.5073\n",
      "Epoch [87/100], Loss: 1.2546, Accuracy: 0.5019\n",
      "Epoch [88/100], Loss: 1.2239, Accuracy: 0.5098\n",
      "Epoch [89/100], Loss: 1.2200, Accuracy: 0.5142\n",
      "Epoch [90/100], Loss: 1.2131, Accuracy: 0.5172\n",
      "Epoch [91/100], Loss: 1.2195, Accuracy: 0.5135\n",
      "Epoch [92/100], Loss: 1.2075, Accuracy: 0.5129\n",
      "Epoch [93/100], Loss: 1.2033, Accuracy: 0.5167\n",
      "Epoch [94/100], Loss: 1.1975, Accuracy: 0.5216\n",
      "Epoch [95/100], Loss: 1.2206, Accuracy: 0.5162\n",
      "Epoch [96/100], Loss: 1.2076, Accuracy: 0.5263\n",
      "Epoch [97/100], Loss: 1.2015, Accuracy: 0.5207\n",
      "Epoch [98/100], Loss: 1.2001, Accuracy: 0.5174\n",
      "Epoch [99/100], Loss: 1.1980, Accuracy: 0.5283\n",
      "Epoch [100/100], Loss: 1.1991, Accuracy: 0.5238\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "lstm_model = LSTMModel(input_size[0], hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "train(lstm_model, train_loaderLSTM, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.6618, Accuracy: 0.2926\n",
      "Epoch [2/100], Loss: 1.5502, Accuracy: 0.3472\n",
      "Epoch [3/100], Loss: 1.5184, Accuracy: 0.3722\n",
      "Epoch [4/100], Loss: 1.4968, Accuracy: 0.3734\n",
      "Epoch [5/100], Loss: 1.4799, Accuracy: 0.3921\n",
      "Epoch [6/100], Loss: 1.4602, Accuracy: 0.3929\n",
      "Epoch [7/100], Loss: 1.4416, Accuracy: 0.4035\n",
      "Epoch [8/100], Loss: 1.4385, Accuracy: 0.4032\n",
      "Epoch [9/100], Loss: 1.4308, Accuracy: 0.4065\n",
      "Epoch [10/100], Loss: 1.4210, Accuracy: 0.4220\n",
      "Epoch [11/100], Loss: 1.4111, Accuracy: 0.4245\n",
      "Epoch [12/100], Loss: 1.3947, Accuracy: 0.4277\n",
      "Epoch [13/100], Loss: 1.4021, Accuracy: 0.4272\n",
      "Epoch [14/100], Loss: 1.4136, Accuracy: 0.4273\n",
      "Epoch [15/100], Loss: 1.4554, Accuracy: 0.4092\n",
      "Epoch [16/100], Loss: 1.4211, Accuracy: 0.4189\n",
      "Epoch [17/100], Loss: 1.3927, Accuracy: 0.4322\n",
      "Epoch [18/100], Loss: 1.3865, Accuracy: 0.4344\n",
      "Epoch [19/100], Loss: 1.3908, Accuracy: 0.4463\n",
      "Epoch [20/100], Loss: 1.3839, Accuracy: 0.4341\n",
      "Epoch [21/100], Loss: 1.3655, Accuracy: 0.4546\n",
      "Epoch [22/100], Loss: 1.3680, Accuracy: 0.4458\n",
      "Epoch [23/100], Loss: 1.3602, Accuracy: 0.4494\n",
      "Epoch [24/100], Loss: 1.3590, Accuracy: 0.4542\n",
      "Epoch [25/100], Loss: 1.3446, Accuracy: 0.4633\n",
      "Epoch [26/100], Loss: 1.3418, Accuracy: 0.4546\n",
      "Epoch [27/100], Loss: 1.3514, Accuracy: 0.4546\n",
      "Epoch [28/100], Loss: 1.3538, Accuracy: 0.4529\n",
      "Epoch [29/100], Loss: 1.3409, Accuracy: 0.4621\n",
      "Epoch [30/100], Loss: 1.3266, Accuracy: 0.4678\n",
      "Epoch [31/100], Loss: 1.3344, Accuracy: 0.4658\n",
      "Epoch [32/100], Loss: 1.3264, Accuracy: 0.4606\n",
      "Epoch [33/100], Loss: 1.3323, Accuracy: 0.4653\n",
      "Epoch [34/100], Loss: 1.3260, Accuracy: 0.4740\n",
      "Epoch [35/100], Loss: 1.3183, Accuracy: 0.4700\n",
      "Epoch [36/100], Loss: 1.3203, Accuracy: 0.4725\n",
      "Epoch [37/100], Loss: 1.3017, Accuracy: 0.4856\n",
      "Epoch [38/100], Loss: 1.2987, Accuracy: 0.4772\n",
      "Epoch [39/100], Loss: 1.2995, Accuracy: 0.4766\n",
      "Epoch [40/100], Loss: 1.2978, Accuracy: 0.4786\n",
      "Epoch [41/100], Loss: 1.2907, Accuracy: 0.4788\n",
      "Epoch [42/100], Loss: 1.2931, Accuracy: 0.4789\n",
      "Epoch [43/100], Loss: 1.2957, Accuracy: 0.4806\n",
      "Epoch [44/100], Loss: 1.2870, Accuracy: 0.4786\n",
      "Epoch [45/100], Loss: 1.2865, Accuracy: 0.4870\n",
      "Epoch [46/100], Loss: 1.2968, Accuracy: 0.4793\n",
      "Epoch [47/100], Loss: 1.2689, Accuracy: 0.4920\n",
      "Epoch [48/100], Loss: 1.2886, Accuracy: 0.4809\n",
      "Epoch [49/100], Loss: 1.2962, Accuracy: 0.4786\n",
      "Epoch [50/100], Loss: 1.2667, Accuracy: 0.4944\n",
      "Epoch [51/100], Loss: 1.2735, Accuracy: 0.4853\n",
      "Epoch [52/100], Loss: 1.2678, Accuracy: 0.4971\n",
      "Epoch [53/100], Loss: 1.2613, Accuracy: 0.4902\n",
      "Epoch [54/100], Loss: 1.2573, Accuracy: 0.4977\n",
      "Epoch [55/100], Loss: 1.2845, Accuracy: 0.4858\n",
      "Epoch [56/100], Loss: 1.2656, Accuracy: 0.4871\n",
      "Epoch [57/100], Loss: 1.2710, Accuracy: 0.4819\n",
      "Epoch [58/100], Loss: 1.2537, Accuracy: 0.4940\n",
      "Epoch [59/100], Loss: 1.2634, Accuracy: 0.4846\n",
      "Epoch [60/100], Loss: 1.2711, Accuracy: 0.4942\n",
      "Epoch [61/100], Loss: 1.2578, Accuracy: 0.4939\n",
      "Epoch [62/100], Loss: 1.2628, Accuracy: 0.4878\n",
      "Epoch [63/100], Loss: 1.2687, Accuracy: 0.4883\n",
      "Epoch [64/100], Loss: 1.2603, Accuracy: 0.4942\n",
      "Epoch [65/100], Loss: 1.2488, Accuracy: 0.4972\n",
      "Epoch [66/100], Loss: 1.2475, Accuracy: 0.4947\n",
      "Epoch [67/100], Loss: 1.2403, Accuracy: 0.4987\n",
      "Epoch [68/100], Loss: 1.2603, Accuracy: 0.4981\n",
      "Epoch [69/100], Loss: 1.2646, Accuracy: 0.4898\n",
      "Epoch [70/100], Loss: 1.2418, Accuracy: 0.4917\n",
      "Epoch [71/100], Loss: 1.2449, Accuracy: 0.4979\n",
      "Epoch [72/100], Loss: 1.2566, Accuracy: 0.4939\n",
      "Epoch [73/100], Loss: 1.2377, Accuracy: 0.4997\n",
      "Epoch [74/100], Loss: 1.2372, Accuracy: 0.5024\n",
      "Epoch [75/100], Loss: 1.2277, Accuracy: 0.5045\n",
      "Epoch [76/100], Loss: 1.2380, Accuracy: 0.4954\n",
      "Epoch [77/100], Loss: 1.2259, Accuracy: 0.5075\n",
      "Epoch [78/100], Loss: 1.2500, Accuracy: 0.4944\n",
      "Epoch [79/100], Loss: 1.2406, Accuracy: 0.5003\n",
      "Epoch [80/100], Loss: 1.2364, Accuracy: 0.5050\n",
      "Epoch [81/100], Loss: 1.2412, Accuracy: 0.4959\n",
      "Epoch [82/100], Loss: 1.2471, Accuracy: 0.4929\n",
      "Epoch [83/100], Loss: 1.2279, Accuracy: 0.5100\n",
      "Epoch [84/100], Loss: 1.2177, Accuracy: 0.5071\n",
      "Epoch [85/100], Loss: 1.2338, Accuracy: 0.5063\n",
      "Epoch [86/100], Loss: 1.2530, Accuracy: 0.4972\n",
      "Epoch [87/100], Loss: 1.2358, Accuracy: 0.5013\n",
      "Epoch [88/100], Loss: 1.2527, Accuracy: 0.4989\n",
      "Epoch [89/100], Loss: 1.2498, Accuracy: 0.5050\n",
      "Epoch [90/100], Loss: 1.2373, Accuracy: 0.5026\n",
      "Epoch [91/100], Loss: 1.2449, Accuracy: 0.4984\n",
      "Epoch [92/100], Loss: 1.2237, Accuracy: 0.5051\n",
      "Epoch [93/100], Loss: 1.2172, Accuracy: 0.5102\n",
      "Epoch [94/100], Loss: 1.2056, Accuracy: 0.5107\n",
      "Epoch [95/100], Loss: 1.2264, Accuracy: 0.5046\n",
      "Epoch [96/100], Loss: 1.2060, Accuracy: 0.5135\n",
      "Epoch [97/100], Loss: 1.2126, Accuracy: 0.5110\n",
      "Epoch [98/100], Loss: 1.2099, Accuracy: 0.5167\n",
      "Epoch [99/100], Loss: 1.2054, Accuracy: 0.5157\n",
      "Epoch [100/100], Loss: 1.1929, Accuracy: 0.5218\n"
     ]
    }
   ],
   "source": [
    "# LSTM with Attention\n",
    "lstm_atn_model = LSTMAttention(input_size[0], hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_atn_model.parameters(), lr=0.001)\n",
    "train(lstm_atn_model, train_loaderLSTM, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.7407, Accuracy: 0.2409\n",
      "Epoch [2/100], Loss: 1.6430, Accuracy: 0.2960\n",
      "Epoch [3/100], Loss: 1.6163, Accuracy: 0.3051\n",
      "Epoch [4/100], Loss: 1.6026, Accuracy: 0.3109\n",
      "Epoch [5/100], Loss: 1.5752, Accuracy: 0.3239\n",
      "Epoch [6/100], Loss: 1.5507, Accuracy: 0.3355\n",
      "Epoch [7/100], Loss: 1.5542, Accuracy: 0.3469\n",
      "Epoch [8/100], Loss: 1.5676, Accuracy: 0.3286\n",
      "Epoch [9/100], Loss: 1.5340, Accuracy: 0.3469\n",
      "Epoch [10/100], Loss: 1.5325, Accuracy: 0.3418\n",
      "Epoch [11/100], Loss: 1.5237, Accuracy: 0.3518\n",
      "Epoch [12/100], Loss: 1.5159, Accuracy: 0.3595\n",
      "Epoch [13/100], Loss: 1.5083, Accuracy: 0.3555\n",
      "Epoch [14/100], Loss: 1.5055, Accuracy: 0.3576\n",
      "Epoch [15/100], Loss: 1.5081, Accuracy: 0.3602\n",
      "Epoch [16/100], Loss: 1.5000, Accuracy: 0.3633\n",
      "Epoch [17/100], Loss: 1.4946, Accuracy: 0.3741\n",
      "Epoch [18/100], Loss: 1.4929, Accuracy: 0.3687\n",
      "Epoch [19/100], Loss: 1.4744, Accuracy: 0.3783\n",
      "Epoch [20/100], Loss: 1.4751, Accuracy: 0.3843\n",
      "Epoch [21/100], Loss: 1.4596, Accuracy: 0.3843\n",
      "Epoch [22/100], Loss: 1.4556, Accuracy: 0.3924\n",
      "Epoch [23/100], Loss: 1.4534, Accuracy: 0.3909\n",
      "Epoch [24/100], Loss: 1.4519, Accuracy: 0.3889\n",
      "Epoch [25/100], Loss: 1.4543, Accuracy: 0.3919\n",
      "Epoch [26/100], Loss: 1.4576, Accuracy: 0.3914\n",
      "Epoch [27/100], Loss: 1.4276, Accuracy: 0.4048\n",
      "Epoch [28/100], Loss: 1.4163, Accuracy: 0.4084\n",
      "Epoch [29/100], Loss: 1.4225, Accuracy: 0.4247\n",
      "Epoch [30/100], Loss: 1.4367, Accuracy: 0.3978\n",
      "Epoch [31/100], Loss: 1.4152, Accuracy: 0.4032\n",
      "Epoch [32/100], Loss: 1.4174, Accuracy: 0.4107\n",
      "Epoch [33/100], Loss: 1.3936, Accuracy: 0.4304\n",
      "Epoch [34/100], Loss: 1.4027, Accuracy: 0.4235\n",
      "Epoch [35/100], Loss: 1.4011, Accuracy: 0.4275\n",
      "Epoch [36/100], Loss: 1.3904, Accuracy: 0.4260\n",
      "Epoch [37/100], Loss: 1.3844, Accuracy: 0.4231\n",
      "Epoch [38/100], Loss: 1.3987, Accuracy: 0.4250\n",
      "Epoch [39/100], Loss: 1.3975, Accuracy: 0.4201\n",
      "Epoch [40/100], Loss: 1.4045, Accuracy: 0.4196\n",
      "Epoch [41/100], Loss: 1.3783, Accuracy: 0.4349\n",
      "Epoch [42/100], Loss: 1.3737, Accuracy: 0.4324\n",
      "Epoch [43/100], Loss: 1.3777, Accuracy: 0.4300\n",
      "Epoch [44/100], Loss: 1.3701, Accuracy: 0.4300\n",
      "Epoch [45/100], Loss: 1.3708, Accuracy: 0.4359\n",
      "Epoch [46/100], Loss: 1.3782, Accuracy: 0.4351\n",
      "Epoch [47/100], Loss: 1.3740, Accuracy: 0.4425\n",
      "Epoch [48/100], Loss: 1.3612, Accuracy: 0.4388\n",
      "Epoch [49/100], Loss: 1.3819, Accuracy: 0.4321\n",
      "Epoch [50/100], Loss: 1.3515, Accuracy: 0.4530\n",
      "Epoch [51/100], Loss: 1.3591, Accuracy: 0.4418\n",
      "Epoch [52/100], Loss: 1.3705, Accuracy: 0.4374\n",
      "Epoch [53/100], Loss: 1.3535, Accuracy: 0.4389\n",
      "Epoch [54/100], Loss: 1.3454, Accuracy: 0.4499\n",
      "Epoch [55/100], Loss: 1.3538, Accuracy: 0.4453\n",
      "Epoch [56/100], Loss: 1.3554, Accuracy: 0.4411\n",
      "Epoch [57/100], Loss: 1.3551, Accuracy: 0.4477\n",
      "Epoch [58/100], Loss: 1.3530, Accuracy: 0.4504\n",
      "Epoch [59/100], Loss: 1.3598, Accuracy: 0.4420\n",
      "Epoch [60/100], Loss: 1.3424, Accuracy: 0.4478\n",
      "Epoch [61/100], Loss: 1.3328, Accuracy: 0.4509\n",
      "Epoch [62/100], Loss: 1.3281, Accuracy: 0.4604\n",
      "Epoch [63/100], Loss: 1.3358, Accuracy: 0.4497\n",
      "Epoch [64/100], Loss: 1.3292, Accuracy: 0.4542\n",
      "Epoch [65/100], Loss: 1.3350, Accuracy: 0.4430\n",
      "Epoch [66/100], Loss: 1.3260, Accuracy: 0.4571\n",
      "Epoch [67/100], Loss: 1.3405, Accuracy: 0.4551\n",
      "Epoch [68/100], Loss: 1.3221, Accuracy: 0.4578\n",
      "Epoch [69/100], Loss: 1.3272, Accuracy: 0.4556\n",
      "Epoch [70/100], Loss: 1.3228, Accuracy: 0.4556\n",
      "Epoch [71/100], Loss: 1.3179, Accuracy: 0.4593\n",
      "Epoch [72/100], Loss: 1.3180, Accuracy: 0.4591\n",
      "Epoch [73/100], Loss: 1.3162, Accuracy: 0.4609\n",
      "Epoch [74/100], Loss: 1.3126, Accuracy: 0.4561\n",
      "Epoch [75/100], Loss: 1.3151, Accuracy: 0.4571\n",
      "Epoch [76/100], Loss: 1.3236, Accuracy: 0.4598\n",
      "Epoch [77/100], Loss: 1.3083, Accuracy: 0.4630\n",
      "Epoch [78/100], Loss: 1.3182, Accuracy: 0.4618\n",
      "Epoch [79/100], Loss: 1.3044, Accuracy: 0.4599\n",
      "Epoch [80/100], Loss: 1.3097, Accuracy: 0.4638\n",
      "Epoch [81/100], Loss: 1.3095, Accuracy: 0.4665\n",
      "Epoch [82/100], Loss: 1.3067, Accuracy: 0.4598\n",
      "Epoch [83/100], Loss: 1.3137, Accuracy: 0.4643\n",
      "Epoch [84/100], Loss: 1.3074, Accuracy: 0.4638\n",
      "Epoch [85/100], Loss: 1.2987, Accuracy: 0.4673\n",
      "Epoch [86/100], Loss: 1.3114, Accuracy: 0.4640\n",
      "Epoch [87/100], Loss: 1.2995, Accuracy: 0.4633\n",
      "Epoch [88/100], Loss: 1.2964, Accuracy: 0.4757\n",
      "Epoch [89/100], Loss: 1.2933, Accuracy: 0.4680\n",
      "Epoch [90/100], Loss: 1.3173, Accuracy: 0.4611\n",
      "Epoch [91/100], Loss: 1.2864, Accuracy: 0.4663\n",
      "Epoch [92/100], Loss: 1.2873, Accuracy: 0.4680\n",
      "Epoch [93/100], Loss: 1.2900, Accuracy: 0.4630\n",
      "Epoch [94/100], Loss: 1.2908, Accuracy: 0.4767\n",
      "Epoch [95/100], Loss: 1.3102, Accuracy: 0.4583\n",
      "Epoch [96/100], Loss: 1.2884, Accuracy: 0.4621\n",
      "Epoch [97/100], Loss: 1.2834, Accuracy: 0.4717\n",
      "Epoch [98/100], Loss: 1.3044, Accuracy: 0.4730\n",
      "Epoch [99/100], Loss: 1.2846, Accuracy: 0.4798\n",
      "Epoch [100/100], Loss: 1.2873, Accuracy: 0.4749\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network\n",
    "cnn_model = CNNModel(input_size[0],num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "train(cnn_model, train_loaderCNN, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.7092, Accuracy: 0.2671\n",
      "Epoch [2/100], Loss: 1.5635, Accuracy: 0.3366\n",
      "Epoch [3/100], Loss: 1.5259, Accuracy: 0.3593\n",
      "Epoch [4/100], Loss: 1.5164, Accuracy: 0.3659\n",
      "Epoch [5/100], Loss: 1.4857, Accuracy: 0.3864\n",
      "Epoch [6/100], Loss: 1.4775, Accuracy: 0.3862\n",
      "Epoch [7/100], Loss: 1.4642, Accuracy: 0.3943\n",
      "Epoch [8/100], Loss: 1.4498, Accuracy: 0.4043\n",
      "Epoch [9/100], Loss: 1.4306, Accuracy: 0.4097\n",
      "Epoch [10/100], Loss: 1.4298, Accuracy: 0.4075\n",
      "Epoch [11/100], Loss: 1.4199, Accuracy: 0.4196\n",
      "Epoch [12/100], Loss: 1.4082, Accuracy: 0.4203\n",
      "Epoch [13/100], Loss: 1.4085, Accuracy: 0.4237\n",
      "Epoch [14/100], Loss: 1.4028, Accuracy: 0.4260\n",
      "Epoch [15/100], Loss: 1.3979, Accuracy: 0.4331\n",
      "Epoch [16/100], Loss: 1.3849, Accuracy: 0.4319\n",
      "Epoch [17/100], Loss: 1.3571, Accuracy: 0.4433\n",
      "Epoch [18/100], Loss: 1.3602, Accuracy: 0.4482\n",
      "Epoch [19/100], Loss: 1.3606, Accuracy: 0.4458\n",
      "Epoch [20/100], Loss: 1.3696, Accuracy: 0.4384\n",
      "Epoch [21/100], Loss: 1.3307, Accuracy: 0.4574\n",
      "Epoch [22/100], Loss: 1.3491, Accuracy: 0.4455\n",
      "Epoch [23/100], Loss: 1.3379, Accuracy: 0.4475\n",
      "Epoch [24/100], Loss: 1.3289, Accuracy: 0.4536\n",
      "Epoch [25/100], Loss: 1.3201, Accuracy: 0.4690\n",
      "Epoch [26/100], Loss: 1.3100, Accuracy: 0.4707\n",
      "Epoch [27/100], Loss: 1.3201, Accuracy: 0.4680\n",
      "Epoch [28/100], Loss: 1.3230, Accuracy: 0.4628\n",
      "Epoch [29/100], Loss: 1.3001, Accuracy: 0.4714\n",
      "Epoch [30/100], Loss: 1.3060, Accuracy: 0.4784\n",
      "Epoch [31/100], Loss: 1.2938, Accuracy: 0.4764\n",
      "Epoch [32/100], Loss: 1.3008, Accuracy: 0.4777\n",
      "Epoch [33/100], Loss: 1.2871, Accuracy: 0.4794\n",
      "Epoch [34/100], Loss: 1.2715, Accuracy: 0.4823\n",
      "Epoch [35/100], Loss: 1.2829, Accuracy: 0.4814\n",
      "Epoch [36/100], Loss: 1.2534, Accuracy: 0.4866\n",
      "Epoch [37/100], Loss: 1.2615, Accuracy: 0.4950\n",
      "Epoch [38/100], Loss: 1.2651, Accuracy: 0.4883\n",
      "Epoch [39/100], Loss: 1.2391, Accuracy: 0.4984\n",
      "Epoch [40/100], Loss: 1.2465, Accuracy: 0.4991\n",
      "Epoch [41/100], Loss: 1.2497, Accuracy: 0.5013\n",
      "Epoch [42/100], Loss: 1.2414, Accuracy: 0.5021\n",
      "Epoch [43/100], Loss: 1.2488, Accuracy: 0.5013\n",
      "Epoch [44/100], Loss: 1.2338, Accuracy: 0.5070\n",
      "Epoch [45/100], Loss: 1.2481, Accuracy: 0.4981\n",
      "Epoch [46/100], Loss: 1.2185, Accuracy: 0.5112\n",
      "Epoch [47/100], Loss: 1.2124, Accuracy: 0.5115\n",
      "Epoch [48/100], Loss: 1.2104, Accuracy: 0.5145\n",
      "Epoch [49/100], Loss: 1.2166, Accuracy: 0.5152\n",
      "Epoch [50/100], Loss: 1.2088, Accuracy: 0.5206\n",
      "Epoch [51/100], Loss: 1.2077, Accuracy: 0.5127\n",
      "Epoch [52/100], Loss: 1.2140, Accuracy: 0.5179\n",
      "Epoch [53/100], Loss: 1.2410, Accuracy: 0.5034\n",
      "Epoch [54/100], Loss: 1.1937, Accuracy: 0.5186\n",
      "Epoch [55/100], Loss: 1.1982, Accuracy: 0.5312\n",
      "Epoch [56/100], Loss: 1.1861, Accuracy: 0.5266\n",
      "Epoch [57/100], Loss: 1.1884, Accuracy: 0.5254\n",
      "Epoch [58/100], Loss: 1.1827, Accuracy: 0.5244\n",
      "Epoch [59/100], Loss: 1.1847, Accuracy: 0.5253\n",
      "Epoch [60/100], Loss: 1.1724, Accuracy: 0.5307\n",
      "Epoch [61/100], Loss: 1.1778, Accuracy: 0.5286\n",
      "Epoch [62/100], Loss: 1.1777, Accuracy: 0.5362\n",
      "Epoch [63/100], Loss: 1.1696, Accuracy: 0.5347\n",
      "Epoch [64/100], Loss: 1.1690, Accuracy: 0.5333\n",
      "Epoch [65/100], Loss: 1.1727, Accuracy: 0.5422\n",
      "Epoch [66/100], Loss: 1.1805, Accuracy: 0.5249\n",
      "Epoch [67/100], Loss: 1.1543, Accuracy: 0.5419\n",
      "Epoch [68/100], Loss: 1.1480, Accuracy: 0.5463\n",
      "Epoch [69/100], Loss: 1.1471, Accuracy: 0.5434\n",
      "Epoch [70/100], Loss: 1.1509, Accuracy: 0.5441\n",
      "Epoch [71/100], Loss: 1.1440, Accuracy: 0.5454\n",
      "Epoch [72/100], Loss: 1.1370, Accuracy: 0.5520\n",
      "Epoch [73/100], Loss: 1.1560, Accuracy: 0.5375\n",
      "Epoch [74/100], Loss: 1.1226, Accuracy: 0.5579\n",
      "Epoch [75/100], Loss: 1.1140, Accuracy: 0.5559\n",
      "Epoch [76/100], Loss: 1.1276, Accuracy: 0.5515\n",
      "Epoch [77/100], Loss: 1.1095, Accuracy: 0.5653\n",
      "Epoch [78/100], Loss: 1.1276, Accuracy: 0.5580\n",
      "Epoch [79/100], Loss: 1.1388, Accuracy: 0.5517\n",
      "Epoch [80/100], Loss: 1.1106, Accuracy: 0.5552\n",
      "Epoch [81/100], Loss: 1.1020, Accuracy: 0.5664\n",
      "Epoch [82/100], Loss: 1.1050, Accuracy: 0.5589\n",
      "Epoch [83/100], Loss: 1.1036, Accuracy: 0.5643\n",
      "Epoch [84/100], Loss: 1.1025, Accuracy: 0.5723\n",
      "Epoch [85/100], Loss: 1.1264, Accuracy: 0.5486\n",
      "Epoch [86/100], Loss: 1.0851, Accuracy: 0.5621\n",
      "Epoch [87/100], Loss: 1.0977, Accuracy: 0.5690\n",
      "Epoch [88/100], Loss: 1.1072, Accuracy: 0.5590\n",
      "Epoch [89/100], Loss: 1.0846, Accuracy: 0.5777\n",
      "Epoch [90/100], Loss: 1.0885, Accuracy: 0.5661\n",
      "Epoch [91/100], Loss: 1.0959, Accuracy: 0.5666\n",
      "Epoch [92/100], Loss: 1.0762, Accuracy: 0.5727\n",
      "Epoch [93/100], Loss: 1.0839, Accuracy: 0.5691\n",
      "Epoch [94/100], Loss: 1.0809, Accuracy: 0.5676\n",
      "Epoch [95/100], Loss: 1.0753, Accuracy: 0.5787\n",
      "Epoch [96/100], Loss: 1.0736, Accuracy: 0.5752\n",
      "Epoch [97/100], Loss: 1.0627, Accuracy: 0.5851\n",
      "Epoch [98/100], Loss: 1.0675, Accuracy: 0.5782\n",
      "Epoch [99/100], Loss: 1.0679, Accuracy: 0.5784\n",
      "Epoch [100/100], Loss: 1.0722, Accuracy: 0.5799\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network with Attention\n",
    "cnn_atn_model = CNNAttention(input_size[0],num_classes).to(device)\n",
    "optimizer = optim.Adam(cnn_atn_model.parameters(), lr=0.001)\n",
    "train(cnn_atn_model, train_loaderCNN, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para teste\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n",
    "\n",
    "    test_loss = running_loss / len(test_loader)\n",
    "    test_accuracy = correct / total\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SimpleDNN:\n",
      "Test Loss: 1.4449, Test Accuracy: 0.3962\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing SimpleDNN:\")\n",
    "test(sdnn_model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing LSTMModel:\n",
      "Test Loss: 1.4472, Test Accuracy: 0.4318\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting LSTMModel:\")\n",
    "test(lstm_model, test_loaderLSTM, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing LSTMAttention:\n",
      "Test Loss: 1.4919, Test Accuracy: 0.4278\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting LSTMAttention:\")\n",
    "test(lstm_atn_model, test_loaderLSTM, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing CNNModel:\n",
      "Test Loss: 1.4901, Test Accuracy: 0.3801\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting CNNModel:\")\n",
    "test(cnn_model, test_loaderCNN, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing CNNAttention:\n",
      "Test Loss: 1.5998, Test Accuracy: 0.4439\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting CNNAttention:\")\n",
    "test(cnn_atn_model, test_loaderCNN, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
