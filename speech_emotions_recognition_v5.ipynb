{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>./AudioWAV/1013_TSI_HAP_XX.wav</td>\n",
       "      <td>happy.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6617</th>\n",
       "      <td>./AudioWAV/1081_WSI_DIS_XX.wav</td>\n",
       "      <td>disgust.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>./AudioWAV/1014_MTI_FEA_XX.wav</td>\n",
       "      <td>fear.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>./AudioWAV/1027_IWW_DIS_XX.wav</td>\n",
       "      <td>disgust.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>./AudioWAV/1089_IEO_SAD_LO.wav</td>\n",
       "      <td>sad.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              speech        label\n",
       "1044  ./AudioWAV/1013_TSI_HAP_XX.wav    happy.wav\n",
       "6617  ./AudioWAV/1081_WSI_DIS_XX.wav  disgust.wav\n",
       "1107  ./AudioWAV/1014_MTI_FEA_XX.wav     fear.wav\n",
       "2160  ./AudioWAV/1027_IWW_DIS_XX.wav  disgust.wav\n",
       "7216  ./AudioWAV/1089_IEO_SAD_LO.wav      sad.wav"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths=[]\n",
    "labels=[]\n",
    "for filename in os.listdir('./AudioWAV'):\n",
    "    \n",
    "    paths.append('./AudioWAV/' + filename)\n",
    "    file = filename.split('.')[0]\n",
    "   \n",
    "    label = file.split('_')[2]\n",
    "    if label == 'ANG':\n",
    "        labels.append('angry.wav')\n",
    "    elif label == 'DIS':\n",
    "        labels.append('disgust.wav')\n",
    "    elif label == 'FEA':\n",
    "        labels.append('fear.wav')\n",
    "    elif label == 'HAP':\n",
    "        labels.append('happy.wav')\n",
    "    elif label == 'NEU':\n",
    "        labels.append('neutral.wav')\n",
    "    elif label == 'SAD':\n",
    "        labels.append('sad.wav')\n",
    "        \n",
    "\n",
    "df_cremad = pd.DataFrame({'speech':paths,'label':labels})\n",
    "df_cremad.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFCC(filename):\n",
    "    y, sr = librosa.load(filename,duration=3,offset=0.5)\n",
    "    return np.mean(librosa.feature.mfcc(y=y,sr=sr,n_mfcc=40).T,axis=0)\n",
    "\n",
    "mfcc_cremad = df_cremad['speech'].apply(lambda x:MFCC(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7442, 40, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X =[x for x in mfcc_cremad]\n",
    "X =np.array(X)\n",
    "X.shape\n",
    "X =np.expand_dims(X,-1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe=OneHotEncoder()\n",
    "y = ohe.fit_transform(df_cremad[['label']] )\n",
    "y = y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7442, 40, 1), (7442, 6))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry.wav', 'disgust.wav', 'fear.wav', 'happy.wav', 'neutral.wav',\n",
       "       'sad.wav'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cremad['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Definindo os modelos\n",
    "\n",
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class LSTMAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
    "        out = torch.sum(attn_weights * out, dim=1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
    "        self.fc_input_size = 32 * 1 * 1\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, self.fc_input_size)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNNAttention(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNNAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
    "        self.attention = nn.Linear(32, 1)\n",
    "        self.fc = nn.Linear(32, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        attn_weights = self.softmax(self.attention(x.permute(0, 2, 1))).squeeze(-1)\n",
    "        attn_weights = attn_weights.unsqueeze(-1)\n",
    "        x = torch.sum(attn_weights * x, dim=2)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "# Construindo e treinando os modelos\n",
    "\n",
    "input_size = X.shape[1:]\n",
    "num_classes = y.shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Convertendo os dados para tensores PyTorch\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "# Definindo o tamanho do lote\n",
    "batch_size = 32\n",
    "\n",
    "# Criando conjuntos de dados PyTorch\n",
    "dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Definindo tensor para o LSTM\n",
    "X_tensorLSTM = X_tensor.permute(0, 2, 1)\n",
    "\n",
    "# Criando conjuntos de dados PyTorch para LSTM\n",
    "datasetLSTM = torch.utils.data.TensorDataset(X_tensorLSTM, y_tensor)\n",
    "train_sizeLSTM = int(0.8 * len(datasetLSTM))\n",
    "test_sizeLSTM = len(datasetLSTM) - train_sizeLSTM\n",
    "train_datasetLSTM, test_datasetLSTM = torch.utils.data.random_split(datasetLSTM, [train_sizeLSTM, test_sizeLSTM])\n",
    "\n",
    "# DataLoader para o LSTM\n",
    "train_loaderLSTM = DataLoader(train_datasetLSTM, batch_size=batch_size, shuffle=True)\n",
    "test_loaderLSTM = DataLoader(test_datasetLSTM, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Convertendo os dados para tensores PyTorch do CNN\n",
    "X_tensorCNN = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "\n",
    "# Criando conjuntos de dados PyTorch do CNN\n",
    "datasetCNN = torch.utils.data.TensorDataset(X_tensorCNN, y_tensor)\n",
    "train_sizeCNN = int(0.8 * len(datasetCNN))\n",
    "test_sizeCNN = len(datasetCNN) - train_sizeCNN\n",
    "train_datasetCNN, test_datasetCNN = torch.utils.data.random_split(datasetCNN, [train_sizeCNN, test_sizeCNN])\n",
    "\n",
    "# DataLoader para o CNN\n",
    "train_loaderCNN = DataLoader(train_datasetCNN, batch_size=batch_size, shuffle=True)\n",
    "test_loaderCNN = DataLoader(test_datasetCNN, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Função para treinamento\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs=500):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            #print(outputs.shape)\n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        accuracy = correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 8.9504, Accuracy: 0.1734\n",
      "Epoch [2/500], Loss: 4.1523, Accuracy: 0.1759\n",
      "Epoch [3/500], Loss: 2.5940, Accuracy: 0.1720\n",
      "Epoch [4/500], Loss: 2.1372, Accuracy: 0.1786\n",
      "Epoch [5/500], Loss: 1.9814, Accuracy: 0.1683\n",
      "Epoch [6/500], Loss: 1.8996, Accuracy: 0.1729\n",
      "Epoch [7/500], Loss: 1.8656, Accuracy: 0.1779\n",
      "Epoch [8/500], Loss: 1.8484, Accuracy: 0.1702\n",
      "Epoch [9/500], Loss: 1.8411, Accuracy: 0.1700\n",
      "Epoch [10/500], Loss: 1.8158, Accuracy: 0.1777\n",
      "Epoch [11/500], Loss: 1.8126, Accuracy: 0.1722\n",
      "Epoch [12/500], Loss: 1.8044, Accuracy: 0.1710\n",
      "Epoch [13/500], Loss: 1.8049, Accuracy: 0.1735\n",
      "Epoch [14/500], Loss: 1.8062, Accuracy: 0.1688\n",
      "Epoch [15/500], Loss: 1.8012, Accuracy: 0.1724\n",
      "Epoch [16/500], Loss: 1.7989, Accuracy: 0.1732\n",
      "Epoch [17/500], Loss: 1.7982, Accuracy: 0.1747\n",
      "Epoch [18/500], Loss: 1.7943, Accuracy: 0.1720\n",
      "Epoch [19/500], Loss: 1.7912, Accuracy: 0.1740\n",
      "Epoch [20/500], Loss: 1.7930, Accuracy: 0.1734\n",
      "Epoch [21/500], Loss: 1.7880, Accuracy: 0.1920\n",
      "Epoch [22/500], Loss: 1.7791, Accuracy: 0.1970\n",
      "Epoch [23/500], Loss: 1.7761, Accuracy: 0.2061\n",
      "Epoch [24/500], Loss: 1.7640, Accuracy: 0.2108\n",
      "Epoch [25/500], Loss: 1.7624, Accuracy: 0.2175\n",
      "Epoch [26/500], Loss: 1.7552, Accuracy: 0.2243\n",
      "Epoch [27/500], Loss: 1.7448, Accuracy: 0.2280\n",
      "Epoch [28/500], Loss: 1.7288, Accuracy: 0.2379\n",
      "Epoch [29/500], Loss: 1.7152, Accuracy: 0.2448\n",
      "Epoch [30/500], Loss: 1.7037, Accuracy: 0.2500\n",
      "Epoch [31/500], Loss: 1.7058, Accuracy: 0.2473\n",
      "Epoch [32/500], Loss: 1.6887, Accuracy: 0.2567\n",
      "Epoch [33/500], Loss: 1.6969, Accuracy: 0.2679\n",
      "Epoch [34/500], Loss: 1.6811, Accuracy: 0.2716\n",
      "Epoch [35/500], Loss: 1.6722, Accuracy: 0.2804\n",
      "Epoch [36/500], Loss: 1.6711, Accuracy: 0.2862\n",
      "Epoch [37/500], Loss: 1.6671, Accuracy: 0.2758\n",
      "Epoch [38/500], Loss: 1.6650, Accuracy: 0.2876\n",
      "Epoch [39/500], Loss: 1.6611, Accuracy: 0.2909\n",
      "Epoch [40/500], Loss: 1.6492, Accuracy: 0.2960\n",
      "Epoch [41/500], Loss: 1.6544, Accuracy: 0.2933\n",
      "Epoch [42/500], Loss: 1.6393, Accuracy: 0.2926\n",
      "Epoch [43/500], Loss: 1.6405, Accuracy: 0.2943\n",
      "Epoch [44/500], Loss: 1.6352, Accuracy: 0.2973\n",
      "Epoch [45/500], Loss: 1.6275, Accuracy: 0.3005\n",
      "Epoch [46/500], Loss: 1.6299, Accuracy: 0.3047\n",
      "Epoch [47/500], Loss: 1.6256, Accuracy: 0.3000\n",
      "Epoch [48/500], Loss: 1.6301, Accuracy: 0.3057\n",
      "Epoch [49/500], Loss: 1.6114, Accuracy: 0.3034\n",
      "Epoch [50/500], Loss: 1.6126, Accuracy: 0.3123\n",
      "Epoch [51/500], Loss: 1.6189, Accuracy: 0.3017\n",
      "Epoch [52/500], Loss: 1.6178, Accuracy: 0.3044\n",
      "Epoch [53/500], Loss: 1.6090, Accuracy: 0.3121\n",
      "Epoch [54/500], Loss: 1.5895, Accuracy: 0.3240\n",
      "Epoch [55/500], Loss: 1.6100, Accuracy: 0.3101\n",
      "Epoch [56/500], Loss: 1.6048, Accuracy: 0.3151\n",
      "Epoch [57/500], Loss: 1.6044, Accuracy: 0.3130\n",
      "Epoch [58/500], Loss: 1.5980, Accuracy: 0.3168\n",
      "Epoch [59/500], Loss: 1.5853, Accuracy: 0.3175\n",
      "Epoch [60/500], Loss: 1.5809, Accuracy: 0.3197\n",
      "Epoch [61/500], Loss: 1.5897, Accuracy: 0.3210\n",
      "Epoch [62/500], Loss: 1.5901, Accuracy: 0.3313\n",
      "Epoch [63/500], Loss: 1.5873, Accuracy: 0.3269\n",
      "Epoch [64/500], Loss: 1.5847, Accuracy: 0.3256\n",
      "Epoch [65/500], Loss: 1.5738, Accuracy: 0.3309\n",
      "Epoch [66/500], Loss: 1.5739, Accuracy: 0.3294\n",
      "Epoch [67/500], Loss: 1.5803, Accuracy: 0.3224\n",
      "Epoch [68/500], Loss: 1.5762, Accuracy: 0.3365\n",
      "Epoch [69/500], Loss: 1.5730, Accuracy: 0.3350\n",
      "Epoch [70/500], Loss: 1.5642, Accuracy: 0.3353\n",
      "Epoch [71/500], Loss: 1.5770, Accuracy: 0.3345\n",
      "Epoch [72/500], Loss: 1.5557, Accuracy: 0.3358\n",
      "Epoch [73/500], Loss: 1.5659, Accuracy: 0.3366\n",
      "Epoch [74/500], Loss: 1.5629, Accuracy: 0.3423\n",
      "Epoch [75/500], Loss: 1.5644, Accuracy: 0.3381\n",
      "Epoch [76/500], Loss: 1.5427, Accuracy: 0.3472\n",
      "Epoch [77/500], Loss: 1.5534, Accuracy: 0.3425\n",
      "Epoch [78/500], Loss: 1.5437, Accuracy: 0.3511\n",
      "Epoch [79/500], Loss: 1.5456, Accuracy: 0.3544\n",
      "Epoch [80/500], Loss: 1.5520, Accuracy: 0.3494\n",
      "Epoch [81/500], Loss: 1.5498, Accuracy: 0.3460\n",
      "Epoch [82/500], Loss: 1.5468, Accuracy: 0.3533\n",
      "Epoch [83/500], Loss: 1.5257, Accuracy: 0.3511\n",
      "Epoch [84/500], Loss: 1.5404, Accuracy: 0.3595\n",
      "Epoch [85/500], Loss: 1.5403, Accuracy: 0.3565\n",
      "Epoch [86/500], Loss: 1.5255, Accuracy: 0.3548\n",
      "Epoch [87/500], Loss: 1.5296, Accuracy: 0.3613\n",
      "Epoch [88/500], Loss: 1.5295, Accuracy: 0.3602\n",
      "Epoch [89/500], Loss: 1.5225, Accuracy: 0.3650\n",
      "Epoch [90/500], Loss: 1.5203, Accuracy: 0.3664\n",
      "Epoch [91/500], Loss: 1.5218, Accuracy: 0.3591\n",
      "Epoch [92/500], Loss: 1.5140, Accuracy: 0.3665\n",
      "Epoch [93/500], Loss: 1.5222, Accuracy: 0.3608\n",
      "Epoch [94/500], Loss: 1.5233, Accuracy: 0.3628\n",
      "Epoch [95/500], Loss: 1.5208, Accuracy: 0.3714\n",
      "Epoch [96/500], Loss: 1.5238, Accuracy: 0.3657\n",
      "Epoch [97/500], Loss: 1.5157, Accuracy: 0.3686\n",
      "Epoch [98/500], Loss: 1.5020, Accuracy: 0.3763\n",
      "Epoch [99/500], Loss: 1.5174, Accuracy: 0.3691\n",
      "Epoch [100/500], Loss: 1.5081, Accuracy: 0.3699\n",
      "Epoch [101/500], Loss: 1.5034, Accuracy: 0.3689\n",
      "Epoch [102/500], Loss: 1.5104, Accuracy: 0.3699\n",
      "Epoch [103/500], Loss: 1.5084, Accuracy: 0.3660\n",
      "Epoch [104/500], Loss: 1.4961, Accuracy: 0.3687\n",
      "Epoch [105/500], Loss: 1.4978, Accuracy: 0.3707\n",
      "Epoch [106/500], Loss: 1.4995, Accuracy: 0.3687\n",
      "Epoch [107/500], Loss: 1.4951, Accuracy: 0.3711\n",
      "Epoch [108/500], Loss: 1.4973, Accuracy: 0.3632\n",
      "Epoch [109/500], Loss: 1.5075, Accuracy: 0.3741\n",
      "Epoch [110/500], Loss: 1.5023, Accuracy: 0.3837\n",
      "Epoch [111/500], Loss: 1.5080, Accuracy: 0.3761\n",
      "Epoch [112/500], Loss: 1.4994, Accuracy: 0.3711\n",
      "Epoch [113/500], Loss: 1.4939, Accuracy: 0.3786\n",
      "Epoch [114/500], Loss: 1.4865, Accuracy: 0.3823\n",
      "Epoch [115/500], Loss: 1.4935, Accuracy: 0.3719\n",
      "Epoch [116/500], Loss: 1.4837, Accuracy: 0.3788\n",
      "Epoch [117/500], Loss: 1.4817, Accuracy: 0.3864\n",
      "Epoch [118/500], Loss: 1.4952, Accuracy: 0.3825\n",
      "Epoch [119/500], Loss: 1.4881, Accuracy: 0.3803\n",
      "Epoch [120/500], Loss: 1.4868, Accuracy: 0.3843\n",
      "Epoch [121/500], Loss: 1.4790, Accuracy: 0.3956\n",
      "Epoch [122/500], Loss: 1.4847, Accuracy: 0.3806\n",
      "Epoch [123/500], Loss: 1.4799, Accuracy: 0.3862\n",
      "Epoch [124/500], Loss: 1.4811, Accuracy: 0.3835\n",
      "Epoch [125/500], Loss: 1.4821, Accuracy: 0.3848\n",
      "Epoch [126/500], Loss: 1.4725, Accuracy: 0.3956\n",
      "Epoch [127/500], Loss: 1.4831, Accuracy: 0.3832\n",
      "Epoch [128/500], Loss: 1.4731, Accuracy: 0.3946\n",
      "Epoch [129/500], Loss: 1.4725, Accuracy: 0.3901\n",
      "Epoch [130/500], Loss: 1.4807, Accuracy: 0.3838\n",
      "Epoch [131/500], Loss: 1.4706, Accuracy: 0.3815\n",
      "Epoch [132/500], Loss: 1.4686, Accuracy: 0.3943\n",
      "Epoch [133/500], Loss: 1.4668, Accuracy: 0.3889\n",
      "Epoch [134/500], Loss: 1.4644, Accuracy: 0.3961\n",
      "Epoch [135/500], Loss: 1.4648, Accuracy: 0.3934\n",
      "Epoch [136/500], Loss: 1.4592, Accuracy: 0.3973\n",
      "Epoch [137/500], Loss: 1.4678, Accuracy: 0.3865\n",
      "Epoch [138/500], Loss: 1.4769, Accuracy: 0.3911\n",
      "Epoch [139/500], Loss: 1.4739, Accuracy: 0.3904\n",
      "Epoch [140/500], Loss: 1.4623, Accuracy: 0.3823\n",
      "Epoch [141/500], Loss: 1.4639, Accuracy: 0.3912\n",
      "Epoch [142/500], Loss: 1.4607, Accuracy: 0.3951\n",
      "Epoch [143/500], Loss: 1.4639, Accuracy: 0.3966\n",
      "Epoch [144/500], Loss: 1.4589, Accuracy: 0.3850\n",
      "Epoch [145/500], Loss: 1.4635, Accuracy: 0.3852\n",
      "Epoch [146/500], Loss: 1.4628, Accuracy: 0.3870\n",
      "Epoch [147/500], Loss: 1.4635, Accuracy: 0.4008\n",
      "Epoch [148/500], Loss: 1.4581, Accuracy: 0.3996\n",
      "Epoch [149/500], Loss: 1.4634, Accuracy: 0.3995\n",
      "Epoch [150/500], Loss: 1.4534, Accuracy: 0.3909\n",
      "Epoch [151/500], Loss: 1.4555, Accuracy: 0.3938\n",
      "Epoch [152/500], Loss: 1.4490, Accuracy: 0.3949\n",
      "Epoch [153/500], Loss: 1.4485, Accuracy: 0.3964\n",
      "Epoch [154/500], Loss: 1.4584, Accuracy: 0.4015\n",
      "Epoch [155/500], Loss: 1.4483, Accuracy: 0.3956\n",
      "Epoch [156/500], Loss: 1.4578, Accuracy: 0.4020\n",
      "Epoch [157/500], Loss: 1.4579, Accuracy: 0.3959\n",
      "Epoch [158/500], Loss: 1.4571, Accuracy: 0.4052\n",
      "Epoch [159/500], Loss: 1.4539, Accuracy: 0.4023\n",
      "Epoch [160/500], Loss: 1.4507, Accuracy: 0.4112\n",
      "Epoch [161/500], Loss: 1.4465, Accuracy: 0.3983\n",
      "Epoch [162/500], Loss: 1.4527, Accuracy: 0.4092\n",
      "Epoch [163/500], Loss: 1.4535, Accuracy: 0.3990\n",
      "Epoch [164/500], Loss: 1.4459, Accuracy: 0.3996\n",
      "Epoch [165/500], Loss: 1.4572, Accuracy: 0.4072\n",
      "Epoch [166/500], Loss: 1.4617, Accuracy: 0.3917\n",
      "Epoch [167/500], Loss: 1.4419, Accuracy: 0.4010\n",
      "Epoch [168/500], Loss: 1.4441, Accuracy: 0.4001\n",
      "Epoch [169/500], Loss: 1.4473, Accuracy: 0.3978\n",
      "Epoch [170/500], Loss: 1.4445, Accuracy: 0.3998\n",
      "Epoch [171/500], Loss: 1.4368, Accuracy: 0.4109\n",
      "Epoch [172/500], Loss: 1.4363, Accuracy: 0.4025\n",
      "Epoch [173/500], Loss: 1.4406, Accuracy: 0.4033\n",
      "Epoch [174/500], Loss: 1.4296, Accuracy: 0.4035\n",
      "Epoch [175/500], Loss: 1.4434, Accuracy: 0.3998\n",
      "Epoch [176/500], Loss: 1.4371, Accuracy: 0.4077\n",
      "Epoch [177/500], Loss: 1.4412, Accuracy: 0.4050\n",
      "Epoch [178/500], Loss: 1.4343, Accuracy: 0.4055\n",
      "Epoch [179/500], Loss: 1.4356, Accuracy: 0.4095\n",
      "Epoch [180/500], Loss: 1.4378, Accuracy: 0.4052\n",
      "Epoch [181/500], Loss: 1.4317, Accuracy: 0.4043\n",
      "Epoch [182/500], Loss: 1.4431, Accuracy: 0.4005\n",
      "Epoch [183/500], Loss: 1.4285, Accuracy: 0.4095\n",
      "Epoch [184/500], Loss: 1.4281, Accuracy: 0.4186\n",
      "Epoch [185/500], Loss: 1.4284, Accuracy: 0.4050\n",
      "Epoch [186/500], Loss: 1.4359, Accuracy: 0.4069\n",
      "Epoch [187/500], Loss: 1.4306, Accuracy: 0.4163\n",
      "Epoch [188/500], Loss: 1.4399, Accuracy: 0.4092\n",
      "Epoch [189/500], Loss: 1.4248, Accuracy: 0.4082\n",
      "Epoch [190/500], Loss: 1.4301, Accuracy: 0.4141\n",
      "Epoch [191/500], Loss: 1.4225, Accuracy: 0.4163\n",
      "Epoch [192/500], Loss: 1.4302, Accuracy: 0.4104\n",
      "Epoch [193/500], Loss: 1.4136, Accuracy: 0.4158\n",
      "Epoch [194/500], Loss: 1.4322, Accuracy: 0.4030\n",
      "Epoch [195/500], Loss: 1.4242, Accuracy: 0.4117\n",
      "Epoch [196/500], Loss: 1.4263, Accuracy: 0.4141\n",
      "Epoch [197/500], Loss: 1.4261, Accuracy: 0.4104\n",
      "Epoch [198/500], Loss: 1.4284, Accuracy: 0.4094\n",
      "Epoch [199/500], Loss: 1.4305, Accuracy: 0.4099\n",
      "Epoch [200/500], Loss: 1.4220, Accuracy: 0.4104\n",
      "Epoch [201/500], Loss: 1.4239, Accuracy: 0.4067\n",
      "Epoch [202/500], Loss: 1.4227, Accuracy: 0.4226\n",
      "Epoch [203/500], Loss: 1.4182, Accuracy: 0.4198\n",
      "Epoch [204/500], Loss: 1.4253, Accuracy: 0.4092\n",
      "Epoch [205/500], Loss: 1.4272, Accuracy: 0.4117\n",
      "Epoch [206/500], Loss: 1.4234, Accuracy: 0.4166\n",
      "Epoch [207/500], Loss: 1.4131, Accuracy: 0.4124\n",
      "Epoch [208/500], Loss: 1.4085, Accuracy: 0.4169\n",
      "Epoch [209/500], Loss: 1.4139, Accuracy: 0.4201\n",
      "Epoch [210/500], Loss: 1.4241, Accuracy: 0.4121\n",
      "Epoch [211/500], Loss: 1.4169, Accuracy: 0.4131\n",
      "Epoch [212/500], Loss: 1.4200, Accuracy: 0.4179\n",
      "Epoch [213/500], Loss: 1.4474, Accuracy: 0.4223\n",
      "Epoch [214/500], Loss: 1.4115, Accuracy: 0.4107\n",
      "Epoch [215/500], Loss: 1.4112, Accuracy: 0.4169\n",
      "Epoch [216/500], Loss: 1.4187, Accuracy: 0.4159\n",
      "Epoch [217/500], Loss: 1.4176, Accuracy: 0.4149\n",
      "Epoch [218/500], Loss: 1.4109, Accuracy: 0.4183\n",
      "Epoch [219/500], Loss: 1.4118, Accuracy: 0.4141\n",
      "Epoch [220/500], Loss: 1.4044, Accuracy: 0.4262\n",
      "Epoch [221/500], Loss: 1.4067, Accuracy: 0.4237\n",
      "Epoch [222/500], Loss: 1.4104, Accuracy: 0.4158\n",
      "Epoch [223/500], Loss: 1.4092, Accuracy: 0.4206\n",
      "Epoch [224/500], Loss: 1.3994, Accuracy: 0.4290\n",
      "Epoch [225/500], Loss: 1.4002, Accuracy: 0.4220\n",
      "Epoch [226/500], Loss: 1.4050, Accuracy: 0.4168\n",
      "Epoch [227/500], Loss: 1.4044, Accuracy: 0.4196\n",
      "Epoch [228/500], Loss: 1.4080, Accuracy: 0.4287\n",
      "Epoch [229/500], Loss: 1.4040, Accuracy: 0.4245\n",
      "Epoch [230/500], Loss: 1.4113, Accuracy: 0.4171\n",
      "Epoch [231/500], Loss: 1.4177, Accuracy: 0.4161\n",
      "Epoch [232/500], Loss: 1.3971, Accuracy: 0.4253\n",
      "Epoch [233/500], Loss: 1.3991, Accuracy: 0.4235\n",
      "Epoch [234/500], Loss: 1.4025, Accuracy: 0.4201\n",
      "Epoch [235/500], Loss: 1.3963, Accuracy: 0.4211\n",
      "Epoch [236/500], Loss: 1.4007, Accuracy: 0.4272\n",
      "Epoch [237/500], Loss: 1.3989, Accuracy: 0.4158\n",
      "Epoch [238/500], Loss: 1.4050, Accuracy: 0.4223\n",
      "Epoch [239/500], Loss: 1.3948, Accuracy: 0.4280\n",
      "Epoch [240/500], Loss: 1.3948, Accuracy: 0.4253\n",
      "Epoch [241/500], Loss: 1.3966, Accuracy: 0.4221\n",
      "Epoch [242/500], Loss: 1.4017, Accuracy: 0.4302\n",
      "Epoch [243/500], Loss: 1.3963, Accuracy: 0.4176\n",
      "Epoch [244/500], Loss: 1.3943, Accuracy: 0.4188\n",
      "Epoch [245/500], Loss: 1.3954, Accuracy: 0.4305\n",
      "Epoch [246/500], Loss: 1.3953, Accuracy: 0.4346\n",
      "Epoch [247/500], Loss: 1.3901, Accuracy: 0.4280\n",
      "Epoch [248/500], Loss: 1.3983, Accuracy: 0.4257\n",
      "Epoch [249/500], Loss: 1.3892, Accuracy: 0.4342\n",
      "Epoch [250/500], Loss: 1.3918, Accuracy: 0.4210\n",
      "Epoch [251/500], Loss: 1.3934, Accuracy: 0.4304\n",
      "Epoch [252/500], Loss: 1.3859, Accuracy: 0.4361\n",
      "Epoch [253/500], Loss: 1.3952, Accuracy: 0.4237\n",
      "Epoch [254/500], Loss: 1.3865, Accuracy: 0.4279\n",
      "Epoch [255/500], Loss: 1.3915, Accuracy: 0.4240\n",
      "Epoch [256/500], Loss: 1.3953, Accuracy: 0.4226\n",
      "Epoch [257/500], Loss: 1.3965, Accuracy: 0.4258\n",
      "Epoch [258/500], Loss: 1.4059, Accuracy: 0.4200\n",
      "Epoch [259/500], Loss: 1.3950, Accuracy: 0.4253\n",
      "Epoch [260/500], Loss: 1.3956, Accuracy: 0.4245\n",
      "Epoch [261/500], Loss: 1.3976, Accuracy: 0.4321\n",
      "Epoch [262/500], Loss: 1.3949, Accuracy: 0.4215\n",
      "Epoch [263/500], Loss: 1.3778, Accuracy: 0.4344\n",
      "Epoch [264/500], Loss: 1.3845, Accuracy: 0.4305\n",
      "Epoch [265/500], Loss: 1.3941, Accuracy: 0.4248\n",
      "Epoch [266/500], Loss: 1.3888, Accuracy: 0.4268\n",
      "Epoch [267/500], Loss: 1.3894, Accuracy: 0.4292\n",
      "Epoch [268/500], Loss: 1.3916, Accuracy: 0.4268\n",
      "Epoch [269/500], Loss: 1.3807, Accuracy: 0.4299\n",
      "Epoch [270/500], Loss: 1.3825, Accuracy: 0.4257\n",
      "Epoch [271/500], Loss: 1.3867, Accuracy: 0.4334\n",
      "Epoch [272/500], Loss: 1.3847, Accuracy: 0.4277\n",
      "Epoch [273/500], Loss: 1.3882, Accuracy: 0.4292\n",
      "Epoch [274/500], Loss: 1.3749, Accuracy: 0.4319\n",
      "Epoch [275/500], Loss: 1.3821, Accuracy: 0.4253\n",
      "Epoch [276/500], Loss: 1.3876, Accuracy: 0.4295\n",
      "Epoch [277/500], Loss: 1.3833, Accuracy: 0.4366\n",
      "Epoch [278/500], Loss: 1.3838, Accuracy: 0.4300\n",
      "Epoch [279/500], Loss: 1.3721, Accuracy: 0.4349\n",
      "Epoch [280/500], Loss: 1.3842, Accuracy: 0.4277\n",
      "Epoch [281/500], Loss: 1.3760, Accuracy: 0.4378\n",
      "Epoch [282/500], Loss: 1.3784, Accuracy: 0.4265\n",
      "Epoch [283/500], Loss: 1.3962, Accuracy: 0.4240\n",
      "Epoch [284/500], Loss: 1.3825, Accuracy: 0.4423\n",
      "Epoch [285/500], Loss: 1.3844, Accuracy: 0.4297\n",
      "Epoch [286/500], Loss: 1.3817, Accuracy: 0.4290\n",
      "Epoch [287/500], Loss: 1.3845, Accuracy: 0.4302\n",
      "Epoch [288/500], Loss: 1.3738, Accuracy: 0.4270\n",
      "Epoch [289/500], Loss: 1.3764, Accuracy: 0.4297\n",
      "Epoch [290/500], Loss: 1.3894, Accuracy: 0.4322\n",
      "Epoch [291/500], Loss: 1.3763, Accuracy: 0.4366\n",
      "Epoch [292/500], Loss: 1.3774, Accuracy: 0.4315\n",
      "Epoch [293/500], Loss: 1.3723, Accuracy: 0.4415\n",
      "Epoch [294/500], Loss: 1.3739, Accuracy: 0.4413\n",
      "Epoch [295/500], Loss: 1.3748, Accuracy: 0.4366\n",
      "Epoch [296/500], Loss: 1.3726, Accuracy: 0.4371\n",
      "Epoch [297/500], Loss: 1.3765, Accuracy: 0.4423\n",
      "Epoch [298/500], Loss: 1.3717, Accuracy: 0.4371\n",
      "Epoch [299/500], Loss: 1.3791, Accuracy: 0.4403\n",
      "Epoch [300/500], Loss: 1.3672, Accuracy: 0.4420\n",
      "Epoch [301/500], Loss: 1.3763, Accuracy: 0.4351\n",
      "Epoch [302/500], Loss: 1.3660, Accuracy: 0.4347\n",
      "Epoch [303/500], Loss: 1.3732, Accuracy: 0.4384\n",
      "Epoch [304/500], Loss: 1.3876, Accuracy: 0.4359\n",
      "Epoch [305/500], Loss: 1.3611, Accuracy: 0.4465\n",
      "Epoch [306/500], Loss: 1.3654, Accuracy: 0.4418\n",
      "Epoch [307/500], Loss: 1.3660, Accuracy: 0.4403\n",
      "Epoch [308/500], Loss: 1.3729, Accuracy: 0.4356\n",
      "Epoch [309/500], Loss: 1.3635, Accuracy: 0.4455\n",
      "Epoch [310/500], Loss: 1.3728, Accuracy: 0.4327\n",
      "Epoch [311/500], Loss: 1.3665, Accuracy: 0.4394\n",
      "Epoch [312/500], Loss: 1.3715, Accuracy: 0.4433\n",
      "Epoch [313/500], Loss: 1.3712, Accuracy: 0.4357\n",
      "Epoch [314/500], Loss: 1.3725, Accuracy: 0.4319\n",
      "Epoch [315/500], Loss: 1.3732, Accuracy: 0.4354\n",
      "Epoch [316/500], Loss: 1.3929, Accuracy: 0.4233\n",
      "Epoch [317/500], Loss: 1.3720, Accuracy: 0.4344\n",
      "Epoch [318/500], Loss: 1.3671, Accuracy: 0.4359\n",
      "Epoch [319/500], Loss: 1.3661, Accuracy: 0.4423\n",
      "Epoch [320/500], Loss: 1.3597, Accuracy: 0.4354\n",
      "Epoch [321/500], Loss: 1.3744, Accuracy: 0.4401\n",
      "Epoch [322/500], Loss: 1.3750, Accuracy: 0.4334\n",
      "Epoch [323/500], Loss: 1.3670, Accuracy: 0.4423\n",
      "Epoch [324/500], Loss: 1.3635, Accuracy: 0.4410\n",
      "Epoch [325/500], Loss: 1.3721, Accuracy: 0.4378\n",
      "Epoch [326/500], Loss: 1.3805, Accuracy: 0.4326\n",
      "Epoch [327/500], Loss: 1.3690, Accuracy: 0.4309\n",
      "Epoch [328/500], Loss: 1.3651, Accuracy: 0.4509\n",
      "Epoch [329/500], Loss: 1.3652, Accuracy: 0.4399\n",
      "Epoch [330/500], Loss: 1.3596, Accuracy: 0.4426\n",
      "Epoch [331/500], Loss: 1.3617, Accuracy: 0.4381\n",
      "Epoch [332/500], Loss: 1.3597, Accuracy: 0.4386\n",
      "Epoch [333/500], Loss: 1.3679, Accuracy: 0.4410\n",
      "Epoch [334/500], Loss: 1.3480, Accuracy: 0.4401\n",
      "Epoch [335/500], Loss: 1.3608, Accuracy: 0.4359\n",
      "Epoch [336/500], Loss: 1.3664, Accuracy: 0.4452\n",
      "Epoch [337/500], Loss: 1.3500, Accuracy: 0.4435\n",
      "Epoch [338/500], Loss: 1.3534, Accuracy: 0.4431\n",
      "Epoch [339/500], Loss: 1.3612, Accuracy: 0.4410\n",
      "Epoch [340/500], Loss: 1.3574, Accuracy: 0.4457\n",
      "Epoch [341/500], Loss: 1.3507, Accuracy: 0.4452\n",
      "Epoch [342/500], Loss: 1.3626, Accuracy: 0.4436\n",
      "Epoch [343/500], Loss: 1.3632, Accuracy: 0.4408\n",
      "Epoch [344/500], Loss: 1.3477, Accuracy: 0.4477\n",
      "Epoch [345/500], Loss: 1.3496, Accuracy: 0.4443\n",
      "Epoch [346/500], Loss: 1.3501, Accuracy: 0.4465\n",
      "Epoch [347/500], Loss: 1.3524, Accuracy: 0.4425\n",
      "Epoch [348/500], Loss: 1.3516, Accuracy: 0.4413\n",
      "Epoch [349/500], Loss: 1.3479, Accuracy: 0.4416\n",
      "Epoch [350/500], Loss: 1.3486, Accuracy: 0.4549\n",
      "Epoch [351/500], Loss: 1.3452, Accuracy: 0.4410\n",
      "Epoch [352/500], Loss: 1.3621, Accuracy: 0.4462\n",
      "Epoch [353/500], Loss: 1.3520, Accuracy: 0.4477\n",
      "Epoch [354/500], Loss: 1.3644, Accuracy: 0.4544\n",
      "Epoch [355/500], Loss: 1.3555, Accuracy: 0.4408\n",
      "Epoch [356/500], Loss: 1.3412, Accuracy: 0.4599\n",
      "Epoch [357/500], Loss: 1.3541, Accuracy: 0.4472\n",
      "Epoch [358/500], Loss: 1.3551, Accuracy: 0.4519\n",
      "Epoch [359/500], Loss: 1.3450, Accuracy: 0.4483\n",
      "Epoch [360/500], Loss: 1.3561, Accuracy: 0.4510\n",
      "Epoch [361/500], Loss: 1.3496, Accuracy: 0.4467\n",
      "Epoch [362/500], Loss: 1.3417, Accuracy: 0.4557\n",
      "Epoch [363/500], Loss: 1.3582, Accuracy: 0.4473\n",
      "Epoch [364/500], Loss: 1.3535, Accuracy: 0.4472\n",
      "Epoch [365/500], Loss: 1.3442, Accuracy: 0.4416\n",
      "Epoch [366/500], Loss: 1.3482, Accuracy: 0.4477\n",
      "Epoch [367/500], Loss: 1.3503, Accuracy: 0.4524\n",
      "Epoch [368/500], Loss: 1.3364, Accuracy: 0.4542\n",
      "Epoch [369/500], Loss: 1.3537, Accuracy: 0.4440\n",
      "Epoch [370/500], Loss: 1.3485, Accuracy: 0.4495\n",
      "Epoch [371/500], Loss: 1.3507, Accuracy: 0.4482\n",
      "Epoch [372/500], Loss: 1.3465, Accuracy: 0.4431\n",
      "Epoch [373/500], Loss: 1.3579, Accuracy: 0.4564\n",
      "Epoch [374/500], Loss: 1.3458, Accuracy: 0.4554\n",
      "Epoch [375/500], Loss: 1.3547, Accuracy: 0.4463\n",
      "Epoch [376/500], Loss: 1.3476, Accuracy: 0.4477\n",
      "Epoch [377/500], Loss: 1.3476, Accuracy: 0.4547\n",
      "Epoch [378/500], Loss: 1.3447, Accuracy: 0.4510\n",
      "Epoch [379/500], Loss: 1.3472, Accuracy: 0.4448\n",
      "Epoch [380/500], Loss: 1.3503, Accuracy: 0.4482\n",
      "Epoch [381/500], Loss: 1.3361, Accuracy: 0.4559\n",
      "Epoch [382/500], Loss: 1.3457, Accuracy: 0.4468\n",
      "Epoch [383/500], Loss: 1.3384, Accuracy: 0.4571\n",
      "Epoch [384/500], Loss: 1.3355, Accuracy: 0.4488\n",
      "Epoch [385/500], Loss: 1.3425, Accuracy: 0.4552\n",
      "Epoch [386/500], Loss: 1.3298, Accuracy: 0.4586\n",
      "Epoch [387/500], Loss: 1.3362, Accuracy: 0.4509\n",
      "Epoch [388/500], Loss: 1.3462, Accuracy: 0.4457\n",
      "Epoch [389/500], Loss: 1.3427, Accuracy: 0.4539\n",
      "Epoch [390/500], Loss: 1.3405, Accuracy: 0.4527\n",
      "Epoch [391/500], Loss: 1.3417, Accuracy: 0.4410\n",
      "Epoch [392/500], Loss: 1.3421, Accuracy: 0.4532\n",
      "Epoch [393/500], Loss: 1.3456, Accuracy: 0.4457\n",
      "Epoch [394/500], Loss: 1.3442, Accuracy: 0.4505\n",
      "Epoch [395/500], Loss: 1.3365, Accuracy: 0.4520\n",
      "Epoch [396/500], Loss: 1.3261, Accuracy: 0.4606\n",
      "Epoch [397/500], Loss: 1.3443, Accuracy: 0.4436\n",
      "Epoch [398/500], Loss: 1.3327, Accuracy: 0.4532\n",
      "Epoch [399/500], Loss: 1.3393, Accuracy: 0.4485\n",
      "Epoch [400/500], Loss: 1.3348, Accuracy: 0.4552\n",
      "Epoch [401/500], Loss: 1.3462, Accuracy: 0.4536\n",
      "Epoch [402/500], Loss: 1.3420, Accuracy: 0.4546\n",
      "Epoch [403/500], Loss: 1.3352, Accuracy: 0.4480\n",
      "Epoch [404/500], Loss: 1.3362, Accuracy: 0.4599\n",
      "Epoch [405/500], Loss: 1.3324, Accuracy: 0.4509\n",
      "Epoch [406/500], Loss: 1.3353, Accuracy: 0.4527\n",
      "Epoch [407/500], Loss: 1.3384, Accuracy: 0.4525\n",
      "Epoch [408/500], Loss: 1.3373, Accuracy: 0.4556\n",
      "Epoch [409/500], Loss: 1.3328, Accuracy: 0.4478\n",
      "Epoch [410/500], Loss: 1.3444, Accuracy: 0.4487\n",
      "Epoch [411/500], Loss: 1.3238, Accuracy: 0.4541\n",
      "Epoch [412/500], Loss: 1.3177, Accuracy: 0.4483\n",
      "Epoch [413/500], Loss: 1.3229, Accuracy: 0.4554\n",
      "Epoch [414/500], Loss: 1.3217, Accuracy: 0.4569\n",
      "Epoch [415/500], Loss: 1.3325, Accuracy: 0.4507\n",
      "Epoch [416/500], Loss: 1.3309, Accuracy: 0.4514\n",
      "Epoch [417/500], Loss: 1.3254, Accuracy: 0.4551\n",
      "Epoch [418/500], Loss: 1.3292, Accuracy: 0.4488\n",
      "Epoch [419/500], Loss: 1.3346, Accuracy: 0.4490\n",
      "Epoch [420/500], Loss: 1.3324, Accuracy: 0.4487\n",
      "Epoch [421/500], Loss: 1.3289, Accuracy: 0.4628\n",
      "Epoch [422/500], Loss: 1.3236, Accuracy: 0.4645\n",
      "Epoch [423/500], Loss: 1.3407, Accuracy: 0.4532\n",
      "Epoch [424/500], Loss: 1.3202, Accuracy: 0.4588\n",
      "Epoch [425/500], Loss: 1.3287, Accuracy: 0.4572\n",
      "Epoch [426/500], Loss: 1.3308, Accuracy: 0.4547\n",
      "Epoch [427/500], Loss: 1.3319, Accuracy: 0.4525\n",
      "Epoch [428/500], Loss: 1.3259, Accuracy: 0.4510\n",
      "Epoch [429/500], Loss: 1.3275, Accuracy: 0.4626\n",
      "Epoch [430/500], Loss: 1.3288, Accuracy: 0.4529\n",
      "Epoch [431/500], Loss: 1.3245, Accuracy: 0.4499\n",
      "Epoch [432/500], Loss: 1.3146, Accuracy: 0.4618\n",
      "Epoch [433/500], Loss: 1.3263, Accuracy: 0.4589\n",
      "Epoch [434/500], Loss: 1.3267, Accuracy: 0.4510\n",
      "Epoch [435/500], Loss: 1.3401, Accuracy: 0.4547\n",
      "Epoch [436/500], Loss: 1.3348, Accuracy: 0.4487\n",
      "Epoch [437/500], Loss: 1.3363, Accuracy: 0.4495\n",
      "Epoch [438/500], Loss: 1.3311, Accuracy: 0.4591\n",
      "Epoch [439/500], Loss: 1.3283, Accuracy: 0.4583\n",
      "Epoch [440/500], Loss: 1.3284, Accuracy: 0.4581\n",
      "Epoch [441/500], Loss: 1.3162, Accuracy: 0.4646\n",
      "Epoch [442/500], Loss: 1.3264, Accuracy: 0.4561\n",
      "Epoch [443/500], Loss: 1.3184, Accuracy: 0.4522\n",
      "Epoch [444/500], Loss: 1.3227, Accuracy: 0.4583\n",
      "Epoch [445/500], Loss: 1.3035, Accuracy: 0.4606\n",
      "Epoch [446/500], Loss: 1.3189, Accuracy: 0.4552\n",
      "Epoch [447/500], Loss: 1.3153, Accuracy: 0.4603\n",
      "Epoch [448/500], Loss: 1.3207, Accuracy: 0.4510\n",
      "Epoch [449/500], Loss: 1.3288, Accuracy: 0.4655\n",
      "Epoch [450/500], Loss: 1.3215, Accuracy: 0.4646\n",
      "Epoch [451/500], Loss: 1.3205, Accuracy: 0.4527\n",
      "Epoch [452/500], Loss: 1.3271, Accuracy: 0.4564\n",
      "Epoch [453/500], Loss: 1.3248, Accuracy: 0.4514\n",
      "Epoch [454/500], Loss: 1.3275, Accuracy: 0.4468\n",
      "Epoch [455/500], Loss: 1.3184, Accuracy: 0.4640\n",
      "Epoch [456/500], Loss: 1.3191, Accuracy: 0.4571\n",
      "Epoch [457/500], Loss: 1.3192, Accuracy: 0.4594\n",
      "Epoch [458/500], Loss: 1.3129, Accuracy: 0.4651\n",
      "Epoch [459/500], Loss: 1.3130, Accuracy: 0.4599\n",
      "Epoch [460/500], Loss: 1.3158, Accuracy: 0.4631\n",
      "Epoch [461/500], Loss: 1.3361, Accuracy: 0.4662\n",
      "Epoch [462/500], Loss: 1.3069, Accuracy: 0.4628\n",
      "Epoch [463/500], Loss: 1.3244, Accuracy: 0.4611\n",
      "Epoch [464/500], Loss: 1.3205, Accuracy: 0.4636\n",
      "Epoch [465/500], Loss: 1.3250, Accuracy: 0.4578\n",
      "Epoch [466/500], Loss: 1.3254, Accuracy: 0.4648\n",
      "Epoch [467/500], Loss: 1.3178, Accuracy: 0.4685\n",
      "Epoch [468/500], Loss: 1.3176, Accuracy: 0.4527\n",
      "Epoch [469/500], Loss: 1.3181, Accuracy: 0.4631\n",
      "Epoch [470/500], Loss: 1.3244, Accuracy: 0.4655\n",
      "Epoch [471/500], Loss: 1.3112, Accuracy: 0.4673\n",
      "Epoch [472/500], Loss: 1.3174, Accuracy: 0.4677\n",
      "Epoch [473/500], Loss: 1.3155, Accuracy: 0.4620\n",
      "Epoch [474/500], Loss: 1.3278, Accuracy: 0.4572\n",
      "Epoch [475/500], Loss: 1.3180, Accuracy: 0.4630\n",
      "Epoch [476/500], Loss: 1.3238, Accuracy: 0.4598\n",
      "Epoch [477/500], Loss: 1.3082, Accuracy: 0.4546\n",
      "Epoch [478/500], Loss: 1.3223, Accuracy: 0.4581\n",
      "Epoch [479/500], Loss: 1.3097, Accuracy: 0.4678\n",
      "Epoch [480/500], Loss: 1.3143, Accuracy: 0.4604\n",
      "Epoch [481/500], Loss: 1.3146, Accuracy: 0.4641\n",
      "Epoch [482/500], Loss: 1.3169, Accuracy: 0.4645\n",
      "Epoch [483/500], Loss: 1.3050, Accuracy: 0.4709\n",
      "Epoch [484/500], Loss: 1.3080, Accuracy: 0.4626\n",
      "Epoch [485/500], Loss: 1.3069, Accuracy: 0.4695\n",
      "Epoch [486/500], Loss: 1.3095, Accuracy: 0.4591\n",
      "Epoch [487/500], Loss: 1.3197, Accuracy: 0.4527\n",
      "Epoch [488/500], Loss: 1.3187, Accuracy: 0.4667\n",
      "Epoch [489/500], Loss: 1.3105, Accuracy: 0.4625\n",
      "Epoch [490/500], Loss: 1.3119, Accuracy: 0.4645\n",
      "Epoch [491/500], Loss: 1.3114, Accuracy: 0.4645\n",
      "Epoch [492/500], Loss: 1.3144, Accuracy: 0.4567\n",
      "Epoch [493/500], Loss: 1.3032, Accuracy: 0.4663\n",
      "Epoch [494/500], Loss: 1.3128, Accuracy: 0.4682\n",
      "Epoch [495/500], Loss: 1.3215, Accuracy: 0.4623\n",
      "Epoch [496/500], Loss: 1.3146, Accuracy: 0.4643\n",
      "Epoch [497/500], Loss: 1.3216, Accuracy: 0.4606\n",
      "Epoch [498/500], Loss: 1.3121, Accuracy: 0.4562\n",
      "Epoch [499/500], Loss: 1.3187, Accuracy: 0.4631\n",
      "Epoch [500/500], Loss: 1.3169, Accuracy: 0.4596\n"
     ]
    }
   ],
   "source": [
    "# Standard Deep Neural Network\n",
    "sdnn_model = SimpleDNN(input_size[0], num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(sdnn_model.parameters(), lr=0.0001)\n",
    "train(sdnn_model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.7886, Accuracy: 0.1729\n",
      "Epoch [2/500], Loss: 1.7664, Accuracy: 0.2508\n",
      "Epoch [3/500], Loss: 1.7186, Accuracy: 0.3066\n",
      "Epoch [4/500], Loss: 1.6540, Accuracy: 0.3074\n",
      "Epoch [5/500], Loss: 1.6109, Accuracy: 0.3170\n",
      "Epoch [6/500], Loss: 1.5894, Accuracy: 0.3313\n",
      "Epoch [7/500], Loss: 1.5724, Accuracy: 0.3410\n",
      "Epoch [8/500], Loss: 1.5580, Accuracy: 0.3393\n",
      "Epoch [9/500], Loss: 1.5557, Accuracy: 0.3496\n",
      "Epoch [10/500], Loss: 1.5476, Accuracy: 0.3538\n",
      "Epoch [11/500], Loss: 1.5369, Accuracy: 0.3575\n",
      "Epoch [12/500], Loss: 1.5360, Accuracy: 0.3597\n",
      "Epoch [13/500], Loss: 1.5246, Accuracy: 0.3620\n",
      "Epoch [14/500], Loss: 1.5231, Accuracy: 0.3659\n",
      "Epoch [15/500], Loss: 1.5136, Accuracy: 0.3697\n",
      "Epoch [16/500], Loss: 1.5068, Accuracy: 0.3665\n",
      "Epoch [17/500], Loss: 1.4950, Accuracy: 0.3701\n",
      "Epoch [18/500], Loss: 1.4991, Accuracy: 0.3739\n",
      "Epoch [19/500], Loss: 1.4863, Accuracy: 0.3753\n",
      "Epoch [20/500], Loss: 1.4849, Accuracy: 0.3798\n",
      "Epoch [21/500], Loss: 1.4842, Accuracy: 0.3828\n",
      "Epoch [22/500], Loss: 1.4792, Accuracy: 0.3843\n",
      "Epoch [23/500], Loss: 1.4748, Accuracy: 0.3862\n",
      "Epoch [24/500], Loss: 1.4671, Accuracy: 0.3899\n",
      "Epoch [25/500], Loss: 1.4609, Accuracy: 0.3911\n",
      "Epoch [26/500], Loss: 1.4568, Accuracy: 0.3980\n",
      "Epoch [27/500], Loss: 1.4522, Accuracy: 0.4013\n",
      "Epoch [28/500], Loss: 1.4496, Accuracy: 0.4018\n",
      "Epoch [29/500], Loss: 1.4438, Accuracy: 0.3978\n",
      "Epoch [30/500], Loss: 1.4397, Accuracy: 0.4062\n",
      "Epoch [31/500], Loss: 1.4357, Accuracy: 0.4121\n",
      "Epoch [32/500], Loss: 1.4250, Accuracy: 0.4079\n",
      "Epoch [33/500], Loss: 1.4251, Accuracy: 0.4159\n",
      "Epoch [34/500], Loss: 1.4207, Accuracy: 0.4159\n",
      "Epoch [35/500], Loss: 1.4218, Accuracy: 0.4174\n",
      "Epoch [36/500], Loss: 1.4204, Accuracy: 0.4171\n",
      "Epoch [37/500], Loss: 1.4077, Accuracy: 0.4206\n",
      "Epoch [38/500], Loss: 1.4022, Accuracy: 0.4230\n",
      "Epoch [39/500], Loss: 1.4099, Accuracy: 0.4253\n",
      "Epoch [40/500], Loss: 1.3984, Accuracy: 0.4300\n",
      "Epoch [41/500], Loss: 1.3929, Accuracy: 0.4310\n",
      "Epoch [42/500], Loss: 1.3962, Accuracy: 0.4342\n",
      "Epoch [43/500], Loss: 1.3881, Accuracy: 0.4344\n",
      "Epoch [44/500], Loss: 1.3945, Accuracy: 0.4359\n",
      "Epoch [45/500], Loss: 1.3890, Accuracy: 0.4331\n",
      "Epoch [46/500], Loss: 1.3771, Accuracy: 0.4388\n",
      "Epoch [47/500], Loss: 1.3780, Accuracy: 0.4373\n",
      "Epoch [48/500], Loss: 1.3752, Accuracy: 0.4393\n",
      "Epoch [49/500], Loss: 1.3687, Accuracy: 0.4440\n",
      "Epoch [50/500], Loss: 1.3706, Accuracy: 0.4420\n",
      "Epoch [51/500], Loss: 1.3638, Accuracy: 0.4490\n",
      "Epoch [52/500], Loss: 1.3627, Accuracy: 0.4473\n",
      "Epoch [53/500], Loss: 1.3549, Accuracy: 0.4519\n",
      "Epoch [54/500], Loss: 1.3532, Accuracy: 0.4504\n",
      "Epoch [55/500], Loss: 1.3499, Accuracy: 0.4520\n",
      "Epoch [56/500], Loss: 1.3474, Accuracy: 0.4586\n",
      "Epoch [57/500], Loss: 1.3483, Accuracy: 0.4562\n",
      "Epoch [58/500], Loss: 1.3455, Accuracy: 0.4578\n",
      "Epoch [59/500], Loss: 1.3440, Accuracy: 0.4578\n",
      "Epoch [60/500], Loss: 1.3360, Accuracy: 0.4631\n",
      "Epoch [61/500], Loss: 1.3304, Accuracy: 0.4662\n",
      "Epoch [62/500], Loss: 1.3274, Accuracy: 0.4651\n",
      "Epoch [63/500], Loss: 1.3213, Accuracy: 0.4677\n",
      "Epoch [64/500], Loss: 1.3350, Accuracy: 0.4658\n",
      "Epoch [65/500], Loss: 1.3294, Accuracy: 0.4693\n",
      "Epoch [66/500], Loss: 1.3206, Accuracy: 0.4692\n",
      "Epoch [67/500], Loss: 1.3127, Accuracy: 0.4759\n",
      "Epoch [68/500], Loss: 1.3078, Accuracy: 0.4725\n",
      "Epoch [69/500], Loss: 1.3087, Accuracy: 0.4754\n",
      "Epoch [70/500], Loss: 1.3124, Accuracy: 0.4759\n",
      "Epoch [71/500], Loss: 1.3062, Accuracy: 0.4788\n",
      "Epoch [72/500], Loss: 1.2980, Accuracy: 0.4771\n",
      "Epoch [73/500], Loss: 1.2981, Accuracy: 0.4774\n",
      "Epoch [74/500], Loss: 1.2904, Accuracy: 0.4791\n",
      "Epoch [75/500], Loss: 1.2921, Accuracy: 0.4794\n",
      "Epoch [76/500], Loss: 1.2864, Accuracy: 0.4814\n",
      "Epoch [77/500], Loss: 1.2885, Accuracy: 0.4840\n",
      "Epoch [78/500], Loss: 1.2843, Accuracy: 0.4841\n",
      "Epoch [79/500], Loss: 1.2800, Accuracy: 0.4851\n",
      "Epoch [80/500], Loss: 1.2783, Accuracy: 0.4833\n",
      "Epoch [81/500], Loss: 1.2809, Accuracy: 0.4910\n",
      "Epoch [82/500], Loss: 1.2759, Accuracy: 0.4908\n",
      "Epoch [83/500], Loss: 1.2707, Accuracy: 0.4892\n",
      "Epoch [84/500], Loss: 1.2740, Accuracy: 0.4895\n",
      "Epoch [85/500], Loss: 1.2691, Accuracy: 0.4934\n",
      "Epoch [86/500], Loss: 1.2633, Accuracy: 0.4880\n",
      "Epoch [87/500], Loss: 1.2675, Accuracy: 0.4929\n",
      "Epoch [88/500], Loss: 1.2625, Accuracy: 0.4961\n",
      "Epoch [89/500], Loss: 1.2597, Accuracy: 0.4999\n",
      "Epoch [90/500], Loss: 1.2544, Accuracy: 0.5031\n",
      "Epoch [91/500], Loss: 1.2496, Accuracy: 0.4962\n",
      "Epoch [92/500], Loss: 1.2468, Accuracy: 0.5001\n",
      "Epoch [93/500], Loss: 1.2462, Accuracy: 0.5001\n",
      "Epoch [94/500], Loss: 1.2439, Accuracy: 0.5006\n",
      "Epoch [95/500], Loss: 1.2435, Accuracy: 0.5029\n",
      "Epoch [96/500], Loss: 1.2394, Accuracy: 0.5038\n",
      "Epoch [97/500], Loss: 1.2362, Accuracy: 0.5050\n",
      "Epoch [98/500], Loss: 1.2374, Accuracy: 0.5053\n",
      "Epoch [99/500], Loss: 1.2378, Accuracy: 0.5081\n",
      "Epoch [100/500], Loss: 1.2411, Accuracy: 0.5050\n",
      "Epoch [101/500], Loss: 1.2310, Accuracy: 0.5088\n",
      "Epoch [102/500], Loss: 1.2354, Accuracy: 0.5087\n",
      "Epoch [103/500], Loss: 1.2281, Accuracy: 0.5080\n",
      "Epoch [104/500], Loss: 1.2247, Accuracy: 0.5100\n",
      "Epoch [105/500], Loss: 1.2249, Accuracy: 0.5120\n",
      "Epoch [106/500], Loss: 1.2254, Accuracy: 0.5097\n",
      "Epoch [107/500], Loss: 1.2239, Accuracy: 0.5115\n",
      "Epoch [108/500], Loss: 1.2236, Accuracy: 0.5132\n",
      "Epoch [109/500], Loss: 1.2121, Accuracy: 0.5174\n",
      "Epoch [110/500], Loss: 1.2168, Accuracy: 0.5160\n",
      "Epoch [111/500], Loss: 1.2225, Accuracy: 0.5139\n",
      "Epoch [112/500], Loss: 1.2104, Accuracy: 0.5186\n",
      "Epoch [113/500], Loss: 1.2056, Accuracy: 0.5197\n",
      "Epoch [114/500], Loss: 1.2048, Accuracy: 0.5179\n",
      "Epoch [115/500], Loss: 1.2014, Accuracy: 0.5197\n",
      "Epoch [116/500], Loss: 1.2046, Accuracy: 0.5196\n",
      "Epoch [117/500], Loss: 1.2113, Accuracy: 0.5241\n",
      "Epoch [118/500], Loss: 1.1982, Accuracy: 0.5204\n",
      "Epoch [119/500], Loss: 1.1983, Accuracy: 0.5216\n",
      "Epoch [120/500], Loss: 1.2016, Accuracy: 0.5238\n",
      "Epoch [121/500], Loss: 1.1962, Accuracy: 0.5249\n",
      "Epoch [122/500], Loss: 1.1946, Accuracy: 0.5270\n",
      "Epoch [123/500], Loss: 1.1852, Accuracy: 0.5273\n",
      "Epoch [124/500], Loss: 1.1967, Accuracy: 0.5258\n",
      "Epoch [125/500], Loss: 1.1847, Accuracy: 0.5283\n",
      "Epoch [126/500], Loss: 1.1902, Accuracy: 0.5271\n",
      "Epoch [127/500], Loss: 1.1853, Accuracy: 0.5328\n",
      "Epoch [128/500], Loss: 1.1807, Accuracy: 0.5307\n",
      "Epoch [129/500], Loss: 1.1841, Accuracy: 0.5313\n",
      "Epoch [130/500], Loss: 1.1847, Accuracy: 0.5268\n",
      "Epoch [131/500], Loss: 1.1777, Accuracy: 0.5307\n",
      "Epoch [132/500], Loss: 1.1750, Accuracy: 0.5330\n",
      "Epoch [133/500], Loss: 1.1784, Accuracy: 0.5293\n",
      "Epoch [134/500], Loss: 1.1795, Accuracy: 0.5307\n",
      "Epoch [135/500], Loss: 1.1797, Accuracy: 0.5302\n",
      "Epoch [136/500], Loss: 1.1965, Accuracy: 0.5380\n",
      "Epoch [137/500], Loss: 1.1809, Accuracy: 0.5328\n",
      "Epoch [138/500], Loss: 1.1640, Accuracy: 0.5391\n",
      "Epoch [139/500], Loss: 1.1650, Accuracy: 0.5333\n",
      "Epoch [140/500], Loss: 1.1591, Accuracy: 0.5386\n",
      "Epoch [141/500], Loss: 1.1620, Accuracy: 0.5359\n",
      "Epoch [142/500], Loss: 1.1598, Accuracy: 0.5391\n",
      "Epoch [143/500], Loss: 1.1596, Accuracy: 0.5370\n",
      "Epoch [144/500], Loss: 1.1613, Accuracy: 0.5417\n",
      "Epoch [145/500], Loss: 1.1573, Accuracy: 0.5428\n",
      "Epoch [146/500], Loss: 1.1534, Accuracy: 0.5422\n",
      "Epoch [147/500], Loss: 1.1553, Accuracy: 0.5411\n",
      "Epoch [148/500], Loss: 1.1509, Accuracy: 0.5443\n",
      "Epoch [149/500], Loss: 1.1476, Accuracy: 0.5433\n",
      "Epoch [150/500], Loss: 1.1599, Accuracy: 0.5458\n",
      "Epoch [151/500], Loss: 1.1581, Accuracy: 0.5345\n",
      "Epoch [152/500], Loss: 1.1586, Accuracy: 0.5451\n",
      "Epoch [153/500], Loss: 1.1462, Accuracy: 0.5412\n",
      "Epoch [154/500], Loss: 1.1414, Accuracy: 0.5488\n",
      "Epoch [155/500], Loss: 1.1382, Accuracy: 0.5481\n",
      "Epoch [156/500], Loss: 1.1400, Accuracy: 0.5458\n",
      "Epoch [157/500], Loss: 1.1441, Accuracy: 0.5453\n",
      "Epoch [158/500], Loss: 1.1367, Accuracy: 0.5451\n",
      "Epoch [159/500], Loss: 1.1369, Accuracy: 0.5456\n",
      "Epoch [160/500], Loss: 1.1329, Accuracy: 0.5458\n",
      "Epoch [161/500], Loss: 1.1283, Accuracy: 0.5525\n",
      "Epoch [162/500], Loss: 1.1304, Accuracy: 0.5525\n",
      "Epoch [163/500], Loss: 1.1333, Accuracy: 0.5518\n",
      "Epoch [164/500], Loss: 1.1353, Accuracy: 0.5527\n",
      "Epoch [165/500], Loss: 1.1290, Accuracy: 0.5552\n",
      "Epoch [166/500], Loss: 1.1383, Accuracy: 0.5525\n",
      "Epoch [167/500], Loss: 1.1302, Accuracy: 0.5525\n",
      "Epoch [168/500], Loss: 1.1312, Accuracy: 0.5513\n",
      "Epoch [169/500], Loss: 1.1227, Accuracy: 0.5538\n",
      "Epoch [170/500], Loss: 1.1204, Accuracy: 0.5559\n",
      "Epoch [171/500], Loss: 1.1265, Accuracy: 0.5530\n",
      "Epoch [172/500], Loss: 1.1225, Accuracy: 0.5532\n",
      "Epoch [173/500], Loss: 1.1136, Accuracy: 0.5554\n",
      "Epoch [174/500], Loss: 1.1195, Accuracy: 0.5537\n",
      "Epoch [175/500], Loss: 1.1212, Accuracy: 0.5525\n",
      "Epoch [176/500], Loss: 1.1133, Accuracy: 0.5545\n",
      "Epoch [177/500], Loss: 1.1138, Accuracy: 0.5565\n",
      "Epoch [178/500], Loss: 1.1116, Accuracy: 0.5570\n",
      "Epoch [179/500], Loss: 1.1091, Accuracy: 0.5601\n",
      "Epoch [180/500], Loss: 1.1260, Accuracy: 0.5612\n",
      "Epoch [181/500], Loss: 1.1088, Accuracy: 0.5621\n",
      "Epoch [182/500], Loss: 1.1135, Accuracy: 0.5629\n",
      "Epoch [183/500], Loss: 1.1108, Accuracy: 0.5621\n",
      "Epoch [184/500], Loss: 1.1073, Accuracy: 0.5612\n",
      "Epoch [185/500], Loss: 1.0995, Accuracy: 0.5666\n",
      "Epoch [186/500], Loss: 1.1012, Accuracy: 0.5624\n",
      "Epoch [187/500], Loss: 1.0990, Accuracy: 0.5612\n",
      "Epoch [188/500], Loss: 1.1001, Accuracy: 0.5631\n",
      "Epoch [189/500], Loss: 1.1004, Accuracy: 0.5664\n",
      "Epoch [190/500], Loss: 1.0935, Accuracy: 0.5683\n",
      "Epoch [191/500], Loss: 1.1056, Accuracy: 0.5659\n",
      "Epoch [192/500], Loss: 1.1014, Accuracy: 0.5611\n",
      "Epoch [193/500], Loss: 1.0931, Accuracy: 0.5681\n",
      "Epoch [194/500], Loss: 1.0961, Accuracy: 0.5676\n",
      "Epoch [195/500], Loss: 1.0927, Accuracy: 0.5700\n",
      "Epoch [196/500], Loss: 1.0915, Accuracy: 0.5706\n",
      "Epoch [197/500], Loss: 1.0916, Accuracy: 0.5686\n",
      "Epoch [198/500], Loss: 1.0895, Accuracy: 0.5716\n",
      "Epoch [199/500], Loss: 1.0857, Accuracy: 0.5703\n",
      "Epoch [200/500], Loss: 1.0831, Accuracy: 0.5718\n",
      "Epoch [201/500], Loss: 1.0837, Accuracy: 0.5710\n",
      "Epoch [202/500], Loss: 1.0840, Accuracy: 0.5738\n",
      "Epoch [203/500], Loss: 1.0792, Accuracy: 0.5772\n",
      "Epoch [204/500], Loss: 1.0842, Accuracy: 0.5747\n",
      "Epoch [205/500], Loss: 1.0843, Accuracy: 0.5700\n",
      "Epoch [206/500], Loss: 1.0753, Accuracy: 0.5740\n",
      "Epoch [207/500], Loss: 1.0895, Accuracy: 0.5738\n",
      "Epoch [208/500], Loss: 1.0801, Accuracy: 0.5753\n",
      "Epoch [209/500], Loss: 1.0747, Accuracy: 0.5720\n",
      "Epoch [210/500], Loss: 1.0778, Accuracy: 0.5760\n",
      "Epoch [211/500], Loss: 1.0724, Accuracy: 0.5770\n",
      "Epoch [212/500], Loss: 1.0730, Accuracy: 0.5748\n",
      "Epoch [213/500], Loss: 1.0678, Accuracy: 0.5837\n",
      "Epoch [214/500], Loss: 1.0677, Accuracy: 0.5812\n",
      "Epoch [215/500], Loss: 1.0693, Accuracy: 0.5809\n",
      "Epoch [216/500], Loss: 1.0726, Accuracy: 0.5800\n",
      "Epoch [217/500], Loss: 1.0677, Accuracy: 0.5784\n",
      "Epoch [218/500], Loss: 1.0698, Accuracy: 0.5841\n",
      "Epoch [219/500], Loss: 1.0598, Accuracy: 0.5779\n",
      "Epoch [220/500], Loss: 1.0601, Accuracy: 0.5851\n",
      "Epoch [221/500], Loss: 1.0645, Accuracy: 0.5851\n",
      "Epoch [222/500], Loss: 1.0615, Accuracy: 0.5839\n",
      "Epoch [223/500], Loss: 1.0561, Accuracy: 0.5864\n",
      "Epoch [224/500], Loss: 1.0568, Accuracy: 0.5861\n",
      "Epoch [225/500], Loss: 1.0582, Accuracy: 0.5878\n",
      "Epoch [226/500], Loss: 1.0713, Accuracy: 0.5888\n",
      "Epoch [227/500], Loss: 1.0571, Accuracy: 0.5836\n",
      "Epoch [228/500], Loss: 1.0507, Accuracy: 0.5863\n",
      "Epoch [229/500], Loss: 1.0539, Accuracy: 0.5915\n",
      "Epoch [230/500], Loss: 1.0474, Accuracy: 0.5901\n",
      "Epoch [231/500], Loss: 1.0465, Accuracy: 0.5923\n",
      "Epoch [232/500], Loss: 1.0444, Accuracy: 0.5908\n",
      "Epoch [233/500], Loss: 1.0485, Accuracy: 0.5886\n",
      "Epoch [234/500], Loss: 1.0583, Accuracy: 0.5910\n",
      "Epoch [235/500], Loss: 1.0533, Accuracy: 0.5866\n",
      "Epoch [236/500], Loss: 1.0541, Accuracy: 0.5884\n",
      "Epoch [237/500], Loss: 1.0487, Accuracy: 0.5931\n",
      "Epoch [238/500], Loss: 1.0428, Accuracy: 0.5918\n",
      "Epoch [239/500], Loss: 1.0380, Accuracy: 0.5973\n",
      "Epoch [240/500], Loss: 1.0471, Accuracy: 0.5921\n",
      "Epoch [241/500], Loss: 1.0408, Accuracy: 0.5985\n",
      "Epoch [242/500], Loss: 1.0376, Accuracy: 0.5942\n",
      "Epoch [243/500], Loss: 1.0360, Accuracy: 0.5997\n",
      "Epoch [244/500], Loss: 1.0328, Accuracy: 0.5930\n",
      "Epoch [245/500], Loss: 1.0386, Accuracy: 0.5963\n",
      "Epoch [246/500], Loss: 1.0440, Accuracy: 0.5995\n",
      "Epoch [247/500], Loss: 1.0369, Accuracy: 0.5937\n",
      "Epoch [248/500], Loss: 1.0410, Accuracy: 0.5962\n",
      "Epoch [249/500], Loss: 1.0323, Accuracy: 0.5978\n",
      "Epoch [250/500], Loss: 1.0247, Accuracy: 0.6007\n",
      "Epoch [251/500], Loss: 1.0305, Accuracy: 0.6009\n",
      "Epoch [252/500], Loss: 1.0333, Accuracy: 0.5937\n",
      "Epoch [253/500], Loss: 1.0293, Accuracy: 0.6007\n",
      "Epoch [254/500], Loss: 1.0257, Accuracy: 0.6024\n",
      "Epoch [255/500], Loss: 1.0328, Accuracy: 0.5997\n",
      "Epoch [256/500], Loss: 1.0304, Accuracy: 0.5999\n",
      "Epoch [257/500], Loss: 1.0221, Accuracy: 0.5980\n",
      "Epoch [258/500], Loss: 1.0161, Accuracy: 0.6068\n",
      "Epoch [259/500], Loss: 1.0157, Accuracy: 0.6068\n",
      "Epoch [260/500], Loss: 1.0152, Accuracy: 0.6068\n",
      "Epoch [261/500], Loss: 1.0154, Accuracy: 0.6057\n",
      "Epoch [262/500], Loss: 1.0141, Accuracy: 0.6056\n",
      "Epoch [263/500], Loss: 1.0234, Accuracy: 0.6057\n",
      "Epoch [264/500], Loss: 1.0184, Accuracy: 0.6044\n",
      "Epoch [265/500], Loss: 1.0144, Accuracy: 0.6074\n",
      "Epoch [266/500], Loss: 1.0119, Accuracy: 0.6056\n",
      "Epoch [267/500], Loss: 1.0186, Accuracy: 0.6098\n",
      "Epoch [268/500], Loss: 1.0096, Accuracy: 0.6064\n",
      "Epoch [269/500], Loss: 1.0254, Accuracy: 0.6073\n",
      "Epoch [270/500], Loss: 1.0168, Accuracy: 0.6059\n",
      "Epoch [271/500], Loss: 1.0102, Accuracy: 0.6059\n",
      "Epoch [272/500], Loss: 1.0056, Accuracy: 0.6121\n",
      "Epoch [273/500], Loss: 1.0050, Accuracy: 0.6094\n",
      "Epoch [274/500], Loss: 1.0028, Accuracy: 0.6111\n",
      "Epoch [275/500], Loss: 1.0021, Accuracy: 0.6108\n",
      "Epoch [276/500], Loss: 1.0117, Accuracy: 0.6089\n",
      "Epoch [277/500], Loss: 1.0083, Accuracy: 0.6094\n",
      "Epoch [278/500], Loss: 1.0127, Accuracy: 0.6064\n",
      "Epoch [279/500], Loss: 1.0057, Accuracy: 0.6098\n",
      "Epoch [280/500], Loss: 1.0004, Accuracy: 0.6126\n",
      "Epoch [281/500], Loss: 0.9998, Accuracy: 0.6158\n",
      "Epoch [282/500], Loss: 0.9937, Accuracy: 0.6143\n",
      "Epoch [283/500], Loss: 0.9976, Accuracy: 0.6128\n",
      "Epoch [284/500], Loss: 0.9942, Accuracy: 0.6133\n",
      "Epoch [285/500], Loss: 0.9943, Accuracy: 0.6116\n",
      "Epoch [286/500], Loss: 0.9966, Accuracy: 0.6172\n",
      "Epoch [287/500], Loss: 0.9907, Accuracy: 0.6172\n",
      "Epoch [288/500], Loss: 0.9915, Accuracy: 0.6160\n",
      "Epoch [289/500], Loss: 0.9881, Accuracy: 0.6150\n",
      "Epoch [290/500], Loss: 1.0071, Accuracy: 0.6167\n",
      "Epoch [291/500], Loss: 0.9861, Accuracy: 0.6162\n",
      "Epoch [292/500], Loss: 0.9833, Accuracy: 0.6190\n",
      "Epoch [293/500], Loss: 0.9878, Accuracy: 0.6209\n",
      "Epoch [294/500], Loss: 0.9840, Accuracy: 0.6195\n",
      "Epoch [295/500], Loss: 0.9853, Accuracy: 0.6162\n",
      "Epoch [296/500], Loss: 0.9890, Accuracy: 0.6212\n",
      "Epoch [297/500], Loss: 0.9873, Accuracy: 0.6209\n",
      "Epoch [298/500], Loss: 0.9912, Accuracy: 0.6163\n",
      "Epoch [299/500], Loss: 1.0013, Accuracy: 0.6133\n",
      "Epoch [300/500], Loss: 0.9884, Accuracy: 0.6126\n",
      "Epoch [301/500], Loss: 0.9820, Accuracy: 0.6175\n",
      "Epoch [302/500], Loss: 0.9839, Accuracy: 0.6234\n",
      "Epoch [303/500], Loss: 0.9765, Accuracy: 0.6187\n",
      "Epoch [304/500], Loss: 0.9776, Accuracy: 0.6244\n",
      "Epoch [305/500], Loss: 0.9892, Accuracy: 0.6232\n",
      "Epoch [306/500], Loss: 0.9834, Accuracy: 0.6266\n",
      "Epoch [307/500], Loss: 0.9725, Accuracy: 0.6274\n",
      "Epoch [308/500], Loss: 0.9687, Accuracy: 0.6261\n",
      "Epoch [309/500], Loss: 0.9799, Accuracy: 0.6217\n",
      "Epoch [310/500], Loss: 0.9754, Accuracy: 0.6234\n",
      "Epoch [311/500], Loss: 0.9754, Accuracy: 0.6249\n",
      "Epoch [312/500], Loss: 0.9686, Accuracy: 0.6269\n",
      "Epoch [313/500], Loss: 0.9781, Accuracy: 0.6252\n",
      "Epoch [314/500], Loss: 0.9731, Accuracy: 0.6267\n",
      "Epoch [315/500], Loss: 0.9690, Accuracy: 0.6232\n",
      "Epoch [316/500], Loss: 0.9673, Accuracy: 0.6264\n",
      "Epoch [317/500], Loss: 0.9675, Accuracy: 0.6267\n",
      "Epoch [318/500], Loss: 0.9655, Accuracy: 0.6294\n",
      "Epoch [319/500], Loss: 0.9674, Accuracy: 0.6264\n",
      "Epoch [320/500], Loss: 0.9642, Accuracy: 0.6314\n",
      "Epoch [321/500], Loss: 0.9616, Accuracy: 0.6311\n",
      "Epoch [322/500], Loss: 0.9625, Accuracy: 0.6274\n",
      "Epoch [323/500], Loss: 0.9587, Accuracy: 0.6299\n",
      "Epoch [324/500], Loss: 0.9592, Accuracy: 0.6236\n",
      "Epoch [325/500], Loss: 0.9609, Accuracy: 0.6246\n",
      "Epoch [326/500], Loss: 0.9647, Accuracy: 0.6298\n",
      "Epoch [327/500], Loss: 0.9716, Accuracy: 0.6298\n",
      "Epoch [328/500], Loss: 0.9639, Accuracy: 0.6236\n",
      "Epoch [329/500], Loss: 0.9667, Accuracy: 0.6286\n",
      "Epoch [330/500], Loss: 0.9555, Accuracy: 0.6328\n",
      "Epoch [331/500], Loss: 0.9585, Accuracy: 0.6326\n",
      "Epoch [332/500], Loss: 0.9590, Accuracy: 0.6283\n",
      "Epoch [333/500], Loss: 0.9600, Accuracy: 0.6325\n",
      "Epoch [334/500], Loss: 0.9581, Accuracy: 0.6336\n",
      "Epoch [335/500], Loss: 0.9488, Accuracy: 0.6398\n",
      "Epoch [336/500], Loss: 0.9518, Accuracy: 0.6348\n",
      "Epoch [337/500], Loss: 0.9489, Accuracy: 0.6365\n",
      "Epoch [338/500], Loss: 0.9607, Accuracy: 0.6321\n",
      "Epoch [339/500], Loss: 0.9516, Accuracy: 0.6293\n",
      "Epoch [340/500], Loss: 0.9560, Accuracy: 0.6367\n",
      "Epoch [341/500], Loss: 0.9560, Accuracy: 0.6269\n",
      "Epoch [342/500], Loss: 0.9543, Accuracy: 0.6360\n",
      "Epoch [343/500], Loss: 0.9463, Accuracy: 0.6325\n",
      "Epoch [344/500], Loss: 0.9457, Accuracy: 0.6393\n",
      "Epoch [345/500], Loss: 0.9460, Accuracy: 0.6360\n",
      "Epoch [346/500], Loss: 0.9458, Accuracy: 0.6397\n",
      "Epoch [347/500], Loss: 0.9453, Accuracy: 0.6340\n",
      "Epoch [348/500], Loss: 0.9486, Accuracy: 0.6350\n",
      "Epoch [349/500], Loss: 0.9425, Accuracy: 0.6365\n",
      "Epoch [350/500], Loss: 0.9411, Accuracy: 0.6370\n",
      "Epoch [351/500], Loss: 0.9474, Accuracy: 0.6392\n",
      "Epoch [352/500], Loss: 0.9441, Accuracy: 0.6355\n",
      "Epoch [353/500], Loss: 0.9447, Accuracy: 0.6393\n",
      "Epoch [354/500], Loss: 0.9400, Accuracy: 0.6410\n",
      "Epoch [355/500], Loss: 0.9389, Accuracy: 0.6444\n",
      "Epoch [356/500], Loss: 0.9358, Accuracy: 0.6417\n",
      "Epoch [357/500], Loss: 0.9377, Accuracy: 0.6365\n",
      "Epoch [358/500], Loss: 0.9339, Accuracy: 0.6412\n",
      "Epoch [359/500], Loss: 0.9343, Accuracy: 0.6395\n",
      "Epoch [360/500], Loss: 0.9328, Accuracy: 0.6380\n",
      "Epoch [361/500], Loss: 0.9296, Accuracy: 0.6414\n",
      "Epoch [362/500], Loss: 0.9353, Accuracy: 0.6415\n",
      "Epoch [363/500], Loss: 0.9384, Accuracy: 0.6409\n",
      "Epoch [364/500], Loss: 0.9370, Accuracy: 0.6383\n",
      "Epoch [365/500], Loss: 0.9360, Accuracy: 0.6356\n",
      "Epoch [366/500], Loss: 0.9251, Accuracy: 0.6432\n",
      "Epoch [367/500], Loss: 0.9367, Accuracy: 0.6427\n",
      "Epoch [368/500], Loss: 0.9294, Accuracy: 0.6471\n",
      "Epoch [369/500], Loss: 0.9355, Accuracy: 0.6481\n",
      "Epoch [370/500], Loss: 0.9360, Accuracy: 0.6462\n",
      "Epoch [371/500], Loss: 0.9397, Accuracy: 0.6372\n",
      "Epoch [372/500], Loss: 0.9310, Accuracy: 0.6439\n",
      "Epoch [373/500], Loss: 0.9399, Accuracy: 0.6456\n",
      "Epoch [374/500], Loss: 0.9284, Accuracy: 0.6447\n",
      "Epoch [375/500], Loss: 0.9259, Accuracy: 0.6459\n",
      "Epoch [376/500], Loss: 0.9243, Accuracy: 0.6482\n",
      "Epoch [377/500], Loss: 0.9237, Accuracy: 0.6462\n",
      "Epoch [378/500], Loss: 0.9236, Accuracy: 0.6459\n",
      "Epoch [379/500], Loss: 0.9230, Accuracy: 0.6452\n",
      "Epoch [380/500], Loss: 0.9246, Accuracy: 0.6456\n",
      "Epoch [381/500], Loss: 0.9580, Accuracy: 0.6467\n",
      "Epoch [382/500], Loss: 0.9481, Accuracy: 0.6336\n",
      "Epoch [383/500], Loss: 0.9386, Accuracy: 0.6452\n",
      "Epoch [384/500], Loss: 0.9277, Accuracy: 0.6440\n",
      "Epoch [385/500], Loss: 0.9143, Accuracy: 0.6449\n",
      "Epoch [386/500], Loss: 0.9227, Accuracy: 0.6489\n",
      "Epoch [387/500], Loss: 0.9239, Accuracy: 0.6405\n",
      "Epoch [388/500], Loss: 0.9241, Accuracy: 0.6477\n",
      "Epoch [389/500], Loss: 0.9100, Accuracy: 0.6454\n",
      "Epoch [390/500], Loss: 0.9134, Accuracy: 0.6496\n",
      "Epoch [391/500], Loss: 0.9139, Accuracy: 0.6516\n",
      "Epoch [392/500], Loss: 0.9156, Accuracy: 0.6457\n",
      "Epoch [393/500], Loss: 0.9157, Accuracy: 0.6516\n",
      "Epoch [394/500], Loss: 0.9125, Accuracy: 0.6486\n",
      "Epoch [395/500], Loss: 0.9124, Accuracy: 0.6503\n",
      "Epoch [396/500], Loss: 0.9201, Accuracy: 0.6533\n",
      "Epoch [397/500], Loss: 0.9110, Accuracy: 0.6524\n",
      "Epoch [398/500], Loss: 0.9155, Accuracy: 0.6472\n",
      "Epoch [399/500], Loss: 0.9196, Accuracy: 0.6536\n",
      "Epoch [400/500], Loss: 0.9246, Accuracy: 0.6454\n",
      "Epoch [401/500], Loss: 0.9150, Accuracy: 0.6546\n",
      "Epoch [402/500], Loss: 0.9127, Accuracy: 0.6498\n",
      "Epoch [403/500], Loss: 0.9050, Accuracy: 0.6558\n",
      "Epoch [404/500], Loss: 0.9116, Accuracy: 0.6543\n",
      "Epoch [405/500], Loss: 0.9139, Accuracy: 0.6479\n",
      "Epoch [406/500], Loss: 0.9065, Accuracy: 0.6560\n",
      "Epoch [407/500], Loss: 0.9068, Accuracy: 0.6556\n",
      "Epoch [408/500], Loss: 0.9088, Accuracy: 0.6563\n",
      "Epoch [409/500], Loss: 0.9292, Accuracy: 0.6477\n",
      "Epoch [410/500], Loss: 0.9065, Accuracy: 0.6521\n",
      "Epoch [411/500], Loss: 0.9074, Accuracy: 0.6533\n",
      "Epoch [412/500], Loss: 0.9067, Accuracy: 0.6538\n",
      "Epoch [413/500], Loss: 0.9063, Accuracy: 0.6561\n",
      "Epoch [414/500], Loss: 0.9009, Accuracy: 0.6592\n",
      "Epoch [415/500], Loss: 0.9143, Accuracy: 0.6573\n",
      "Epoch [416/500], Loss: 0.9042, Accuracy: 0.6580\n",
      "Epoch [417/500], Loss: 0.8985, Accuracy: 0.6580\n",
      "Epoch [418/500], Loss: 0.9010, Accuracy: 0.6585\n",
      "Epoch [419/500], Loss: 0.8969, Accuracy: 0.6551\n",
      "Epoch [420/500], Loss: 0.8988, Accuracy: 0.6637\n",
      "Epoch [421/500], Loss: 0.8948, Accuracy: 0.6593\n",
      "Epoch [422/500], Loss: 0.8986, Accuracy: 0.6560\n",
      "Epoch [423/500], Loss: 0.9272, Accuracy: 0.6543\n",
      "Epoch [424/500], Loss: 0.9062, Accuracy: 0.6540\n",
      "Epoch [425/500], Loss: 0.9065, Accuracy: 0.6526\n",
      "Epoch [426/500], Loss: 0.8910, Accuracy: 0.6615\n",
      "Epoch [427/500], Loss: 0.8943, Accuracy: 0.6612\n",
      "Epoch [428/500], Loss: 0.8877, Accuracy: 0.6585\n",
      "Epoch [429/500], Loss: 0.8923, Accuracy: 0.6555\n",
      "Epoch [430/500], Loss: 0.9066, Accuracy: 0.6558\n",
      "Epoch [431/500], Loss: 0.8946, Accuracy: 0.6548\n",
      "Epoch [432/500], Loss: 0.8878, Accuracy: 0.6634\n",
      "Epoch [433/500], Loss: 0.8949, Accuracy: 0.6571\n",
      "Epoch [434/500], Loss: 0.8941, Accuracy: 0.6570\n",
      "Epoch [435/500], Loss: 0.8984, Accuracy: 0.6634\n",
      "Epoch [436/500], Loss: 0.8854, Accuracy: 0.6612\n",
      "Epoch [437/500], Loss: 0.8918, Accuracy: 0.6632\n",
      "Epoch [438/500], Loss: 0.8920, Accuracy: 0.6627\n",
      "Epoch [439/500], Loss: 0.8903, Accuracy: 0.6644\n",
      "Epoch [440/500], Loss: 0.8909, Accuracy: 0.6620\n",
      "Epoch [441/500], Loss: 0.8834, Accuracy: 0.6612\n",
      "Epoch [442/500], Loss: 0.8825, Accuracy: 0.6635\n",
      "Epoch [443/500], Loss: 0.8940, Accuracy: 0.6639\n",
      "Epoch [444/500], Loss: 0.9006, Accuracy: 0.6578\n",
      "Epoch [445/500], Loss: 0.8871, Accuracy: 0.6640\n",
      "Epoch [446/500], Loss: 0.8838, Accuracy: 0.6659\n",
      "Epoch [447/500], Loss: 0.8805, Accuracy: 0.6598\n",
      "Epoch [448/500], Loss: 0.8842, Accuracy: 0.6666\n",
      "Epoch [449/500], Loss: 0.8934, Accuracy: 0.6608\n",
      "Epoch [450/500], Loss: 0.8777, Accuracy: 0.6669\n",
      "Epoch [451/500], Loss: 0.8778, Accuracy: 0.6615\n",
      "Epoch [452/500], Loss: 0.8849, Accuracy: 0.6645\n",
      "Epoch [453/500], Loss: 0.8809, Accuracy: 0.6637\n",
      "Epoch [454/500], Loss: 0.8752, Accuracy: 0.6662\n",
      "Epoch [455/500], Loss: 0.8749, Accuracy: 0.6659\n",
      "Epoch [456/500], Loss: 0.8836, Accuracy: 0.6622\n",
      "Epoch [457/500], Loss: 0.8870, Accuracy: 0.6590\n",
      "Epoch [458/500], Loss: 0.8835, Accuracy: 0.6682\n",
      "Epoch [459/500], Loss: 0.8741, Accuracy: 0.6684\n",
      "Epoch [460/500], Loss: 0.8788, Accuracy: 0.6676\n",
      "Epoch [461/500], Loss: 0.8767, Accuracy: 0.6667\n",
      "Epoch [462/500], Loss: 0.8762, Accuracy: 0.6694\n",
      "Epoch [463/500], Loss: 0.8856, Accuracy: 0.6617\n",
      "Epoch [464/500], Loss: 0.8735, Accuracy: 0.6703\n",
      "Epoch [465/500], Loss: 0.8702, Accuracy: 0.6696\n",
      "Epoch [466/500], Loss: 0.8812, Accuracy: 0.6709\n",
      "Epoch [467/500], Loss: 0.8808, Accuracy: 0.6689\n",
      "Epoch [468/500], Loss: 0.8836, Accuracy: 0.6694\n",
      "Epoch [469/500], Loss: 0.8726, Accuracy: 0.6600\n",
      "Epoch [470/500], Loss: 0.8660, Accuracy: 0.6657\n",
      "Epoch [471/500], Loss: 0.8685, Accuracy: 0.6691\n",
      "Epoch [472/500], Loss: 0.8669, Accuracy: 0.6744\n",
      "Epoch [473/500], Loss: 0.8680, Accuracy: 0.6711\n",
      "Epoch [474/500], Loss: 0.8599, Accuracy: 0.6758\n",
      "Epoch [475/500], Loss: 0.8678, Accuracy: 0.6714\n",
      "Epoch [476/500], Loss: 0.8620, Accuracy: 0.6724\n",
      "Epoch [477/500], Loss: 0.8626, Accuracy: 0.6637\n",
      "Epoch [478/500], Loss: 0.8608, Accuracy: 0.6728\n",
      "Epoch [479/500], Loss: 0.8604, Accuracy: 0.6750\n",
      "Epoch [480/500], Loss: 0.8605, Accuracy: 0.6726\n",
      "Epoch [481/500], Loss: 0.8609, Accuracy: 0.6739\n",
      "Epoch [482/500], Loss: 0.8622, Accuracy: 0.6723\n",
      "Epoch [483/500], Loss: 0.8599, Accuracy: 0.6728\n",
      "Epoch [484/500], Loss: 0.8653, Accuracy: 0.6718\n",
      "Epoch [485/500], Loss: 0.8643, Accuracy: 0.6733\n",
      "Epoch [486/500], Loss: 0.8538, Accuracy: 0.6736\n",
      "Epoch [487/500], Loss: 0.8632, Accuracy: 0.6711\n",
      "Epoch [488/500], Loss: 0.8568, Accuracy: 0.6751\n",
      "Epoch [489/500], Loss: 0.8588, Accuracy: 0.6733\n",
      "Epoch [490/500], Loss: 0.8574, Accuracy: 0.6719\n",
      "Epoch [491/500], Loss: 0.8556, Accuracy: 0.6746\n",
      "Epoch [492/500], Loss: 0.8663, Accuracy: 0.6775\n",
      "Epoch [493/500], Loss: 0.8615, Accuracy: 0.6687\n",
      "Epoch [494/500], Loss: 0.8581, Accuracy: 0.6788\n",
      "Epoch [495/500], Loss: 0.8550, Accuracy: 0.6795\n",
      "Epoch [496/500], Loss: 0.8499, Accuracy: 0.6792\n",
      "Epoch [497/500], Loss: 0.8539, Accuracy: 0.6756\n",
      "Epoch [498/500], Loss: 0.8511, Accuracy: 0.6755\n",
      "Epoch [499/500], Loss: 0.8549, Accuracy: 0.6768\n",
      "Epoch [500/500], Loss: 0.8492, Accuracy: 0.6785\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "lstm_model = LSTMModel(input_size[0], hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.0001)\n",
    "train(lstm_model, train_loaderLSTM, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.7882, Accuracy: 0.2011\n",
      "Epoch [2/500], Loss: 1.7621, Accuracy: 0.2930\n",
      "Epoch [3/500], Loss: 1.7045, Accuracy: 0.2977\n",
      "Epoch [4/500], Loss: 1.6441, Accuracy: 0.3029\n",
      "Epoch [5/500], Loss: 1.6098, Accuracy: 0.3096\n",
      "Epoch [6/500], Loss: 1.5951, Accuracy: 0.3203\n",
      "Epoch [7/500], Loss: 1.5783, Accuracy: 0.3306\n",
      "Epoch [8/500], Loss: 1.5630, Accuracy: 0.3397\n",
      "Epoch [9/500], Loss: 1.5559, Accuracy: 0.3423\n",
      "Epoch [10/500], Loss: 1.5472, Accuracy: 0.3492\n",
      "Epoch [11/500], Loss: 1.5401, Accuracy: 0.3586\n",
      "Epoch [12/500], Loss: 1.5320, Accuracy: 0.3605\n",
      "Epoch [13/500], Loss: 1.5269, Accuracy: 0.3647\n",
      "Epoch [14/500], Loss: 1.5190, Accuracy: 0.3674\n",
      "Epoch [15/500], Loss: 1.5119, Accuracy: 0.3783\n",
      "Epoch [16/500], Loss: 1.5030, Accuracy: 0.3758\n",
      "Epoch [17/500], Loss: 1.5003, Accuracy: 0.3848\n",
      "Epoch [18/500], Loss: 1.4962, Accuracy: 0.3825\n",
      "Epoch [19/500], Loss: 1.4892, Accuracy: 0.3909\n",
      "Epoch [20/500], Loss: 1.4836, Accuracy: 0.3887\n",
      "Epoch [21/500], Loss: 1.4747, Accuracy: 0.3921\n",
      "Epoch [22/500], Loss: 1.4707, Accuracy: 0.3938\n",
      "Epoch [23/500], Loss: 1.4665, Accuracy: 0.4015\n",
      "Epoch [24/500], Loss: 1.4604, Accuracy: 0.4006\n",
      "Epoch [25/500], Loss: 1.4515, Accuracy: 0.4055\n",
      "Epoch [26/500], Loss: 1.4488, Accuracy: 0.4048\n",
      "Epoch [27/500], Loss: 1.4443, Accuracy: 0.4099\n",
      "Epoch [28/500], Loss: 1.4360, Accuracy: 0.4100\n",
      "Epoch [29/500], Loss: 1.4308, Accuracy: 0.4126\n",
      "Epoch [30/500], Loss: 1.4320, Accuracy: 0.4149\n",
      "Epoch [31/500], Loss: 1.4243, Accuracy: 0.4153\n",
      "Epoch [32/500], Loss: 1.4190, Accuracy: 0.4198\n",
      "Epoch [33/500], Loss: 1.4216, Accuracy: 0.4191\n",
      "Epoch [34/500], Loss: 1.4173, Accuracy: 0.4235\n",
      "Epoch [35/500], Loss: 1.4128, Accuracy: 0.4171\n",
      "Epoch [36/500], Loss: 1.4025, Accuracy: 0.4226\n",
      "Epoch [37/500], Loss: 1.4052, Accuracy: 0.4263\n",
      "Epoch [38/500], Loss: 1.4008, Accuracy: 0.4285\n",
      "Epoch [39/500], Loss: 1.4045, Accuracy: 0.4351\n",
      "Epoch [40/500], Loss: 1.4007, Accuracy: 0.4282\n",
      "Epoch [41/500], Loss: 1.3905, Accuracy: 0.4317\n",
      "Epoch [42/500], Loss: 1.3939, Accuracy: 0.4359\n",
      "Epoch [43/500], Loss: 1.3873, Accuracy: 0.4341\n",
      "Epoch [44/500], Loss: 1.3866, Accuracy: 0.4440\n",
      "Epoch [45/500], Loss: 1.3767, Accuracy: 0.4403\n",
      "Epoch [46/500], Loss: 1.3792, Accuracy: 0.4425\n",
      "Epoch [47/500], Loss: 1.3676, Accuracy: 0.4468\n",
      "Epoch [48/500], Loss: 1.3670, Accuracy: 0.4455\n",
      "Epoch [49/500], Loss: 1.3660, Accuracy: 0.4463\n",
      "Epoch [50/500], Loss: 1.3633, Accuracy: 0.4483\n",
      "Epoch [51/500], Loss: 1.3698, Accuracy: 0.4480\n",
      "Epoch [52/500], Loss: 1.3629, Accuracy: 0.4509\n",
      "Epoch [53/500], Loss: 1.3550, Accuracy: 0.4510\n",
      "Epoch [54/500], Loss: 1.3556, Accuracy: 0.4512\n",
      "Epoch [55/500], Loss: 1.3560, Accuracy: 0.4517\n",
      "Epoch [56/500], Loss: 1.3600, Accuracy: 0.4599\n",
      "Epoch [57/500], Loss: 1.3533, Accuracy: 0.4524\n",
      "Epoch [58/500], Loss: 1.3536, Accuracy: 0.4574\n",
      "Epoch [59/500], Loss: 1.3432, Accuracy: 0.4559\n",
      "Epoch [60/500], Loss: 1.3372, Accuracy: 0.4586\n",
      "Epoch [61/500], Loss: 1.3367, Accuracy: 0.4569\n",
      "Epoch [62/500], Loss: 1.3387, Accuracy: 0.4604\n",
      "Epoch [63/500], Loss: 1.3364, Accuracy: 0.4593\n",
      "Epoch [64/500], Loss: 1.3361, Accuracy: 0.4564\n",
      "Epoch [65/500], Loss: 1.3280, Accuracy: 0.4596\n",
      "Epoch [66/500], Loss: 1.3262, Accuracy: 0.4625\n",
      "Epoch [67/500], Loss: 1.3305, Accuracy: 0.4631\n",
      "Epoch [68/500], Loss: 1.3236, Accuracy: 0.4636\n",
      "Epoch [69/500], Loss: 1.3268, Accuracy: 0.4672\n",
      "Epoch [70/500], Loss: 1.3266, Accuracy: 0.4625\n",
      "Epoch [71/500], Loss: 1.3185, Accuracy: 0.4670\n",
      "Epoch [72/500], Loss: 1.3219, Accuracy: 0.4725\n",
      "Epoch [73/500], Loss: 1.3167, Accuracy: 0.4648\n",
      "Epoch [74/500], Loss: 1.3175, Accuracy: 0.4709\n",
      "Epoch [75/500], Loss: 1.3080, Accuracy: 0.4690\n",
      "Epoch [76/500], Loss: 1.3064, Accuracy: 0.4740\n",
      "Epoch [77/500], Loss: 1.3080, Accuracy: 0.4759\n",
      "Epoch [78/500], Loss: 1.2985, Accuracy: 0.4739\n",
      "Epoch [79/500], Loss: 1.2972, Accuracy: 0.4734\n",
      "Epoch [80/500], Loss: 1.3022, Accuracy: 0.4752\n",
      "Epoch [81/500], Loss: 1.3036, Accuracy: 0.4747\n",
      "Epoch [82/500], Loss: 1.2965, Accuracy: 0.4747\n",
      "Epoch [83/500], Loss: 1.2981, Accuracy: 0.4808\n",
      "Epoch [84/500], Loss: 1.2913, Accuracy: 0.4804\n",
      "Epoch [85/500], Loss: 1.2906, Accuracy: 0.4801\n",
      "Epoch [86/500], Loss: 1.2861, Accuracy: 0.4818\n",
      "Epoch [87/500], Loss: 1.2821, Accuracy: 0.4890\n",
      "Epoch [88/500], Loss: 1.2897, Accuracy: 0.4791\n",
      "Epoch [89/500], Loss: 1.2880, Accuracy: 0.4823\n",
      "Epoch [90/500], Loss: 1.2939, Accuracy: 0.4804\n",
      "Epoch [91/500], Loss: 1.2816, Accuracy: 0.4838\n",
      "Epoch [92/500], Loss: 1.2755, Accuracy: 0.4892\n",
      "Epoch [93/500], Loss: 1.2786, Accuracy: 0.4897\n",
      "Epoch [94/500], Loss: 1.2699, Accuracy: 0.4913\n",
      "Epoch [95/500], Loss: 1.2735, Accuracy: 0.4878\n",
      "Epoch [96/500], Loss: 1.2759, Accuracy: 0.4962\n",
      "Epoch [97/500], Loss: 1.2660, Accuracy: 0.4892\n",
      "Epoch [98/500], Loss: 1.2657, Accuracy: 0.4915\n",
      "Epoch [99/500], Loss: 1.2602, Accuracy: 0.4922\n",
      "Epoch [100/500], Loss: 1.2615, Accuracy: 0.4913\n",
      "Epoch [101/500], Loss: 1.2615, Accuracy: 0.4954\n",
      "Epoch [102/500], Loss: 1.2577, Accuracy: 0.4897\n",
      "Epoch [103/500], Loss: 1.2531, Accuracy: 0.5028\n",
      "Epoch [104/500], Loss: 1.2594, Accuracy: 0.4959\n",
      "Epoch [105/500], Loss: 1.2530, Accuracy: 0.5024\n",
      "Epoch [106/500], Loss: 1.2517, Accuracy: 0.4987\n",
      "Epoch [107/500], Loss: 1.2506, Accuracy: 0.5003\n",
      "Epoch [108/500], Loss: 1.2563, Accuracy: 0.4977\n",
      "Epoch [109/500], Loss: 1.2454, Accuracy: 0.4971\n",
      "Epoch [110/500], Loss: 1.2480, Accuracy: 0.4976\n",
      "Epoch [111/500], Loss: 1.2435, Accuracy: 0.4984\n",
      "Epoch [112/500], Loss: 1.2350, Accuracy: 0.4989\n",
      "Epoch [113/500], Loss: 1.2369, Accuracy: 0.5048\n",
      "Epoch [114/500], Loss: 1.2305, Accuracy: 0.5031\n",
      "Epoch [115/500], Loss: 1.2339, Accuracy: 0.5036\n",
      "Epoch [116/500], Loss: 1.2329, Accuracy: 0.5076\n",
      "Epoch [117/500], Loss: 1.2342, Accuracy: 0.5039\n",
      "Epoch [118/500], Loss: 1.2321, Accuracy: 0.5088\n",
      "Epoch [119/500], Loss: 1.2289, Accuracy: 0.5048\n",
      "Epoch [120/500], Loss: 1.2297, Accuracy: 0.5038\n",
      "Epoch [121/500], Loss: 1.2214, Accuracy: 0.5081\n",
      "Epoch [122/500], Loss: 1.2276, Accuracy: 0.5127\n",
      "Epoch [123/500], Loss: 1.2272, Accuracy: 0.5102\n",
      "Epoch [124/500], Loss: 1.2201, Accuracy: 0.5076\n",
      "Epoch [125/500], Loss: 1.2170, Accuracy: 0.5112\n",
      "Epoch [126/500], Loss: 1.2211, Accuracy: 0.5105\n",
      "Epoch [127/500], Loss: 1.2143, Accuracy: 0.5127\n",
      "Epoch [128/500], Loss: 1.2143, Accuracy: 0.5123\n",
      "Epoch [129/500], Loss: 1.2078, Accuracy: 0.5134\n",
      "Epoch [130/500], Loss: 1.2078, Accuracy: 0.5177\n",
      "Epoch [131/500], Loss: 1.2083, Accuracy: 0.5157\n",
      "Epoch [132/500], Loss: 1.2057, Accuracy: 0.5167\n",
      "Epoch [133/500], Loss: 1.2024, Accuracy: 0.5152\n",
      "Epoch [134/500], Loss: 1.1980, Accuracy: 0.5139\n",
      "Epoch [135/500], Loss: 1.2028, Accuracy: 0.5162\n",
      "Epoch [136/500], Loss: 1.2010, Accuracy: 0.5171\n",
      "Epoch [137/500], Loss: 1.1987, Accuracy: 0.5201\n",
      "Epoch [138/500], Loss: 1.2051, Accuracy: 0.5184\n",
      "Epoch [139/500], Loss: 1.2015, Accuracy: 0.5139\n",
      "Epoch [140/500], Loss: 1.1958, Accuracy: 0.5229\n",
      "Epoch [141/500], Loss: 1.2011, Accuracy: 0.5197\n",
      "Epoch [142/500], Loss: 1.2006, Accuracy: 0.5186\n",
      "Epoch [143/500], Loss: 1.1990, Accuracy: 0.5206\n",
      "Epoch [144/500], Loss: 1.1892, Accuracy: 0.5248\n",
      "Epoch [145/500], Loss: 1.1875, Accuracy: 0.5218\n",
      "Epoch [146/500], Loss: 1.1838, Accuracy: 0.5251\n",
      "Epoch [147/500], Loss: 1.1908, Accuracy: 0.5228\n",
      "Epoch [148/500], Loss: 1.1841, Accuracy: 0.5234\n",
      "Epoch [149/500], Loss: 1.1845, Accuracy: 0.5256\n",
      "Epoch [150/500], Loss: 1.1909, Accuracy: 0.5256\n",
      "Epoch [151/500], Loss: 1.1824, Accuracy: 0.5226\n",
      "Epoch [152/500], Loss: 1.1787, Accuracy: 0.5248\n",
      "Epoch [153/500], Loss: 1.1707, Accuracy: 0.5290\n",
      "Epoch [154/500], Loss: 1.1710, Accuracy: 0.5260\n",
      "Epoch [155/500], Loss: 1.1680, Accuracy: 0.5313\n",
      "Epoch [156/500], Loss: 1.1723, Accuracy: 0.5327\n",
      "Epoch [157/500], Loss: 1.1705, Accuracy: 0.5337\n",
      "Epoch [158/500], Loss: 1.1701, Accuracy: 0.5302\n",
      "Epoch [159/500], Loss: 1.1788, Accuracy: 0.5340\n",
      "Epoch [160/500], Loss: 1.1725, Accuracy: 0.5338\n",
      "Epoch [161/500], Loss: 1.1686, Accuracy: 0.5335\n",
      "Epoch [162/500], Loss: 1.1664, Accuracy: 0.5327\n",
      "Epoch [163/500], Loss: 1.1711, Accuracy: 0.5362\n",
      "Epoch [164/500], Loss: 1.1619, Accuracy: 0.5315\n",
      "Epoch [165/500], Loss: 1.1625, Accuracy: 0.5347\n",
      "Epoch [166/500], Loss: 1.1607, Accuracy: 0.5322\n",
      "Epoch [167/500], Loss: 1.1596, Accuracy: 0.5349\n",
      "Epoch [168/500], Loss: 1.1561, Accuracy: 0.5377\n",
      "Epoch [169/500], Loss: 1.1627, Accuracy: 0.5337\n",
      "Epoch [170/500], Loss: 1.1709, Accuracy: 0.5370\n",
      "Epoch [171/500], Loss: 1.1584, Accuracy: 0.5357\n",
      "Epoch [172/500], Loss: 1.1598, Accuracy: 0.5384\n",
      "Epoch [173/500], Loss: 1.1599, Accuracy: 0.5379\n",
      "Epoch [174/500], Loss: 1.1588, Accuracy: 0.5412\n",
      "Epoch [175/500], Loss: 1.1582, Accuracy: 0.5391\n",
      "Epoch [176/500], Loss: 1.1544, Accuracy: 0.5394\n",
      "Epoch [177/500], Loss: 1.1443, Accuracy: 0.5396\n",
      "Epoch [178/500], Loss: 1.1411, Accuracy: 0.5429\n",
      "Epoch [179/500], Loss: 1.1410, Accuracy: 0.5463\n",
      "Epoch [180/500], Loss: 1.1432, Accuracy: 0.5448\n",
      "Epoch [181/500], Loss: 1.1481, Accuracy: 0.5429\n",
      "Epoch [182/500], Loss: 1.1426, Accuracy: 0.5391\n",
      "Epoch [183/500], Loss: 1.1481, Accuracy: 0.5459\n",
      "Epoch [184/500], Loss: 1.1415, Accuracy: 0.5419\n",
      "Epoch [185/500], Loss: 1.1389, Accuracy: 0.5438\n",
      "Epoch [186/500], Loss: 1.1384, Accuracy: 0.5407\n",
      "Epoch [187/500], Loss: 1.1496, Accuracy: 0.5478\n",
      "Epoch [188/500], Loss: 1.1395, Accuracy: 0.5428\n",
      "Epoch [189/500], Loss: 1.1371, Accuracy: 0.5444\n",
      "Epoch [190/500], Loss: 1.1310, Accuracy: 0.5458\n",
      "Epoch [191/500], Loss: 1.1287, Accuracy: 0.5480\n",
      "Epoch [192/500], Loss: 1.1353, Accuracy: 0.5481\n",
      "Epoch [193/500], Loss: 1.1319, Accuracy: 0.5483\n",
      "Epoch [194/500], Loss: 1.1266, Accuracy: 0.5464\n",
      "Epoch [195/500], Loss: 1.1268, Accuracy: 0.5528\n",
      "Epoch [196/500], Loss: 1.1315, Accuracy: 0.5510\n",
      "Epoch [197/500], Loss: 1.1247, Accuracy: 0.5505\n",
      "Epoch [198/500], Loss: 1.1229, Accuracy: 0.5554\n",
      "Epoch [199/500], Loss: 1.1219, Accuracy: 0.5543\n",
      "Epoch [200/500], Loss: 1.1146, Accuracy: 0.5565\n",
      "Epoch [201/500], Loss: 1.1268, Accuracy: 0.5559\n",
      "Epoch [202/500], Loss: 1.1182, Accuracy: 0.5515\n",
      "Epoch [203/500], Loss: 1.1189, Accuracy: 0.5599\n",
      "Epoch [204/500], Loss: 1.1179, Accuracy: 0.5557\n",
      "Epoch [205/500], Loss: 1.1153, Accuracy: 0.5547\n",
      "Epoch [206/500], Loss: 1.1123, Accuracy: 0.5547\n",
      "Epoch [207/500], Loss: 1.1081, Accuracy: 0.5582\n",
      "Epoch [208/500], Loss: 1.1077, Accuracy: 0.5564\n",
      "Epoch [209/500], Loss: 1.1111, Accuracy: 0.5663\n",
      "Epoch [210/500], Loss: 1.1159, Accuracy: 0.5589\n",
      "Epoch [211/500], Loss: 1.1284, Accuracy: 0.5564\n",
      "Epoch [212/500], Loss: 1.1158, Accuracy: 0.5631\n",
      "Epoch [213/500], Loss: 1.1027, Accuracy: 0.5580\n",
      "Epoch [214/500], Loss: 1.1030, Accuracy: 0.5585\n",
      "Epoch [215/500], Loss: 1.1066, Accuracy: 0.5624\n",
      "Epoch [216/500], Loss: 1.1081, Accuracy: 0.5639\n",
      "Epoch [217/500], Loss: 1.1034, Accuracy: 0.5589\n",
      "Epoch [218/500], Loss: 1.1059, Accuracy: 0.5621\n",
      "Epoch [219/500], Loss: 1.1049, Accuracy: 0.5612\n",
      "Epoch [220/500], Loss: 1.0993, Accuracy: 0.5590\n",
      "Epoch [221/500], Loss: 1.0958, Accuracy: 0.5659\n",
      "Epoch [222/500], Loss: 1.0924, Accuracy: 0.5663\n",
      "Epoch [223/500], Loss: 1.0918, Accuracy: 0.5666\n",
      "Epoch [224/500], Loss: 1.0958, Accuracy: 0.5671\n",
      "Epoch [225/500], Loss: 1.1037, Accuracy: 0.5639\n",
      "Epoch [226/500], Loss: 1.1022, Accuracy: 0.5641\n",
      "Epoch [227/500], Loss: 1.0957, Accuracy: 0.5678\n",
      "Epoch [228/500], Loss: 1.0950, Accuracy: 0.5713\n",
      "Epoch [229/500], Loss: 1.1073, Accuracy: 0.5715\n",
      "Epoch [230/500], Loss: 1.0894, Accuracy: 0.5696\n",
      "Epoch [231/500], Loss: 1.0846, Accuracy: 0.5654\n",
      "Epoch [232/500], Loss: 1.0923, Accuracy: 0.5691\n",
      "Epoch [233/500], Loss: 1.0936, Accuracy: 0.5708\n",
      "Epoch [234/500], Loss: 1.0903, Accuracy: 0.5710\n",
      "Epoch [235/500], Loss: 1.0827, Accuracy: 0.5733\n",
      "Epoch [236/500], Loss: 1.0873, Accuracy: 0.5700\n",
      "Epoch [237/500], Loss: 1.0831, Accuracy: 0.5695\n",
      "Epoch [238/500], Loss: 1.0751, Accuracy: 0.5747\n",
      "Epoch [239/500], Loss: 1.0788, Accuracy: 0.5779\n",
      "Epoch [240/500], Loss: 1.0868, Accuracy: 0.5785\n",
      "Epoch [241/500], Loss: 1.0835, Accuracy: 0.5676\n",
      "Epoch [242/500], Loss: 1.0847, Accuracy: 0.5742\n",
      "Epoch [243/500], Loss: 1.0818, Accuracy: 0.5797\n",
      "Epoch [244/500], Loss: 1.0722, Accuracy: 0.5745\n",
      "Epoch [245/500], Loss: 1.0764, Accuracy: 0.5767\n",
      "Epoch [246/500], Loss: 1.0769, Accuracy: 0.5753\n",
      "Epoch [247/500], Loss: 1.0743, Accuracy: 0.5740\n",
      "Epoch [248/500], Loss: 1.0694, Accuracy: 0.5785\n",
      "Epoch [249/500], Loss: 1.0648, Accuracy: 0.5765\n",
      "Epoch [250/500], Loss: 1.0685, Accuracy: 0.5811\n",
      "Epoch [251/500], Loss: 1.0707, Accuracy: 0.5807\n",
      "Epoch [252/500], Loss: 1.0828, Accuracy: 0.5819\n",
      "Epoch [253/500], Loss: 1.0794, Accuracy: 0.5807\n",
      "Epoch [254/500], Loss: 1.0662, Accuracy: 0.5790\n",
      "Epoch [255/500], Loss: 1.0690, Accuracy: 0.5839\n",
      "Epoch [256/500], Loss: 1.0710, Accuracy: 0.5861\n",
      "Epoch [257/500], Loss: 1.0686, Accuracy: 0.5854\n",
      "Epoch [258/500], Loss: 1.0637, Accuracy: 0.5760\n",
      "Epoch [259/500], Loss: 1.0912, Accuracy: 0.5811\n",
      "Epoch [260/500], Loss: 1.0681, Accuracy: 0.5779\n",
      "Epoch [261/500], Loss: 1.0619, Accuracy: 0.5836\n",
      "Epoch [262/500], Loss: 1.0568, Accuracy: 0.5864\n",
      "Epoch [263/500], Loss: 1.0631, Accuracy: 0.5871\n",
      "Epoch [264/500], Loss: 1.0597, Accuracy: 0.5821\n",
      "Epoch [265/500], Loss: 1.0766, Accuracy: 0.5811\n",
      "Epoch [266/500], Loss: 1.0569, Accuracy: 0.5849\n",
      "Epoch [267/500], Loss: 1.0598, Accuracy: 0.5841\n",
      "Epoch [268/500], Loss: 1.0489, Accuracy: 0.5920\n",
      "Epoch [269/500], Loss: 1.0595, Accuracy: 0.5886\n",
      "Epoch [270/500], Loss: 1.0629, Accuracy: 0.5864\n",
      "Epoch [271/500], Loss: 1.0511, Accuracy: 0.5898\n",
      "Epoch [272/500], Loss: 1.0431, Accuracy: 0.5916\n",
      "Epoch [273/500], Loss: 1.0470, Accuracy: 0.5873\n",
      "Epoch [274/500], Loss: 1.0437, Accuracy: 0.5868\n",
      "Epoch [275/500], Loss: 1.0478, Accuracy: 0.5891\n",
      "Epoch [276/500], Loss: 1.0430, Accuracy: 0.5898\n",
      "Epoch [277/500], Loss: 1.0401, Accuracy: 0.5893\n",
      "Epoch [278/500], Loss: 1.0494, Accuracy: 0.5881\n",
      "Epoch [279/500], Loss: 1.0428, Accuracy: 0.5926\n",
      "Epoch [280/500], Loss: 1.0468, Accuracy: 0.5926\n",
      "Epoch [281/500], Loss: 1.0448, Accuracy: 0.5886\n",
      "Epoch [282/500], Loss: 1.0328, Accuracy: 0.5938\n",
      "Epoch [283/500], Loss: 1.0375, Accuracy: 0.5883\n",
      "Epoch [284/500], Loss: 1.0355, Accuracy: 0.5987\n",
      "Epoch [285/500], Loss: 1.0426, Accuracy: 0.5913\n",
      "Epoch [286/500], Loss: 1.0380, Accuracy: 0.5952\n",
      "Epoch [287/500], Loss: 1.0336, Accuracy: 0.5970\n",
      "Epoch [288/500], Loss: 1.0381, Accuracy: 0.5989\n",
      "Epoch [289/500], Loss: 1.0318, Accuracy: 0.5978\n",
      "Epoch [290/500], Loss: 1.0325, Accuracy: 0.5985\n",
      "Epoch [291/500], Loss: 1.0273, Accuracy: 0.5970\n",
      "Epoch [292/500], Loss: 1.0329, Accuracy: 0.5982\n",
      "Epoch [293/500], Loss: 1.0294, Accuracy: 0.5987\n",
      "Epoch [294/500], Loss: 1.0334, Accuracy: 0.5926\n",
      "Epoch [295/500], Loss: 1.0321, Accuracy: 0.6010\n",
      "Epoch [296/500], Loss: 1.0243, Accuracy: 0.5987\n",
      "Epoch [297/500], Loss: 1.0292, Accuracy: 0.5987\n",
      "Epoch [298/500], Loss: 1.0245, Accuracy: 0.5955\n",
      "Epoch [299/500], Loss: 1.0237, Accuracy: 0.6002\n",
      "Epoch [300/500], Loss: 1.0256, Accuracy: 0.6044\n",
      "Epoch [301/500], Loss: 1.0352, Accuracy: 0.6012\n",
      "Epoch [302/500], Loss: 1.0253, Accuracy: 0.5948\n",
      "Epoch [303/500], Loss: 1.0192, Accuracy: 0.6051\n",
      "Epoch [304/500], Loss: 1.0184, Accuracy: 0.6014\n",
      "Epoch [305/500], Loss: 1.0194, Accuracy: 0.5992\n",
      "Epoch [306/500], Loss: 1.0165, Accuracy: 0.6041\n",
      "Epoch [307/500], Loss: 1.0203, Accuracy: 0.6019\n",
      "Epoch [308/500], Loss: 1.0159, Accuracy: 0.6027\n",
      "Epoch [309/500], Loss: 1.0144, Accuracy: 0.6054\n",
      "Epoch [310/500], Loss: 1.0099, Accuracy: 0.6076\n",
      "Epoch [311/500], Loss: 1.0184, Accuracy: 0.6029\n",
      "Epoch [312/500], Loss: 1.0139, Accuracy: 0.6057\n",
      "Epoch [313/500], Loss: 1.0176, Accuracy: 0.6068\n",
      "Epoch [314/500], Loss: 1.0113, Accuracy: 0.6054\n",
      "Epoch [315/500], Loss: 1.0189, Accuracy: 0.6056\n",
      "Epoch [316/500], Loss: 1.0187, Accuracy: 0.6057\n",
      "Epoch [317/500], Loss: 1.0149, Accuracy: 0.6074\n",
      "Epoch [318/500], Loss: 1.0172, Accuracy: 0.6068\n",
      "Epoch [319/500], Loss: 1.0096, Accuracy: 0.6062\n",
      "Epoch [320/500], Loss: 1.0059, Accuracy: 0.6116\n",
      "Epoch [321/500], Loss: 1.0111, Accuracy: 0.6059\n",
      "Epoch [322/500], Loss: 1.0018, Accuracy: 0.6110\n",
      "Epoch [323/500], Loss: 1.0004, Accuracy: 0.6118\n",
      "Epoch [324/500], Loss: 1.0036, Accuracy: 0.6163\n",
      "Epoch [325/500], Loss: 1.0094, Accuracy: 0.6120\n",
      "Epoch [326/500], Loss: 1.0034, Accuracy: 0.6056\n",
      "Epoch [327/500], Loss: 1.0061, Accuracy: 0.6099\n",
      "Epoch [328/500], Loss: 1.0151, Accuracy: 0.6081\n",
      "Epoch [329/500], Loss: 1.0159, Accuracy: 0.6057\n",
      "Epoch [330/500], Loss: 1.0019, Accuracy: 0.6106\n",
      "Epoch [331/500], Loss: 1.0001, Accuracy: 0.6115\n",
      "Epoch [332/500], Loss: 1.0066, Accuracy: 0.6120\n",
      "Epoch [333/500], Loss: 1.0106, Accuracy: 0.6116\n",
      "Epoch [334/500], Loss: 1.0077, Accuracy: 0.6136\n",
      "Epoch [335/500], Loss: 1.0024, Accuracy: 0.6150\n",
      "Epoch [336/500], Loss: 0.9956, Accuracy: 0.6185\n",
      "Epoch [337/500], Loss: 0.9971, Accuracy: 0.6126\n",
      "Epoch [338/500], Loss: 0.9974, Accuracy: 0.6115\n",
      "Epoch [339/500], Loss: 0.9978, Accuracy: 0.6180\n",
      "Epoch [340/500], Loss: 0.9917, Accuracy: 0.6183\n",
      "Epoch [341/500], Loss: 0.9909, Accuracy: 0.6204\n",
      "Epoch [342/500], Loss: 0.9959, Accuracy: 0.6148\n",
      "Epoch [343/500], Loss: 0.9904, Accuracy: 0.6199\n",
      "Epoch [344/500], Loss: 0.9841, Accuracy: 0.6172\n",
      "Epoch [345/500], Loss: 0.9843, Accuracy: 0.6148\n",
      "Epoch [346/500], Loss: 0.9861, Accuracy: 0.6190\n",
      "Epoch [347/500], Loss: 0.9907, Accuracy: 0.6183\n",
      "Epoch [348/500], Loss: 1.0052, Accuracy: 0.6210\n",
      "Epoch [349/500], Loss: 0.9887, Accuracy: 0.6152\n",
      "Epoch [350/500], Loss: 0.9806, Accuracy: 0.6227\n",
      "Epoch [351/500], Loss: 0.9868, Accuracy: 0.6205\n",
      "Epoch [352/500], Loss: 0.9871, Accuracy: 0.6209\n",
      "Epoch [353/500], Loss: 0.9991, Accuracy: 0.6162\n",
      "Epoch [354/500], Loss: 0.9987, Accuracy: 0.6170\n",
      "Epoch [355/500], Loss: 0.9843, Accuracy: 0.6172\n",
      "Epoch [356/500], Loss: 0.9811, Accuracy: 0.6237\n",
      "Epoch [357/500], Loss: 0.9833, Accuracy: 0.6195\n",
      "Epoch [358/500], Loss: 0.9890, Accuracy: 0.6162\n",
      "Epoch [359/500], Loss: 0.9760, Accuracy: 0.6209\n",
      "Epoch [360/500], Loss: 0.9780, Accuracy: 0.6224\n",
      "Epoch [361/500], Loss: 0.9763, Accuracy: 0.6225\n",
      "Epoch [362/500], Loss: 0.9764, Accuracy: 0.6209\n",
      "Epoch [363/500], Loss: 0.9798, Accuracy: 0.6222\n",
      "Epoch [364/500], Loss: 0.9760, Accuracy: 0.6244\n",
      "Epoch [365/500], Loss: 0.9733, Accuracy: 0.6247\n",
      "Epoch [366/500], Loss: 0.9707, Accuracy: 0.6261\n",
      "Epoch [367/500], Loss: 0.9702, Accuracy: 0.6286\n",
      "Epoch [368/500], Loss: 0.9724, Accuracy: 0.6230\n",
      "Epoch [369/500], Loss: 0.9826, Accuracy: 0.6241\n",
      "Epoch [370/500], Loss: 0.9770, Accuracy: 0.6256\n",
      "Epoch [371/500], Loss: 0.9664, Accuracy: 0.6281\n",
      "Epoch [372/500], Loss: 0.9668, Accuracy: 0.6224\n",
      "Epoch [373/500], Loss: 0.9683, Accuracy: 0.6259\n",
      "Epoch [374/500], Loss: 0.9667, Accuracy: 0.6289\n",
      "Epoch [375/500], Loss: 0.9709, Accuracy: 0.6284\n",
      "Epoch [376/500], Loss: 0.9681, Accuracy: 0.6237\n",
      "Epoch [377/500], Loss: 0.9736, Accuracy: 0.6283\n",
      "Epoch [378/500], Loss: 0.9817, Accuracy: 0.6236\n",
      "Epoch [379/500], Loss: 0.9653, Accuracy: 0.6256\n",
      "Epoch [380/500], Loss: 0.9586, Accuracy: 0.6269\n",
      "Epoch [381/500], Loss: 0.9675, Accuracy: 0.6281\n",
      "Epoch [382/500], Loss: 0.9751, Accuracy: 0.6256\n",
      "Epoch [383/500], Loss: 0.9673, Accuracy: 0.6267\n",
      "Epoch [384/500], Loss: 0.9682, Accuracy: 0.6276\n",
      "Epoch [385/500], Loss: 0.9681, Accuracy: 0.6271\n",
      "Epoch [386/500], Loss: 0.9620, Accuracy: 0.6266\n",
      "Epoch [387/500], Loss: 0.9669, Accuracy: 0.6227\n",
      "Epoch [388/500], Loss: 0.9658, Accuracy: 0.6298\n",
      "Epoch [389/500], Loss: 0.9623, Accuracy: 0.6284\n",
      "Epoch [390/500], Loss: 0.9699, Accuracy: 0.6259\n",
      "Epoch [391/500], Loss: 0.9657, Accuracy: 0.6279\n",
      "Epoch [392/500], Loss: 0.9566, Accuracy: 0.6288\n",
      "Epoch [393/500], Loss: 0.9635, Accuracy: 0.6308\n",
      "Epoch [394/500], Loss: 0.9667, Accuracy: 0.6283\n",
      "Epoch [395/500], Loss: 0.9594, Accuracy: 0.6335\n",
      "Epoch [396/500], Loss: 0.9539, Accuracy: 0.6331\n",
      "Epoch [397/500], Loss: 0.9522, Accuracy: 0.6316\n",
      "Epoch [398/500], Loss: 0.9507, Accuracy: 0.6348\n",
      "Epoch [399/500], Loss: 0.9585, Accuracy: 0.6356\n",
      "Epoch [400/500], Loss: 0.9550, Accuracy: 0.6313\n",
      "Epoch [401/500], Loss: 0.9461, Accuracy: 0.6372\n",
      "Epoch [402/500], Loss: 0.9496, Accuracy: 0.6338\n",
      "Epoch [403/500], Loss: 0.9485, Accuracy: 0.6380\n",
      "Epoch [404/500], Loss: 0.9486, Accuracy: 0.6351\n",
      "Epoch [405/500], Loss: 0.9541, Accuracy: 0.6358\n",
      "Epoch [406/500], Loss: 0.9496, Accuracy: 0.6367\n",
      "Epoch [407/500], Loss: 0.9450, Accuracy: 0.6373\n",
      "Epoch [408/500], Loss: 0.9563, Accuracy: 0.6304\n",
      "Epoch [409/500], Loss: 0.9445, Accuracy: 0.6377\n",
      "Epoch [410/500], Loss: 0.9449, Accuracy: 0.6350\n",
      "Epoch [411/500], Loss: 0.9554, Accuracy: 0.6348\n",
      "Epoch [412/500], Loss: 0.9432, Accuracy: 0.6330\n",
      "Epoch [413/500], Loss: 0.9574, Accuracy: 0.6390\n",
      "Epoch [414/500], Loss: 0.9519, Accuracy: 0.6377\n",
      "Epoch [415/500], Loss: 0.9508, Accuracy: 0.6288\n",
      "Epoch [416/500], Loss: 0.9561, Accuracy: 0.6363\n",
      "Epoch [417/500], Loss: 0.9458, Accuracy: 0.6343\n",
      "Epoch [418/500], Loss: 0.9413, Accuracy: 0.6368\n",
      "Epoch [419/500], Loss: 0.9525, Accuracy: 0.6393\n",
      "Epoch [420/500], Loss: 0.9400, Accuracy: 0.6454\n",
      "Epoch [421/500], Loss: 0.9412, Accuracy: 0.6331\n",
      "Epoch [422/500], Loss: 0.9479, Accuracy: 0.6414\n",
      "Epoch [423/500], Loss: 0.9443, Accuracy: 0.6355\n",
      "Epoch [424/500], Loss: 0.9401, Accuracy: 0.6432\n",
      "Epoch [425/500], Loss: 0.9372, Accuracy: 0.6454\n",
      "Epoch [426/500], Loss: 0.9364, Accuracy: 0.6378\n",
      "Epoch [427/500], Loss: 0.9374, Accuracy: 0.6387\n",
      "Epoch [428/500], Loss: 0.9383, Accuracy: 0.6447\n",
      "Epoch [429/500], Loss: 0.9346, Accuracy: 0.6417\n",
      "Epoch [430/500], Loss: 0.9419, Accuracy: 0.6388\n",
      "Epoch [431/500], Loss: 0.9452, Accuracy: 0.6385\n",
      "Epoch [432/500], Loss: 0.9327, Accuracy: 0.6387\n",
      "Epoch [433/500], Loss: 0.9334, Accuracy: 0.6407\n",
      "Epoch [434/500], Loss: 0.9330, Accuracy: 0.6430\n",
      "Epoch [435/500], Loss: 0.9275, Accuracy: 0.6405\n",
      "Epoch [436/500], Loss: 0.9252, Accuracy: 0.6466\n",
      "Epoch [437/500], Loss: 0.9330, Accuracy: 0.6449\n",
      "Epoch [438/500], Loss: 0.9381, Accuracy: 0.6412\n",
      "Epoch [439/500], Loss: 0.9338, Accuracy: 0.6398\n",
      "Epoch [440/500], Loss: 0.9334, Accuracy: 0.6409\n",
      "Epoch [441/500], Loss: 0.9293, Accuracy: 0.6402\n",
      "Epoch [442/500], Loss: 0.9260, Accuracy: 0.6484\n",
      "Epoch [443/500], Loss: 0.9316, Accuracy: 0.6425\n",
      "Epoch [444/500], Loss: 0.9345, Accuracy: 0.6477\n",
      "Epoch [445/500], Loss: 0.9355, Accuracy: 0.6402\n",
      "Epoch [446/500], Loss: 0.9338, Accuracy: 0.6405\n",
      "Epoch [447/500], Loss: 0.9267, Accuracy: 0.6437\n",
      "Epoch [448/500], Loss: 0.9330, Accuracy: 0.6482\n",
      "Epoch [449/500], Loss: 0.9263, Accuracy: 0.6444\n",
      "Epoch [450/500], Loss: 0.9211, Accuracy: 0.6415\n",
      "Epoch [451/500], Loss: 0.9211, Accuracy: 0.6514\n",
      "Epoch [452/500], Loss: 0.9223, Accuracy: 0.6407\n",
      "Epoch [453/500], Loss: 0.9288, Accuracy: 0.6447\n",
      "Epoch [454/500], Loss: 0.9314, Accuracy: 0.6451\n",
      "Epoch [455/500], Loss: 0.9225, Accuracy: 0.6409\n",
      "Epoch [456/500], Loss: 0.9160, Accuracy: 0.6493\n",
      "Epoch [457/500], Loss: 0.9208, Accuracy: 0.6482\n",
      "Epoch [458/500], Loss: 0.9205, Accuracy: 0.6509\n",
      "Epoch [459/500], Loss: 0.9210, Accuracy: 0.6491\n",
      "Epoch [460/500], Loss: 0.9234, Accuracy: 0.6432\n",
      "Epoch [461/500], Loss: 0.9206, Accuracy: 0.6427\n",
      "Epoch [462/500], Loss: 0.9232, Accuracy: 0.6444\n",
      "Epoch [463/500], Loss: 0.9167, Accuracy: 0.6481\n",
      "Epoch [464/500], Loss: 0.9144, Accuracy: 0.6457\n",
      "Epoch [465/500], Loss: 0.9160, Accuracy: 0.6489\n",
      "Epoch [466/500], Loss: 0.9201, Accuracy: 0.6481\n",
      "Epoch [467/500], Loss: 0.9264, Accuracy: 0.6489\n",
      "Epoch [468/500], Loss: 0.9207, Accuracy: 0.6461\n",
      "Epoch [469/500], Loss: 0.9234, Accuracy: 0.6457\n",
      "Epoch [470/500], Loss: 0.9176, Accuracy: 0.6459\n",
      "Epoch [471/500], Loss: 0.9121, Accuracy: 0.6452\n",
      "Epoch [472/500], Loss: 0.9106, Accuracy: 0.6466\n",
      "Epoch [473/500], Loss: 0.9109, Accuracy: 0.6486\n",
      "Epoch [474/500], Loss: 0.9108, Accuracy: 0.6467\n",
      "Epoch [475/500], Loss: 0.9167, Accuracy: 0.6481\n",
      "Epoch [476/500], Loss: 0.9192, Accuracy: 0.6526\n",
      "Epoch [477/500], Loss: 0.9136, Accuracy: 0.6466\n",
      "Epoch [478/500], Loss: 0.9067, Accuracy: 0.6528\n",
      "Epoch [479/500], Loss: 0.9103, Accuracy: 0.6528\n",
      "Epoch [480/500], Loss: 0.9155, Accuracy: 0.6444\n",
      "Epoch [481/500], Loss: 0.9080, Accuracy: 0.6467\n",
      "Epoch [482/500], Loss: 0.9102, Accuracy: 0.6494\n",
      "Epoch [483/500], Loss: 0.9063, Accuracy: 0.6499\n",
      "Epoch [484/500], Loss: 0.9154, Accuracy: 0.6509\n",
      "Epoch [485/500], Loss: 0.9129, Accuracy: 0.6503\n",
      "Epoch [486/500], Loss: 0.9041, Accuracy: 0.6521\n",
      "Epoch [487/500], Loss: 0.9102, Accuracy: 0.6516\n",
      "Epoch [488/500], Loss: 0.9052, Accuracy: 0.6546\n",
      "Epoch [489/500], Loss: 0.9041, Accuracy: 0.6538\n",
      "Epoch [490/500], Loss: 0.9061, Accuracy: 0.6540\n",
      "Epoch [491/500], Loss: 0.9316, Accuracy: 0.6524\n",
      "Epoch [492/500], Loss: 0.9144, Accuracy: 0.6471\n",
      "Epoch [493/500], Loss: 0.9047, Accuracy: 0.6521\n",
      "Epoch [494/500], Loss: 0.9035, Accuracy: 0.6540\n",
      "Epoch [495/500], Loss: 0.9028, Accuracy: 0.6523\n",
      "Epoch [496/500], Loss: 0.9136, Accuracy: 0.6553\n",
      "Epoch [497/500], Loss: 0.9110, Accuracy: 0.6509\n",
      "Epoch [498/500], Loss: 0.9083, Accuracy: 0.6575\n",
      "Epoch [499/500], Loss: 0.8993, Accuracy: 0.6575\n",
      "Epoch [500/500], Loss: 0.9026, Accuracy: 0.6558\n"
     ]
    }
   ],
   "source": [
    "# LSTM with Attention\n",
    "lstm_atn_model = LSTMAttention(input_size[0], hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_atn_model.parameters(), lr=0.0001)\n",
    "train(lstm_atn_model, train_loaderLSTM, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.8478, Accuracy: 0.1787\n",
      "Epoch [2/500], Loss: 1.7549, Accuracy: 0.2308\n",
      "Epoch [3/500], Loss: 1.7118, Accuracy: 0.2629\n",
      "Epoch [4/500], Loss: 1.6637, Accuracy: 0.2935\n",
      "Epoch [5/500], Loss: 1.6471, Accuracy: 0.3029\n",
      "Epoch [6/500], Loss: 1.6288, Accuracy: 0.3099\n",
      "Epoch [7/500], Loss: 1.6153, Accuracy: 0.3130\n",
      "Epoch [8/500], Loss: 1.6027, Accuracy: 0.3198\n",
      "Epoch [9/500], Loss: 1.5961, Accuracy: 0.3219\n",
      "Epoch [10/500], Loss: 1.5928, Accuracy: 0.3262\n",
      "Epoch [11/500], Loss: 1.5909, Accuracy: 0.3180\n",
      "Epoch [12/500], Loss: 1.5850, Accuracy: 0.3215\n",
      "Epoch [13/500], Loss: 1.5732, Accuracy: 0.3329\n",
      "Epoch [14/500], Loss: 1.5763, Accuracy: 0.3339\n",
      "Epoch [15/500], Loss: 1.5696, Accuracy: 0.3333\n",
      "Epoch [16/500], Loss: 1.5646, Accuracy: 0.3402\n",
      "Epoch [17/500], Loss: 1.5627, Accuracy: 0.3400\n",
      "Epoch [18/500], Loss: 1.5645, Accuracy: 0.3365\n",
      "Epoch [19/500], Loss: 1.5521, Accuracy: 0.3429\n",
      "Epoch [20/500], Loss: 1.5515, Accuracy: 0.3457\n",
      "Epoch [21/500], Loss: 1.5497, Accuracy: 0.3486\n",
      "Epoch [22/500], Loss: 1.5504, Accuracy: 0.3507\n",
      "Epoch [23/500], Loss: 1.5466, Accuracy: 0.3418\n",
      "Epoch [24/500], Loss: 1.5410, Accuracy: 0.3479\n",
      "Epoch [25/500], Loss: 1.5399, Accuracy: 0.3555\n",
      "Epoch [26/500], Loss: 1.5400, Accuracy: 0.3534\n",
      "Epoch [27/500], Loss: 1.5382, Accuracy: 0.3502\n",
      "Epoch [28/500], Loss: 1.5337, Accuracy: 0.3640\n",
      "Epoch [29/500], Loss: 1.5316, Accuracy: 0.3590\n",
      "Epoch [30/500], Loss: 1.5304, Accuracy: 0.3565\n",
      "Epoch [31/500], Loss: 1.5273, Accuracy: 0.3590\n",
      "Epoch [32/500], Loss: 1.5288, Accuracy: 0.3551\n",
      "Epoch [33/500], Loss: 1.5253, Accuracy: 0.3565\n",
      "Epoch [34/500], Loss: 1.5257, Accuracy: 0.3580\n",
      "Epoch [35/500], Loss: 1.5126, Accuracy: 0.3729\n",
      "Epoch [36/500], Loss: 1.5152, Accuracy: 0.3573\n",
      "Epoch [37/500], Loss: 1.5127, Accuracy: 0.3731\n",
      "Epoch [38/500], Loss: 1.5206, Accuracy: 0.3719\n",
      "Epoch [39/500], Loss: 1.5076, Accuracy: 0.3677\n",
      "Epoch [40/500], Loss: 1.5125, Accuracy: 0.3701\n",
      "Epoch [41/500], Loss: 1.5095, Accuracy: 0.3669\n",
      "Epoch [42/500], Loss: 1.5003, Accuracy: 0.3817\n",
      "Epoch [43/500], Loss: 1.5074, Accuracy: 0.3759\n",
      "Epoch [44/500], Loss: 1.4977, Accuracy: 0.3820\n",
      "Epoch [45/500], Loss: 1.4993, Accuracy: 0.3696\n",
      "Epoch [46/500], Loss: 1.5011, Accuracy: 0.3702\n",
      "Epoch [47/500], Loss: 1.4952, Accuracy: 0.3813\n",
      "Epoch [48/500], Loss: 1.4952, Accuracy: 0.3736\n",
      "Epoch [49/500], Loss: 1.4891, Accuracy: 0.3741\n",
      "Epoch [50/500], Loss: 1.4929, Accuracy: 0.3786\n",
      "Epoch [51/500], Loss: 1.4897, Accuracy: 0.3722\n",
      "Epoch [52/500], Loss: 1.4911, Accuracy: 0.3847\n",
      "Epoch [53/500], Loss: 1.4868, Accuracy: 0.3872\n",
      "Epoch [54/500], Loss: 1.4838, Accuracy: 0.3827\n",
      "Epoch [55/500], Loss: 1.4860, Accuracy: 0.3790\n",
      "Epoch [56/500], Loss: 1.4828, Accuracy: 0.3885\n",
      "Epoch [57/500], Loss: 1.4828, Accuracy: 0.3823\n",
      "Epoch [58/500], Loss: 1.4852, Accuracy: 0.3875\n",
      "Epoch [59/500], Loss: 1.4712, Accuracy: 0.3951\n",
      "Epoch [60/500], Loss: 1.4806, Accuracy: 0.3894\n",
      "Epoch [61/500], Loss: 1.4792, Accuracy: 0.3909\n",
      "Epoch [62/500], Loss: 1.4730, Accuracy: 0.3906\n",
      "Epoch [63/500], Loss: 1.4783, Accuracy: 0.3916\n",
      "Epoch [64/500], Loss: 1.4665, Accuracy: 0.3961\n",
      "Epoch [65/500], Loss: 1.4730, Accuracy: 0.3904\n",
      "Epoch [66/500], Loss: 1.4697, Accuracy: 0.3958\n",
      "Epoch [67/500], Loss: 1.4558, Accuracy: 0.3938\n",
      "Epoch [68/500], Loss: 1.4592, Accuracy: 0.3949\n",
      "Epoch [69/500], Loss: 1.4636, Accuracy: 0.3973\n",
      "Epoch [70/500], Loss: 1.4670, Accuracy: 0.3922\n",
      "Epoch [71/500], Loss: 1.4630, Accuracy: 0.3948\n",
      "Epoch [72/500], Loss: 1.4577, Accuracy: 0.3974\n",
      "Epoch [73/500], Loss: 1.4618, Accuracy: 0.3973\n",
      "Epoch [74/500], Loss: 1.4584, Accuracy: 0.3971\n",
      "Epoch [75/500], Loss: 1.4601, Accuracy: 0.3948\n",
      "Epoch [76/500], Loss: 1.4569, Accuracy: 0.3949\n",
      "Epoch [77/500], Loss: 1.4544, Accuracy: 0.3964\n",
      "Epoch [78/500], Loss: 1.4677, Accuracy: 0.3956\n",
      "Epoch [79/500], Loss: 1.4557, Accuracy: 0.3983\n",
      "Epoch [80/500], Loss: 1.4494, Accuracy: 0.4050\n",
      "Epoch [81/500], Loss: 1.4526, Accuracy: 0.4000\n",
      "Epoch [82/500], Loss: 1.4607, Accuracy: 0.3943\n",
      "Epoch [83/500], Loss: 1.4468, Accuracy: 0.4040\n",
      "Epoch [84/500], Loss: 1.4422, Accuracy: 0.3991\n",
      "Epoch [85/500], Loss: 1.4430, Accuracy: 0.4060\n",
      "Epoch [86/500], Loss: 1.4653, Accuracy: 0.4037\n",
      "Epoch [87/500], Loss: 1.4455, Accuracy: 0.3995\n",
      "Epoch [88/500], Loss: 1.4435, Accuracy: 0.4048\n",
      "Epoch [89/500], Loss: 1.4674, Accuracy: 0.4067\n",
      "Epoch [90/500], Loss: 1.4447, Accuracy: 0.3996\n",
      "Epoch [91/500], Loss: 1.4474, Accuracy: 0.3993\n",
      "Epoch [92/500], Loss: 1.4438, Accuracy: 0.4060\n",
      "Epoch [93/500], Loss: 1.4398, Accuracy: 0.4100\n",
      "Epoch [94/500], Loss: 1.4371, Accuracy: 0.4050\n",
      "Epoch [95/500], Loss: 1.4412, Accuracy: 0.4042\n",
      "Epoch [96/500], Loss: 1.4379, Accuracy: 0.4048\n",
      "Epoch [97/500], Loss: 1.4435, Accuracy: 0.4042\n",
      "Epoch [98/500], Loss: 1.4420, Accuracy: 0.4032\n",
      "Epoch [99/500], Loss: 1.4488, Accuracy: 0.4027\n",
      "Epoch [100/500], Loss: 1.4490, Accuracy: 0.3964\n",
      "Epoch [101/500], Loss: 1.4459, Accuracy: 0.4013\n",
      "Epoch [102/500], Loss: 1.4303, Accuracy: 0.4132\n",
      "Epoch [103/500], Loss: 1.4380, Accuracy: 0.4126\n",
      "Epoch [104/500], Loss: 1.4345, Accuracy: 0.4063\n",
      "Epoch [105/500], Loss: 1.4295, Accuracy: 0.4121\n",
      "Epoch [106/500], Loss: 1.4296, Accuracy: 0.4074\n",
      "Epoch [107/500], Loss: 1.4403, Accuracy: 0.4114\n",
      "Epoch [108/500], Loss: 1.4328, Accuracy: 0.4082\n",
      "Epoch [109/500], Loss: 1.4256, Accuracy: 0.4139\n",
      "Epoch [110/500], Loss: 1.4313, Accuracy: 0.4032\n",
      "Epoch [111/500], Loss: 1.4268, Accuracy: 0.4141\n",
      "Epoch [112/500], Loss: 1.4227, Accuracy: 0.4117\n",
      "Epoch [113/500], Loss: 1.4176, Accuracy: 0.4107\n",
      "Epoch [114/500], Loss: 1.4167, Accuracy: 0.4131\n",
      "Epoch [115/500], Loss: 1.4170, Accuracy: 0.4189\n",
      "Epoch [116/500], Loss: 1.4197, Accuracy: 0.4122\n",
      "Epoch [117/500], Loss: 1.4275, Accuracy: 0.4163\n",
      "Epoch [118/500], Loss: 1.4254, Accuracy: 0.4183\n",
      "Epoch [119/500], Loss: 1.4149, Accuracy: 0.4215\n",
      "Epoch [120/500], Loss: 1.4233, Accuracy: 0.4127\n",
      "Epoch [121/500], Loss: 1.4233, Accuracy: 0.4142\n",
      "Epoch [122/500], Loss: 1.4315, Accuracy: 0.4179\n",
      "Epoch [123/500], Loss: 1.4125, Accuracy: 0.4107\n",
      "Epoch [124/500], Loss: 1.4118, Accuracy: 0.4208\n",
      "Epoch [125/500], Loss: 1.4142, Accuracy: 0.4242\n",
      "Epoch [126/500], Loss: 1.4120, Accuracy: 0.4203\n",
      "Epoch [127/500], Loss: 1.4215, Accuracy: 0.4158\n",
      "Epoch [128/500], Loss: 1.4181, Accuracy: 0.4233\n",
      "Epoch [129/500], Loss: 1.4109, Accuracy: 0.4233\n",
      "Epoch [130/500], Loss: 1.4150, Accuracy: 0.4213\n",
      "Epoch [131/500], Loss: 1.4163, Accuracy: 0.4210\n",
      "Epoch [132/500], Loss: 1.4045, Accuracy: 0.4230\n",
      "Epoch [133/500], Loss: 1.4034, Accuracy: 0.4270\n",
      "Epoch [134/500], Loss: 1.4114, Accuracy: 0.4223\n",
      "Epoch [135/500], Loss: 1.4047, Accuracy: 0.4289\n",
      "Epoch [136/500], Loss: 1.4053, Accuracy: 0.4136\n",
      "Epoch [137/500], Loss: 1.4000, Accuracy: 0.4226\n",
      "Epoch [138/500], Loss: 1.4078, Accuracy: 0.4247\n",
      "Epoch [139/500], Loss: 1.4023, Accuracy: 0.4273\n",
      "Epoch [140/500], Loss: 1.3994, Accuracy: 0.4226\n",
      "Epoch [141/500], Loss: 1.3990, Accuracy: 0.4243\n",
      "Epoch [142/500], Loss: 1.3959, Accuracy: 0.4272\n",
      "Epoch [143/500], Loss: 1.3999, Accuracy: 0.4211\n",
      "Epoch [144/500], Loss: 1.4035, Accuracy: 0.4324\n",
      "Epoch [145/500], Loss: 1.3974, Accuracy: 0.4267\n",
      "Epoch [146/500], Loss: 1.3914, Accuracy: 0.4317\n",
      "Epoch [147/500], Loss: 1.4066, Accuracy: 0.4188\n",
      "Epoch [148/500], Loss: 1.3982, Accuracy: 0.4198\n",
      "Epoch [149/500], Loss: 1.3947, Accuracy: 0.4273\n",
      "Epoch [150/500], Loss: 1.3928, Accuracy: 0.4357\n",
      "Epoch [151/500], Loss: 1.3989, Accuracy: 0.4272\n",
      "Epoch [152/500], Loss: 1.4048, Accuracy: 0.4299\n",
      "Epoch [153/500], Loss: 1.3951, Accuracy: 0.4272\n",
      "Epoch [154/500], Loss: 1.3979, Accuracy: 0.4255\n",
      "Epoch [155/500], Loss: 1.3990, Accuracy: 0.4221\n",
      "Epoch [156/500], Loss: 1.3942, Accuracy: 0.4255\n",
      "Epoch [157/500], Loss: 1.3896, Accuracy: 0.4265\n",
      "Epoch [158/500], Loss: 1.3946, Accuracy: 0.4351\n",
      "Epoch [159/500], Loss: 1.3852, Accuracy: 0.4289\n",
      "Epoch [160/500], Loss: 1.3970, Accuracy: 0.4280\n",
      "Epoch [161/500], Loss: 1.3967, Accuracy: 0.4263\n",
      "Epoch [162/500], Loss: 1.3841, Accuracy: 0.4297\n",
      "Epoch [163/500], Loss: 1.3832, Accuracy: 0.4364\n",
      "Epoch [164/500], Loss: 1.3839, Accuracy: 0.4289\n",
      "Epoch [165/500], Loss: 1.3963, Accuracy: 0.4280\n",
      "Epoch [166/500], Loss: 1.3826, Accuracy: 0.4321\n",
      "Epoch [167/500], Loss: 1.3904, Accuracy: 0.4309\n",
      "Epoch [168/500], Loss: 1.3869, Accuracy: 0.4326\n",
      "Epoch [169/500], Loss: 1.3856, Accuracy: 0.4373\n",
      "Epoch [170/500], Loss: 1.3880, Accuracy: 0.4351\n",
      "Epoch [171/500], Loss: 1.3798, Accuracy: 0.4364\n",
      "Epoch [172/500], Loss: 1.3797, Accuracy: 0.4339\n",
      "Epoch [173/500], Loss: 1.3776, Accuracy: 0.4339\n",
      "Epoch [174/500], Loss: 1.3776, Accuracy: 0.4346\n",
      "Epoch [175/500], Loss: 1.3797, Accuracy: 0.4357\n",
      "Epoch [176/500], Loss: 1.3742, Accuracy: 0.4326\n",
      "Epoch [177/500], Loss: 1.3753, Accuracy: 0.4363\n",
      "Epoch [178/500], Loss: 1.3690, Accuracy: 0.4416\n",
      "Epoch [179/500], Loss: 1.3729, Accuracy: 0.4357\n",
      "Epoch [180/500], Loss: 1.3782, Accuracy: 0.4373\n",
      "Epoch [181/500], Loss: 1.3722, Accuracy: 0.4416\n",
      "Epoch [182/500], Loss: 1.3808, Accuracy: 0.4378\n",
      "Epoch [183/500], Loss: 1.3694, Accuracy: 0.4406\n",
      "Epoch [184/500], Loss: 1.3775, Accuracy: 0.4277\n",
      "Epoch [185/500], Loss: 1.3790, Accuracy: 0.4388\n",
      "Epoch [186/500], Loss: 1.3774, Accuracy: 0.4351\n",
      "Epoch [187/500], Loss: 1.3732, Accuracy: 0.4405\n",
      "Epoch [188/500], Loss: 1.3808, Accuracy: 0.4418\n",
      "Epoch [189/500], Loss: 1.3659, Accuracy: 0.4398\n",
      "Epoch [190/500], Loss: 1.3685, Accuracy: 0.4331\n",
      "Epoch [191/500], Loss: 1.3647, Accuracy: 0.4396\n",
      "Epoch [192/500], Loss: 1.3633, Accuracy: 0.4394\n",
      "Epoch [193/500], Loss: 1.3680, Accuracy: 0.4430\n",
      "Epoch [194/500], Loss: 1.3723, Accuracy: 0.4430\n",
      "Epoch [195/500], Loss: 1.3687, Accuracy: 0.4420\n",
      "Epoch [196/500], Loss: 1.3799, Accuracy: 0.4388\n",
      "Epoch [197/500], Loss: 1.3685, Accuracy: 0.4378\n",
      "Epoch [198/500], Loss: 1.3727, Accuracy: 0.4359\n",
      "Epoch [199/500], Loss: 1.3733, Accuracy: 0.4383\n",
      "Epoch [200/500], Loss: 1.3563, Accuracy: 0.4475\n",
      "Epoch [201/500], Loss: 1.3643, Accuracy: 0.4425\n",
      "Epoch [202/500], Loss: 1.3684, Accuracy: 0.4420\n",
      "Epoch [203/500], Loss: 1.3687, Accuracy: 0.4364\n",
      "Epoch [204/500], Loss: 1.3611, Accuracy: 0.4462\n",
      "Epoch [205/500], Loss: 1.3701, Accuracy: 0.4436\n",
      "Epoch [206/500], Loss: 1.3642, Accuracy: 0.4430\n",
      "Epoch [207/500], Loss: 1.3630, Accuracy: 0.4467\n",
      "Epoch [208/500], Loss: 1.3716, Accuracy: 0.4445\n",
      "Epoch [209/500], Loss: 1.3759, Accuracy: 0.4317\n",
      "Epoch [210/500], Loss: 1.3674, Accuracy: 0.4401\n",
      "Epoch [211/500], Loss: 1.3594, Accuracy: 0.4465\n",
      "Epoch [212/500], Loss: 1.3604, Accuracy: 0.4418\n",
      "Epoch [213/500], Loss: 1.3583, Accuracy: 0.4448\n",
      "Epoch [214/500], Loss: 1.3606, Accuracy: 0.4480\n",
      "Epoch [215/500], Loss: 1.3634, Accuracy: 0.4423\n",
      "Epoch [216/500], Loss: 1.3661, Accuracy: 0.4384\n",
      "Epoch [217/500], Loss: 1.3497, Accuracy: 0.4507\n",
      "Epoch [218/500], Loss: 1.3555, Accuracy: 0.4450\n",
      "Epoch [219/500], Loss: 1.3536, Accuracy: 0.4478\n",
      "Epoch [220/500], Loss: 1.3572, Accuracy: 0.4440\n",
      "Epoch [221/500], Loss: 1.3607, Accuracy: 0.4487\n",
      "Epoch [222/500], Loss: 1.3613, Accuracy: 0.4490\n",
      "Epoch [223/500], Loss: 1.3615, Accuracy: 0.4426\n",
      "Epoch [224/500], Loss: 1.3467, Accuracy: 0.4438\n",
      "Epoch [225/500], Loss: 1.3428, Accuracy: 0.4473\n",
      "Epoch [226/500], Loss: 1.3573, Accuracy: 0.4480\n",
      "Epoch [227/500], Loss: 1.3525, Accuracy: 0.4443\n",
      "Epoch [228/500], Loss: 1.3509, Accuracy: 0.4455\n",
      "Epoch [229/500], Loss: 1.3519, Accuracy: 0.4505\n",
      "Epoch [230/500], Loss: 1.3457, Accuracy: 0.4495\n",
      "Epoch [231/500], Loss: 1.3516, Accuracy: 0.4525\n",
      "Epoch [232/500], Loss: 1.3511, Accuracy: 0.4472\n",
      "Epoch [233/500], Loss: 1.3412, Accuracy: 0.4453\n",
      "Epoch [234/500], Loss: 1.3516, Accuracy: 0.4488\n",
      "Epoch [235/500], Loss: 1.3508, Accuracy: 0.4460\n",
      "Epoch [236/500], Loss: 1.3472, Accuracy: 0.4514\n",
      "Epoch [237/500], Loss: 1.3527, Accuracy: 0.4542\n",
      "Epoch [238/500], Loss: 1.3505, Accuracy: 0.4500\n",
      "Epoch [239/500], Loss: 1.3383, Accuracy: 0.4519\n",
      "Epoch [240/500], Loss: 1.3495, Accuracy: 0.4509\n",
      "Epoch [241/500], Loss: 1.3498, Accuracy: 0.4510\n",
      "Epoch [242/500], Loss: 1.3447, Accuracy: 0.4492\n",
      "Epoch [243/500], Loss: 1.3403, Accuracy: 0.4557\n",
      "Epoch [244/500], Loss: 1.3416, Accuracy: 0.4559\n",
      "Epoch [245/500], Loss: 1.3371, Accuracy: 0.4487\n",
      "Epoch [246/500], Loss: 1.3373, Accuracy: 0.4524\n",
      "Epoch [247/500], Loss: 1.3372, Accuracy: 0.4529\n",
      "Epoch [248/500], Loss: 1.3338, Accuracy: 0.4499\n",
      "Epoch [249/500], Loss: 1.3362, Accuracy: 0.4552\n",
      "Epoch [250/500], Loss: 1.3380, Accuracy: 0.4509\n",
      "Epoch [251/500], Loss: 1.3390, Accuracy: 0.4591\n",
      "Epoch [252/500], Loss: 1.3346, Accuracy: 0.4524\n",
      "Epoch [253/500], Loss: 1.3306, Accuracy: 0.4515\n",
      "Epoch [254/500], Loss: 1.3314, Accuracy: 0.4614\n",
      "Epoch [255/500], Loss: 1.3366, Accuracy: 0.4520\n",
      "Epoch [256/500], Loss: 1.3275, Accuracy: 0.4542\n",
      "Epoch [257/500], Loss: 1.3351, Accuracy: 0.4534\n",
      "Epoch [258/500], Loss: 1.3360, Accuracy: 0.4567\n",
      "Epoch [259/500], Loss: 1.3294, Accuracy: 0.4552\n",
      "Epoch [260/500], Loss: 1.3348, Accuracy: 0.4596\n",
      "Epoch [261/500], Loss: 1.3371, Accuracy: 0.4578\n",
      "Epoch [262/500], Loss: 1.3235, Accuracy: 0.4556\n",
      "Epoch [263/500], Loss: 1.3239, Accuracy: 0.4589\n",
      "Epoch [264/500], Loss: 1.3280, Accuracy: 0.4557\n",
      "Epoch [265/500], Loss: 1.3246, Accuracy: 0.4660\n",
      "Epoch [266/500], Loss: 1.3268, Accuracy: 0.4559\n",
      "Epoch [267/500], Loss: 1.3399, Accuracy: 0.4536\n",
      "Epoch [268/500], Loss: 1.3242, Accuracy: 0.4517\n",
      "Epoch [269/500], Loss: 1.3228, Accuracy: 0.4499\n",
      "Epoch [270/500], Loss: 1.3284, Accuracy: 0.4532\n",
      "Epoch [271/500], Loss: 1.3178, Accuracy: 0.4668\n",
      "Epoch [272/500], Loss: 1.3276, Accuracy: 0.4559\n",
      "Epoch [273/500], Loss: 1.3185, Accuracy: 0.4651\n",
      "Epoch [274/500], Loss: 1.3304, Accuracy: 0.4549\n",
      "Epoch [275/500], Loss: 1.3364, Accuracy: 0.4598\n",
      "Epoch [276/500], Loss: 1.3244, Accuracy: 0.4625\n",
      "Epoch [277/500], Loss: 1.3143, Accuracy: 0.4593\n",
      "Epoch [278/500], Loss: 1.3156, Accuracy: 0.4687\n",
      "Epoch [279/500], Loss: 1.3211, Accuracy: 0.4549\n",
      "Epoch [280/500], Loss: 1.3240, Accuracy: 0.4593\n",
      "Epoch [281/500], Loss: 1.3195, Accuracy: 0.4656\n",
      "Epoch [282/500], Loss: 1.3259, Accuracy: 0.4614\n",
      "Epoch [283/500], Loss: 1.3171, Accuracy: 0.4631\n",
      "Epoch [284/500], Loss: 1.3224, Accuracy: 0.4631\n",
      "Epoch [285/500], Loss: 1.3166, Accuracy: 0.4658\n",
      "Epoch [286/500], Loss: 1.3174, Accuracy: 0.4660\n",
      "Epoch [287/500], Loss: 1.3197, Accuracy: 0.4641\n",
      "Epoch [288/500], Loss: 1.3092, Accuracy: 0.4643\n",
      "Epoch [289/500], Loss: 1.3169, Accuracy: 0.4620\n",
      "Epoch [290/500], Loss: 1.3280, Accuracy: 0.4604\n",
      "Epoch [291/500], Loss: 1.3235, Accuracy: 0.4625\n",
      "Epoch [292/500], Loss: 1.3238, Accuracy: 0.4547\n",
      "Epoch [293/500], Loss: 1.3198, Accuracy: 0.4591\n",
      "Epoch [294/500], Loss: 1.3004, Accuracy: 0.4715\n",
      "Epoch [295/500], Loss: 1.3100, Accuracy: 0.4714\n",
      "Epoch [296/500], Loss: 1.3113, Accuracy: 0.4697\n",
      "Epoch [297/500], Loss: 1.3256, Accuracy: 0.4658\n",
      "Epoch [298/500], Loss: 1.3180, Accuracy: 0.4571\n",
      "Epoch [299/500], Loss: 1.3104, Accuracy: 0.4635\n",
      "Epoch [300/500], Loss: 1.3188, Accuracy: 0.4623\n",
      "Epoch [301/500], Loss: 1.3150, Accuracy: 0.4593\n",
      "Epoch [302/500], Loss: 1.3034, Accuracy: 0.4662\n",
      "Epoch [303/500], Loss: 1.3170, Accuracy: 0.4636\n",
      "Epoch [304/500], Loss: 1.3093, Accuracy: 0.4646\n",
      "Epoch [305/500], Loss: 1.3075, Accuracy: 0.4757\n",
      "Epoch [306/500], Loss: 1.3060, Accuracy: 0.4717\n",
      "Epoch [307/500], Loss: 1.3103, Accuracy: 0.4653\n",
      "Epoch [308/500], Loss: 1.3148, Accuracy: 0.4677\n",
      "Epoch [309/500], Loss: 1.3072, Accuracy: 0.4656\n",
      "Epoch [310/500], Loss: 1.3020, Accuracy: 0.4616\n",
      "Epoch [311/500], Loss: 1.3096, Accuracy: 0.4656\n",
      "Epoch [312/500], Loss: 1.3019, Accuracy: 0.4690\n",
      "Epoch [313/500], Loss: 1.2982, Accuracy: 0.4704\n",
      "Epoch [314/500], Loss: 1.3022, Accuracy: 0.4707\n",
      "Epoch [315/500], Loss: 1.3062, Accuracy: 0.4724\n",
      "Epoch [316/500], Loss: 1.2931, Accuracy: 0.4672\n",
      "Epoch [317/500], Loss: 1.3027, Accuracy: 0.4677\n",
      "Epoch [318/500], Loss: 1.3023, Accuracy: 0.4635\n",
      "Epoch [319/500], Loss: 1.3062, Accuracy: 0.4682\n",
      "Epoch [320/500], Loss: 1.2944, Accuracy: 0.4693\n",
      "Epoch [321/500], Loss: 1.2963, Accuracy: 0.4717\n",
      "Epoch [322/500], Loss: 1.3016, Accuracy: 0.4707\n",
      "Epoch [323/500], Loss: 1.2978, Accuracy: 0.4693\n",
      "Epoch [324/500], Loss: 1.2949, Accuracy: 0.4742\n",
      "Epoch [325/500], Loss: 1.2979, Accuracy: 0.4710\n",
      "Epoch [326/500], Loss: 1.2836, Accuracy: 0.4794\n",
      "Epoch [327/500], Loss: 1.3059, Accuracy: 0.4648\n",
      "Epoch [328/500], Loss: 1.2881, Accuracy: 0.4766\n",
      "Epoch [329/500], Loss: 1.2896, Accuracy: 0.4801\n",
      "Epoch [330/500], Loss: 1.2945, Accuracy: 0.4798\n",
      "Epoch [331/500], Loss: 1.3027, Accuracy: 0.4697\n",
      "Epoch [332/500], Loss: 1.2964, Accuracy: 0.4771\n",
      "Epoch [333/500], Loss: 1.2964, Accuracy: 0.4653\n",
      "Epoch [334/500], Loss: 1.2990, Accuracy: 0.4680\n",
      "Epoch [335/500], Loss: 1.2914, Accuracy: 0.4727\n",
      "Epoch [336/500], Loss: 1.2986, Accuracy: 0.4744\n",
      "Epoch [337/500], Loss: 1.2940, Accuracy: 0.4714\n",
      "Epoch [338/500], Loss: 1.2931, Accuracy: 0.4801\n",
      "Epoch [339/500], Loss: 1.3000, Accuracy: 0.4725\n",
      "Epoch [340/500], Loss: 1.2942, Accuracy: 0.4702\n",
      "Epoch [341/500], Loss: 1.2945, Accuracy: 0.4749\n",
      "Epoch [342/500], Loss: 1.2956, Accuracy: 0.4746\n",
      "Epoch [343/500], Loss: 1.2892, Accuracy: 0.4772\n",
      "Epoch [344/500], Loss: 1.2907, Accuracy: 0.4799\n",
      "Epoch [345/500], Loss: 1.2937, Accuracy: 0.4690\n",
      "Epoch [346/500], Loss: 1.2876, Accuracy: 0.4742\n",
      "Epoch [347/500], Loss: 1.2910, Accuracy: 0.4734\n",
      "Epoch [348/500], Loss: 1.2906, Accuracy: 0.4727\n",
      "Epoch [349/500], Loss: 1.2922, Accuracy: 0.4756\n",
      "Epoch [350/500], Loss: 1.2836, Accuracy: 0.4811\n",
      "Epoch [351/500], Loss: 1.2889, Accuracy: 0.4727\n",
      "Epoch [352/500], Loss: 1.2925, Accuracy: 0.4794\n",
      "Epoch [353/500], Loss: 1.2980, Accuracy: 0.4722\n",
      "Epoch [354/500], Loss: 1.2820, Accuracy: 0.4764\n",
      "Epoch [355/500], Loss: 1.2867, Accuracy: 0.4759\n",
      "Epoch [356/500], Loss: 1.2929, Accuracy: 0.4841\n",
      "Epoch [357/500], Loss: 1.2947, Accuracy: 0.4767\n",
      "Epoch [358/500], Loss: 1.2795, Accuracy: 0.4843\n",
      "Epoch [359/500], Loss: 1.2810, Accuracy: 0.4819\n",
      "Epoch [360/500], Loss: 1.2769, Accuracy: 0.4782\n",
      "Epoch [361/500], Loss: 1.2715, Accuracy: 0.4848\n",
      "Epoch [362/500], Loss: 1.2834, Accuracy: 0.4826\n",
      "Epoch [363/500], Loss: 1.2821, Accuracy: 0.4782\n",
      "Epoch [364/500], Loss: 1.2725, Accuracy: 0.4824\n",
      "Epoch [365/500], Loss: 1.2853, Accuracy: 0.4860\n",
      "Epoch [366/500], Loss: 1.3027, Accuracy: 0.4791\n",
      "Epoch [367/500], Loss: 1.2747, Accuracy: 0.4806\n",
      "Epoch [368/500], Loss: 1.2669, Accuracy: 0.4804\n",
      "Epoch [369/500], Loss: 1.2735, Accuracy: 0.4811\n",
      "Epoch [370/500], Loss: 1.2721, Accuracy: 0.4793\n",
      "Epoch [371/500], Loss: 1.2707, Accuracy: 0.4890\n",
      "Epoch [372/500], Loss: 1.2767, Accuracy: 0.4781\n",
      "Epoch [373/500], Loss: 1.2816, Accuracy: 0.4766\n",
      "Epoch [374/500], Loss: 1.2693, Accuracy: 0.4779\n",
      "Epoch [375/500], Loss: 1.2668, Accuracy: 0.4833\n",
      "Epoch [376/500], Loss: 1.2820, Accuracy: 0.4784\n",
      "Epoch [377/500], Loss: 1.2726, Accuracy: 0.4786\n",
      "Epoch [378/500], Loss: 1.2762, Accuracy: 0.4833\n",
      "Epoch [379/500], Loss: 1.2783, Accuracy: 0.4776\n",
      "Epoch [380/500], Loss: 1.2796, Accuracy: 0.4799\n",
      "Epoch [381/500], Loss: 1.2814, Accuracy: 0.4776\n",
      "Epoch [382/500], Loss: 1.2831, Accuracy: 0.4789\n",
      "Epoch [383/500], Loss: 1.2664, Accuracy: 0.4828\n",
      "Epoch [384/500], Loss: 1.2672, Accuracy: 0.4831\n",
      "Epoch [385/500], Loss: 1.2636, Accuracy: 0.4890\n",
      "Epoch [386/500], Loss: 1.2645, Accuracy: 0.4798\n",
      "Epoch [387/500], Loss: 1.2669, Accuracy: 0.4846\n",
      "Epoch [388/500], Loss: 1.2723, Accuracy: 0.4774\n",
      "Epoch [389/500], Loss: 1.2718, Accuracy: 0.4900\n",
      "Epoch [390/500], Loss: 1.2706, Accuracy: 0.4826\n",
      "Epoch [391/500], Loss: 1.2750, Accuracy: 0.4897\n",
      "Epoch [392/500], Loss: 1.2748, Accuracy: 0.4772\n",
      "Epoch [393/500], Loss: 1.2699, Accuracy: 0.4855\n",
      "Epoch [394/500], Loss: 1.2739, Accuracy: 0.4858\n",
      "Epoch [395/500], Loss: 1.2684, Accuracy: 0.4843\n",
      "Epoch [396/500], Loss: 1.2647, Accuracy: 0.4885\n",
      "Epoch [397/500], Loss: 1.2828, Accuracy: 0.4816\n",
      "Epoch [398/500], Loss: 1.2711, Accuracy: 0.4754\n",
      "Epoch [399/500], Loss: 1.2622, Accuracy: 0.4861\n",
      "Epoch [400/500], Loss: 1.2728, Accuracy: 0.4882\n",
      "Epoch [401/500], Loss: 1.2855, Accuracy: 0.4786\n",
      "Epoch [402/500], Loss: 1.2625, Accuracy: 0.4767\n",
      "Epoch [403/500], Loss: 1.2691, Accuracy: 0.4885\n",
      "Epoch [404/500], Loss: 1.2700, Accuracy: 0.4919\n",
      "Epoch [405/500], Loss: 1.2668, Accuracy: 0.4939\n",
      "Epoch [406/500], Loss: 1.2726, Accuracy: 0.4855\n",
      "Epoch [407/500], Loss: 1.2729, Accuracy: 0.4912\n",
      "Epoch [408/500], Loss: 1.2755, Accuracy: 0.4824\n",
      "Epoch [409/500], Loss: 1.2608, Accuracy: 0.4831\n",
      "Epoch [410/500], Loss: 1.2748, Accuracy: 0.4883\n",
      "Epoch [411/500], Loss: 1.2662, Accuracy: 0.4856\n",
      "Epoch [412/500], Loss: 1.2589, Accuracy: 0.4895\n",
      "Epoch [413/500], Loss: 1.2603, Accuracy: 0.4851\n",
      "Epoch [414/500], Loss: 1.2586, Accuracy: 0.4900\n",
      "Epoch [415/500], Loss: 1.2573, Accuracy: 0.4903\n",
      "Epoch [416/500], Loss: 1.2546, Accuracy: 0.4917\n",
      "Epoch [417/500], Loss: 1.2591, Accuracy: 0.4888\n",
      "Epoch [418/500], Loss: 1.2640, Accuracy: 0.4888\n",
      "Epoch [419/500], Loss: 1.2510, Accuracy: 0.4917\n",
      "Epoch [420/500], Loss: 1.2580, Accuracy: 0.4915\n",
      "Epoch [421/500], Loss: 1.2550, Accuracy: 0.4856\n",
      "Epoch [422/500], Loss: 1.2578, Accuracy: 0.4897\n",
      "Epoch [423/500], Loss: 1.2518, Accuracy: 0.4944\n",
      "Epoch [424/500], Loss: 1.2662, Accuracy: 0.4873\n",
      "Epoch [425/500], Loss: 1.2529, Accuracy: 0.4861\n",
      "Epoch [426/500], Loss: 1.2586, Accuracy: 0.4784\n",
      "Epoch [427/500], Loss: 1.2608, Accuracy: 0.4895\n",
      "Epoch [428/500], Loss: 1.2655, Accuracy: 0.4861\n",
      "Epoch [429/500], Loss: 1.2641, Accuracy: 0.4868\n",
      "Epoch [430/500], Loss: 1.2511, Accuracy: 0.4947\n",
      "Epoch [431/500], Loss: 1.2492, Accuracy: 0.4898\n",
      "Epoch [432/500], Loss: 1.2644, Accuracy: 0.4833\n",
      "Epoch [433/500], Loss: 1.2477, Accuracy: 0.4959\n",
      "Epoch [434/500], Loss: 1.2516, Accuracy: 0.4882\n",
      "Epoch [435/500], Loss: 1.2538, Accuracy: 0.4897\n",
      "Epoch [436/500], Loss: 1.2571, Accuracy: 0.4882\n",
      "Epoch [437/500], Loss: 1.2522, Accuracy: 0.4945\n",
      "Epoch [438/500], Loss: 1.2593, Accuracy: 0.4893\n",
      "Epoch [439/500], Loss: 1.2480, Accuracy: 0.4927\n",
      "Epoch [440/500], Loss: 1.2679, Accuracy: 0.4833\n",
      "Epoch [441/500], Loss: 1.2481, Accuracy: 0.4957\n",
      "Epoch [442/500], Loss: 1.2472, Accuracy: 0.4932\n",
      "Epoch [443/500], Loss: 1.2419, Accuracy: 0.4942\n",
      "Epoch [444/500], Loss: 1.2434, Accuracy: 0.4917\n",
      "Epoch [445/500], Loss: 1.2542, Accuracy: 0.4934\n",
      "Epoch [446/500], Loss: 1.2537, Accuracy: 0.4887\n",
      "Epoch [447/500], Loss: 1.2594, Accuracy: 0.4848\n",
      "Epoch [448/500], Loss: 1.2548, Accuracy: 0.4922\n",
      "Epoch [449/500], Loss: 1.2455, Accuracy: 0.4947\n",
      "Epoch [450/500], Loss: 1.2443, Accuracy: 0.4935\n",
      "Epoch [451/500], Loss: 1.2436, Accuracy: 0.4987\n",
      "Epoch [452/500], Loss: 1.2477, Accuracy: 0.4930\n",
      "Epoch [453/500], Loss: 1.2450, Accuracy: 0.4994\n",
      "Epoch [454/500], Loss: 1.2496, Accuracy: 0.4910\n",
      "Epoch [455/500], Loss: 1.2465, Accuracy: 0.4922\n",
      "Epoch [456/500], Loss: 1.2553, Accuracy: 0.4902\n",
      "Epoch [457/500], Loss: 1.2469, Accuracy: 0.4912\n",
      "Epoch [458/500], Loss: 1.2522, Accuracy: 0.4945\n",
      "Epoch [459/500], Loss: 1.2595, Accuracy: 0.4964\n",
      "Epoch [460/500], Loss: 1.2340, Accuracy: 0.5019\n",
      "Epoch [461/500], Loss: 1.2421, Accuracy: 0.4954\n",
      "Epoch [462/500], Loss: 1.2465, Accuracy: 0.4895\n",
      "Epoch [463/500], Loss: 1.2424, Accuracy: 0.4924\n",
      "Epoch [464/500], Loss: 1.2546, Accuracy: 0.4863\n",
      "Epoch [465/500], Loss: 1.2417, Accuracy: 0.5003\n",
      "Epoch [466/500], Loss: 1.2330, Accuracy: 0.5066\n",
      "Epoch [467/500], Loss: 1.2335, Accuracy: 0.5092\n",
      "Epoch [468/500], Loss: 1.2414, Accuracy: 0.4991\n",
      "Epoch [469/500], Loss: 1.2411, Accuracy: 0.4947\n",
      "Epoch [470/500], Loss: 1.2494, Accuracy: 0.4863\n",
      "Epoch [471/500], Loss: 1.2398, Accuracy: 0.5018\n",
      "Epoch [472/500], Loss: 1.2393, Accuracy: 0.5011\n",
      "Epoch [473/500], Loss: 1.2502, Accuracy: 0.4925\n",
      "Epoch [474/500], Loss: 1.2425, Accuracy: 0.4929\n",
      "Epoch [475/500], Loss: 1.2372, Accuracy: 0.4952\n",
      "Epoch [476/500], Loss: 1.2379, Accuracy: 0.4945\n",
      "Epoch [477/500], Loss: 1.2483, Accuracy: 0.5011\n",
      "Epoch [478/500], Loss: 1.2487, Accuracy: 0.4971\n",
      "Epoch [479/500], Loss: 1.2394, Accuracy: 0.5029\n",
      "Epoch [480/500], Loss: 1.2380, Accuracy: 0.4972\n",
      "Epoch [481/500], Loss: 1.2361, Accuracy: 0.4966\n",
      "Epoch [482/500], Loss: 1.2329, Accuracy: 0.4955\n",
      "Epoch [483/500], Loss: 1.2431, Accuracy: 0.4947\n",
      "Epoch [484/500], Loss: 1.2334, Accuracy: 0.5034\n",
      "Epoch [485/500], Loss: 1.2495, Accuracy: 0.5008\n",
      "Epoch [486/500], Loss: 1.2391, Accuracy: 0.5043\n",
      "Epoch [487/500], Loss: 1.2316, Accuracy: 0.4994\n",
      "Epoch [488/500], Loss: 1.2378, Accuracy: 0.4967\n",
      "Epoch [489/500], Loss: 1.2372, Accuracy: 0.5016\n",
      "Epoch [490/500], Loss: 1.2394, Accuracy: 0.4992\n",
      "Epoch [491/500], Loss: 1.2367, Accuracy: 0.4920\n",
      "Epoch [492/500], Loss: 1.2347, Accuracy: 0.4997\n",
      "Epoch [493/500], Loss: 1.2314, Accuracy: 0.5009\n",
      "Epoch [494/500], Loss: 1.2294, Accuracy: 0.4959\n",
      "Epoch [495/500], Loss: 1.2224, Accuracy: 0.5043\n",
      "Epoch [496/500], Loss: 1.2266, Accuracy: 0.4950\n",
      "Epoch [497/500], Loss: 1.2329, Accuracy: 0.5033\n",
      "Epoch [498/500], Loss: 1.2301, Accuracy: 0.5003\n",
      "Epoch [499/500], Loss: 1.2291, Accuracy: 0.5018\n",
      "Epoch [500/500], Loss: 1.2342, Accuracy: 0.4977\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network\n",
    "cnn_model = CNNModel(input_size[0],num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.0001)\n",
    "train(cnn_model, train_loaderCNN, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 2.0271, Accuracy: 0.2019\n",
      "Epoch [2/500], Loss: 1.7401, Accuracy: 0.2590\n",
      "Epoch [3/500], Loss: 1.6848, Accuracy: 0.2928\n",
      "Epoch [4/500], Loss: 1.6369, Accuracy: 0.3103\n",
      "Epoch [5/500], Loss: 1.6080, Accuracy: 0.3225\n",
      "Epoch [6/500], Loss: 1.5890, Accuracy: 0.3339\n",
      "Epoch [7/500], Loss: 1.5713, Accuracy: 0.3459\n",
      "Epoch [8/500], Loss: 1.5609, Accuracy: 0.3588\n",
      "Epoch [9/500], Loss: 1.5560, Accuracy: 0.3526\n",
      "Epoch [10/500], Loss: 1.5442, Accuracy: 0.3702\n",
      "Epoch [11/500], Loss: 1.5367, Accuracy: 0.3649\n",
      "Epoch [12/500], Loss: 1.5282, Accuracy: 0.3712\n",
      "Epoch [13/500], Loss: 1.5212, Accuracy: 0.3771\n",
      "Epoch [14/500], Loss: 1.5164, Accuracy: 0.3776\n",
      "Epoch [15/500], Loss: 1.5080, Accuracy: 0.3780\n",
      "Epoch [16/500], Loss: 1.5038, Accuracy: 0.3786\n",
      "Epoch [17/500], Loss: 1.5080, Accuracy: 0.3848\n",
      "Epoch [18/500], Loss: 1.5011, Accuracy: 0.3815\n",
      "Epoch [19/500], Loss: 1.4942, Accuracy: 0.3869\n",
      "Epoch [20/500], Loss: 1.4899, Accuracy: 0.3931\n",
      "Epoch [21/500], Loss: 1.4877, Accuracy: 0.3889\n",
      "Epoch [22/500], Loss: 1.4808, Accuracy: 0.3872\n",
      "Epoch [23/500], Loss: 1.4765, Accuracy: 0.3919\n",
      "Epoch [24/500], Loss: 1.4717, Accuracy: 0.3958\n",
      "Epoch [25/500], Loss: 1.4714, Accuracy: 0.4003\n",
      "Epoch [26/500], Loss: 1.4684, Accuracy: 0.3985\n",
      "Epoch [27/500], Loss: 1.4713, Accuracy: 0.3932\n",
      "Epoch [28/500], Loss: 1.4624, Accuracy: 0.3990\n",
      "Epoch [29/500], Loss: 1.4612, Accuracy: 0.4018\n",
      "Epoch [30/500], Loss: 1.4579, Accuracy: 0.4047\n",
      "Epoch [31/500], Loss: 1.4565, Accuracy: 0.4047\n",
      "Epoch [32/500], Loss: 1.4491, Accuracy: 0.4003\n",
      "Epoch [33/500], Loss: 1.4491, Accuracy: 0.4057\n",
      "Epoch [34/500], Loss: 1.4517, Accuracy: 0.4070\n",
      "Epoch [35/500], Loss: 1.4469, Accuracy: 0.4100\n",
      "Epoch [36/500], Loss: 1.4459, Accuracy: 0.4137\n",
      "Epoch [37/500], Loss: 1.4481, Accuracy: 0.4052\n",
      "Epoch [38/500], Loss: 1.4490, Accuracy: 0.4141\n",
      "Epoch [39/500], Loss: 1.4359, Accuracy: 0.4085\n",
      "Epoch [40/500], Loss: 1.4387, Accuracy: 0.4072\n",
      "Epoch [41/500], Loss: 1.4332, Accuracy: 0.4146\n",
      "Epoch [42/500], Loss: 1.4371, Accuracy: 0.4087\n",
      "Epoch [43/500], Loss: 1.4310, Accuracy: 0.4163\n",
      "Epoch [44/500], Loss: 1.4298, Accuracy: 0.4153\n",
      "Epoch [45/500], Loss: 1.4277, Accuracy: 0.4166\n",
      "Epoch [46/500], Loss: 1.4296, Accuracy: 0.4134\n",
      "Epoch [47/500], Loss: 1.4294, Accuracy: 0.4116\n",
      "Epoch [48/500], Loss: 1.4241, Accuracy: 0.4226\n",
      "Epoch [49/500], Loss: 1.4192, Accuracy: 0.4191\n",
      "Epoch [50/500], Loss: 1.4305, Accuracy: 0.4166\n",
      "Epoch [51/500], Loss: 1.4154, Accuracy: 0.4248\n",
      "Epoch [52/500], Loss: 1.4163, Accuracy: 0.4218\n",
      "Epoch [53/500], Loss: 1.4133, Accuracy: 0.4228\n",
      "Epoch [54/500], Loss: 1.4143, Accuracy: 0.4220\n",
      "Epoch [55/500], Loss: 1.4176, Accuracy: 0.4240\n",
      "Epoch [56/500], Loss: 1.4107, Accuracy: 0.4210\n",
      "Epoch [57/500], Loss: 1.4074, Accuracy: 0.4235\n",
      "Epoch [58/500], Loss: 1.4030, Accuracy: 0.4243\n",
      "Epoch [59/500], Loss: 1.4021, Accuracy: 0.4243\n",
      "Epoch [60/500], Loss: 1.3995, Accuracy: 0.4284\n",
      "Epoch [61/500], Loss: 1.3955, Accuracy: 0.4312\n",
      "Epoch [62/500], Loss: 1.3971, Accuracy: 0.4292\n",
      "Epoch [63/500], Loss: 1.4049, Accuracy: 0.4287\n",
      "Epoch [64/500], Loss: 1.3953, Accuracy: 0.4319\n",
      "Epoch [65/500], Loss: 1.3951, Accuracy: 0.4275\n",
      "Epoch [66/500], Loss: 1.3880, Accuracy: 0.4295\n",
      "Epoch [67/500], Loss: 1.3927, Accuracy: 0.4319\n",
      "Epoch [68/500], Loss: 1.3865, Accuracy: 0.4331\n",
      "Epoch [69/500], Loss: 1.3889, Accuracy: 0.4319\n",
      "Epoch [70/500], Loss: 1.3832, Accuracy: 0.4336\n",
      "Epoch [71/500], Loss: 1.3877, Accuracy: 0.4394\n",
      "Epoch [72/500], Loss: 1.3855, Accuracy: 0.4359\n",
      "Epoch [73/500], Loss: 1.3886, Accuracy: 0.4371\n",
      "Epoch [74/500], Loss: 1.3898, Accuracy: 0.4361\n",
      "Epoch [75/500], Loss: 1.3824, Accuracy: 0.4406\n",
      "Epoch [76/500], Loss: 1.3832, Accuracy: 0.4391\n",
      "Epoch [77/500], Loss: 1.3778, Accuracy: 0.4428\n",
      "Epoch [78/500], Loss: 1.3808, Accuracy: 0.4423\n",
      "Epoch [79/500], Loss: 1.3737, Accuracy: 0.4356\n",
      "Epoch [80/500], Loss: 1.3713, Accuracy: 0.4428\n",
      "Epoch [81/500], Loss: 1.3763, Accuracy: 0.4430\n",
      "Epoch [82/500], Loss: 1.3698, Accuracy: 0.4475\n",
      "Epoch [83/500], Loss: 1.3664, Accuracy: 0.4416\n",
      "Epoch [84/500], Loss: 1.3747, Accuracy: 0.4430\n",
      "Epoch [85/500], Loss: 1.3699, Accuracy: 0.4433\n",
      "Epoch [86/500], Loss: 1.3688, Accuracy: 0.4477\n",
      "Epoch [87/500], Loss: 1.3692, Accuracy: 0.4431\n",
      "Epoch [88/500], Loss: 1.3706, Accuracy: 0.4475\n",
      "Epoch [89/500], Loss: 1.3626, Accuracy: 0.4460\n",
      "Epoch [90/500], Loss: 1.3591, Accuracy: 0.4510\n",
      "Epoch [91/500], Loss: 1.3653, Accuracy: 0.4485\n",
      "Epoch [92/500], Loss: 1.3635, Accuracy: 0.4504\n",
      "Epoch [93/500], Loss: 1.3701, Accuracy: 0.4445\n",
      "Epoch [94/500], Loss: 1.3574, Accuracy: 0.4499\n",
      "Epoch [95/500], Loss: 1.3643, Accuracy: 0.4490\n",
      "Epoch [96/500], Loss: 1.3550, Accuracy: 0.4507\n",
      "Epoch [97/500], Loss: 1.3483, Accuracy: 0.4499\n",
      "Epoch [98/500], Loss: 1.3605, Accuracy: 0.4524\n",
      "Epoch [99/500], Loss: 1.3489, Accuracy: 0.4561\n",
      "Epoch [100/500], Loss: 1.3496, Accuracy: 0.4572\n",
      "Epoch [101/500], Loss: 1.3513, Accuracy: 0.4551\n",
      "Epoch [102/500], Loss: 1.3483, Accuracy: 0.4539\n",
      "Epoch [103/500], Loss: 1.3448, Accuracy: 0.4578\n",
      "Epoch [104/500], Loss: 1.3512, Accuracy: 0.4571\n",
      "Epoch [105/500], Loss: 1.3563, Accuracy: 0.4551\n",
      "Epoch [106/500], Loss: 1.3453, Accuracy: 0.4534\n",
      "Epoch [107/500], Loss: 1.3473, Accuracy: 0.4608\n",
      "Epoch [108/500], Loss: 1.3443, Accuracy: 0.4571\n",
      "Epoch [109/500], Loss: 1.3407, Accuracy: 0.4616\n",
      "Epoch [110/500], Loss: 1.3397, Accuracy: 0.4567\n",
      "Epoch [111/500], Loss: 1.3383, Accuracy: 0.4616\n",
      "Epoch [112/500], Loss: 1.3454, Accuracy: 0.4606\n",
      "Epoch [113/500], Loss: 1.3342, Accuracy: 0.4618\n",
      "Epoch [114/500], Loss: 1.3363, Accuracy: 0.4636\n",
      "Epoch [115/500], Loss: 1.3350, Accuracy: 0.4643\n",
      "Epoch [116/500], Loss: 1.3316, Accuracy: 0.4633\n",
      "Epoch [117/500], Loss: 1.3344, Accuracy: 0.4653\n",
      "Epoch [118/500], Loss: 1.3322, Accuracy: 0.4670\n",
      "Epoch [119/500], Loss: 1.3306, Accuracy: 0.4662\n",
      "Epoch [120/500], Loss: 1.3299, Accuracy: 0.4625\n",
      "Epoch [121/500], Loss: 1.3325, Accuracy: 0.4636\n",
      "Epoch [122/500], Loss: 1.3310, Accuracy: 0.4655\n",
      "Epoch [123/500], Loss: 1.3343, Accuracy: 0.4641\n",
      "Epoch [124/500], Loss: 1.3341, Accuracy: 0.4640\n",
      "Epoch [125/500], Loss: 1.3238, Accuracy: 0.4608\n",
      "Epoch [126/500], Loss: 1.3210, Accuracy: 0.4698\n",
      "Epoch [127/500], Loss: 1.3213, Accuracy: 0.4662\n",
      "Epoch [128/500], Loss: 1.3182, Accuracy: 0.4680\n",
      "Epoch [129/500], Loss: 1.3183, Accuracy: 0.4714\n",
      "Epoch [130/500], Loss: 1.3261, Accuracy: 0.4685\n",
      "Epoch [131/500], Loss: 1.3207, Accuracy: 0.4702\n",
      "Epoch [132/500], Loss: 1.3163, Accuracy: 0.4672\n",
      "Epoch [133/500], Loss: 1.3183, Accuracy: 0.4692\n",
      "Epoch [134/500], Loss: 1.3183, Accuracy: 0.4767\n",
      "Epoch [135/500], Loss: 1.3210, Accuracy: 0.4698\n",
      "Epoch [136/500], Loss: 1.3107, Accuracy: 0.4700\n",
      "Epoch [137/500], Loss: 1.3135, Accuracy: 0.4766\n",
      "Epoch [138/500], Loss: 1.3131, Accuracy: 0.4729\n",
      "Epoch [139/500], Loss: 1.3075, Accuracy: 0.4730\n",
      "Epoch [140/500], Loss: 1.3049, Accuracy: 0.4786\n",
      "Epoch [141/500], Loss: 1.3037, Accuracy: 0.4752\n",
      "Epoch [142/500], Loss: 1.3017, Accuracy: 0.4759\n",
      "Epoch [143/500], Loss: 1.3077, Accuracy: 0.4764\n",
      "Epoch [144/500], Loss: 1.3262, Accuracy: 0.4781\n",
      "Epoch [145/500], Loss: 1.3055, Accuracy: 0.4744\n",
      "Epoch [146/500], Loss: 1.3048, Accuracy: 0.4786\n",
      "Epoch [147/500], Loss: 1.3006, Accuracy: 0.4751\n",
      "Epoch [148/500], Loss: 1.3016, Accuracy: 0.4777\n",
      "Epoch [149/500], Loss: 1.3070, Accuracy: 0.4836\n",
      "Epoch [150/500], Loss: 1.2986, Accuracy: 0.4814\n",
      "Epoch [151/500], Loss: 1.2967, Accuracy: 0.4794\n",
      "Epoch [152/500], Loss: 1.2948, Accuracy: 0.4818\n",
      "Epoch [153/500], Loss: 1.2985, Accuracy: 0.4808\n",
      "Epoch [154/500], Loss: 1.3052, Accuracy: 0.4814\n",
      "Epoch [155/500], Loss: 1.2918, Accuracy: 0.4816\n",
      "Epoch [156/500], Loss: 1.2915, Accuracy: 0.4814\n",
      "Epoch [157/500], Loss: 1.3052, Accuracy: 0.4828\n",
      "Epoch [158/500], Loss: 1.3078, Accuracy: 0.4767\n",
      "Epoch [159/500], Loss: 1.2931, Accuracy: 0.4796\n",
      "Epoch [160/500], Loss: 1.2946, Accuracy: 0.4813\n",
      "Epoch [161/500], Loss: 1.2884, Accuracy: 0.4793\n",
      "Epoch [162/500], Loss: 1.2916, Accuracy: 0.4846\n",
      "Epoch [163/500], Loss: 1.2841, Accuracy: 0.4829\n",
      "Epoch [164/500], Loss: 1.2862, Accuracy: 0.4813\n",
      "Epoch [165/500], Loss: 1.2969, Accuracy: 0.4828\n",
      "Epoch [166/500], Loss: 1.2940, Accuracy: 0.4831\n",
      "Epoch [167/500], Loss: 1.2871, Accuracy: 0.4813\n",
      "Epoch [168/500], Loss: 1.2828, Accuracy: 0.4866\n",
      "Epoch [169/500], Loss: 1.2826, Accuracy: 0.4840\n",
      "Epoch [170/500], Loss: 1.2813, Accuracy: 0.4793\n",
      "Epoch [171/500], Loss: 1.2876, Accuracy: 0.4855\n",
      "Epoch [172/500], Loss: 1.2834, Accuracy: 0.4828\n",
      "Epoch [173/500], Loss: 1.2753, Accuracy: 0.4885\n",
      "Epoch [174/500], Loss: 1.2789, Accuracy: 0.4882\n",
      "Epoch [175/500], Loss: 1.2749, Accuracy: 0.4873\n",
      "Epoch [176/500], Loss: 1.2835, Accuracy: 0.4861\n",
      "Epoch [177/500], Loss: 1.2782, Accuracy: 0.4873\n",
      "Epoch [178/500], Loss: 1.2850, Accuracy: 0.4920\n",
      "Epoch [179/500], Loss: 1.2759, Accuracy: 0.4878\n",
      "Epoch [180/500], Loss: 1.2760, Accuracy: 0.4875\n",
      "Epoch [181/500], Loss: 1.2741, Accuracy: 0.4873\n",
      "Epoch [182/500], Loss: 1.2774, Accuracy: 0.4945\n",
      "Epoch [183/500], Loss: 1.2663, Accuracy: 0.4924\n",
      "Epoch [184/500], Loss: 1.2670, Accuracy: 0.4893\n",
      "Epoch [185/500], Loss: 1.2678, Accuracy: 0.4892\n",
      "Epoch [186/500], Loss: 1.2708, Accuracy: 0.4892\n",
      "Epoch [187/500], Loss: 1.2699, Accuracy: 0.4935\n",
      "Epoch [188/500], Loss: 1.2671, Accuracy: 0.4882\n",
      "Epoch [189/500], Loss: 1.2637, Accuracy: 0.4939\n",
      "Epoch [190/500], Loss: 1.2611, Accuracy: 0.4974\n",
      "Epoch [191/500], Loss: 1.2647, Accuracy: 0.4961\n",
      "Epoch [192/500], Loss: 1.2600, Accuracy: 0.4924\n",
      "Epoch [193/500], Loss: 1.2606, Accuracy: 0.4917\n",
      "Epoch [194/500], Loss: 1.2571, Accuracy: 0.4959\n",
      "Epoch [195/500], Loss: 1.2559, Accuracy: 0.4924\n",
      "Epoch [196/500], Loss: 1.2640, Accuracy: 0.4937\n",
      "Epoch [197/500], Loss: 1.2667, Accuracy: 0.4927\n",
      "Epoch [198/500], Loss: 1.2638, Accuracy: 0.4982\n",
      "Epoch [199/500], Loss: 1.2587, Accuracy: 0.4944\n",
      "Epoch [200/500], Loss: 1.2649, Accuracy: 0.4903\n",
      "Epoch [201/500], Loss: 1.2537, Accuracy: 0.4925\n",
      "Epoch [202/500], Loss: 1.2563, Accuracy: 0.4984\n",
      "Epoch [203/500], Loss: 1.2567, Accuracy: 0.4950\n",
      "Epoch [204/500], Loss: 1.2595, Accuracy: 0.5018\n",
      "Epoch [205/500], Loss: 1.2614, Accuracy: 0.4883\n",
      "Epoch [206/500], Loss: 1.2560, Accuracy: 0.4967\n",
      "Epoch [207/500], Loss: 1.2537, Accuracy: 0.4947\n",
      "Epoch [208/500], Loss: 1.2562, Accuracy: 0.4971\n",
      "Epoch [209/500], Loss: 1.2581, Accuracy: 0.4987\n",
      "Epoch [210/500], Loss: 1.2523, Accuracy: 0.4967\n",
      "Epoch [211/500], Loss: 1.2582, Accuracy: 0.4984\n",
      "Epoch [212/500], Loss: 1.2644, Accuracy: 0.4920\n",
      "Epoch [213/500], Loss: 1.2567, Accuracy: 0.5011\n",
      "Epoch [214/500], Loss: 1.2510, Accuracy: 0.5038\n",
      "Epoch [215/500], Loss: 1.2566, Accuracy: 0.4966\n",
      "Epoch [216/500], Loss: 1.2498, Accuracy: 0.4974\n",
      "Epoch [217/500], Loss: 1.2547, Accuracy: 0.5009\n",
      "Epoch [218/500], Loss: 1.2466, Accuracy: 0.4957\n",
      "Epoch [219/500], Loss: 1.2502, Accuracy: 0.5039\n",
      "Epoch [220/500], Loss: 1.2479, Accuracy: 0.5004\n",
      "Epoch [221/500], Loss: 1.2444, Accuracy: 0.5014\n",
      "Epoch [222/500], Loss: 1.2490, Accuracy: 0.5038\n",
      "Epoch [223/500], Loss: 1.2434, Accuracy: 0.5034\n",
      "Epoch [224/500], Loss: 1.2414, Accuracy: 0.5073\n",
      "Epoch [225/500], Loss: 1.2432, Accuracy: 0.5045\n",
      "Epoch [226/500], Loss: 1.2415, Accuracy: 0.5029\n",
      "Epoch [227/500], Loss: 1.2533, Accuracy: 0.5056\n",
      "Epoch [228/500], Loss: 1.2380, Accuracy: 0.5048\n",
      "Epoch [229/500], Loss: 1.2442, Accuracy: 0.5041\n",
      "Epoch [230/500], Loss: 1.2372, Accuracy: 0.5034\n",
      "Epoch [231/500], Loss: 1.2402, Accuracy: 0.5038\n",
      "Epoch [232/500], Loss: 1.2390, Accuracy: 0.5024\n",
      "Epoch [233/500], Loss: 1.2395, Accuracy: 0.5034\n",
      "Epoch [234/500], Loss: 1.2375, Accuracy: 0.5028\n",
      "Epoch [235/500], Loss: 1.2371, Accuracy: 0.5043\n",
      "Epoch [236/500], Loss: 1.2406, Accuracy: 0.5065\n",
      "Epoch [237/500], Loss: 1.2431, Accuracy: 0.5050\n",
      "Epoch [238/500], Loss: 1.2375, Accuracy: 0.5065\n",
      "Epoch [239/500], Loss: 1.2321, Accuracy: 0.5078\n",
      "Epoch [240/500], Loss: 1.2321, Accuracy: 0.5065\n",
      "Epoch [241/500], Loss: 1.2447, Accuracy: 0.5113\n",
      "Epoch [242/500], Loss: 1.2427, Accuracy: 0.5073\n",
      "Epoch [243/500], Loss: 1.2363, Accuracy: 0.5046\n",
      "Epoch [244/500], Loss: 1.2351, Accuracy: 0.5076\n",
      "Epoch [245/500], Loss: 1.2304, Accuracy: 0.5083\n",
      "Epoch [246/500], Loss: 1.2402, Accuracy: 0.5125\n",
      "Epoch [247/500], Loss: 1.2374, Accuracy: 0.5068\n",
      "Epoch [248/500], Loss: 1.2302, Accuracy: 0.5105\n",
      "Epoch [249/500], Loss: 1.2287, Accuracy: 0.5090\n",
      "Epoch [250/500], Loss: 1.2239, Accuracy: 0.5085\n",
      "Epoch [251/500], Loss: 1.2311, Accuracy: 0.5135\n",
      "Epoch [252/500], Loss: 1.2285, Accuracy: 0.5055\n",
      "Epoch [253/500], Loss: 1.2329, Accuracy: 0.5080\n",
      "Epoch [254/500], Loss: 1.2287, Accuracy: 0.5105\n",
      "Epoch [255/500], Loss: 1.2247, Accuracy: 0.5087\n",
      "Epoch [256/500], Loss: 1.2225, Accuracy: 0.5088\n",
      "Epoch [257/500], Loss: 1.2268, Accuracy: 0.5140\n",
      "Epoch [258/500], Loss: 1.2294, Accuracy: 0.5113\n",
      "Epoch [259/500], Loss: 1.2293, Accuracy: 0.5115\n",
      "Epoch [260/500], Loss: 1.2255, Accuracy: 0.5087\n",
      "Epoch [261/500], Loss: 1.2212, Accuracy: 0.5080\n",
      "Epoch [262/500], Loss: 1.2185, Accuracy: 0.5112\n",
      "Epoch [263/500], Loss: 1.2254, Accuracy: 0.5123\n",
      "Epoch [264/500], Loss: 1.2190, Accuracy: 0.5130\n",
      "Epoch [265/500], Loss: 1.2226, Accuracy: 0.5112\n",
      "Epoch [266/500], Loss: 1.2204, Accuracy: 0.5147\n",
      "Epoch [267/500], Loss: 1.2295, Accuracy: 0.5112\n",
      "Epoch [268/500], Loss: 1.2188, Accuracy: 0.5105\n",
      "Epoch [269/500], Loss: 1.2131, Accuracy: 0.5076\n",
      "Epoch [270/500], Loss: 1.2196, Accuracy: 0.5127\n",
      "Epoch [271/500], Loss: 1.2243, Accuracy: 0.5066\n",
      "Epoch [272/500], Loss: 1.2117, Accuracy: 0.5144\n",
      "Epoch [273/500], Loss: 1.2174, Accuracy: 0.5172\n",
      "Epoch [274/500], Loss: 1.2192, Accuracy: 0.5149\n",
      "Epoch [275/500], Loss: 1.2185, Accuracy: 0.5130\n",
      "Epoch [276/500], Loss: 1.2166, Accuracy: 0.5134\n",
      "Epoch [277/500], Loss: 1.2148, Accuracy: 0.5172\n",
      "Epoch [278/500], Loss: 1.2159, Accuracy: 0.5152\n",
      "Epoch [279/500], Loss: 1.2281, Accuracy: 0.5165\n",
      "Epoch [280/500], Loss: 1.2209, Accuracy: 0.5172\n",
      "Epoch [281/500], Loss: 1.2084, Accuracy: 0.5199\n",
      "Epoch [282/500], Loss: 1.2076, Accuracy: 0.5165\n",
      "Epoch [283/500], Loss: 1.2390, Accuracy: 0.5127\n",
      "Epoch [284/500], Loss: 1.2214, Accuracy: 0.5149\n",
      "Epoch [285/500], Loss: 1.2123, Accuracy: 0.5159\n",
      "Epoch [286/500], Loss: 1.2055, Accuracy: 0.5174\n",
      "Epoch [287/500], Loss: 1.2087, Accuracy: 0.5169\n",
      "Epoch [288/500], Loss: 1.2178, Accuracy: 0.5139\n",
      "Epoch [289/500], Loss: 1.2198, Accuracy: 0.5162\n",
      "Epoch [290/500], Loss: 1.2118, Accuracy: 0.5140\n",
      "Epoch [291/500], Loss: 1.2159, Accuracy: 0.5224\n",
      "Epoch [292/500], Loss: 1.2143, Accuracy: 0.5224\n",
      "Epoch [293/500], Loss: 1.2199, Accuracy: 0.5165\n",
      "Epoch [294/500], Loss: 1.2091, Accuracy: 0.5164\n",
      "Epoch [295/500], Loss: 1.2100, Accuracy: 0.5159\n",
      "Epoch [296/500], Loss: 1.2056, Accuracy: 0.5181\n",
      "Epoch [297/500], Loss: 1.2020, Accuracy: 0.5176\n",
      "Epoch [298/500], Loss: 1.2078, Accuracy: 0.5243\n",
      "Epoch [299/500], Loss: 1.2048, Accuracy: 0.5162\n",
      "Epoch [300/500], Loss: 1.2040, Accuracy: 0.5207\n",
      "Epoch [301/500], Loss: 1.2079, Accuracy: 0.5162\n",
      "Epoch [302/500], Loss: 1.2069, Accuracy: 0.5212\n",
      "Epoch [303/500], Loss: 1.2002, Accuracy: 0.5159\n",
      "Epoch [304/500], Loss: 1.2023, Accuracy: 0.5223\n",
      "Epoch [305/500], Loss: 1.2103, Accuracy: 0.5192\n",
      "Epoch [306/500], Loss: 1.2039, Accuracy: 0.5194\n",
      "Epoch [307/500], Loss: 1.2031, Accuracy: 0.5191\n",
      "Epoch [308/500], Loss: 1.2111, Accuracy: 0.5199\n",
      "Epoch [309/500], Loss: 1.2008, Accuracy: 0.5199\n",
      "Epoch [310/500], Loss: 1.1948, Accuracy: 0.5256\n",
      "Epoch [311/500], Loss: 1.2036, Accuracy: 0.5187\n",
      "Epoch [312/500], Loss: 1.2051, Accuracy: 0.5244\n",
      "Epoch [313/500], Loss: 1.1961, Accuracy: 0.5191\n",
      "Epoch [314/500], Loss: 1.2053, Accuracy: 0.5228\n",
      "Epoch [315/500], Loss: 1.1961, Accuracy: 0.5209\n",
      "Epoch [316/500], Loss: 1.1982, Accuracy: 0.5218\n",
      "Epoch [317/500], Loss: 1.1983, Accuracy: 0.5223\n",
      "Epoch [318/500], Loss: 1.1938, Accuracy: 0.5181\n",
      "Epoch [319/500], Loss: 1.2031, Accuracy: 0.5212\n",
      "Epoch [320/500], Loss: 1.1972, Accuracy: 0.5214\n",
      "Epoch [321/500], Loss: 1.1992, Accuracy: 0.5206\n",
      "Epoch [322/500], Loss: 1.1980, Accuracy: 0.5226\n",
      "Epoch [323/500], Loss: 1.1981, Accuracy: 0.5201\n",
      "Epoch [324/500], Loss: 1.1968, Accuracy: 0.5248\n",
      "Epoch [325/500], Loss: 1.1939, Accuracy: 0.5206\n",
      "Epoch [326/500], Loss: 1.1889, Accuracy: 0.5199\n",
      "Epoch [327/500], Loss: 1.1923, Accuracy: 0.5253\n",
      "Epoch [328/500], Loss: 1.1934, Accuracy: 0.5251\n",
      "Epoch [329/500], Loss: 1.1908, Accuracy: 0.5202\n",
      "Epoch [330/500], Loss: 1.1943, Accuracy: 0.5249\n",
      "Epoch [331/500], Loss: 1.1909, Accuracy: 0.5244\n",
      "Epoch [332/500], Loss: 1.1860, Accuracy: 0.5221\n",
      "Epoch [333/500], Loss: 1.1952, Accuracy: 0.5260\n",
      "Epoch [334/500], Loss: 1.1963, Accuracy: 0.5249\n",
      "Epoch [335/500], Loss: 1.1958, Accuracy: 0.5186\n",
      "Epoch [336/500], Loss: 1.1878, Accuracy: 0.5228\n",
      "Epoch [337/500], Loss: 1.1817, Accuracy: 0.5238\n",
      "Epoch [338/500], Loss: 1.1908, Accuracy: 0.5256\n",
      "Epoch [339/500], Loss: 1.1919, Accuracy: 0.5270\n",
      "Epoch [340/500], Loss: 1.1940, Accuracy: 0.5295\n",
      "Epoch [341/500], Loss: 1.1873, Accuracy: 0.5234\n",
      "Epoch [342/500], Loss: 1.1848, Accuracy: 0.5251\n",
      "Epoch [343/500], Loss: 1.1825, Accuracy: 0.5251\n",
      "Epoch [344/500], Loss: 1.1867, Accuracy: 0.5253\n",
      "Epoch [345/500], Loss: 1.1866, Accuracy: 0.5280\n",
      "Epoch [346/500], Loss: 1.1834, Accuracy: 0.5276\n",
      "Epoch [347/500], Loss: 1.1835, Accuracy: 0.5278\n",
      "Epoch [348/500], Loss: 1.1807, Accuracy: 0.5310\n",
      "Epoch [349/500], Loss: 1.1864, Accuracy: 0.5288\n",
      "Epoch [350/500], Loss: 1.1798, Accuracy: 0.5340\n",
      "Epoch [351/500], Loss: 1.1797, Accuracy: 0.5238\n",
      "Epoch [352/500], Loss: 1.1837, Accuracy: 0.5293\n",
      "Epoch [353/500], Loss: 1.1835, Accuracy: 0.5261\n",
      "Epoch [354/500], Loss: 1.1868, Accuracy: 0.5275\n",
      "Epoch [355/500], Loss: 1.1782, Accuracy: 0.5290\n",
      "Epoch [356/500], Loss: 1.1792, Accuracy: 0.5275\n",
      "Epoch [357/500], Loss: 1.1801, Accuracy: 0.5315\n",
      "Epoch [358/500], Loss: 1.1773, Accuracy: 0.5234\n",
      "Epoch [359/500], Loss: 1.1762, Accuracy: 0.5244\n",
      "Epoch [360/500], Loss: 1.1793, Accuracy: 0.5310\n",
      "Epoch [361/500], Loss: 1.1757, Accuracy: 0.5315\n",
      "Epoch [362/500], Loss: 1.1737, Accuracy: 0.5313\n",
      "Epoch [363/500], Loss: 1.1783, Accuracy: 0.5302\n",
      "Epoch [364/500], Loss: 1.1745, Accuracy: 0.5295\n",
      "Epoch [365/500], Loss: 1.1846, Accuracy: 0.5320\n",
      "Epoch [366/500], Loss: 1.1888, Accuracy: 0.5278\n",
      "Epoch [367/500], Loss: 1.1760, Accuracy: 0.5318\n",
      "Epoch [368/500], Loss: 1.1733, Accuracy: 0.5310\n",
      "Epoch [369/500], Loss: 1.1788, Accuracy: 0.5271\n",
      "Epoch [370/500], Loss: 1.1823, Accuracy: 0.5350\n",
      "Epoch [371/500], Loss: 1.1775, Accuracy: 0.5310\n",
      "Epoch [372/500], Loss: 1.1730, Accuracy: 0.5344\n",
      "Epoch [373/500], Loss: 1.1822, Accuracy: 0.5268\n",
      "Epoch [374/500], Loss: 1.1738, Accuracy: 0.5286\n",
      "Epoch [375/500], Loss: 1.1779, Accuracy: 0.5333\n",
      "Epoch [376/500], Loss: 1.1706, Accuracy: 0.5317\n",
      "Epoch [377/500], Loss: 1.1695, Accuracy: 0.5350\n",
      "Epoch [378/500], Loss: 1.1721, Accuracy: 0.5354\n",
      "Epoch [379/500], Loss: 1.1707, Accuracy: 0.5350\n",
      "Epoch [380/500], Loss: 1.1697, Accuracy: 0.5317\n",
      "Epoch [381/500], Loss: 1.1751, Accuracy: 0.5389\n",
      "Epoch [382/500], Loss: 1.1723, Accuracy: 0.5375\n",
      "Epoch [383/500], Loss: 1.1732, Accuracy: 0.5402\n",
      "Epoch [384/500], Loss: 1.1722, Accuracy: 0.5342\n",
      "Epoch [385/500], Loss: 1.1698, Accuracy: 0.5325\n",
      "Epoch [386/500], Loss: 1.1726, Accuracy: 0.5338\n",
      "Epoch [387/500], Loss: 1.1737, Accuracy: 0.5357\n",
      "Epoch [388/500], Loss: 1.1698, Accuracy: 0.5367\n",
      "Epoch [389/500], Loss: 1.1672, Accuracy: 0.5342\n",
      "Epoch [390/500], Loss: 1.1757, Accuracy: 0.5338\n",
      "Epoch [391/500], Loss: 1.1722, Accuracy: 0.5384\n",
      "Epoch [392/500], Loss: 1.1666, Accuracy: 0.5364\n",
      "Epoch [393/500], Loss: 1.1771, Accuracy: 0.5344\n",
      "Epoch [394/500], Loss: 1.1699, Accuracy: 0.5369\n",
      "Epoch [395/500], Loss: 1.1704, Accuracy: 0.5342\n",
      "Epoch [396/500], Loss: 1.1737, Accuracy: 0.5350\n",
      "Epoch [397/500], Loss: 1.1612, Accuracy: 0.5382\n",
      "Epoch [398/500], Loss: 1.1630, Accuracy: 0.5328\n",
      "Epoch [399/500], Loss: 1.1610, Accuracy: 0.5354\n",
      "Epoch [400/500], Loss: 1.1645, Accuracy: 0.5355\n",
      "Epoch [401/500], Loss: 1.1636, Accuracy: 0.5325\n",
      "Epoch [402/500], Loss: 1.1621, Accuracy: 0.5389\n",
      "Epoch [403/500], Loss: 1.1633, Accuracy: 0.5399\n",
      "Epoch [404/500], Loss: 1.1594, Accuracy: 0.5404\n",
      "Epoch [405/500], Loss: 1.1763, Accuracy: 0.5370\n",
      "Epoch [406/500], Loss: 1.1649, Accuracy: 0.5357\n",
      "Epoch [407/500], Loss: 1.1606, Accuracy: 0.5352\n",
      "Epoch [408/500], Loss: 1.1623, Accuracy: 0.5384\n",
      "Epoch [409/500], Loss: 1.1600, Accuracy: 0.5392\n",
      "Epoch [410/500], Loss: 1.1593, Accuracy: 0.5404\n",
      "Epoch [411/500], Loss: 1.1616, Accuracy: 0.5399\n",
      "Epoch [412/500], Loss: 1.1655, Accuracy: 0.5382\n",
      "Epoch [413/500], Loss: 1.1620, Accuracy: 0.5372\n",
      "Epoch [414/500], Loss: 1.1586, Accuracy: 0.5374\n",
      "Epoch [415/500], Loss: 1.1582, Accuracy: 0.5406\n",
      "Epoch [416/500], Loss: 1.1536, Accuracy: 0.5417\n",
      "Epoch [417/500], Loss: 1.1657, Accuracy: 0.5379\n",
      "Epoch [418/500], Loss: 1.1599, Accuracy: 0.5396\n",
      "Epoch [419/500], Loss: 1.1586, Accuracy: 0.5411\n",
      "Epoch [420/500], Loss: 1.1616, Accuracy: 0.5374\n",
      "Epoch [421/500], Loss: 1.1632, Accuracy: 0.5409\n",
      "Epoch [422/500], Loss: 1.1630, Accuracy: 0.5367\n",
      "Epoch [423/500], Loss: 1.1594, Accuracy: 0.5407\n",
      "Epoch [424/500], Loss: 1.1641, Accuracy: 0.5360\n",
      "Epoch [425/500], Loss: 1.1592, Accuracy: 0.5401\n",
      "Epoch [426/500], Loss: 1.1562, Accuracy: 0.5429\n",
      "Epoch [427/500], Loss: 1.1541, Accuracy: 0.5441\n",
      "Epoch [428/500], Loss: 1.1560, Accuracy: 0.5429\n",
      "Epoch [429/500], Loss: 1.1550, Accuracy: 0.5377\n",
      "Epoch [430/500], Loss: 1.1553, Accuracy: 0.5451\n",
      "Epoch [431/500], Loss: 1.1494, Accuracy: 0.5402\n",
      "Epoch [432/500], Loss: 1.1510, Accuracy: 0.5439\n",
      "Epoch [433/500], Loss: 1.1607, Accuracy: 0.5386\n",
      "Epoch [434/500], Loss: 1.1517, Accuracy: 0.5399\n",
      "Epoch [435/500], Loss: 1.1594, Accuracy: 0.5424\n",
      "Epoch [436/500], Loss: 1.1630, Accuracy: 0.5365\n",
      "Epoch [437/500], Loss: 1.1566, Accuracy: 0.5399\n",
      "Epoch [438/500], Loss: 1.1576, Accuracy: 0.5406\n",
      "Epoch [439/500], Loss: 1.1495, Accuracy: 0.5386\n",
      "Epoch [440/500], Loss: 1.1529, Accuracy: 0.5372\n",
      "Epoch [441/500], Loss: 1.1511, Accuracy: 0.5438\n",
      "Epoch [442/500], Loss: 1.1454, Accuracy: 0.5397\n",
      "Epoch [443/500], Loss: 1.1472, Accuracy: 0.5441\n",
      "Epoch [444/500], Loss: 1.1502, Accuracy: 0.5365\n",
      "Epoch [445/500], Loss: 1.1520, Accuracy: 0.5392\n",
      "Epoch [446/500], Loss: 1.1539, Accuracy: 0.5488\n",
      "Epoch [447/500], Loss: 1.1519, Accuracy: 0.5416\n",
      "Epoch [448/500], Loss: 1.1516, Accuracy: 0.5475\n",
      "Epoch [449/500], Loss: 1.1545, Accuracy: 0.5449\n",
      "Epoch [450/500], Loss: 1.1444, Accuracy: 0.5377\n",
      "Epoch [451/500], Loss: 1.1509, Accuracy: 0.5463\n",
      "Epoch [452/500], Loss: 1.1478, Accuracy: 0.5466\n",
      "Epoch [453/500], Loss: 1.1509, Accuracy: 0.5429\n",
      "Epoch [454/500], Loss: 1.1438, Accuracy: 0.5443\n",
      "Epoch [455/500], Loss: 1.1474, Accuracy: 0.5464\n",
      "Epoch [456/500], Loss: 1.1477, Accuracy: 0.5421\n",
      "Epoch [457/500], Loss: 1.1446, Accuracy: 0.5433\n",
      "Epoch [458/500], Loss: 1.1529, Accuracy: 0.5523\n",
      "Epoch [459/500], Loss: 1.1544, Accuracy: 0.5436\n",
      "Epoch [460/500], Loss: 1.1458, Accuracy: 0.5444\n",
      "Epoch [461/500], Loss: 1.1566, Accuracy: 0.5406\n",
      "Epoch [462/500], Loss: 1.1471, Accuracy: 0.5451\n",
      "Epoch [463/500], Loss: 1.1438, Accuracy: 0.5481\n",
      "Epoch [464/500], Loss: 1.1406, Accuracy: 0.5444\n",
      "Epoch [465/500], Loss: 1.1409, Accuracy: 0.5411\n",
      "Epoch [466/500], Loss: 1.1437, Accuracy: 0.5459\n",
      "Epoch [467/500], Loss: 1.1503, Accuracy: 0.5473\n",
      "Epoch [468/500], Loss: 1.1427, Accuracy: 0.5486\n",
      "Epoch [469/500], Loss: 1.1387, Accuracy: 0.5446\n",
      "Epoch [470/500], Loss: 1.1434, Accuracy: 0.5501\n",
      "Epoch [471/500], Loss: 1.1537, Accuracy: 0.5429\n",
      "Epoch [472/500], Loss: 1.1552, Accuracy: 0.5446\n",
      "Epoch [473/500], Loss: 1.1382, Accuracy: 0.5475\n",
      "Epoch [474/500], Loss: 1.1428, Accuracy: 0.5458\n",
      "Epoch [475/500], Loss: 1.1526, Accuracy: 0.5431\n",
      "Epoch [476/500], Loss: 1.1422, Accuracy: 0.5459\n",
      "Epoch [477/500], Loss: 1.1448, Accuracy: 0.5515\n",
      "Epoch [478/500], Loss: 1.1408, Accuracy: 0.5414\n",
      "Epoch [479/500], Loss: 1.1445, Accuracy: 0.5446\n",
      "Epoch [480/500], Loss: 1.1381, Accuracy: 0.5458\n",
      "Epoch [481/500], Loss: 1.1375, Accuracy: 0.5480\n",
      "Epoch [482/500], Loss: 1.1447, Accuracy: 0.5471\n",
      "Epoch [483/500], Loss: 1.1439, Accuracy: 0.5481\n",
      "Epoch [484/500], Loss: 1.1350, Accuracy: 0.5476\n",
      "Epoch [485/500], Loss: 1.1388, Accuracy: 0.5501\n",
      "Epoch [486/500], Loss: 1.1338, Accuracy: 0.5503\n",
      "Epoch [487/500], Loss: 1.1474, Accuracy: 0.5417\n",
      "Epoch [488/500], Loss: 1.1349, Accuracy: 0.5488\n",
      "Epoch [489/500], Loss: 1.1348, Accuracy: 0.5483\n",
      "Epoch [490/500], Loss: 1.1397, Accuracy: 0.5485\n",
      "Epoch [491/500], Loss: 1.1425, Accuracy: 0.5456\n",
      "Epoch [492/500], Loss: 1.1483, Accuracy: 0.5481\n",
      "Epoch [493/500], Loss: 1.1443, Accuracy: 0.5470\n",
      "Epoch [494/500], Loss: 1.1361, Accuracy: 0.5453\n",
      "Epoch [495/500], Loss: 1.1562, Accuracy: 0.5488\n",
      "Epoch [496/500], Loss: 1.1363, Accuracy: 0.5449\n",
      "Epoch [497/500], Loss: 1.1292, Accuracy: 0.5517\n",
      "Epoch [498/500], Loss: 1.1384, Accuracy: 0.5515\n",
      "Epoch [499/500], Loss: 1.1366, Accuracy: 0.5451\n",
      "Epoch [500/500], Loss: 1.1340, Accuracy: 0.5512\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network with Attention\n",
    "cnn_atn_model = CNNAttention(input_size[0],num_classes).to(device)\n",
    "optimizer = optim.Adam(cnn_atn_model.parameters(), lr=0.0001)\n",
    "train(cnn_atn_model, train_loaderCNN, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para teste\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n",
    "\n",
    "    test_loss = running_loss / len(test_loader)\n",
    "    test_accuracy = correct / total\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SimpleDNN:\n",
      "Test Loss: 1.4331, Test Accuracy: 0.4486\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing SimpleDNN:\")\n",
    "test(sdnn_model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing LSTMModel:\n",
      "Test Loss: 1.7635, Test Accuracy: 0.4312\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting LSTMModel:\")\n",
    "test(lstm_model, test_loaderLSTM, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing LSTMAttention:\n",
      "Test Loss: 1.6836, Test Accuracy: 0.4439\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting LSTMAttention:\")\n",
    "test(lstm_atn_model, test_loaderLSTM, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing CNNModel:\n",
      "Test Loss: 1.4547, Test Accuracy: 0.3976\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting CNNModel:\")\n",
    "test(cnn_model, test_loaderCNN, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing CNNAttention:\n",
      "Test Loss: 1.3652, Test Accuracy: 0.4520\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting CNNAttention:\")\n",
    "test(cnn_atn_model, test_loaderCNN, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
